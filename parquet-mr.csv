commit_hash,author_name,author_email,author_date,author_date_unix_timestamp,commit_message,la,ld,fileschanged,nf,ns,nd,entrophy,ndev,lt,nuc,age,exp,rexp,sexp,classification,fix,contains_bug,fixes
e9e36cdc44a68662885e35773187cca00d20239e,nandorKollar,nandorKollar@users.noreply.github.com,Mon Jul 9 10:10:24 2018 +0200,1531123824,PARQUET - 1335 : Logical type names in parquet - mr are not consistent with parquet - format ( #503 ) Add test case for STRING annotation and revert UTF8 annotations removed in PR#496,23,5,"parquet-column/src/test/java/org/apache/parquet/parser/TestParquetParser.java,CAS_DELIMITER",1,1,1,0.0,43,351.0,5,14.073715277777778,6.0,5.628346782679405,3.0,None,FALSE,FALSE,
94ae6c84d22ed33e158b3cc822ca4a0484c829c9,nandorKollar,nandorKollar@users.noreply.github.com,Wed Jul 4 13:58:33 2018 +0200,1530705513,"PARQUET - 1344 : Type builders don't honor new logical types ( #500 ) * PARQUET - 1344 : Type builders don't honor new logical types Call propert constructor when builder is caller with new logical type , call the deprecated OriginalType version otherwise . * Use static imports in test",39,2,"parquet-column/src/main/java/org/apache/parquet/schema/Types.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuilders.java,CAS_DELIMITER",2,1,2,0.8721617883411701,43,1453.5,25,41.00858796296296,5.0,4.699347379828332,2.0,None,FALSE,FALSE,
d320a457a9de67be25a03f79e1695d549a0145f3,Ryan Blue,rdblue@users.noreply.github.com,Tue Jul 3 15:24:53 2018 -0700,1530656693,PARQUET - 1341 : Fix null count stats in unsigned - sort columns . ( #499 ) * Fix null count stats in unsigned - sort columns . * Fix test case for old min / max values and unsigned ordering .,7,7,"parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java,CAS_DELIMITER",2,1,2,0.863120568566631,43,1391.0,52,25.379432870370373,141.0,41.91223071764919,75.0,None,FALSE,FALSE,
dc61e510126aaa1a95a46fe39bf1529f394147e9,Yuming Wang,wgyumg@gmail.com,Tue Jun 26 15:38:23 2018 +0800,1529998703,PARQUET - 1336 : PrimitiveComparator should implements Serializable ( #497 ),3,1,"parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveComparator.java,CAS_DELIMITER",1,1,1,0.0,40,290.0,1,164.2976273148148,1.0,0.9439893938888242,0.0,None,FALSE,FALSE,
33ee5497490cbc97f3eabe9ef7a6391e4dbee8bc,nandorKollar,nandorKollar@users.noreply.github.com,Mon Jun 25 08:24:15 2018 +0200,1529907855,PARQUET - 1335 : Logical type names in parquet - mr are not consistent with parquet - format ( #496 ),17,17,"parquet-column/src/main/java/org/apache/parquet/schema/LogicalTypeAnnotation.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/parser/TestParquetParser.java,CAS_DELIMITER",2,1,2,0.7871265862012691,43,625.5,6,22.317569444444445,4.0,3.813878558633871,1.0,None,FALSE,FALSE,
cc8bdf1d13639d12d02170d40cc4890180bbabc5,nandorKollar,nandorKollar@users.noreply.github.com,Mon Jun 18 09:47:25 2018 +0200,1529308045,PARQUET - 952 : Avro union with single type fails with 'is not a group' ( #459 ),46,7,"parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java,CAS_DELIMITER,parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java,CAS_DELIMITER",2,1,2,0.9790981671667148,35,648.0,19,744.5396296296296,3.0,2.8843624138591917,0.0,None,FALSE,FALSE,
f2d58718a5c7759d0f46d68ac954bd1d8064d7be,nandorKollar,nandorKollar@users.noreply.github.com,Tue Jun 12 11:47:43 2018 +0200,1528796863,PARQUET - 1321 : LogicalTypeAnnotation . LogicalTypeAnnotationVisitor#visit methods should have a return value ( #493 ),179,127,"parquet-column/src/main/java/org/apache/parquet/schema/LogicalTypeAnnotation.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER",2,2,2,0.9246935609850175,43,1217.5,33,13.332216435185185,2.0,1.9300454309303716,0.5,None,FALSE,FALSE,
9181e1d536bafedcb3587ca30e5b6e2d66f06bf0,Gabor Szadovszky,gabor@apache.org,Tue Jun 5 11:16:05 2018 +0200,1528190165,PARQUET - 1309 : Parquet Java uses incorrect stats and dictionary filter properties ( #490 ),2,2,"parquet-hadoop/src/main/java/org/apache/parquet/HadoopReadOptions.java,CAS_DELIMITER",1,1,1,0.0,38,103.0,2,103.64997685185185,13.0,8.947184963741245,8.0,None,FALSE,FALSE,
a918c493296c88da94b36600213c7c188f2589b4,nandorKollar,nandorKollar@users.noreply.github.com,Mon Jun 4 18:49:17 2018 +0200,1528130957,PARQUET - 1317 : Fix ParquetMetadataConverter throw NPE ( #491 ) New test case in TestParquetMetadataConverter to reproduce NPE and ensure backward compatibility,16,0,"parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java,CAS_DELIMITER",1,1,1,0.0,43,1179.0,18,11.210486111111111,1.0,0.9702015586354491,0.0,None,FALSE,FALSE,
3fd2492fcce073f0c36e4d7e23e34881557e6e5e,Yuming Wang,wgyumg@gmail.com,Mon Jun 4 23:52:28 2018 +0800,1528127548,PARQUET - 1317 : Fix ParquetMetadataConverter throw NPE ( #489 ),2,2,"parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER",1,1,1,0.0,43,1557.0,31,11.171030092592593,0.0,0.0,0.0,None,FALSE,FALSE,
345e2d541128471641e76aaa44dd5046f199197d,Gabor Szadovszky,gabor@apache.org,Thu May 31 16:38:43 2018 +0200,1527777523,PARQUET - 1304 : Release 1 . 10 contains breaking changes for Hive ( #485 ),383,10,"parquet-column/src/main/java/org/apache/parquet/column/values/ValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/BitPackingValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/plain/BooleanPlainValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/rle/ZeroIntegerValuesReader.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForIntegerTest.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForLongTest.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/values/dictionary/TestDictionary.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/bytes/ByteBufferInputStream.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/bytes/BytesInput.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/bytes/MultiBufferInputStream.java,CAS_DELIMITER,parquet-common/src/test/java/org/apache/parquet/bytes/TestByteBufferInputStreams.java,CAS_DELIMITER,parquet-common/src/test/java/org/apache/parquet/bytes/TestDeprecatedBufferInputStream.java,CAS_DELIMITER,parquet-common/src/test/java/org/apache/parquet/bytes/TestSingleBufferInputStream.java,CAS_DELIMITER",16,2,9,2.5037479154928497,42,162.125,52,76.53859809027779,12.0,8.035923406397941,4.0,None,FALSE,FALSE,
94a8bf6d304d08e8a1fc181e7a06a545103e8ddb,nandorKollar,nandorKollar@users.noreply.github.com,Thu May 24 13:46:11 2018 +0200,1527162371,PARQUET - 1253 : Support for new logical type representation ( #463 ),1434,160,"parquet-cascading3/src/test/java/org/apache/parquet/cascading/TestParquetTBaseScheme.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/schema/GroupType.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/schema/LogicalTypeAnnotation.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/schema/MessageTypeParser.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/schema/Type.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/schema/Types.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/parser/TestParquetParser.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuilders.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ParquetMetadata.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java,CAS_DELIMITER,parquet-pig/src/main/java/org/apache/parquet/pig/PigSchemaConverter.java,CAS_DELIMITER",13,4,8,2.196624740690049,43,631.0,121,154.69363247863248,0.0,0.0,0.0,None,FALSE,TRUE,
b635beb6efc07a97c143775c78a32d42b3b73c8e,Masayuki Takahashi,masayuki038@gmail.com,Mon May 14 02:31:02 2018 +0900,1526232662,"PARQUET - 1297 : SchemaConverter should not convert from Timestamp ( TimeUnit . SECOND ) and Timestamp ( TimeUnit . NANOSECOND ) of Arrow ( #477 ) Arrow's 'Timestamp' definition is below : { ""name"" : ""timestamp"" , ""unit"" : ""SECOND | MILLISECOND | MICROSECOND | NANOSECOND"" } http : / / arrow . apache . org / docs / metadata . html But Parquet only supports 'TIMESTAMP MILLIS' and 'TIMESTAMP MICROS' . https : / / github . com / Apache / parquet - format / blob / master / LogicalTypes . md Therefore SchemaConverter should not convert from Timestamp ( TimeUnit . SECOND ) and Timestamp ( TimeUnit . NANOSECOND ) of Arrow to Parquet . Related : https : / / issues . apache . org / jira / browse / PARQUET - 1285 Author : Masayuki Takahashi < masayuki038 @ gmail . com >",74,6,"parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaConverter.java,CAS_DELIMITER,parquet-arrow/src/test/java/org/apache/parquet/arrow/schema/TestSchemaConverter.java,CAS_DELIMITER",2,1,2,0.7462343013654811,42,542.5,7,6.38824074074074,2.0,1.9255920595143008,2.0,None,FALSE,FALSE,
e021734b62ea5ac273e516b4ac83727cbb99ec08,Masayuki Takahashi,masayuki038@gmail.com,Mon May 7 17:11:58 2018 +0900,1525680718,"PARQUET - 1285 : [ Java ] SchemaConverter should not convert from TimeUnit . SECOND and TimeUnit . NANOSECOND of Arrow ( #469 ) * PARQUET - 1285 : [ Java ] SchemaConverter should not convert from TimeUnit . SECOND AND TimeUnit . NANOSECOND of Arrow Arrow's 'Time' definition is below : { ""name"" : ""time"" , ""unit"" : ""SECOND | MILLISECOND | MICROSECOND | NANOSECOND"" , ""bitWidth"" : / * integer : 32 or 64 * / } http : / / arrow . apache . org / docs / metadata . html But Parquet only supports 'TIME MILLIS' and 'TIME MICROS' . https : / / github . com / Apache / parquet - format / blob / master / LogicalTypes . md Therefore SchemaConverter should not convert from TimeUnit . SECOND AND TimeUnit . NANOSECOND of Arrow to Parquet . Author : Masayuki Takahashi < masayuki038 @ gmail . com > * PARQUET - 1285 : [ Java ] SchemaConverter should not convert from TimeUnit . SECOND AND TimeUnit . NANOSECOND of Arrow Since the import statements were collected , I restored it . Author : Masayuki Takahashi < masayuki038 @ gmail . com > * PARQUET - 1285 : [ Java ] SchemaConverter should not convert from TimeUnit . SECOND AND TimeUnit . NANOSECOND of Arrow Remove unnecessary updates . Author : Masayuki Takahashi < masayuki038 @ gmail . com > * PARQUET - 1285 : [ Java ] SchemaConverter should not convert from TimeUnit . SECOND AND TimeUnit . NANOSECOND of Arrow Remove unnecessary package name Author : Masayuki Takahashi < masayuki038 @ gmail . com > * PARQUET - 1285 : [ Java ] SchemaConverter should not convert from TimeUnit . SECOND AND TimeUnit . NANOSECOND of Arrow Add a conversion pattern from Parquet's TIME MICROS to Arrow's MICROSECOND Author : Masayuki Takahashi < masayuki038 @ gmail . com > * PARQUET - 1285 : [ Java ] SchemaConverter should not convert from TimeUnit . SECOND AND TimeUnit . NANOSECOND of Arrow Fix to specify `expected` positions in assertEquals Author : Masayuki Takahashi < masayuki038 @ gmail . com > * PARQUET - 1285 : [ Java ] SchemaConverter should not convert from TimeUnit . SECOND AND TimeUnit . NANOSECOND of Arrow Add a test to convert from Parquet's TIME MICROS to Arrow's MICROSECOND Author : Masayuki Takahashi < masayuki038 @ gmail . com >",89,14,"parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaConverter.java,CAS_DELIMITER,parquet-arrow/src/test/java/org/apache/parquet/arrow/schema/TestSchemaConverter.java,CAS_DELIMITER",2,1,2,0.7832211182191516,42,505.0,5,15.759293981481482,1.0,0.9586108750841208,1.0,None,FALSE,FALSE,
f84938441be49c665595c936ac631c3e5f171bf9,Constantin Muraru,cmuraru@adobe.com,Thu Apr 26 08:48:08 2018 -0400,1524746888,"PARQUET - 968 Add Hive / Presto support in ProtoParquet This PR adds Hive ( https : / / github . com / apache / hive ) and Presto ( https : / / github . com / prestodb / presto ) support for parquet messages written with ProtoParquetWriter . Hive and other tools , such as Presto ( used by AWS Athena ) , rely on specific LIST / MAP wrappers ( as defined in the parquet spec : https : / / github . com / apache / parquet - format / blob / master / LogicalTypes . md ) . These wrappers are currently missing from the ProtoParquet schema . AvroParquet works just fine , because it adds these wrappers when it deals with arrays and maps . This PR brings these wrappers in parquet - proto , providing the same functionality that already exists in parquet - avro . This is backward compatible . Messages written without the extra LIST / MAP wrappers are still being read successfully using the updated ProtoParquetReader . Regarding the change . Given the following protobuf schema : ``` message ListOfPrimitives { repeated int64 my repeated id = 1 ; } ``` Old parquet schema was : ``` message ListOfPrimitives { repeated int64 my repeated id = 1 ; } ``` New parquet schema is : ``` message ListOfPrimitives { required group my repeated id ( LIST ) = 1 { repeated group list { required int64 element ; } } } ``` - - - For list of messages , the changes look like this : Protobuf schema : ``` message ListOfMessages { string top field = 1 ; repeated MyInnerMessage first array = 2 ; } message MyInnerMessage { int32 inner field = 1 ; } ``` Old parquet schema was : ``` message TestProto3 . ListOfMessages { optional binary top field ( UTF8 ) = 1 ; repeated group first array = 2 { optional int32 inner field = 1 ; } } ``` The expected parquet schema , compatible with Hive ( and similar to parquet - avro ) is the following ( notice the LIST wrapper ) : ``` message TestProto3 . ListOfMessages { optional binary top field ( UTF8 ) = 1 ; required group first array ( LIST ) = 2 { repeated group list { optional group element { optional int32 inner field = 1 ; } } } } ``` - - - Similar for maps . Protobuf schema : ``` message TopMessage { map < int64 , MyInnerMessage > myMap = 1 ; } message MyInnerMessage { int32 inner field = 1 ; } ``` Old parquet schema : ``` message TestProto3 . TopMessage { repeated group myMap = 1 { optional int64 key = 1 ; optional group value = 2 { optional int32 inner field = 1 ; } } } ``` New parquet schema ( notice the `MAP` wrapper ) : ``` message TestProto3 . TopMessage { required group myMap ( MAP ) = 1 { repeated group key value { required int64 key ; optional group value { optional int32 inner field = 1 ; } } } } ``` Jira : https : / / issues . apache . org / jira / browse / PARQUET - 968 Author : Constantin Muraru < cmuraru @ adobe . com > Author : Benoît Hanotte < BenoitHanotte @ users . noreply . github . com > Closes #411 from costimuraru / PARQUET - 968 and squashes the following commits : 16eafcb6 [ Benoît Hanotte ] PARQUET - 968 add proto flag to enable writing using specs - compliant schemas ( #2 ) a8bd7041 [ Constantin Muraru ] Pick up commit from @ andredasilvapinto 5cf92487 [ Constantin Muraru ] PARQUET - 968 Add Hive support in ProtoParquet",1315,84,"parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoMessageConverter.java,CAS_DELIMITER,parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoSchemaConverter.java,CAS_DELIMITER,parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java,CAS_DELIMITER,parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoInputOutputFormatTest.java,CAS_DELIMITER,parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoSchemaConverterTest.java,CAS_DELIMITER,parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoWriteSupportTest.java,CAS_DELIMITER,parquet-protobuf/src/test/java/org/apache/parquet/proto/utils/WriteUsingMR.java,CAS_DELIMITER",7,1,3,2.374287847932407,42,230.28571428571428,30,235.06483796296297,0.0,0.0,0.0,Feature Addition,FALSE,FALSE,
af977adc43a071a09652fea4ce3deba2d5b8d171,Masayuki Takahashi,masayuki038@gmail.com,Sat Apr 21 14:58:35 2018 +0100,1524319115,"PARQUET - 1128 : [ Java ] Upgrade the Apache Arrow version to 0 . 8 . 0 for SchemaConverter When I converted parquet ( 1 . 9 . 1 - SNAPSHOT ) schema to arrow ( 0 . 4 . 0 ) with SchemaConverter , this exception raised . ``` java . lang . NoClassDefFoundError : org / apache / arrow / vector / types / pojo / ArrowType$Struct at net . wrap trap . parquet arrow . ParquetToArrowConverter . convertToArrow ( ParquetToArrowConverter . java : 67 ) at net . wrap trap . parquet arrow . ParquetToArrowConverter . convertToArrow ( ParquetToArrowConverter . java : 40 ) at net . wrap trap . parquet arrow . ParquetToArrowConverterTest . parquetToArrowConverterTest ( ParquetToArrowConverterTest . java : 27 ) ``` This reason is that SchemaConverter refer to Apache Arrow 0 . 1 . 0 . I upgrade the Apache Arrow version to 0 . 8 . 0 ( latest ) for SchemaConverter . Author : Masayuki Takahashi < masayuki038 @ gmail . com > Closes #443 from masayuki038 / PARQUET - 1128 and squashes the following commits : 8ba47813 [ Masayuki Takahashi ] PARQUET - 1128 : [ Java ] Upgrade the Apache Arrow version to 0 . 8 . 0 for SchemaConverter b80d793a [ Masayuki Takahashi ] PARQUET - 1128 : [ Java ] Upgrade the Apache Arrow version to 0 . 8 . 0 for SchemaConverter",298,273,"parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaConverter.java,CAS_DELIMITER,parquet-arrow/src/test/java/org/apache/parquet/arrow/schema/TestSchemaConverter.java,CAS_DELIMITER",2,1,2,0.969498279964315,42,492.5,3,271.81936921296295,0.0,0.0,0.0,None,FALSE,FALSE,
150c578edb161bdb2e8c039f0914984f570ef8f0,Ryan Blue,blue@apache.org,Fri Mar 30 17:53:49 2018 -0700,1522457629,PARQUET - 1264 : Fix javadoc 8 problem in VersionGenerator .,1,1,"parquet-generator/src/main/java/org/apache/parquet/version/VersionGenerator.java,CAS_DELIMITER",1,1,1,0.0,36,87.0,2,428.05649305555556,139.0,44.37069763061974,4.0,None,FALSE,FALSE,
d61d221c9e752ce2cc0da65ede8b55653b3ae21f,Ryan Blue,blue@apache.org,Fri Mar 30 17:51:23 2018 -0700,1522457483,PARQUET - 1264 : Fix javadoc warnings for Java 8 .,240,139,"parquet-column/src/main/java/org/apache/parquet/CorruptStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/page/DataPageV1.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/page/DataPageV2.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/page/PageWriter.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/statistics/BinaryStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/ValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/ValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/BitPackingValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/filter/AndRecordFilter.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/filter/ColumnRecordFilter.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/filter/NotRecordFilter.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/filter/OrRecordFilter.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/filter/PagedRecordFilter.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/filter/RecordFilter.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/filter/UnboundRecordFilter.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/io/RecordConsumerLoggingWrapper.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/io/RecordReader.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/io/api/RecordConsumer.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/schema/ConversionPatterns.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/schema/GroupType.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/schema/MessageType.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/schema/Type.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/schema/Types.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/Exceptions.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/IOExceptionUtils.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/Log.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/Preconditions.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/Strings.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/bytes/ByteBufferAllocator.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/bytes/BytesInput.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/bytes/BytesUtils.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/bytes/CapacityByteArrayOutputStream.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/bytes/LittleEndianDataInputStream.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/glob/GlobExpander.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/Canonicalizer.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/io/SeekableInputStream.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/util/DynMethods.java,CAS_DELIMITER,parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BitPacking.java,CAS_DELIMITER,parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java,CAS_DELIMITER,parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePacker.java,CAS_DELIMITER,parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/ByteBasedBitPackingGenerator.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/CodecConfig.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyDecompressor.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkMetaData.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkProperties.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ParquetMetadata.java,CAS_DELIMITER",49,5,19,4.885658026285734,41,211.73469387755102,160,612.9340837585036,138.0,43.3707795620368,31.0,None,FALSE,FALSE,
12bbaf3550d56bc945b50f538b5f18af93bd316a,Ryan Blue,rdblue@users.noreply.github.com,Fri Mar 30 15:31:01 2018 -0700,1522449061,"PARQUET - 1263 : If file has a config , use it for ParquetReadOptions . ( #464 )",12,2,"parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java,CAS_DELIMITER",1,1,1,0.0,38,306.0,6,107.12716435185185,137.0,42.375239327909064,72.0,None,FALSE,FALSE,
d54fad867da7f762ac4c0d947adffdc1f8f356f1,Ryan Blue,rdblue@users.noreply.github.com,Fri Mar 30 15:24:17 2018 -0700,1522448657,PARQUET - 1183 : Add Avro builders using InputFile and OutputFile . ( #460 ) * PARQUET - 1183 : Add Avro builders using InputFile and OutputFile . * PARQUET - 1183 : Add deprecation warnings to Avro read builder . Closes #446,23,0,"parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetReader.java,CAS_DELIMITER,parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetWriter.java,CAS_DELIMITER",2,1,1,0.9656361333706098,27,145.5,9,930.0769444444445,136.0,41.37544048064997,32.0,None,FALSE,FALSE,
0a86429939075984edce5e3b8195dfb7f9e3ab6b,Gabor Szadovszky,gabor.szadovszky@cloudera.com,Mon Mar 19 14:43:12 2018 +0100,1521466992,PARQUET - 1246 : Ignore float / double statistics in case of NaN Because of the ambigous sorting order of float / double the following changes made at the reading path of the related statistics : - Ignoring statistics in case of it contains a NaN value . - Using - 0 . 0 as min value and + 0 . 0 as max value independently from which 0 . 0 value was saved in the statistics . Author : Gabor Szadovszky < gabor . szadovszky @ cloudera . com > Closes #461 from gszadovszky / PARQUET - 1246 and squashes the following commits : 20e9332 [ Gabor Szadovszky ] PARQUET - 1246 : Changes according to zi's comments 3447938 [ Gabor Szadovszky ] PARQUET - 1246 : Ignore float / double statistics in case of NaN,232,10,"parquet-column/src/main/java/org/apache/parquet/column/statistics/Statistics.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/statistics/TestStatistics.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/filter2/statisticslevel/TestStatisticsFilter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnChunkPageWriteStore.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java,CAS_DELIMITER",6,2,5,1.222470816316985,40,664.8333333333334,64,20.016643518518517,8.0,5.255837780157667,4.5,None,FALSE,FALSE,
3d2d4fd1588c8eb3f67f34d75b66967d0c7b06b6,Julien Le Dem,julien.ledem@wework.com,Fri Mar 9 16:14:11 2018 -0800,1520640851,PARQUET - 1135 : upgrade thrift and protobuf dependencies Author : Julien Le Dem < julien . ledem @ wework . com > Author : Julien Le Dem < julien @ ledem . net > Closes #427 from julienledem / PARQUET 1135 thrift PB and squashes the following commits : f23b32d9 [ Julien Le Dem ] remove double install 78cbf734 [ Julien Le Dem ] remove running check on protobuf build 4bc2b8f7 [ Julien Le Dem ] add timing ; upgrade proto version e17ca956 [ Julien Le Dem ] without - nodejs d15e523d [ Julien Le Dem ] PARQUET - 1135 : upgrade thrift and protobuf dependencies,30,2,"parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftBytesWriteSupport.java,CAS_DELIMITER",1,1,1,0.0,35,151.0,5,120.58196759259259,2.0,1.0012579993718904,0.0,None,FALSE,FALSE,
b82d96218bfd37f6df95a2e8d7675d091ab61970,Gabor Szadovszky,gabor.szadovszky@cloudera.com,Tue Feb 27 14:19:14 2018 +0100,1519737554,PARQUET - 1217 : Incorrect handling of missing values in Statistics In parquet - format every value in Statistics is optional while parquet - mr does not properly handle these scenarios : - null count is set but min / max or min value / max value are not : filtering may fail with NPE or incorrect filtering occurs fix : check if min / max is set before comparing to the related values - null count is not set : filtering handles null count as if it would be 0 - > incorrect filtering may occur fix : introduce new method in Statistics object to check if num nulls is set ; check if num nulls is set by the new method before using its value for filtering Author : Gabor Szadovszky < gabor . szadovszky @ cloudera . com > Closes #458 from gszadovszky / PARQUET - 1217 and squashes the following commits : 9d14090 [ Gabor Szadovszky ] Updates according to rdblue's comments 116d1d3 [ Gabor Szadovszky ] PARQUET - 1217 : Updates according to zi's comments c264b50 [ Gabor Szadovszky ] PARQUET - 1217 : fix handling of unset nullCount 2ec2fb1 [ Gabor Szadovszky ] PARQUET - 1217 : Incorrect handling of missing values in Statistics,249,46,"parquet-cli/src/main/java/org/apache/parquet/cli/commands/ParquetMetadataCommand.java,CAS_DELIMITER,parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowPagesCommand.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/statistics/Statistics.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/statistics/TestStatistics.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/filter2/statisticslevel/StatisticsFilter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/filter2/statisticslevel/TestStatisticsFilter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnChunkPageWriteStore.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java,CAS_DELIMITER",10,3,8,2.6656134033785737,40,581.1,81,188.81634722222222,7.0,4.47654119377023,3.0,None,FALSE,TRUE,
8bbc6cb95fd9b4b9e86c924ca1e40fd555ecac1d,Ryan Blue,blue@apache.org,Wed Feb 21 09:40:07 2018 -0800,1519234807,"PARQUET - 787 : Limit read allocation size WIP : This update the `ParquetFileReader` to use multiple buffers when reading a row group , instead of a single humongous allocation . As a consequence , many classes needed to be updated to accept a stream backed by multiple buffers , instead of using a single buffer directly . Assuming a single contiguous buffer would require too many copies . Author : Ryan Blue < blue @ apache . org > Closes #390 from rdblue / PARQUET - 787 - limit - read - allocation - size and squashes the following commits : 4abba3e7a [ Ryan Blue ] PARQUET - 787 : Update byte buffer input streams for review comments . e7c6c5dd2 [ Ryan Blue ] PARQUET - 787 : Fix problems from Zoltan's review . be52b59fa [ Ryan Blue ] PARQUET - 787 : Update tests for both ByteBufferInputStreams . b0b614748 [ Ryan Blue ] PARQUET - 787 : Update encodings to use ByteBufferInputStream . a4fa05ac5 [ Ryan Blue ] Refactor ByteBufferInputStream implementations . 56b22a6a1 [ Ryan Blue ] Make allocation size configurable . 103ed3d86 [ Ryan Blue ] Add tests for ByteBufferInputStream and fix bugs . 614a2bbc8 [ Ryan Blue ] Limit allocation size to 8MB chunks for better garbage collection .",1852,441,"parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderImpl.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/ValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/BitPackingValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayReader.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/PlainValuesDictionary.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/plain/BinaryPlainValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/plain/BooleanPlainValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/plain/PlainValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/rle/ZeroIntegerValuesReader.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/impl/TestCorruptDeltaByteArrays.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/values/Utils.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/values/bitpacking/BitPackingPerfTest.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/values/bitpacking/TestBitPackingColumn.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForIntegerTest.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForLongTest.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/TestDeltaByteArray.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/values/dictionary/TestDictionary.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/bytes/ByteBufferInputStream.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/bytes/BytesInput.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/bytes/MultiBufferInputStream.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/bytes/SingleBufferInputStream.java,CAS_DELIMITER,parquet-common/src/test/java/org/apache/parquet/bytes/TestByteBufferInputStreams.java,CAS_DELIMITER,parquet-common/src/test/java/org/apache/parquet/bytes/TestMultiBufferInputStream.java,CAS_DELIMITER,parquet-common/src/test/java/org/apache/parquet/bytes/TestSingleBufferInputStream.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/HadoopReadOptions.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/ParquetReadOptions.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/CodecFactory.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DirectCodecFactory.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestDirectCodecFactory.java,CAS_DELIMITER",43,3,25,3.972663371926549,38,176.2325581395349,143,507.60671861541795,135.0,41.94536184422358,48.333333333333336,None,FALSE,FALSE,
ad80bfe559e7380fedd7998daea5f27393ab643b,Zoltan Ivanfi,zi@cloudera.com,Mon Feb 19 18:37:54 2018 +0100,1519061874,PARQUET - 1208 : Occasional endless loop in unit test Author : Zoltan Ivanfi < zi @ cloudera . com > Closes #455 from zivanfi / PARQUET - 1208 and squashes the following commits : 665ba37 [ Zoltan Ivanfi ] PARQUET - 1208 : Addressing Ryan's comments . 2ff96a3 [ Zoltan Ivanfi ] PARQUET - 1208 : Occasional endless loop in unit test,2,2,"parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java,CAS_DELIMITER",1,1,1,0.0,40,1105.0,14,37.71395833333333,4.0,2.358168675321872,2.0,None,FALSE,FALSE,
445cb9dc2f07553f8e1e5f7c1150f00fbb05c63f,Ryan Blue,blue@apache.org,Thu Feb 15 09:07:29 2018 -0800,1518714449,"PARQUET - 1215 : Add getFooter to ParquetWriter . This adds getFooter to ParquetWriter , which will return the file footer that was written after the file is closed . Author : Ryan Blue < blue @ apache . org > Closes #457 from rdblue / PARQUET - 1215 - add - footer - accessor - to - writers and squashes the following commits : 79c5965a1 [ Ryan Blue ] PARQUET - 1215 : Add getFooter to ParquetWriter .",22,1,"parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java,CAS_DELIMITER",3,1,1,1.531000155043516,40,625.6666666666666,49,167.45841049382716,134.0,41.197238795925415,70.0,None,FALSE,FALSE,
89aeec028b6f56be96b9c56c2fdbb931f80853ad,Gabor Szadovszky,gabor.szadovszky@cloudera.com,Mon Jan 22 17:21:27 2018 +0100,1516638087,PARQUET - 1170 : Logical - type - based toString for proper representeation in tools / logs Author : Gabor Szadovszky < gabor . szadovszky @ cloudera . com > Closes #448 from gszadovszky / PARQUET - 1170 and squashes the following commits : 8f1f8cc [ Gabor Szadovszky ] PARQUET - 1170 : Make interval test more readable 90f73b5 [ Gabor Szadovszky ] PARQUET - 1170 : Fix endianess of interval 612d70b [ Gabor Szadovszky ] PARQUET - 1170 : Add unit test for different locale d8c5204 [ Gabor Szadovszky ] PARQUET - 1170 : Implement toString based on logical type so values will be represented properly in tools / logs etc .,791,98,"parquet-cli/src/main/java/org/apache/parquet/cli/Util.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/statistics/BinaryStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/statistics/BooleanStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/statistics/DoubleStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/statistics/FloatStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/statistics/IntStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/statistics/LongStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/statistics/Statistics.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/schema/OriginalType.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveStringifier.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/statistics/TestStatistics.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/schema/TestPrimitiveStringifier.java,CAS_DELIMITER,parquet-tools/src/main/java/org/apache/parquet/tools/command/DumpCommand.java,CAS_DELIMITER",14,3,6,2.3219214546430416,40,244.07142857142858,57,64.09566550925925,6.0,3.8183126079765595,1.6666666666666667,None,FALSE,FALSE,
878ebcd0bc2592fa9d5dda01117c07bc3c40bb33,Nandor Kollar,nkollar@cloudera.com,Fri Jan 19 16:53:42 2018 +0100,1516377222,PARQUET - 1191 : Type . hashCode ( ) takes originalType into account but Type . equals ( ) does not Author : Nandor Kollar < nkollar @ cloudera . com > Closes #450 from nandorKollar / PARQUET - 1191 and squashes the following commits : c7131df [ Nandor Kollar ] PARQUET - 1191 : Type . hashCode ( ) takes originalType into account but Type . equals ( ) does not,17,15,"parquet-column/src/main/java/org/apache/parquet/schema/Type.java,CAS_DELIMITER,parquet-pig/src/test/java/org/apache/parquet/pig/TestPigSchemaConverter.java,CAS_DELIMITER,parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeStructConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConverter.java,CAS_DELIMITER,parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestBinary.java,CAS_DELIMITER",5,4,5,2.0713950996790307,39,260.8,23,211.45962962962963,5.0,4.4433919028990365,0.75,None,FALSE,FALSE,
c6764c4a0848abf1d581e22df8b33e28ee9f2ced,Gabor Szadovszky,gabor.szadovszky@cloudera.com,Fri Jan 12 16:29:48 2018 -0800,1515803388,PARQUET - 1025 : Support new min - max statistics in parquet - mr Author : Gabor Szadovszky < gabor . szadovszky @ cloudera . com > Closes #435 from gszadovszky / PARQUET - 1025 and squashes the following commits : 2a63fcf13 [ Gabor Szadovszky ] PARQUET - 1025 : Use constant instead of creating new TypeDefinedOrder instances 820df6fb7 [ Gabor Szadovszky ] PARQUET - 1025 : Minor fixes at data generation for TestStatistics dc838f273 [ Gabor Szadovszky ] PARQUET - 1025 : Implement ColumnOrder ; other updates for rdblue's findings 524750be0 [ Gabor Szadovszky ] PARQUET - 1025 : Some updates for zi's findings a2ae97ce5 [ Gabor Szadovszky ] PARQUET - 1025 : Unified formatting / comments / deprecation bc86e8a63 [ Gabor Szadovszky ] PARQUET - 1025 : Updates according to rdblue's comments 70e56a759 [ Gabor Szadovszky ] PARQUET - 1025 : Add explicit list of types to not to read / write statistics 95199e5e0 [ Gabor Szadovszky ] PARQUET - 1025 : Use lexicographical comparison for Binary . compareTo Also rename SIGNED BINARY COMPARATOR to a more descriptive name Also added comments for haxa representation of values at unsigned comparison testing 2f28c2c0e [ Gabor Szadovszky ] PARQUET - 1025 : Finalize read / write stats updates c5536a0a3 [ Gabor Szadovszky ] PARQUET - 1025 : Some modifications according to zi's comments 318e585d9 [ Gabor Szadovszky ] PARQUET - 1025 : Finalize reading / writing new stats ; modify / implement unit tests accordingly 688ef2efe [ Gabor Szadovszky ] PARQUET - 1025 : Updates according to zi's and rdblue's comments 51bc1f827 [ Gabor Szadovszky ] PARQUET - 1025 : Add the proper comparators as required ; revert Binary related changes 20b937f46 [ Gabor Szadovszky ] PARQUET - 1025 : reading / writing new min - max statistics ; use the comparators as needed 52cd58f61 [ Gabor Szadovszky ] PARQUET - 1025 : Move comparators to Type 3378b6d34 [ Gabor Szadovszky ] PARQUET - 1025 : Implement comparators and use them with statistics e1719bb3b [ Gabor Szadovszky ] PARQUET - 1025 : Refactor Binary to prepare from custom comparators,2398,499,"parquet-cli/src/main/java/org/apache/parquet/cli/Util.java,CAS_DELIMITER,parquet-cli/src/main/java/org/apache/parquet/cli/commands/CheckParquet251Command.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/ColumnDescriptor.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV1.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV2.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/statistics/BinaryStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/statistics/BooleanStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/statistics/DoubleStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/statistics/FloatStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/statistics/IntStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/statistics/LongStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/statistics/Statistics.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/statistics/StatisticsClassException.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/filter2/predicate/Statistics.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/io/PrimitiveColumnIO.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/schema/ColumnOrder.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/schema/MessageType.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveComparator.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/schema/Types.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/statistics/TestStatistics.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/io/api/TestBinary.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/schema/TestMessageType.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/schema/TestPrimitiveComparator.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuilders.java,CAS_DELIMITER,parquet-generator/src/main/java/org/apache/parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/filter2/statisticslevel/StatisticsFilter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkMetaData.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkProperties.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestUtils.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/statistics/RandomValues.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/statistics/TestStatistics.java,CAS_DELIMITER,parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java,CAS_DELIMITER",42,5,23,4.556901228155383,40,403.0238095238095,225,507.9760345017635,5.0,2.893258801224838,1.0,None,FALSE,TRUE,
4d996d1bac1bb1886cd9c473ba00e53e3c19cf3e,Gabor Szadovszky,gabor.szadovszky@cloudera.com,Wed Jan 10 14:59:24 2018 +0100,1515592764,PARQUET - 386 : Printing out the statistics of metadata in parquet - tools Author : Gabor Szadovszky < gabor . szadovszky @ cloudera . com > Closes #442 from gszadovszky / PARQUET - 386 and squashes the following commits : db8c4b9 [ Gabor Szadovszky ] PARQUET - 386 : Printing out the statistics of metadata in parquet - tools,7,0,"parquet-tools/src/main/java/org/apache/parquet/tools/util/MetadataUtils.java,CAS_DELIMITER",1,1,1,0.0,38,226.0,2,64.01510416666666,4.0,1.9059721097101716,1.0,None,FALSE,FALSE,
3783ca4476fec8186c867e4e57084e649c318c6b,Nandor Kollar,nkollar@cloudera.com,Wed Jan 10 14:54:01 2018 +0100,1515592441,PARQUET - 1185 : TestBinary#testBinary unit test fails after PARQUET - 1141 Author : Nandor Kollar < nkollar @ cloudera . com > Closes #444 from nandorKollar / PARQUET - 1185 and squashes the following commits : 533aeb4 [ Nandor Kollar ] PARQUET - 1185 : TestBinary#testBinary unit test fails after PARQUET - 1141 e75adef [ Nandor Kollar ] PARQUET - 1185 : TestBinary#testBinary unit test fails after PARQUET - 1141 5e919cb [ Nandor Kollar ] PARQUET - 1185 : TestBinary#testBinary unit test fails after PARQUET - 1141,2,2,"parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestBinary.java,CAS_DELIMITER",1,1,1,0.0,28,89.0,2,5.877337962962963,4.0,3.5444439521139652,2.0,None,FALSE,FALSE,
9191fbd202cd76d03fc23057c5a16cac547d90df,Ryan Blue,blue@apache.org,Thu Jan 4 10:32:31 2018 -0800,1515090751,PARQUET - 1141 : Fix field ID handling There are two places where field IDs are dropped : * Map and list type builders were not passing IDs when building * ParquetMetadataConverter was not writing field IDs or reading the ID for root schemas Author : Ryan Blue < blue @ apache . org > Closes #428 from rdblue / PARQUET - 1141 - fix - column - ids and squashes the following commits : 475a90ed7 [ Ryan Blue ] PARQUET - 1141 : Fix tests by adding Type$ID#getId . e110c00a7 [ Ryan Blue ] PARQUET - 1141 : Fix IDs in ParquetMetadataConverter . a63066a8c [ Ryan Blue ] PARQUET - 1141 : Fix IDs for lists and maps .,37,3,"parquet-column/src/main/java/org/apache/parquet/schema/Type.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/schema/Types.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER",3,2,2,1.5394910703001345,38,996.6666666666666,36,542.9621720679012,133.0,41.9336298676219,62.0,None,FALSE,FALSE,
da3e8eb7e5a8cdc28ab0e36651bd7eceed35c2fe,Nandor Kollar,nkollar@cloudera.com,Thu Jan 4 17:50:39 2018 +0100,1515084639,PARQUET - 357 : Parquet - thrift generates wrong schema for Thrift binary fields Author : Nandor Kollar < nkollar @ cloudera . com > Closes #439 from nandorKollar / PARQUET - 357 and squashes the following commits : 90cfcfb [ Nandor Kollar ] Address code review feedback 4bf8089 [ Nandor Kollar ] PARQUET - 357 : Parquet - thrift generates wrong schema for Thrift binary fields,43,4,"parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftType.java,CAS_DELIMITER,parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestBinary.java,CAS_DELIMITER",4,1,3,1.5630730323736528,28,329.25,17,877.7333796296296,3.0,2.595965493625746,1.0,None,FALSE,FALSE,
8bfd9b4d8f4fb0a2b522c9328f67eb642066306b,Ryan Blue,blue@apache.org,Wed Dec 13 11:27:54 2017 -0800,1513193274,"PARQUET - 1142 : Add alternatives to Hadoop classes in the API This updates the read and write paths to avoid using Hadoop classes where possible . * Adds a generic compression interface , `CompressionCodecFactory` * Adds `OutputFile` and `PositionOutputStream` * Adds classes to help implementations wrap input and output streams : `DelegatingSeekableInputStream` and `DelegatingPositionOutputStream` * Adds `ParquetReadOptions` to avoid passing options with `Configuration` * Updates the read and write APIs to use new abstractions instead of Hadoop Author : Ryan Blue < blue @ apache . org > Closes #429 from rdblue / PARQUET - 1142 - add - hadoop - alternatives and squashes the following commits : 21500337b [ Ryan Blue ] PARQUET - 1142 : Fix NPE when not filtering with new read API . 35eddd735 [ Ryan Blue ] PARQUET - 1142 : Fix problems from Gabor's review . da391b0d4 [ Ryan Blue ] PARQUET - 1142 : Fix binary incompatibilities . 2e3d693ab [ Ryan Blue ] PARQUET - 1142 : Update the read and write paths to use new files and streams . 8d57e089f [ Ryan Blue ] PARQUET - 1142 : Add OutputFile and PositionOutputStream . 42908a95e [ Ryan Blue ] PARQUET - 1142 : Extract non - Hadoop API from CodecFactory .",1797,543,"parquet-common/src/main/java/org/apache/parquet/bytes/BytesInput.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/bytes/CapacityByteArrayOutputStream.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/bytes/ConcatenatingByteArrayCollector.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/bytes/LittleEndianDataInputStream.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/bytes/LittleEndianDataOutputStream.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/compression/CompressionCodecFactory.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/hadoop/codec/CompressionCodecNotSupportedException.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/CompressionCodecName.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/io/DelegatingPositionOutputStream.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/io/DelegatingSeekableInputStream.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/io/InputFile.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/io/OutputFile.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/io/PositionOutputStream.java,CAS_DELIMITER,parquet-common/src/test/java/org/apache/parquet/io/MockInputStream.java,CAS_DELIMITER,parquet-common/src/test/java/org/apache/parquet/io/TestDelegatingSeekableInputStream.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/HadoopReadOptions.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/ParquetReadOptions.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/filter2/compat/RowGroupFilter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/CodecFactory.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageReadStore.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DirectCodecFactory.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/UnmaterializableRecordCounter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/CompressionCodecNotSupportedException.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/H1SeekableInputStream.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/H2SeekableInputStream.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopCodecs.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopOutputFile.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopPositionOutputStream.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopStreams.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputOutputFormatWithPadding.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/MockHadoopInputStream.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestHadoop2ByteBufferReads.java,CAS_DELIMITER,parquet-tools/src/main/java/org/apache/parquet/tools/command/MergeCommand.java,CAS_DELIMITER",43,3,15,4.393334905598301,38,239.0,186,236.9868569659776,132.0,41.85289524122661,29.333333333333332,None,FALSE,TRUE,
132b2a8c553bdcfd445e88680beac6f225c50ac4,Ryan Blue,blue@apache.org,Tue Nov 14 16:16:28 2017 -0800,1510704988,PARQUET - 1143 : Update to Parquet format 2 . 4 . 0 . This adds new compression codecs that are required by format 2 . 4 . 0 . Author : Ryan Blue < blue @ apache . org > Closes #430 from rdblue / PARQUET - 1143 - format - 2 . 4 . 0 - updates and squashes the following commits : 0aca87812 [ Ryan Blue ] PARQUET - 1143 : Remove staging repository now that 2 . 4 . 0 is released . 89b01cb64 [ Ryan Blue ] PARQUET - 1143 : Make brotli - codec an optional dependency . a2f57ba5b [ Ryan Blue ] PARQUET - 1143 : Drop hadoop - 1 tests from Travis CI . d0f81d7cd [ Ryan Blue ] PARQUET - 1143 : Use slf4j - simple and log4j in Thrift / Pig tests . 326b8ac74 [ Ryan Blue ] PARQUET - 1143 : Update Travis to use the default ubuntu image . 4ad46f94c [ Ryan Blue ] PARQUET - 1143 : Use slf4j - log4j12 in Pig tests . 785e84dff [ Ryan Blue ] PARQUET - 1143 : Fix Travis CI . efa171fda [ Ryan Blue ] PARQUET - 1143 : Ban slf4j - log4j12 dependency . bf61e84ab [ Ryan Blue ] PARQUET - 1143 : Update to Parquet format 2 . 4 . 0 .,22,3,"parquet-cli/src/main/java/org/apache/parquet/cli/Util.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/CompressionCodecName.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestDirectCodecFactory.java,CAS_DELIMITER",3,2,3,1.4269608142719163,35,199.0,5,496.10540509259255,131.0,42.04892132168696,34.0,None,FALSE,FALSE,
170cfa758547b4d9be50058ad93cf60ce0da5564,Nandor Kollar,nkollar@cloudera.com,Thu Nov 9 11:16:09 2017 +0100,1510222569,PARQUET - 1152 : Parquet - thrift doesn't compile with Thrift 0 . 9 . 3 Author : Nandor Kollar < nkollar @ cloudera . com > Closes #432 from nandorKollar / PARQUET - 1152 and squashes the following commits : fd578ec [ Zoltan Ivanfi ] Undo unrelated whitespace changes . 8bbcfad [ Nandor Kollar ] PARQUET - 1152 : Parquet - thrift doesn't compile with Thrift 0 . 9 . 3,1,21,"parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftBytesWriteSupport.java,CAS_DELIMITER",1,1,1,0.0,35,171.0,4,701.6671180555555,1.0,0.994929757694095,0.0,None,FALSE,FALSE,
328c5deb015ee5bc0a24623bc29225f6ec1ae23d,Nandor Kollar,nkollar@cloudera.com,Tue Nov 7 14:37:39 2017 +0100,1510061859,PARQUET - 1115 : Warn users when misusing parquet - tools merge Author : Nandor Kollar < nkollar @ cloudera . com > Closes #433 from nandorKollar / PARQUET - 1115 and squashes the following commits : 5504a39 [ Nandor Kollar ] PARQUET - 1115 : Warn users when misusing parquet - tools merge f2ece26 [ Nandor Kollar ] PARQUET - 1115 : Warn users when misusing parquet - tools merge 4f3ec99 [ Nandor Kollar ] PARQUET - 1115 : Warn users when misusing parquet - tools merge f97e620 [ Nandor Kollar ] PARQUET - 1115 : Prevent users from misusing parquet - tools merge,70,24,"parquet-tools/src/main/java/org/apache/parquet/tools/Main.java,CAS_DELIMITER,parquet-tools/src/main/java/org/apache/parquet/tools/command/CatCommand.java,CAS_DELIMITER,parquet-tools/src/main/java/org/apache/parquet/tools/command/Command.java,CAS_DELIMITER,parquet-tools/src/main/java/org/apache/parquet/tools/command/DumpCommand.java,CAS_DELIMITER,parquet-tools/src/main/java/org/apache/parquet/tools/command/HeadCommand.java,CAS_DELIMITER,parquet-tools/src/main/java/org/apache/parquet/tools/command/MergeCommand.java,CAS_DELIMITER,parquet-tools/src/main/java/org/apache/parquet/tools/command/RowCountCommand.java,CAS_DELIMITER,parquet-tools/src/main/java/org/apache/parquet/tools/command/ShowMetaCommand.java,CAS_DELIMITER,parquet-tools/src/main/java/org/apache/parquet/tools/command/ShowSchemaCommand.java,CAS_DELIMITER,parquet-tools/src/main/java/org/apache/parquet/tools/command/SizeCommand.java,CAS_DELIMITER,parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleRecord.java,CAS_DELIMITER,parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleRecordConverter.java,CAS_DELIMITER,parquet-tools/src/main/java/org/apache/parquet/tools/util/MetadataUtils.java,CAS_DELIMITER",13,1,4,3.31912318204353,38,150.15384615384616,30,511.7854273504272,0.0,0.0,0.0,None,FALSE,FALSE,
d55a572e5867832f6d5755fcd46101da51a38aa4,Addisu Feyissa,addisu.feyissa@C1159.local,Tue Oct 10 16:20:55 2017 -0700,1507677655,"PARQUET - 1133 Add int96 support by returning bytearray , Skip originalType comparison for map types when originalType is null - PigSchemaConverter : Added a null check before comparing a mapKeyValueType's original type with the static constant - PigSchemaConverter : Changed the handling of int96 types - return bytearray instead of rejecting input - PigSchemaConverterTest : Added unit tests for int96 conversion and handling map entries without original type specified Author : Addisu Feyissa < addisu . feyissa @ C1159 . local > Closes #422 from adisu - feyissa / hotfix / remove originalType check for maps and add int96 support and squashes the following commits : e6fa3444 [ Addisu Feyissa ] - PigSchemaConverter : Added a null check before comparing a mapKeyValueType's original type with the static constant - PigSchemaConverter : Changed the handling of int96 types - return bytearray instead of rejecting input - PigSchemaConverTest : Added unit tests for int96 conversion and handling map entries without original type specified",31,2,"parquet-pig/src/main/java/org/apache/parquet/pig/PigSchemaConverter.java,CAS_DELIMITER,parquet-pig/src/test/java/org/apache/parquet/pig/TestPigSchemaConverter.java,CAS_DELIMITER",2,1,2,0.6136190195993708,37,394.5,10,237.15681712962962,0.0,0.0,0.0,Feature Addition,FALSE,FALSE,
ddbeb4dd17d9c219b99b1e66d8be28efe37e3aa6,Ryan Blue,blue@apache.org,Fri Jul 28 16:25:21 2017 -0700,1501284321,"PARQUET - 777 : Add Parquet CLI . This adds a new parquet - cli module with an improved command - line tool . The parquet - cli / README . md file has instructions for building and testing locally . Author : Ryan Blue < blue @ apache . org > Author : Tom White < tom @ cloudera . com > Closes #384 from rdblue / PARQUET - 777 - add - parquet - cli and squashes the following commits : de49eff [ Ryan Blue ] PARQUET - 777 : Move dynamic support classes , add tests . affdfb9 [ Ryan Blue ] PARQUET - 777 : Update for review feedback . f953fd4 [ Ryan Blue ] PARQUET - 777 : Update README . md with better instructions . aed223d [ Tom White ] Replace source file headers with Apache header . d718363 [ Ryan Blue ] PARQUET - 777 : Add Parquet CLI .",7160,0,"parquet-cli/src/main/java/org/apache/parquet/cli/BaseCommand.java,CAS_DELIMITER,parquet-cli/src/main/java/org/apache/parquet/cli/Command.java,CAS_DELIMITER,parquet-cli/src/main/java/org/apache/parquet/cli/HadoopFileSystemURLStreamHandler.java,CAS_DELIMITER,parquet-cli/src/main/java/org/apache/parquet/cli/Help.java,CAS_DELIMITER,parquet-cli/src/main/java/org/apache/parquet/cli/Main.java,CAS_DELIMITER,parquet-cli/src/main/java/org/apache/parquet/cli/Util.java,CAS_DELIMITER,parquet-cli/src/main/java/org/apache/parquet/cli/commands/CSVSchemaCommand.java,CAS_DELIMITER,parquet-cli/src/main/java/org/apache/parquet/cli/commands/CatCommand.java,CAS_DELIMITER,parquet-cli/src/main/java/org/apache/parquet/cli/commands/CheckParquet251Command.java,CAS_DELIMITER,parquet-cli/src/main/java/org/apache/parquet/cli/commands/ConvertCSVCommand.java,CAS_DELIMITER,parquet-cli/src/main/java/org/apache/parquet/cli/commands/ConvertCommand.java,CAS_DELIMITER,parquet-cli/src/main/java/org/apache/parquet/cli/commands/ParquetMetadataCommand.java,CAS_DELIMITER,parquet-cli/src/main/java/org/apache/parquet/cli/commands/SchemaCommand.java,CAS_DELIMITER,parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowDictionaryCommand.java,CAS_DELIMITER,parquet-cli/src/main/java/org/apache/parquet/cli/commands/ShowPagesCommand.java,CAS_DELIMITER,parquet-cli/src/main/java/org/apache/parquet/cli/commands/ToAvroCommand.java,CAS_DELIMITER,parquet-cli/src/main/java/org/apache/parquet/cli/csv/AvroCSV.java,CAS_DELIMITER,parquet-cli/src/main/java/org/apache/parquet/cli/csv/AvroCSVReader.java,CAS_DELIMITER,parquet-cli/src/main/java/org/apache/parquet/cli/csv/CSVProperties.java,CAS_DELIMITER,parquet-cli/src/main/java/org/apache/parquet/cli/csv/RecordBuilder.java,CAS_DELIMITER,parquet-cli/src/main/java/org/apache/parquet/cli/json/AvroJson.java,CAS_DELIMITER,parquet-cli/src/main/java/org/apache/parquet/cli/json/AvroJsonReader.java,CAS_DELIMITER,parquet-cli/src/main/java/org/apache/parquet/cli/util/Codecs.java,CAS_DELIMITER,parquet-cli/src/main/java/org/apache/parquet/cli/util/Expressions.java,CAS_DELIMITER,parquet-cli/src/main/java/org/apache/parquet/cli/util/Formats.java,CAS_DELIMITER,parquet-cli/src/main/java/org/apache/parquet/cli/util/GetClassLoader.java,CAS_DELIMITER,parquet-cli/src/main/java/org/apache/parquet/cli/util/RecordException.java,CAS_DELIMITER,parquet-cli/src/main/java/org/apache/parquet/cli/util/RuntimeIOException.java,CAS_DELIMITER,parquet-cli/src/main/java/org/apache/parquet/cli/util/Schemas.java,CAS_DELIMITER,parquet-cli/src/main/java/org/apache/parquet/cli/util/SeekableFSDataInputStream.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/Exceptions.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/util/DynConstructors.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/util/DynMethods.java,CAS_DELIMITER,parquet-common/src/test/java/org/apache/parquet/TestUtils.java,CAS_DELIMITER,parquet-common/src/test/java/org/apache/parquet/util/Concatenator.java,CAS_DELIMITER,parquet-common/src/test/java/org/apache/parquet/util/TestDynConstructors.java,CAS_DELIMITER,parquet-common/src/test/java/org/apache/parquet/util/TestDynMethods.java,CAS_DELIMITER",37,2,9,4.808388968951716,1,0.0,0,0.0,130.0,45.99735268696101,8.0,None,FALSE,TRUE,
352b906996f392030bfd53b93e3cf4adb78d1a55,Julien Le Dem,julien@apache.org,Fri Jun 9 14:31:14 2017 -0700,1497043874,PARQUET - 1026 : allow unsigned binary stats when min = = max When min equals max this is a special case where unsigned stats would actually be the same as signed stats since there is only one value . This is useful when the data is partitioned by that column and there's only one value in the file . Drill for example takes advantage of this . Author : Julien Le Dem < julien @ apache . org > Closes #416 from julienledem / min eq max and squashes the following commits : 1d71624 [ Julien Le Dem ] revert package import ordering change 47d89fc [ Julien Le Dem ] allow unsigned binary stats when min = = max,32,8,"parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java,CAS_DELIMITER",3,1,3,1.4266098981515114,36,947.6666666666666,42,182.71042052469136,1.0,0.632375115389509,0.0,None,FALSE,FALSE,
2d3203b10cc8edf71a6e3e0822f0d742c9516aa3,Gera Shegalov,gera@twitter.com,Fri Jun 9 11:34:21 2017 -0700,1497033261,"PARQUET - 1005 : Fix DumpCommand parsing to allow column projection DumpCommand option for - c is specified as hasArgs ( ) for unlimited number of arguments following - c . The very description of the option shows the real intent of using hasArg ( ) such that multiple columns can be specified as ' - c c1 - c c2 . . . ' . Otherwise , the input path is parsed as an argument for - c instead of the command itself . Author : Gera Shegalov < gera @ twitter . com > Closes #413 from gerashegalov / dump specific columns fix and squashes the following commits : a6b2df3 [ Gera Shegalov ] Fix DumpCommand parsing to allow column projection",7,9,"parquet-tools/src/main/java/org/apache/parquet/tools/Main.java,CAS_DELIMITER,parquet-tools/src/main/java/org/apache/parquet/tools/command/DumpCommand.java,CAS_DELIMITER",2,1,2,0.9886994082884974,36,301.5,10,133.79107060185186,0.0,0.0,0.0,None,FALSE,FALSE,
9d58b6a83aa79dcad01c3bcc2ec0a7db74ba83b1,EllenKletscher,ellen.kletscher@capitalone.com,Wed Jun 7 15:22:28 2017 -0700,1496874148,Parquet - 884 : Add support for Decimal datatype to Parquet - Pig record reader Adds conversion support to Pig for Decimal datatype . Based on the scala code in the spark project that provides a similar function for their sql library . Author : EllenKletscher < ellen . kletscher @ capitalone . com > Closes #404 from EllenKletscher / master and squashes the following commits : 7714738 [ EllenKletscher ] add comment for precision check 50c75c8 [ EllenKletscher ] remove check for primitiveType null 08d4dbb [ EllenKletscher ] PARQUET - 884 : Add missing AL header 57c4d72 [ EllenKletscher ] PARQUET - 884 : Add missing AL header ea61267 [ EllenKletscher ] PARQUET - 884 : add support for decimal type to pig reader,177,2,"parquet-pig/src/main/java/org/apache/parquet/pig/PigSchemaConverter.java,CAS_DELIMITER,parquet-pig/src/main/java/org/apache/parquet/pig/convert/DecimalUtils.java,CAS_DELIMITER,parquet-pig/src/main/java/org/apache/parquet/pig/convert/TupleConverter.java,CAS_DELIMITER,parquet-pig/src/test/java/org/apache/parquet/pig/TestDecimalUtils.java,CAS_DELIMITER",4,1,3,1.6635110313913273,37,278.25,5,230.99111400462965,0.0,0.0,0.0,None,FALSE,FALSE,
9491d7a61681f7acc7103a6d1d45efe96f7981d2,Andrew Ash,andrew@andrewash.com,Tue May 16 17:19:06 2017 -0700,1494980346,PARQUET - 990 More detailed error messages in footer parsing Include invalid values in exception messages when reading footer for two situations : - too - short files ( include file length ) - files with corrupted footer lengths ( include calculated footer start index ) Author : Andrew Ash < andrew @ andrewash . com > Closes #408 from ash211 / patch - 1 and squashes the following commits : 74f5836 [ Andrew Ash ] More detailed error messages in footer parsing,2,2,"parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER",1,1,1,0.0,36,1394.0,26,130.07964120370372,0.0,0.0,0.0,None,FALSE,FALSE,
1de41ef4baeee1c95e245837299f8be265294445,John Jenkins,jjenkins@kcg.com,Fri May 12 15:09:56 2017 -0700,1494626996,PARQUET - 852 : Slowly ramp up sizes of byte [ ] in ByteBasedBitPackingEncoder https : / / issues . apache . org / jira / browse / PARQUET - 852 Author : John Jenkins < jjenkins @ kcg . com > Closes #401 from JohnPJenkins / PARQUET - 852 and squashes the following commits : 334acec [ John Jenkins ] PARQUET - 852 : Slowly ramp up sizes of byte [ ] in ByteBasedBitPackingEncoder,34,14,"parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java,CAS_DELIMITER,parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder.java,CAS_DELIMITER",2,1,2,0.9544340029249649,36,85.0,4,435.97352430555554,0.0,0.0,0.0,None,FALSE,FALSE,
fd7cfed070c2aab60521afb7dcc633a0b7abea80,Swapnil Shinde,swapnilushinde@gmail.com,Fri May 12 15:02:27 2017 -0700,1494626547,PARQUET - 196 : parquet - tools command for row count & size This is a rebase on already existing PR - https : / / github . com / apache / parquet - mr / pull / 132 Author : Swapnil Shinde < swapnilushinde @ gmail . com > Closes #406 from swapnilushinde / master and squashes the following commits : 59a8980 [ Swapnil Shinde ] Spacing to conform java style ( if / for ) is fixed 5fd0279 [ Swapnil Shinde ] Parquet - 196 : parquet - tools command for row count & size,239,0,"parquet-tools/src/main/java/org/apache/parquet/tools/command/Registry.java,CAS_DELIMITER,parquet-tools/src/main/java/org/apache/parquet/tools/command/RowCountCommand.java,CAS_DELIMITER,parquet-tools/src/main/java/org/apache/parquet/tools/command/SizeCommand.java,CAS_DELIMITER",3,1,1,1.0377238453680009,37,20.333333333333332,3,35.31249614197531,0.0,0.0,0.0,None,FALSE,FALSE,
a703ee75c40e0207f6831c4d48e1c7e62f160305,dsfcode,fowler.dn@gmail.com,Fri May 12 14:40:29 2017 -0700,1494625229,PARQUET - 969 : Update parquet - tools to convert Decimal datatype to BigD… Update parquet - tools so that decimal datatypes in parquet files are converted to their actual number representation when cat'ing to stdout . Currently they are output in binary format . Author : dsfcode < fowler . dn @ gmail . com > Closes #412 from dsfcode / master and squashes the following commits : 7f05509 [ dsfcode ] PARQUET - 969 : Update parquet - tools to convert Decimal datatype to BigDecimal,78,0,"parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleRecordConverter.java,CAS_DELIMITER,parquet-tools/src/test/java/org/apache/parquet/tools/read/TestSimplePrimitiveRecord.java,CAS_DELIMITER",2,1,2,0.8212809417449864,28,79.5,1,372.9683275462963,0.0,0.0,0.0,None,FALSE,FALSE,
70f28810a5547219e18ffc3465f519c454fee6e5,Mark Chua,mark@asana.com,Fri Apr 21 16:07:55 2017 -0700,1492816075,"PARQUET - 665 Adds support for proto3 This change bumps the protobuf version and adds tests to show compatibility with proto3 . It does not actually change anything else . Tests are mostly identical to existing tests , and tests that tested functionality not present in proto3 are not present ( such as groups and extensions ) . Proto3 oneof and map are represented in the tests . Tested by running `mvn test - - am - - projects parquet - protobuf` Author : Mark Chua < mark @ asana . com > Closes #407 from markchua / mkc / proto3 and squashes the following commits : 40ef997 [ Mark Chua ] PARQUET - 665 Adds support for proto3",408,28,"parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoInputOutputFormatTest.java,CAS_DELIMITER,parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoRecordConverterTest.java,CAS_DELIMITER,parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoSchemaConverterTest.java,CAS_DELIMITER,parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoWriteSupportTest.java,CAS_DELIMITER",4,1,1,1.9056466287576972,35,162.5,8,599.3933391203703,0.0,0.0,0.0,Feature Addition,FALSE,FALSE,
2fd62ee4d524c270764e9b91dca72e5cf1a005b7,Zoltan Ivanfi,zi@cloudera.com,Thu Jan 26 15:39:31 2017 -0800,1485473971,"PARQUET - 772 : Fix locale - specific test failures . The statistics tests were failing in locales with a decimal mark other than "" . "" Author : Zoltan Ivanfi < zi @ cloudera . com > Closes #395 from zivanfi / PARQUET - 772 and squashes the following commits : acec99c [ Zoltan Ivanfi ] PARQUET - 772 : Fix locale - specific test failures .",2,2,"parquet-column/src/test/java/org/apache/parquet/column/statistics/TestStatistics.java,CAS_DELIMITER",1,1,1,0.0,28,587.0,2,575.9199421296296,2.0,1.879114271384677,0.0,None,FALSE,FALSE,
3634821fa515365618209f0452443728e7290fca,Zoltan Ivanfi,zi@cloudera.com,Thu Jan 26 15:37:57 2017 -0800,1485473877,"PARQUET - 806 : Parquet - tools silently suppresses error messages The ""error message"" that used to be org / apache / hadoop / conf / Configuration now becomes : NoClassDefFoundError : org / apache / hadoop / conf / Configuration Author : Zoltan Ivanfi < zi @ cloudera . com > Closes #396 from zivanfi / PARQUET - 806 and squashes the following commits : b1fe699 [ Zoltan Ivanfi ] PARQUET - 806 : Parquet - tools silently suppresses error messages",1,1,"parquet-tools/src/main/java/org/apache/parquet/tools/Main.java,CAS_DELIMITER",1,1,1,0.0,27,232.0,2,282.34123842592595,1.0,0.8791195557435559,0.0,None,FALSE,FALSE,
6fb60857be1fed21bdacc4ce830bbf99103b6fdd,Gabor Szadovszky,gabor.szadovszky@Budapests-MacBook-Pro-8.local,Thu Jan 26 15:34:22 2017 -0800,1485473662,"PARQUET - 822 : Upgrade java dependencies 2 minor code / config modification related to the version upgrades : - TestMemoryManager . java : I guess , it was caused by the junit upgrade however , it is not clear why it was working before . The issue was that the second run of `createWriter ( 1 ) . close ( null ) ` failed with `IOException` about that the file already exists . - pom . xml ( added exclusion for fastutil ) : The shaded dependency upgrade in `parquet - column` caused failure of API version compatibility check . `mvn clean install` worked fine . Any idea about additional testing is welcomed . Author : Gabor Szadovszky < gabor . szadovszky @ Budapests - MacBook - Pro - 8 . local > Closes #398 from gszadovszky / PARQUET - 822 and squashes the following commits : 25d0c7f [ Gabor Szadovszky ] Update hadoop - 1 version ; back to the old httpclient because of hadoop - 1 test failure 17a8137 [ Gabor Szadovszky ] PARQUET - 822 : Upgrade java dependencies",1,1,"parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMemoryManager.java,CAS_DELIMITER",1,1,1,0.0,27,256.0,7,113.13450231481481,3.0,2.5267656080900536,2.0,None,FALSE,FALSE,
f68dbc3ea20230cb14ed3364539ad16e114bcdd9,Gabor Szadovszky,gabor.szadovszky@Budapests-MacBook-Pro-8.local,Thu Jan 26 15:32:28 2017 -0800,1485473548,"PARQUET - 825 : Static analyzer findings ( NPEs , resource leaks ) Some trivial code fixes based on findings on static code analyzer tools ( Sonar , Fortify ) @ piyushnarang : Sorry , renaming the branch caused the closing of the original PR . . . Author : Gabor Szadovszky < gabor . szadovszky @ Budapests - MacBook - Pro - 8 . local > Author : Gabor Szadovszky < gabor . szadovszky @ cloudera . com > Closes #399 from gszadovszky / PARQUET - 825 and squashes the following commits : 68a4764 [ Gabor Szadovszky ] PARQUET - 825 - Static analyzer findings ( NPEs , resource leaks ) a689c1c [ Gabor Szadovszky ] Code fixes related to null checks , exception handling and closing streams",86,81,"parquet-column/src/main/java/org/apache/parquet/io/RecordReaderImplementation.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/glob/GlobNode.java,CAS_DELIMITER,parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/ByteBasedBitPackingGenerator.java,CAS_DELIMITER,parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/IntBasedBitPackingGenerator.java,CAS_DELIMITER,parquet-generator/src/main/java/org/apache/parquet/version/VersionGenerator.java,CAS_DELIMITER,parquet-tools/src/main/java/org/apache/parquet/tools/command/DumpCommand.java,CAS_DELIMITER,parquet-tools/src/main/java/org/apache/parquet/tools/command/Registry.java,CAS_DELIMITER,parquet-tools/src/main/java/org/apache/parquet/tools/util/PrettyPrintWriter.java,CAS_DELIMITER",8,4,6,1.8314799824597845,36,339.375,19,442.27774594907413,2.0,1.52677343623368,0.0,None,FALSE,FALSE,
89e0607cf6470dda1a6a47b46abf37468df4e50f,Patrick Woody,pwoody@palantir.com,Tue Dec 20 14:35:57 2016 -0800,1482273357,PARQUET - 801 : Allow UserDefinedPredicates in DictionaryFilter Author : Patrick Woody < pwoody @ palantir . com > Author : Patrick Woody < patrick . woody1 @ gmail . com > Closes #394 from pwoody / pw / dictionaryUdp and squashes the following commits : d8499a0 [ Patrick Woody ] short circuiting and style changes 4cb9f0c [ Patrick Woody ] more missing imports 1ec0d39 [ Patrick Woody ] fix missing import 3ee4489 [ Patrick Woody ] PARQUET - 801 : Allow UserDefinedPredicates in DictionaryFilter,140,10,"parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilterTest.java,CAS_DELIMITER",2,1,2,0.9531971725430559,34,427.0,9,62.08215856481481,0.0,0.0,0.0,None,FALSE,FALSE,
71cff7c5940b7101ff098601850d46b7a4698180,Liang-Chi Hsieh,viirya@gmail.com,Thu Dec 8 09:07:37 2016 -0800,1481216857,PARQUET - 791 : Add missing column support for UserDefinedPredicate This extends the fixing #354 to UserDefinedPredicate . Author : Liang - Chi Hsieh < viirya @ gmail . com > Closes #389 from viirya / PARQUET - 791 and squashes the following commits : d6be37d [ Liang - Chi Hsieh ] Address comment . 7e929c3 [ Liang - Chi Hsieh ] PARQUET - 791 : Add missing column support for UserDefinedPredicate .,91,6,"parquet-hadoop/src/main/java/org/apache/parquet/filter2/statisticslevel/StatisticsFilter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/filter2/statisticslevel/TestStatisticsFilter.java,CAS_DELIMITER",2,1,2,0.7902069241886371,31,353.5,4,146.0097685185185,0.0,0.0,0.0,None,FALSE,FALSE,
98c27699cbcf65c3d9d655ecbcd67adcd8b45b05,Zoltan Ivanfi,zi@cloudera.com,Wed Dec 7 11:07:03 2016 -0800,1481137623,PARQUET - 321 : Default maximum block padding to 8MB . rdblue's change applied to the newest code . Original pull request : https : / / github . com / apache / parquet - mr / pull / 232 / Author : Zoltan Ivanfi < zi @ cloudera . com > Closes #391 from zicl / master and squashes the following commits : b1c5c1d [ Zoltan Ivanfi ] PARQUET - 321 : Default maximum block padding to 8MB .,2,6,"parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java,CAS_DELIMITER",2,1,1,0.8112781244591328,34,477.5,19,202.01635416666664,0.0,0.0,0.0,None,FALSE,FALSE,
4fd34e6517f2c400a06e3c1d43ec56df2ff5c392,Reuben Kuhnert,reuben.kuhnert@cloudera.com,Mon Dec 5 17:01:38 2016 -0800,1480986098,"PARQUET - 220 : Unnecessary warning in ParquetRecordReader . initialize Rather than querying the COUNTER METHOD up front , the counter method is resolved per object . This allows us to use the 'getCounter' method on any TaskAttemptContext with the correct signature ( ignoring versions where TaskAttemptContext does not have an appropriate method / signature - preserving current behavior ) . Author : Reuben Kuhnert < reuben . kuhnert @ cloudera . com > Closes #280 from sircodesalotOfTheRound / context - utils - parquet - 220 and squashes the following commits : f118990 [ Reuben Kuhnert ] PARQUET - 220 : Unnecessary warning in ParquetRecordReader . initialize",57,20,"parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/ContextUtil.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/BenchmarkCounter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/counters/mapreduce/MapReduceCounterLoader.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/TestInputOutputFormat.java,CAS_DELIMITER",5,1,5,1.2628430052312558,34,205.0,13,368.99350000000004,3.0,1.582492865564642,1.0,None,FALSE,FALSE,
09d28fe7995db1a4da2c651d362007d2082c663c,Michael Allman,michael@videoamp.com,Mon Dec 5 15:27:14 2016 -0800,1480980434,"PARQUET - 783 : Close the underlying stream when an H2SeekableInputStream is closed This PR addresses https : / / issues . apache . org / jira / browse / PARQUET - 783 . `ParquetFileReader` opens a `SeekableInputStream` to read a footer . In the process , it opens a new `FSDataInputStream` and wraps it . However , `H2SeekableInputStream` does not override the `close` method . Therefore , when `ParquetFileReader` closes it , the underlying `FSDataInputStream` is not closed . As a result , these stale connections can exhaust a clusters' data nodes' connection resources and lead to mysterious HDFS read failures in HDFS clients , e . g . ``` org . apache . hadoop . hdfs . BlockMissingException : Could not obtain block : BP - 905337612 - 172 . 16 . 70 . 103 - 1444328960665 : blk 1720536852 646811517 ``` Author : Michael Allman < michael @ videoamp . com > Closes #388 from mallman / parquet - 783 - close underlying inputstream and squashes the following commits : f4b27c1 [ Michael Allman ] PARQUET - 783 Close the underlying stream when an H2SeekableInputStream is closed",5,0,"parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/H2SeekableInputStream.java,CAS_DELIMITER",1,1,1,0.0,31,107.0,1,111.2605787037037,1.0,0.6104081204255319,1.0,None,FALSE,FALSE,
cf991604d75d446d02baddc536c7c05b43cd8dea,Julien Le Dem,julien@dremio.com,Wed Nov 9 08:58:59 2016 -0800,1478710739,PARQUET - 755 : create parquet - arrow module with schema converter Author : Julien Le Dem < julien @ dremio . com > Closes #381 from julienledem / parquet arrow and squashes the following commits : 9792683 [ Julien Le Dem ] PARQUET - 755 : create parquet - arrow module with schema converter introduces SchemaMapping add repeated mapping,1270,4,"parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/List3Levels.java,CAS_DELIMITER,parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaConverter.java,CAS_DELIMITER,parquet-arrow/src/main/java/org/apache/parquet/arrow/schema/SchemaMapping.java,CAS_DELIMITER,parquet-arrow/src/test/java/org/apache/parquet/arrow/schema/TestSchemaConverter.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/schema/Types.java,CAS_DELIMITER",5,2,3,1.7252978939950192,32,275.4,7,40.61078009259259,0.0,0.0,0.0,None,FALSE,FALSE,
e5cd652aeb3305ef2b82a7925cce3a132bf6f5ae,adeneche,adeneche@apache.org,Wed Oct 26 09:47:44 2016 -0700,1477500464,PARQUET - 753 : Fixed GroupType . union ( ) to handle original type also fixed GroupType . equals ( ) to compare the original type and 2 unit tests that weren't setting the original type properly on the expected results Author : adeneche < adeneche @ apache . org > Author : adeneche < adeneche @ gmail . com > Closes #380 from adeneche / fix - grouptype - union and squashes the following commits : b04af7d [ adeneche ] reverted unnecessary formatting changes 5461a57 [ adeneche ] Fixed unit tests in TestPigSchemaConverter that were failing because of my fix to GroupType . equals ( ) ec91315 [ adeneche ] fixed expected error message in TestMessageType#testMergeSchema a1d7f63 [ adeneche ] Fixed GroupType . union ( ) to handle original type,65,33,"parquet-column/src/main/java/org/apache/parquet/schema/GroupType.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/parser/TestParquetParser.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/schema/TestMessageType.java,CAS_DELIMITER,parquet-pig/src/test/java/org/apache/parquet/pig/TestPigSchemaConverter.java,CAS_DELIMITER",4,2,4,1.5567050074536304,31,286.75,12,393.3113657407407,0.0,0.0,0.0,None,FALSE,FALSE,
ece4b70cce24b89483236b4cff079c10597d680a,Ryan Blue,blue@apache.org,Tue Oct 18 17:45:32 2016 -0700,1476837932,"PARQUET - 751 : Add setRequestedSchema to ParquetFileReader . This fixes a bug introduced by dictionary filters , which reused an existing file reader to avoid opening multiple input streams . Before that commit , a new file reader was opened and passed the projection columns from the read context . The fix is to set the requested schema on the file reader instead of creating a new instance . This also adds a test to ensure that column projection works to catch bugs like this in the future . Author : Ryan Blue < blue @ apache . org > Closes #379 from rdblue / PARQUET - 751 - fix - column - projection and squashes the following commits : 7ea0c16 [ Ryan Blue ] PARQUET - 751 : Fix column projection test . 1da507e [ Ryan Blue ] PARQUET - 751 : Add setRequestedSchema to ParquetFileReader .",189,0,"parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputFormatColumnProjection.java,CAS_DELIMITER",3,1,2,0.3001601102563032,31,450.0,22,34.48728780864197,98.0,43.41601858234737,45.0,None,FALSE,FALSE,
59ec4f018963eb55e32fafc2b924826c39c09682,Ryan Blue,blue@apache.org,Wed Oct 12 18:05:21 2016 -0700,1476320721,"PARQUET - 743 : Fix DictionaryFilter when compressed dictionaries are reused . BytesInput is not supposed to be held and reused , but decompressed dictionary pages do this . Reusing the dictionary will cause a failure , so the cleanest option is to keep the bytes around once the underlying stream has been read . Author : Ryan Blue < blue @ apache . org > Closes #376 from rdblue / PARQUET - 743 - fix - reused - dictionaries and squashes the following commits : 28c0903 [ Ryan Blue ] PARQUET - 743 : Fix DictionaryFilter when dictionaries are reused .",20,3,"parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DictionaryPageReader.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilterTest.java,CAS_DELIMITER",2,1,2,0.6665783579949205,31,282.0,5,131.17961226851853,97.0,42.78809093090792,44.0,None,FALSE,FALSE,
de99127d77dabfc6c8134b3c58e0b9a0b74e5f37,Ryan Blue,blue@apache.org,Wed Oct 12 09:35:51 2016 -0700,1476290151,"PARQUET - 686 : Do not return min / max for the wrong order . Min and max are currently calculated using the default Java ordering that uses signed comparison for all values . This is not correct for binary types like strings and decimals or for unsigned numeric types . This commit prevents statistics accumulated using the signed ordering from being returned by ParquetMetadataConverter when the type should use the unsigned ordering . Because many binary strings are not affected by using the wrong ordering , this adds a property , parquet . strings . use - signed - order to allow overriding this change . Author : Ryan Blue < blue @ apache . org > Closes #367 from rdblue / PARQUET - 686 - suppress - signed - stats and squashes the following commits : f9d459f [ Ryan Blue ] PARQUET - 686 : Add getConfiguration to HadoopInputFile . 301bd3a [ Ryan Blue ] PARQUET - 686 : Address review comments . c099c35 [ Ryan Blue ] PARQUET - 686 : Do not return min / max for the wrong order .",228,20,"parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopInputFile.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java,CAS_DELIMITER,parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java,CAS_DELIMITER",6,2,6,1.7642532466304943,31,603.0,39,205.94120563271608,96.0,41.80934659049745,26.0,None,FALSE,FALSE,
e6da0f682436e1387ad68e86edf7418c0f7cb368,Gabor Szadovszky,gabor.szadovszky@cloudera.com,Wed Oct 5 13:21:40 2016 -0700,1475698900,PARQUET - 685 - Deprecated ParquetInputSplit constructor passes paramet… The problem was not discovered because the test was bugous . Updated both sides . Author : Gabor Szadovszky < gabor . szadovszky @ cloudera . com > Closes #372 from gszadovszky / PARQUET - 685 and squashes the following commits : 9cbeee2 [ Gabor Szadovszky ] PARQUET - 685 - Deprecated ParquetInputSplit constructor passes parameters in the wrong order .,2,6,"parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputSplit.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputFormat.java,CAS_DELIMITER",2,1,2,0.9544340029249649,28,427.5,3,434.3919849537037,0.0,0.0,0.0,Corrective,TRUE,FALSE,
07a42d3ffd034e467e49b5c449d4f5f81c471cc5,Niels Basjes,nbasjes@bol.com,Wed Oct 5 13:20:41 2016 -0700,1475698841,PARQUET - 726 : Increase max difference of testMemoryManagerUpperLimit to 10 % Author : Niels Basjes < nbasjes @ bol . com > Closes #370 from nielsbasjes / PARQUET - 726 and squashes the following commits : f385ede [ Niels Basjes ] PARQUET - 726 : Increase max difference of testMemoryManagerUpperLimit to 10 %,4,3,"parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMemoryManager.java,CAS_DELIMITER",1,1,1,0.0,27,193.0,4,351.8955324074074,0.0,0.0,0.0,None,FALSE,FALSE,
b59be86597cfcd805c24fa406af46071400e24c8,Ryan Blue,blue@apache.org,Mon Oct 3 15:04:12 2016 -0700,1475532252,PARQUET - 674 : Add InputFile abstraction for openable files . Author : Ryan Blue < blue @ apache . org > Closes #368 from rdblue / PARQUET - 674 - add - data - source and squashes the following commits : 8c689e9 [ Ryan Blue ] PARQUET - 674 : Implement review comments . 4a7c327 [ Ryan Blue ] PARQUET - 674 : Add DataSource abstraction for openable files .,130,11,"parquet-common/src/main/java/org/apache/parquet/io/InputFile.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopInputFile.java,CAS_DELIMITER",3,2,3,1.520690385520438,31,362.0,12,16.06763888888889,95.0,41.31969550862023,26.0,None,FALSE,FALSE,
e54ca615f213f5db6d34d9163c97eec98920d7a7,Jakub Kukul,jakub.kukul@gmail.com,Thu Sep 8 14:48:42 2016 -0700,1473371322,"PARQUET - 660 : Ignore extension fields in protobuf messages . Currently , converting protobuf messages with extension can result in an uninformative error or a data corruption . A more detailed explanation in the corresponding [ jira ] ( https : / / issues . apache . org / jira / browse / PARQUET - 660 ) . This patch simply ignores extension fields in protobuf messages . In the longer run , I'd like to add a proper support for Protobuf extensions . This might take a little longer though , so I've decided to improve the current situation with this patch . Author : Jakub Kukul < jakub . kukul @ gmail . com > Closes #351 from jkukul / master and squashes the following commits : 27580ab [ Jakub Kukul ] PARQUET - 660 : Throw Unsupported exception for messages with extensions . db6e08b [ Jakub Kukul ] PARQUET - 660 : Refactor : Don't use additional variable for indexing fieldWriters . e910a8a [ Jakub Kukul ] PARQUET - 660 : Refactor : Add missing indentation .",39,19,"parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoSchemaConverter.java,CAS_DELIMITER,parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java,CAS_DELIMITER,parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoWriteSupportTest.java,CAS_DELIMITER",3,1,2,1.4801224927445111,31,206.33333333333334,6,403.64446759259255,0.0,0.0,0.0,None,FALSE,FALSE,
044de16c14076019f87763b7b58c45664ee57c11,Ryan Blue,blue@apache.org,Thu Sep 8 14:22:30 2016 -0700,1473369750,"PARQUET - 623 : Fix DeltaByteArrayReader#skip . Previously , this passed the skip to the underlying readers , but would not update previous and would corrupt values or cause exceptions . Author : Ryan Blue < blue @ apache . org > Closes #366 from rdblue / PARQUET - 623 - fix - delta - byte - array - skip and squashes the following commits : f85800c [ Ryan Blue ] PARQUET - 623 : Fix DeltaByteArrayReader#skip .",20,2,"parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayReader.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/TestDeltaByteArray.java,CAS_DELIMITER",2,1,2,0.6840384356390417,31,97.0,7,309.17315972222224,94.0,41.78540123270986,42.0,None,FALSE,FALSE,
255f10834a67cf13518316de0e2c8a345677ebbf,flykobe,flykobecy@gmail.com,Tue Aug 16 10:40:52 2016 -0700,1471369252,PARQUET - 460 : merge multi parquet files to one file A merge command for parquet - tools based on https : / / issues . apache . org / jira / browse / PARQUET - 382 . Author : flykobe < flykobecy @ gmail . com > Closes #327 from flykobe / merge tool and squashes the following commits : b031c18 [ flykobe ] check input files da28832 [ flykobe ] merge multi parquet files to one file,158,0,"parquet-tools/src/main/java/org/apache/parquet/tools/command/MergeCommand.java,CAS_DELIMITER,parquet-tools/src/main/java/org/apache/parquet/tools/command/Registry.java,CAS_DELIMITER",2,1,1,0.05532848503795462,28,30.0,1,238.3851273148148,0.0,0.0,0.0,None,FALSE,FALSE,
898f3d0f652f313473c67fef32e22d94d8294d4f,Ryan Blue,blue@apache.org,Tue Aug 16 10:12:00 2016 -0700,1471367520,"PARQUET - 400 : Replace CompatibilityUtil with SeekableInputStream . This fixes PARQUET - 400 by replacing `CompatibilityUtil` with `SeekableInputStream` that's implemented for hadoop - 1 and hadoop - 2 . The benefit of this approach is that `SeekableInputStream` can be used for non - Hadoop file systems in the future . This also changes the default Hadoop version to Hadoop - 2 . The library is still compatible with Hadoop 1 . x , but this makes building Hadoop - 2 classes , like `H2SeekableInputStream` , much easier and removes the need for multiple hadoop versions during compilation . Author : Ryan Blue < blue @ apache . org > Closes #349 from rdblue / PARQUET - 400 - byte - buffers and squashes the following commits : 1bcb8a8 [ Ryan Blue ] PARQUET - 400 : Fix review nits . 823ca00 [ Ryan Blue ] PARQUET - 400 : Add tests for Hadoop 2 readFully . 02d3709 [ Ryan Blue ] PARQUET - 400 : Remove unused property . b543013 [ Ryan Blue ] PARQUET - 400 : Fix logger for HadoopStreams . 2cb6934 [ Ryan Blue ] PARQUET - 400 : Remove H2SeekableInputStream tests . abaa695 [ Ryan Blue ] PARQUET - 400 : Fix review items . 5dc50a5 [ Ryan Blue ] PARQUET - 400 : Add tests for H1SeekableInputStream methods . 730a9e2 [ Ryan Blue ] PARQUET - 400 : Move SeekableInputStream to io package . 506a556 [ Ryan Blue ] PARQUET - 400 : Remove Hadoop dependencies from SeekableInputStream . c80580c [ Ryan Blue ] PARQUET - 400 : Handle UnsupportedOperationException from read ( ByteBuffer ) . ba08b3f [ Ryan Blue ] PARQUET - 400 : Replace CompatibilityUtil with SeekableInputStream .",1752,130,"parquet-common/src/main/java/org/apache/parquet/io/SeekableInputStream.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/CompatibilityUtil.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/H1SeekableInputStream.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/H2SeekableInputStream.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/util/HadoopStreams.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/MockInputStream.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestHadoop1ByteBufferReads.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/util/TestHadoop2ByteBufferReads.java,CAS_DELIMITER",10,2,4,2.603532489267415,31,212.0,24,41.451425925925925,93.0,42.186874939406074,25.0,None,FALSE,FALSE,
30aa91012cf6019bb9720609c1d03b5386a87ffb,Piyush Narang,pnarang@twitter.com,Thu Aug 11 13:30:43 2016 -0700,1470947443,"PARQUET - 601 : Add support to configure the encoding used by ValueWriters ### Context : Parquet is currently structured to choose the appropriate value writer based on the type of the column as well as the Parquet version . As of now , the writer ( s ) ( and hence encoding ) for each data type is hard coded in the Parquet source code . This PR adds support for being able to override the encodings per type via config . That allows users to experiment with various encoding strategies manually as well as enables them to override the hardcoded defaults if they don't suit their use case . We can override encodings per data type ( int32 / int64 / . . . ) . Something on the lines of : ``` parquet . writer . encoding - override . < type > = ""encoding1 [ , encoding2 ] "" ``` As an example : ``` ""parquet . writer . encoding - override . int32"" = ""plain"" ( Chooses Plain encoding and hence the PlainValuesWriter ) . ``` When a primary + fallback need to be specified , we can do the following : ``` ""parquet . writer . encoding - override . binary"" = ""rle dictionary , delta byte array"" ( Chooses RLE DICTIONARY encoding as the initial encoding and DELTA BYTE ARRAY encoding as the fallback and hence creates a FallbackWriter ( PlainBinaryDictionaryValuesWriter , DeltaByteArrayWriter ) . ``` In such cases we can mandate that the first encoding listed must allow for Fallbacks by implementing [ RequiresFallback ] ( https : / / github . com / apache / parquet - mr / blob / master / parquet - column / src / main / java / org / apache / parquet / column / values / RequiresFallback . java#L31 ) . ### PR notes : - Restructured the ValuesWriter creation code . Pulled it out of ParquetProperties into a new class and refactored the flow based on type as it was getting hard to follow and I felt adding the overrides would make it harder . Added a bunch of unit tests to verify the ValuesWriter we create for combinations of type , parquet version and dictionary on / off . - Added unit tests to verify parsing of the encoding overrides + creation of ValuesWriters based on these overrides . - Manually tested some encoding overrides scenarios out on Hadoop ( both parquet v1 , v2 ) . Author : Piyush Narang < pnarang @ twitter . com > Closes #342 from piyushnarang / master and squashes the following commits : 3ebab28 [ Piyush Narang ] Remove Configurable 149bb98 [ Piyush Narang ] Switch to getValuesWriterFactory call to non - static 0b78e04 [ Piyush Narang ] Address Ryan's feedback 1da6ca3 [ Piyush Narang ] Merge branch 'master' into piyush / dynamic - encoding - overrides f021ed2 [ Piyush Narang ] Tweak comment in ValuesWriterFactory cb02ea0 [ Piyush Narang ] Fix review comments bf4bc6d [ Piyush Narang ] Add support for Config setting in ValuesWriter factory 8a852a3 [ Piyush Narang ] Log values writer factory chosen e4b61a4 [ Piyush Narang ] Tweak factory instantiation a bit b46cccd [ Piyush Narang ] Add class based factory override 6a5428f [ Piyush Narang ] Clean up some stuff in ValuesWriterFactory 0f8cd09 [ Piyush Narang ] Refactor mockito version 9ead61d [ Piyush Narang ] Add guava test dep 5c636c7 [ Piyush Narang ] Add encoding - overrides config to ParquetOutputFormat config b9d6c13 [ Piyush Narang ] Refactor code in ValuesWriterFactory a bit ff4c90d [ Piyush Narang ] Pull out value writer creation to ValuesWriterFactory and add unit tests",760,149,"parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/factory/DefaultV1ValuesWriterFactory.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/factory/DefaultV2ValuesWriterFactory.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/factory/DefaultValuesWriterFactory.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/factory/ValuesWriterFactory.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/values/factory/DefaultValuesWriterFactoryTest.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER",7,2,4,2.4157722859521447,33,125.0,14,20.245051256613756,3.0,2.4180710011596416,1.5,None,FALSE,FALSE,
76a2ac814caa194c46be1cf7a3f5dc129546b1c1,Robert Kruszewski,robertk@palantir.com,Wed Aug 3 14:22:27 2016 -0700,1470259347,PARQUET - 669 : allow reading footers from provided file listing and streams The use case is that I want to reuse existing listing of files and avoid doing it again when opening streams . This is in case where filesystem . open is expensive but you have other means of obtaining input stream for a file . Author : Robert Kruszewski < robertk @ palantir . com > Closes #357 from robert3005 / robertk / allow - reading - footers - from - streams and squashes the following commits : 4d8a54c [ Robert Kruszewski ] allow reading footers from provided file listing and streams,18,10,"parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER",1,1,1,0.0,31,1075.0,10,20.980775462962963,0.0,0.0,0.0,None,FALSE,TRUE,
f8489499aa6d460a7548b14d516638b0bd7b862b,Robert Kruszewski,robertk@palantir.com,Wed Aug 3 14:22:27 2016 -0700,1470259347,PARQUET - 669 : allow reading footers from provided file listing and streams The use case is that I want to reuse existing listing of files and avoid doing it again when opening streams . This is in case where filesystem . open is expensive but you have other means of obtaining input stream for a file . Author : Robert Kruszewski < robertk @ palantir . com > Closes #357 from robert3005 / robertk / allow - reading - footers - from - streams and squashes the following commits : 4d8a54c [ Robert Kruszewski ] allow reading footers from provided file listing and streams,18,10,"parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER",1,1,1,0.0,35,1353.0,20,20.980775462962963,1.0,1.0,1.0,None,FALSE,TRUE,
ea402becca436dc1a8e47ac9385a3db475b49355,djhworld,djharperuk@gmail.com,Wed Aug 3 14:14:26 2016 -0700,1470258866,"PARQUET - 668 - Provide option to disable auto crop feature in dump https : / / issues . apache . org / jira / browse / PARQUET - 668 1 . Added option ` - - disable - crop` 2 . Updated `README . md` to reflect changes Author : djhworld < djharperuk @ gmail . com > Closes #358 from djhworld / master and squashes the following commits : 493c3d0 [ djhworld ] PARQUET - 668 : Removed usage instructions from README , replaced with - - help flag 696a5e6 [ djhworld ] PARQUET - 668 - > Updated README . md to fix issue in usage string 6cbf59b [ djhworld ] PARQUET - 668 - Provide option to disable auto crop feature in DumpCommand output",22,9,"parquet-tools/src/main/java/org/apache/parquet/tools/command/DumpCommand.java,CAS_DELIMITER",1,1,1,0.0,28,358.0,5,393.2214583333333,0.0,0.0,0.0,None,FALSE,FALSE,
5c85b8dda5f3047732a17b818256b9289274d071,Michal Gorecki,goreckim@amazon.com,Mon Aug 1 14:38:07 2016 -0700,1470087487,"PARQUET - 511 : Integer overflow when counting values in column . This commit fixes an issue when the number of entries in a column page is larger than the size of an integer . No exception is thrown directly , but the def level is set incorrectly , leading to a null value being returned during read . Author : Michal Gorecki < goreckim @ amazon . com > Closes #321 from goreckm / int - overflow and squashes the following commits : d224815 [ Michal Gorecki ] enhancing exception message 7334be2 [ Michal Gorecki ] PARQUET - 511 : Integer overflow when counting values in column .",4,4,"parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderImpl.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageReadStore.java,CAS_DELIMITER",2,2,2,0.8112781244591328,31,436.0,7,208.0980787037037,0.0,0.0,0.0,None,FALSE,FALSE,
6a62646bfcecec9c0806a216b17e1a4ccb4609aa,Ryan Blue,blue@apache.org,Sun Jul 17 16:27:20 2016 -0700,1468798040,"PARQUET - 543 : Remove unused boundedint package . This relocates the DevNullValuesWriter and ZeroIntegerValuesReader , which are used but are not related to the boundedint code . Author : Ryan Blue < blue @ apache . org > Closes #329 from rdblue / PARQUET - 543 - remove - boundedint and squashes the following commits : 0158c51 [ Ryan Blue ] PARQUET - 543 : Update new import in ParquetProperties . 550a1a3 [ Ryan Blue ] PARQUET - 543 : Remove unused boundedint package .",4,762,"parquet-column/src/main/java/org/apache/parquet/column/Encoding.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/bitpacking/DevNullValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/BitReader.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/BitWriter.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/BoundedIntValuesFactory.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/BoundedIntValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/boundedint/BoundedIntValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/rle/ZeroIntegerValuesReader.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/values/boundedint/TestBoundedColumns.java,CAS_DELIMITER",10,1,5,2.524542060712316,32,147.1,19,249.93011574074075,92.0,43.06587555542507,41.0,None,FALSE,FALSE,
626014eaf093fc2e3b53f5ad00c425bc209e1428,Ryan Blue,blue@apache.org,Sun Jul 17 14:59:20 2016 -0700,1468792760,"PARQUET - 651 : Improve Avro's isElementType check . The Avro implementation needs to check whether the read schema that is passed by the user ( or automatically converted from the file schema ) expects an extra 1 - field layer to be returned , which matches the previous behavior of Avro when reading a 3 - level list . Before this commit , the check was done by testing the structure of the expected list element type against the repeated group's schema . If they matched , then Avro assumed that the user expected an extra layer . However , for records that happened to match ( 1 - field records with a field named ""element"" ) the check could be wrong and would cause exceptions later . This commit updates the check to convert the file's element schema to Avro and compare the compatibility of that schema with what was passed by the user . This checks the entire tree from the element down and gets the answer right based on the element and its children , not just the field names on the element . Author : Ryan Blue < blue @ apache . org > Closes #352 from rdblue / PARQUET - 651 - improve - is - element - type - check and squashes the following commits : ad9c1ee [ Ryan Blue ] PARQUET - 651 : Undo accidental default setting change . 1efa248 [ Ryan Blue ] PARQUET - 651 : Improve Avro's isElementType check .",179,7,"parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordConverter.java,CAS_DELIMITER,parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java,CAS_DELIMITER,parquet-avro/src/test/java/org/apache/parquet/avro/TestArrayCompatibility.java,CAS_DELIMITER",3,1,2,0.9281675098363991,31,831.3333333333334,16,121.17120370370371,91.0,42.06977002324538,24.0,None,FALSE,FALSE,
42662f8750a2c33ee169f17f4b4e4586db98d869,Ryan Blue,blue@apache.org,Fri Jul 15 09:53:33 2016 -0700,1468601613,"PARQUET - 389 : Support predicate push down on missing columns . Predicate push - down will complain when predicates reference columns that aren't in a file's schema . This makes it difficult to implement predicate push - down in engines where schemas evolve because each task needs to process the predicates and prune references to columns not in that task's file . This PR implements predicate evaluation for missing columns , where the values are all null . This allows engines to pass predicates as they are written . A future commit should rewrite the predicates to avoid the extra work currently done in record - level filtering , but that isn't included here because it is an optimization . Author : Ryan Blue < blue @ apache . org > Closes #354 from rdblue / PARQUET - 389 - predicate - push - down - on - missing - columns and squashes the following commits : b4d809a [ Ryan Blue ] PARQUET - 389 : Support record - level filtering with missing columns . 91b841c [ Ryan Blue ] PARQUET - 389 : Add missing column support to StatisticsFilter . 275f950 [ Ryan Blue ] PARQUET - 389 : Add missing column support to DictionaryFilter .",508,77,"parquet-column/src/main/java/org/apache/parquet/filter2/predicate/SchemaCompatibilityValidator.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/filter2/statisticslevel/StatisticsFilter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/filter2/TestFiltersWithMissingColumns.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilterTest.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/filter2/statisticslevel/TestStatisticsFilter.java,CAS_DELIMITER",6,2,6,2.072011746272116,31,263.5,9,217.71882908950616,90.0,41.20521172458282,40.0,None,FALSE,TRUE,
2282c22c5b252859b459cc2474350fbaf2a588e9,Ryan Blue,blue@apache.org,Fri Jul 15 09:53:33 2016 -0700,1468601613,"PARQUET - 389 : Support predicate push down on missing columns . Predicate push - down will complain when predicates reference columns that aren't in a file's schema . This makes it difficult to implement predicate push - down in engines where schemas evolve because each task needs to process the predicates and prune references to columns not in that task's file . This PR implements predicate evaluation for missing columns , where the values are all null . This allows engines to pass predicates as they are written . A future commit should rewrite the predicates to avoid the extra work currently done in record - level filtering , but that isn't included here because it is an optimization . Author : Ryan Blue < blue @ apache . org > Closes #354 from rdblue / PARQUET - 389 - predicate - push - down - on - missing - columns and squashes the following commits : b4d809a [ Ryan Blue ] PARQUET - 389 : Support record - level filtering with missing columns . 91b841c [ Ryan Blue ] PARQUET - 389 : Add missing column support to StatisticsFilter . 275f950 [ Ryan Blue ] PARQUET - 389 : Add missing column support to DictionaryFilter .",508,77,"parquet-column/src/main/java/org/apache/parquet/filter2/predicate/SchemaCompatibilityValidator.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/filter2/statisticslevel/StatisticsFilter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/filter2/TestFiltersWithMissingColumns.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilterTest.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/filter2/statisticslevel/TestStatisticsFilter.java,CAS_DELIMITER",6,2,6,2.072011746272116,35,499.1666666666667,26,-43.66859182098765,120.0,67.75741977069704,55.5,None,FALSE,TRUE,
e036d60d8a210d5ac28b2e5c51a45ceb82b58f09,Ryan Blue,blue@apache.org,Wed Jul 13 14:50:08 2016 -0700,1468446608,PARQUET - 654 : Add option to disable record - level filtering . This can be used by frameworks that use codegen for filtering to avoid running filters within Parquet . Author : Ryan Blue < blue @ apache . org > Closes #353 from rdblue / PARQUET - 654 - add - record - level - filter - option and squashes the following commits : b497e7f [ Ryan Blue ] PARQUET - 654 : Add option to disable record - level filtering .,33,3,"parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER",3,1,1,1.4955380299191112,31,700.6666666666666,19,164.6961612654321,89.0,40.310845041043585,39.0,None,FALSE,FALSE,
bd0b5af025fab9cad8f94260138741c252f45fc8,Ryan Blue,blue@apache.org,Thu Jun 30 09:54:08 2016 -0700,1467305648,PARQUET - 612 : Add compression codec to FileEncodingsIT . Author : Ryan Blue < blue @ apache . org > Closes #343 from rdblue / PARQUET - 612 - test - compression and squashes the following commits : a5b7dbb [ Ryan Blue ] PARQUET - 612 : Add compression codec to FileEncodingsIT .,93,19,"parquet-hadoop/src/test/java/org/apache/parquet/encodings/FileEncodingsIT.java,CAS_DELIMITER",1,1,1,0.0,30,490.0,1,223.9222337962963,88.0,40.07038732660907,38.0,None,FALSE,FALSE,
7f8e952abc4d2fc4b96c97a51aa25fcf6ed8af02,Piyush Narang,pnarang@twitter.com,Thu Jun 30 09:50:59 2016 -0700,1467305459,"PARQUET - 642 : Improve performance of ByteBuffer based read / write paths While trying out the newest Parquet version , we noticed that the changes to start using ByteBuffers : https : / / github . com / apache / parquet - mr / commit / 6b605a4ea05b66e1a6bf843353abcb4834a4ced8 and https : / / github . com / apache / parquet - mr / commit / 6b24a1d1b5e2792a7821ad172a45e38d2b04f9b8 ( mostly avro but a couple of ByteBuffer changes ) caused our jobs to slow down a bit . Read overhead : 4 - 6 % ( in MB Millis ) Write overhead : 6 - 10 % ( MB Millis ) . Seems like this seems to be due to the encoding / decoding of Strings in the [ Binary class ] ( https : / / github . com / apache / parquet - mr / blob / master / parquet - column / src / main / java / org / apache / parquet / io / api / Binary . java ) : [ toStringUsingUTF8 ( ) ] ( https : / / github . com / apache / parquet - mr / blob / master / parquet - column / src / main / java / org / apache / parquet / io / api / Binary . java#L388 ) - for reads [ encodeUTF8 ( ) ] ( https : / / github . com / apache / parquet - mr / blob / master / parquet - column / src / main / java / org / apache / parquet / io / api / Binary . java#L236 ) - for writes With these changes we see around 5 % improvement in MB Millis while running the job on our Hadoop cluster . Added some microbenchmark details to the jira . Note that I've left the behavior the same for the avro write path - it still uses CharSequence and the Charset based encoders . Author : Piyush Narang < pnarang @ twitter . com > Closes #347 from piyushnarang / bytebuffer - encoding - fix - pr and squashes the following commits : 43c5bdd [ Piyush Narang ] Keep avro on char sequence 2d50c8c [ Piyush Narang ] Update Binary approach 9e58237 [ Piyush Narang ] Proof of concept fixes",53,22,"parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java,CAS_DELIMITER",2,2,2,0.1773894531859974,31,679.0,12,71.04834490740741,2.0,1.6681736787968937,1.0,None,FALSE,FALSE,
9c40a7bb3c9aca51d17490960c988dfb7b5acebb,Ryan Blue,blue@apache.org,Thu Jun 30 09:47:48 2016 -0700,1467305268,"PARQUET - 645 : Fix null handling in DictionaryFilter . This fixes how null is handled by `DictionaryFilter` for equals predicates . Null is never in the dictionary and is encoded by the definition level , so the `DictionaryFilter` would never find the value in the dictionary and would incorrectly filter row groups whenever the filter was `col = = null` . Author : Ryan Blue < blue @ apache . org > Closes #348 from rdblue / PARQUET - 645 - fix - null - dictionary - filter and squashes the following commits : ae8dd41 [ Ryan Blue ] PARQUET - 645 : Fix null handling in DictionaryFilter .",18,0,"parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilterTest.java,CAS_DELIMITER",2,1,2,0.9182958340544896,31,374.5,3,90.74135995370371,87.0,39.07063366854116,37.0,None,FALSE,FALSE,
1f470253c46471033048383c027192e757480492,Mark Reddy,mark.l.reddy@gmail.com,Thu Jun 30 09:41:51 2016 -0700,1467304911,PARQUET - 544 : Add closed flag to allow for closeable contract adherence The closeable interface states : > Closes this stream and releases any system resources associated with it . If the stream is already closed then invoking this method has no effect . As InternalParquetRecordWriter implements this interface we should adhere to this contract . Author : Mark Reddy < mark . l . reddy @ gmail . com > Closes #345 from markreddy / PARQUET - 544 - adhere - to - closeable - contract and squashes the following commits : 135db9b [ Mark Reddy ] PARQUET - 544 : add closed flag to allow for adherence to closeable contract,13,8,"parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java,CAS_DELIMITER",1,1,1,0.0,31,188.0,7,204.75015046296295,0.0,0.0,0.0,None,FALSE,FALSE,
da69d4b764f4d13d38a4f7fe7462ef0c7d17c619,Reuben Kuhnert,reuben.kuhnert@cloudera.com,Thu May 5 13:56:53 2016 -0700,1462481813,"PARQUET - 367 : ""parquet - cat - j"" doesn't show all records . Added JsonRecordFormatter which formats SimpleRecords into an structure that can be used with ObjectMapper to create a valid json structure . Unit test included . Author : Reuben Kuhnert < reuben . kuhnert @ cloudera . com > Closes #281 from sircodesalotOfTheRound / fix - parquet - cat and squashes the following commits : 67207ef [ Reuben Kuhnert ] PARQUET - 367 : ""parquet - cat - j"" doesn't show all records .",372,1,"parquet-tools/src/main/java/org/apache/parquet/tools/command/CatCommand.java,CAS_DELIMITER,parquet-tools/src/main/java/org/apache/parquet/tools/json/JsonRecordFormatter.java,CAS_DELIMITER,parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleRecord.java,CAS_DELIMITER,parquet-tools/src/test/java/org/apache/parquet/tools/read/TestJsonRecordFormatter.java,CAS_DELIMITER",4,1,4,1.1110120418761333,29,60.0,3,151.24919849537036,2.0,1.3234463666112894,0.0,None,FALSE,FALSE,
c3f3830f771f26a537d2930b00b270451bbc5627,Ryan Blue,blue@apache.org,Thu May 5 13:54:28 2016 -0700,1462481668,"PARQUET - 372 : Do not write stats larger than 4k . This updates the stats conversion to check whether the min and max values for page stats are larger than 4k . If so , no statistics for a page are written . Author : Ryan Blue < blue @ apache . org > Closes #275 from rdblue / PARQUET - 372 - fix - min - max - for - long - values and squashes the following commits : 61e05d9 [ Ryan Blue ] PARQUET - 372 : Add comment to explain not truncating values . fbbc1c4 [ Ryan Blue ] PARQUET - 372 : Do not write stats larger than 4k .",232,2,"parquet-column/src/main/java/org/apache/parquet/column/statistics/BinaryStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/statistics/BooleanStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/statistics/DoubleStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/statistics/FloatStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/statistics/IntStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/statistics/LongStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/statistics/Statistics.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/statistics/TestStatistics.java,CAS_DELIMITER",10,2,4,1.8300983861656888,31,259.0,27,275.30137268518513,86.0,41.321883137533284,37.5,None,FALSE,FALSE,
39a3cd0f4210dbec1ae8ef39a87d34b76eac91a3,Nezih Yigitbasi,nyigitbasi@netflix.com,Mon Apr 25 15:05:11 2016 -0700,1461621911,"PARQUET - 560 : Synchronize writes to the finishCalled variable Reads of the `finishCalled` variable are properly synchronized , but writes are not - - so there's some sort of inconsistent synch . going on here . This PR fixes that . / cc @ rdblue can you please take a look ? Author : Nezih Yigitbasi < nyigitbasi @ netflix . com > Closes #334 from nezihyigitbasi / sc - synch - fix and squashes the following commits : a85cf0c [ Nezih Yigitbasi ] Synchronize writes to the finishCalled variable",1,1,"parquet-hadoop/src/main/java/org/apache/parquet/hadoop/codec/SnappyCompressor.java,CAS_DELIMITER",1,1,1,0.0,27,161.0,1,363.9538078703704,8.0,5.242087284104069,5.0,None,FALSE,FALSE,
2f22533ef41533e2b839a6b41b262dca59e6dbf9,Ryan Blue,blue@apache.org,Fri Apr 22 17:42:35 2016 -0700,1461372155,PARQUET - 569 : Separate metadata filtering for ranges and offsets . Range filtering should use the row group midpoint and offset filtering should use the start offset . Author : Ryan Blue < blue @ apache . org > Closes #337 from rdblue / PARQUET - 569 - fix - metadata - filter and squashes the following commits : 6171af4 [ Ryan Blue ] PARQUET - 569 : Add tests for new offset metadata filter . 3fe2d5e [ Ryan Blue ] PARQUET - 569 : Separate metadata filtering for ranges and offsets .,54,13,"parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java,CAS_DELIMITER",2,1,2,0.995978956518722,31,596.0,14,64.10539351851851,85.0,41.12202699194141,35.0,None,FALSE,FALSE,
3dd2210e79a8eb84378c370b32652f9a53f87a93,Ryan Blue,blue@apache.org,Fri Apr 22 17:39:52 2016 -0700,1461371992,"PARQUET - 548 : Add EncodingStats . This adds `EncodingStats` , which tracks the number of pages for each encoding , separated into dictionary and data pages . It also adds convenience functions that are useful for dictionary filtering , like `hasDictionaryEncodedPages` and `hasNonDictionaryEncodedPages` . `EncodingStats` have a unit test in parquet - column and an integration test in parquet - hadoop that writes a file and verifies the stats are present and correct when it is read . This includes commits from #330 because it updates the dictionary filter . I'll rebase and remove them once it is merged . Author : Ryan Blue < blue @ apache . org > Closes #332 from rdblue / PARQUET - 548 - add - encoding - stats and squashes the following commits : 5f148e6 [ Ryan Blue ] PARQUET - 548 : Fixes for review comments . dc332d3 [ Ryan Blue ] PARQUET - 548 : Add EncodingStats .",628,43,"parquet-column/src/main/java/org/apache/parquet/column/EncodingStats.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/TestEncodingStats.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DictionaryPageReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ColumnChunkMetaData.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestReadWriteEncodingStats.java,CAS_DELIMITER",9,2,7,2.5844231935058524,31,312.77777777777777,26,85.56824588477366,84.0,40.12214194232958,36.0,None,FALSE,FALSE,
36ce032b612fc0a1156d28bca7327e06337c8815,Piyush Narang,pnarang@twitter.com,Wed Apr 20 20:47:49 2016 -0700,1461210469,"PARQUET - 585 : Slowly ramp up sizes of int [ ] s in IntList to keep sizes small when data sets are small One of the follow up items from PR - https : / / github . com / apache / parquet - mr / pull / 339 was to slowly ramp up the size of the int [ ] created in IntList to ensure we don't allocate 64K arrays right off the bat . This PR updates the code to start with a 4K array then keeps doubling till 64K ( and stays at 64K after that ) . Author : Piyush Narang < pnarang @ twitter . com > Closes #341 from piyushnarang / master and squashes the following commits : 0bc6b84 [ Piyush Narang ] Fix review comments - add spaces , check slab size , fix slab init d1b4df1 [ Piyush Narang ] Make IntListTest values relative to constants in IntList 9617015 [ Piyush Narang ] Update IntList slab creation to keep bumping up size gradually ebf1c58 [ Piyush Narang ] Merge branch 'master' of https : / / github . com / apache / parquet - mr 3ecc577 [ Piyush Narang ] Remove redundant IntList ctor f7dfd5f [ Piyush Narang ] Switch int [ ] initialization in IntList to be lazy",136,12,"parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/IntList.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/values/dictionary/IntListTest.java,CAS_DELIMITER",2,1,2,0.9867867202680318,28,63.0,2,2.0702430555555558,1.0,0.9887834408121118,1.0,None,FALSE,FALSE,
6b24a1d1b5e2792a7821ad172a45e38d2b04f9b8,Ryan Blue,blue@apache.org,Wed Apr 20 08:41:22 2016 -0700,1461166882,"PARQUET - 358 : Add support for Avro's logical types API . This adds support for Avro's logical types API to parquet - avro . * The logical types API was introduced in Avro 1 . 8 . 0 , so this bumps the Avro dependency version to 1 . 8 . 0 . * Types supported are : decimal , date , time - millis , time - micros , timestamp - millis , and timestamp - micros * Tests have been copied from Avro and ported to the parquet - avro API Author : Ryan Blue < blue @ apache . org > Closes #318 from rdblue / PARQUET - 358 - add - avro - logical - types - api and squashes the following commits : bd81f9c [ Ryan Blue ] PARQUET - 358 : Fix review items . 0a882ee [ Ryan Blue ] PARQUET - 358 : Add logical types circular reference test . 5124618 [ Ryan Blue ] PARQUET - 358 : Add license documentation for code from Avro . dcb14be [ Ryan Blue ] PARQUET - 358 : Add support for Avro's logical types API .",2369,149,"parquet-avro/src/main/java/org/apache/parquet/avro/AvroIndexedRecordConverter.java,CAS_DELIMITER,parquet-avro/src/main/java/org/apache/parquet/avro/AvroReadSupport.java,CAS_DELIMITER,parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordConverter.java,CAS_DELIMITER,parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java,CAS_DELIMITER,parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java,CAS_DELIMITER,parquet-avro/src/main/java/org/apache/parquet/avro/ParentValueContainer.java,CAS_DELIMITER,parquet-avro/src/test/java/org/apache/parquet/avro/AvroTestUtil.java,CAS_DELIMITER,parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java,CAS_DELIMITER,parquet-avro/src/test/java/org/apache/parquet/avro/TestCircularReferences.java,CAS_DELIMITER,parquet-avro/src/test/java/org/apache/parquet/avro/TestGenericLogicalTypes.java,CAS_DELIMITER,parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java,CAS_DELIMITER,parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWriteOldListBehavior.java,CAS_DELIMITER,parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectLogicalTypes.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/schema/Types.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/io/api/TestBinary.java,CAS_DELIMITER",16,2,5,3.184540082176157,31,376.5625,52,142.1196195023148,83.0,39.260815179504995,30.0,None,FALSE,FALSE,
82b8ecc3275d7c3578a6531ac3f1da3ffada9dcc,Liwei Lin,proflin.me@gmail.com,Tue Apr 19 09:17:01 2016 -0700,1461082621,PARQUET - 484 : Warn when Decimal is stored as INT64 while could be stored as INT32 Below is documented in [ LogicalTypes . md ] ( https : / / github . com / Parquet / parquet - format / blob / master / LogicalTypes . md#decimal ) : > int32 : for 1 < = precision < = 9 > int64 : for 1 < = precision < = 18 ; precision < 10 will produce a warning This PR implements the `precision < 10 will produce a warning` part . @ rdblue @ liancheng would mind taking a look at this when you have time ? It's a fairly small addition ; cheers . Author : Liwei Lin < proflin . me @ gmail . com > Author : proflin < proflin . me @ gmail . com > Closes #316 from lw - lin / P - 484 - 2 and squashes the following commits : 207e509 [ Liwei Lin ] Address comments b227484 [ proflin ] PARQUET - 484 : Warn when Decimal is stored as INT64 while could be stored as INT32,9,0,"parquet-column/src/main/java/org/apache/parquet/schema/Types.java,CAS_DELIMITER",1,1,1,0.0,31,1368.0,5,77.92200231481482,2.0,1.6755779646506481,1.0,None,FALSE,FALSE,
dc08bb8ea6cdf01188f6699559e779e6cc296287,Kaufman Ng,kaufman@cloudera.com,Tue Apr 19 08:26:34 2016 -0700,1461079594,PARQUET - 584 show proper command usage when there's no arguments Author : Kaufman Ng < kaufman @ cloudera . com > Author : Ryan Blue < blue @ apache . org > Closes #336 from coughman / master and squashes the following commits : cd459f9 [ Kaufman Ng ] PARQUET - 584 : fixed formatting 1d1e965 [ Kaufman Ng ] Merge branch 'master' of https : / / github . com / coughman / incubator - parquet - mr 25b6d86 [ Kaufman Ng ] Merge branch 'master' of https : / / github . com / apache / parquet - mr bee66e5 [ Ryan Blue ] PARQUET - 384 : Add dictionary filtering . 283f7c7 [ Kaufman Ng ] show proper command usage when there's no arguments,4,3,"parquet-tools/src/main/java/org/apache/parquet/tools/Main.java,CAS_DELIMITER",1,1,1,0.0,27,231.0,1,357.67699074074073,0.0,0.0,0.0,None,FALSE,FALSE,
ac62c1c29f319a97a2552c39f32c8e6acd70c9e1,Piyush Narang,pnarang@twitter.com,Sat Apr 16 17:25:31 2016 -0700,1460852731,"PARQUET - 580 : Switch int [ ] initialization in IntList to be lazy Noticed that for a dataset that we were trying to import that had a lot of columns ( few thousand ) that weren't being used , we ended up allocating a lot of unnecessary int arrays ( each 64K in size ) . Heap footprint for all those int [ ] s turned out to be around 2GB or so ( and results in some jobs OOMing ) . This seems unnecessary for columns that might not be used . The changes in this PR switch over to initialize the int [ ] only when it being used for the first time . Also wondering if 64K is the right size to start off with . Wondering if a potential improvement is if we could allocate these int [ ] s in IntList in a way that slowly ramps up their size . So rather than create arrays of size 64K at a time ( which is potentially wasteful if there are only a few hundred bytes ) , we could create say a 4K int [ ] , then when it fills up an 8K [ ] and so on till we reach 64K ( at which point the behavior is the same as the current implementation ) . If this sounds like a reasonable idea , I can update this PR to do that as well . Wasn't sure if there was some historical context around that . . Author : Piyush Narang < pnarang @ twitter . com > Closes #339 from piyushnarang / master and squashes the following commits : 3ecc577 [ Piyush Narang ] Remove redundant IntList ctor f7dfd5f [ Piyush Narang ] Switch int [ ] initialization in IntList to be lazy",12,9,"parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/IntList.java,CAS_DELIMITER",1,1,1,0.0,27,123.0,1,355.0512615740741,0.0,0.0,0.0,None,FALSE,FALSE,
d4021487539b0f7758ec644f2e0d83df95c66bba,Michael Allman,michael@videoamp.com,Sat Apr 16 17:23:59 2016 -0700,1460852639,PARQUET - 581 : Fix two instances of the conflation of the min and max row count for page size check in ParquetOutputFormat . java Author : Michael Allman < michael @ videoamp . com > Closes #340 from mallman / fix minmax conflation and squashes the following commits : 79331a5 [ Michael Allman ] PARQUET - 581 : Fix two instances of the conflation of the min and max row count for page size check in ParquetOutputFormat . java,2,2,"parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER",1,1,1,0.0,31,455.0,8,60.99091435185185,0.0,0.0,0.0,None,FALSE,FALSE,
e9928c94ce1385ec72028336417f19f30ac38ac0,Nezih Yigitbasi,nyigitbasi@netflix.com,Fri Mar 25 12:19:39 2016 -0700,1458933579,"PARQUET - 571 : Fix potential leak in ParquetFileReader . close ( ) If an exception occurs when closing the input stream `f` , the codecs will not be released . This may cause native memory leaks for some codecs . \ cc @ rdblue Author : Nezih Yigitbasi < nyigitbasi @ netflix . com > Closes #338 from nezihyigitbasi / leak - fix and squashes the following commits : fcc5528 [ Nezih Yigitbasi ] Fix potential leak in close ( )",8,5,"parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER",1,1,1,0.0,31,1066.0,8,15.91599537037037,7.0,4.569413189928439,4.0,None,FALSE,FALSE,
4b1ff8f4b9dfa0ccb064ef286cf2953bfb2c492d,Ryan Blue,blue@apache.org,Wed Mar 9 13:20:37 2016 -0800,1457558437,"PARQUET - 384 : Add dictionary filtering . This builds on #286 from @ danielcweeks and cleans up some of the interfaces . It introduces `DictionaryPageReadStore` to expose dictionary pages to the filters and cleans up some internal calls by passing `ParquetFileReader` . When committed , this closes #286 . Author : Ryan Blue < blue @ apache . org > Author : Daniel Weeks < dweeks @ netflix . com > Closes #330 from rdblue / PARQUET - 384 - add - dictionary - filtering and squashes the following commits : ff89424 [ Ryan Blue ] PARQUET - 384 : Add a cache to DictionaryPageReader . 1f6861c [ Ryan Blue ] PARQUET - 384 : Use ParquetFileReader to initialize readers . 21ef4b6 [ Daniel Weeks ] PARQUET - 384 : Add dictionary row group filter .",1286,144,"parquet-column/src/main/java/org/apache/parquet/column/page/DictionaryPageReadStore.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/filter2/compat/RowGroupFilter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageReadStore.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DictionaryPageReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilterTest.java,CAS_DELIMITER",11,2,6,2.692670251397762,31,234.36363636363637,30,115.1488646885522,82.0,40.75930217471012,34.5,None,FALSE,TRUE,
a87c98163505fab39bcf8461b11fbb909a4c1bed,Ryan Blue,blue@apache.org,Wed Mar 9 13:20:37 2016 -0800,1457558437,"PARQUET - 384 : Add dictionary filtering . This builds on #286 from @ danielcweeks and cleans up some of the interfaces . It introduces `DictionaryPageReadStore` to expose dictionary pages to the filters and cleans up some internal calls by passing `ParquetFileReader` . When committed , this closes #286 . Author : Ryan Blue < blue @ apache . org > Author : Daniel Weeks < dweeks @ netflix . com > Closes #330 from rdblue / PARQUET - 384 - add - dictionary - filtering and squashes the following commits : ff89424 [ Ryan Blue ] PARQUET - 384 : Add a cache to DictionaryPageReader . 1f6861c [ Ryan Blue ] PARQUET - 384 : Use ParquetFileReader to initialize readers . 21ef4b6 [ Daniel Weeks ] PARQUET - 384 : Add dictionary row group filter . Conflicts : parquet - hadoop / src / main / java / org / apache / parquet / hadoop / ParquetFileReader . java Resolution : Removed unnecessary allocator args and fields Minor changes for using the codec API",1285,138,"parquet-column/src/main/java/org/apache/parquet/column/page/DictionaryPageReadStore.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/filter2/compat/RowGroupFilter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageReadStore.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DictionaryPageReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/filter2/dictionarylevel/DictionaryFilterTest.java,CAS_DELIMITER",11,2,6,2.6952303917062586,35,387.3636363636364,76,-86.9484859006734,113.0,85.03656500500632,50.5,None,FALSE,TRUE,
1f91c79de5e2d852c6e7d0cf7a4255087ef618ef,proflin,proflin.me@gmail.com,Sat Mar 5 19:45:25 2016 +0800,1457178325,"PARQUET - 528 : Fix flush ( ) for RecordConsumer and implementations `flush ( ) ` was added in `RecordConsumer` and `MessageColumnIO` to help implementing nulls caching . However , other `RecordConsumer` implementations should also implements `flush ( ) ` properly . For instance , `RecordConsumerLoggingWrapper` and `ValidatingRecordConsumer` should call `delegate . flush ( ) ` in their `flush ( ) ` methods , otherwise data might be mistakenly truncated . This PR : - makes `flush ( ) ` abstract in `RecordConsumer` - implements `flush ( ) ` properly for all `RecordConsumer` subclasses , specifically : - `RecordConsumerLoggingWrapper` - `ValidatingRecordConsumer` - `ConverterConsumer ` - `ExpectationValidatingRecordConsumer ` Author : proflin < proflin . me @ gmail . com > Author : Liwei Lin < proflin . me @ gmail . com > Closes #325 from proflin / PARQUET - 528 and squashes the following commits : 2c90740 [ proflin ] Minor style issue 25444b9 [ proflin ] Still keep RecordConsumer . flush ( ) non - abstract 8776e3a [ proflin ] PARQUET - 528 : Fix flush ( ) for RecordConsumer and implementations bb4283a [ Liwei Lin ] Merge branch 'master' of https : / / github . com / proflin / parquet - mr 839b458 [ proflin ] Merge remote - tracking branch 'refs / remotes / apache / master'",33,1,"parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/io/RecordConsumerLoggingWrapper.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/io/ValidatingRecordConsumer.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/io/api/RecordConsumer.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/io/ConverterConsumer.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/io/ExpectationValidatingRecordConsumer.java,CAS_DELIMITER",6,1,3,2.366012105574433,28,214.5,12,244.37855324074076,5.0,4.578303567667869,3.0,None,FALSE,FALSE,
fb46b941f7763314d667c437c06b1675e61c3d38,Daniel Weeks,dweeks@netflix.com,Fri Feb 26 10:28:07 2016 -0800,1456511287,PARQUET - 397 : Implement Pig predicate pushdown This is based on #296 from @ danielcweeks and implements a few remaining review items . Closes #296 . Author : Daniel Weeks < dweeks @ netflix . com > Author : Ryan Blue < blue @ apache . org > Closes #331 from rdblue / PARQUET - 397 - pig - predicate - pushdown and squashes the following commits : c7a9b02 [ Ryan Blue ] PARQUET - 397 : Address review comments . 54e23a6 [ Ryan Blue ] PARQUET - 397 : Update Pig PPD to throw for bad expressions . 388099b [ Daniel Weeks ] Cleaning up imports 6b405b4 [ Daniel Weeks ] Merge remote - tracking branch 'rdblue / pig - predicate - pushdown' into pig - predicate - pushdown f1ef73e [ Daniel Weeks ] Fixed binary type and storing filter predicate a39fdff [ Ryan Blue ] WIP : Handle a few error cases in Pig predicate pushdown . 2666849 [ Daniel Weeks ] Fixed test to check the actual number of materialized rows from the reader 7b019a6 [ Daniel Weeks ] update tests and logging f8ca447 [ Daniel Weeks ] Add predicate pushdown using filter2 api,230,13,"parquet-pig/src/main/java/org/apache/parquet/pig/ParquetLoader.java,CAS_DELIMITER,parquet-pig/src/test/java/org/apache/parquet/pig/TestParquetLoader.java,CAS_DELIMITER",2,1,2,0.7858895831387682,27,364.5,3,154.7318402777778,13.0,5.528451595037202,8.0,None,FALSE,FALSE,
c44f982e89b63a97190638cd12bd8bee2bafb883,proflin,proflin.me@gmail.com,Sun Feb 21 18:36:50 2016 -0800,1456108610,"PARQUET - 529 : Avoid evoking job . toString ( ) in ParquetLoader When ran under hadoop2 environment and log level setting to `DEBUG` , ParquetLoader would evoke `job . toString ( ) ` in several methods , which might cause the whole application to stop due to : ``` java . lang . IllegalStateException : Job in state DEFINE instead of RUNNING at org . apache . hadoop . mapreduce . Job . ensureState ( Job . java : 283 ) at org . apache . hadoop . mapreduce . Job . toString ( Job . java : 452 ) at java . lang . String . valueOf ( String . java : 2847 ) at java . lang . StringBuilder . append ( StringBuilder . java : 128 ) at org . apache . parquet . pig . ParquetLoader . getSchema ( ParquetLoader . java : 260 ) at org . apache . parquet . pig . TestParquetLoader . testSchema ( TestParquetLoader . java : 54 ) . . . ``` The reason is that in the hadoop 2 . x branch , `org . apache . hadoop . mapreduce . Job . toString ( ) ` has added an `ensureState ( JobState . RUNNING ) ` check ; see [ map - reduce : Job . java#452 ] ( http : / / grepcode . com / file / repo1 . maven . org / maven2 / org . apache . hadoop / hadoop - mapreduce - client - core / 2 . 3 . 0 / org / apache / hadoop / mapreduce / Job . java#452 ) . In contrast , the hadoop 1 . x branch does not contain such checks , so `ParquetLoader` works well . This PR simply avoids evoking `job . toString ( ) ` in `ParquetLoader` . Author : proflin < proflin . me @ gmail . com > Author : Liwei Lin < proflin . me @ gmail . com > Closes #326 from proflin / PARQUET - 529 - - Avoid - evoking - job . toString ( ) - in - ParquetLoader and squashes the following commits : f464c7b [ proflin ] Add jobToString 5d4c750 [ proflin ] PARQUET - 529 : Avoid evoking job . toString ( ) in ParquetLoader . java bb4283a [ Liwei Lin ] Merge branch 'master' of https : / / github . com / proflin / parquet - mr 839b458 [ proflin ] Merge remote - tracking branch 'refs / remotes / apache / master'",16,4,"parquet-pig/src/main/java/org/apache/parquet/pig/ParquetLoader.java,CAS_DELIMITER",1,1,1,0.0,27,383.0,1,300.1424537037037,4.0,3.7253394205052244,0.0,None,FALSE,FALSE,
944291b748bcfec4e2f3c17623884db7a17b9f21,Liwei Lin,proflin.me@gmail.com,Mon Feb 15 16:37:04 2016 -0800,1455583024,"PARQUET - 431 : Make ParquetOutputFormat . memoryManager volatile Currently ParquetOutputFormat . getRecordWriter ( ) contains an unsynchronized lazy initialization of the non - volatile static field * memoryManager * . Because the compiler or processor may reorder instructions , threads are not guaranteed to see a completely initialized object , when ParquetOutputFormat . getRecordWriter ( ) is called by multiple threads . This PR makes * memoryManager * volatile to correct the problem . Author : Liwei Lin < proflin . me @ gmail . com > Author : proflin < proflin . me @ gmail . com > Closes #313 from proflin / PARQUET - 431 and squashes the following commits : 1aa4a44 [ Liwei Lin ] empty commit to trigger CI 5e94fa3 [ Liwei Lin ] Remove the volatile modifier for memoryManager d54bb99 [ Liwei Lin ] Undo the Deprecated anotation fd1df4e [ Liwei Lin ] Adds synchronization around the creation of memoryManager as well as getMemoryManager ( ) 615aa5a [ proflin ] PARQUET - 431",7,5,"parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER",1,1,1,0.0,31,453.0,7,66.13888888888889,1.0,0.9623769685760238,0.0,None,FALSE,FALSE,
6c9ca4d4c0de4dff29b79f28ac5c51b4f6fed0da,proflin,proflin.me@gmail.com,Mon Feb 15 16:35:33 2016 -0800,1455582933,"PARQUET - 430 : Change to use Locale parameterized version of String . toUpperCase ( ) / toLowerCase A String is being converted to upper or lowercase , using the platform's default encoding . This may result in improper conversions when used with international characters . For instance , ""TITLE"" . toLowerCase ( ) in a Turkish locale returns ""tıtle"" , where 'ı' - - without a dot - - is the LATIN SMALL LETTER DOTLESS I character . To obtain correct results for locale insensitive strings , we'd better use toLowerCase ( Locale . ENGLISH ) . For more information on this , please see : - http : / / stackoverflow . com / questions / 11063102 / using - locales - with - javas - tolowercase - and - touppercase - http : / / lotusnotus . com / lotusnotus en . nsf / dx / dotless - i - tolowercase - and - touppercase - functions - use - responsibly . htm - http : / / java . sys - con . com / node / 46241 This PR changes our use of String . toUpperCase ( ) / toLowerCase ( ) to String . toUpperCase ( Locale . * ENGLISH * ) / toLowerCase ( * Locale . ENGLISH * ) Author : proflin < proflin . me @ gmail . com > Closes #312 from proflin / PARQUET - 430 and squashes the following commits : ed55822 [ proflin ] PARQUET - 430",15,9,"parquet-column/src/main/java/org/apache/parquet/filter2/predicate/Operators.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/schema/GroupType.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/schema/MessageTypeParser.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/CompressionCodecName.java,CAS_DELIMITER",5,2,3,2.1829316468984663,31,355.4,11,157.69689351851852,3.0,2.7841670636776312,1.5,None,FALSE,FALSE,
c26fa78817f30cc3eb91165b783e07fb80d80f59,Cheng Lian,lian@databricks.com,Sat Feb 6 11:57:19 2016 -0800,1454788639,"PARQUET - 385 PARQUET - 379 : Fixes strict schema merging This PR fixes strict mode schema merging . To merge two `PrimitiveType` `t1` and `t2` , they must satisfy the following conditions : 1 . `t1` and `t2` have the same primitive type name 1 . `t1` and `t2` either - don't have original type , or - have the same original type 1 . If `t1` and `t2` are both `FIXED LEN BYTE ARRAY` , they should have the same length Also , merged schema now preserves original name if there's any . Author : Cheng Lian < lian @ databricks . com > Closes #315 from liancheng / fix - strict - schema - merge and squashes the following commits : a29138c [ Cheng Lian ] Addresses PR comment 1ac804e [ Cheng Lian ] Fixes strict schema merging",59,12,"parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/schema/TestMessageType.java,CAS_DELIMITER",2,1,2,0.9998568991526107,31,339.0,6,121.00954282407409,5.0,2.5409714553963823,0.0,None,FALSE,FALSE,
a4acf53336a482f50335d33b4f650a70c9243b7b,Nezih Yigitbasi,nyigitbasi@netflix.com,Sat Feb 6 11:41:21 2016 -0800,1454787681,PARQUET - 509 : Fix args passed to string format calls This PR fixes the args passed to the `String . format ( ) ` call . Author : Nezih Yigitbasi < nyigitbasi @ netflix . com > Closes #320 from nezihyigitbasi / debug args and squashes the following commits : 43a6088 [ Nezih Yigitbasi ] Fix args passed to string format calls,2,2,"parquet-hadoop/src/main/java/org/apache/parquet/hadoop/DirectCodecFactory.java,CAS_DELIMITER",1,1,1,0.0,31,522.0,1,94.10291666666667,6.0,4.017529457286891,3.0,None,FALSE,FALSE,
0a711ebcec7d32b66ab3c90b2a1f48681201e557,Ryan Blue,blue@apache.org,Wed Feb 3 12:45:27 2016 -0800,1454532327,PARQUET - 415 : Fix ByteBuffer Binary serialization . This also adds a test to validate that serialization works for all Binary objects that are already test cases . Author : Ryan Blue < blue @ apache . org > Closes #305 from rdblue / PARQUET - 415 - fix - bytebuffer - binary - serialization and squashes the following commits : 4e75d54 [ Ryan Blue ] PARQUET - 415 : Fix ByteBuffer Binary serialization .,26,3,"parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/io/api/TestBinary.java,CAS_DELIMITER",2,1,2,0.8497511372532974,31,456.0,5,91.14743055555556,81.0,42.039713467381226,35.0,None,FALSE,FALSE,
57694790f8ca0e1a4f3ac76fbd25a6dd13041e03,Cyrille Chu00c3u00a9pu00c3u00a9lov (TP12),cch@transparencyrights.com,Sun Jan 31 19:21:48 2016 -0800,1454296908,"PARQUET - 480 : Update for Cascading 3 . 0 The code in parquet - cascading is adapted to the API as of Cascading 2 . 5 . 3 Some incompatible changes were introduced in Cascading 3 . 0 . This patch forks the parquet - cascading module to also provide a parquet - cascading3 module , which is about identical save for overloads which changed from requiring a Foo < JobConf > to requiring a Foo < ? extends JobConf > Author : Cyrille Chépélov ( TP12 ) < cch @ transparencyrights . com > Closes #284 from cchepelov / try cascading3 and squashes the following commits : e7d1304 [ Cyrille Chépélov ( TP12 ) ] Adding a @ Deprecated notice on parquet - cascading's remaining classes 05a417d [ Cyrille Chépélov ( TP12 ) ] cascading2 / 3 : share back TupleWriteSupport . java ( accidentally unmerged ) 7fff2d4 [ Cyrille Chépélov ( TP12 ) ] cascading / cascading3 : remove duplicates , push common files into parquet - cascading - common23 338a416 [ Cyrille Chépélov ( TP12 ) ] Removing unwanted file ( what ? ! ) + . gitignoring this kind of files d9f0455 [ Cyrille Chépélov ( TP12 ) ] TupleEntry#get is now TupleEntry#getObject a7f490a [ Cyrille Chépélov ( TP12 ) ] Revert ""Missing test conversion to Cascading 3 . 0"" cc8b870 [ Cyrille Chépélov ( TP12 ) ] Missing test conversion to Cascading 3 . 0 2d73512 [ Cyrille Chépélov ( TP12 ) ] conflicting values can come in one order or the other . Accept both . 33355d5 [ Cyrille Chépélov ( TP12 ) ] Fix version mismatch ( duh! ) 7128639 [ Cyrille Chépélov ( TP12 ) ] non - C locale can break tests implementation ( decimal formats ) 53aa2f9 [ Cyrille Chépélov ( TP12 ) ] Adding a parquet - cascading3 module ( forking the parquet - cascading module and accounting for API changes )",654,3,"parquet-cascading-common23/src/main/java/org/apache/parquet/cascading/SchemaIntersection.java,CAS_DELIMITER,parquet-cascading-common23/src/main/java/org/apache/parquet/cascading/TupleReadSupport.java,CAS_DELIMITER,parquet-cascading-common23/src/main/java/org/apache/parquet/cascading/TupleWriteSupport.java,CAS_DELIMITER,parquet-cascading-common23/src/main/java/org/apache/parquet/cascading/convert/TupleConverter.java,CAS_DELIMITER,parquet-cascading-common23/src/main/java/org/apache/parquet/cascading/convert/TupleRecordMaterializer.java,CAS_DELIMITER,parquet-cascading-common23/src/test/java/org/apache/parquet/cascading/TestParquetTupleScheme.java,CAS_DELIMITER,parquet-cascading/src/main/java/org/apache/parquet/cascading/ParquetTBaseScheme.java,CAS_DELIMITER,parquet-cascading/src/main/java/org/apache/parquet/cascading/ParquetTupleScheme.java,CAS_DELIMITER,parquet-cascading/src/main/java/org/apache/parquet/cascading/ParquetValueScheme.java,CAS_DELIMITER,parquet-cascading/src/test/java/org/apache/parquet/cascading/TestParquetTBaseScheme.java,CAS_DELIMITER,parquet-cascading3/src/main/java/org/apache/parquet/cascading/ParquetTBaseScheme.java,CAS_DELIMITER,parquet-cascading3/src/main/java/org/apache/parquet/cascading/ParquetTupleScheme.java,CAS_DELIMITER,parquet-cascading3/src/main/java/org/apache/parquet/cascading/ParquetValueScheme.java,CAS_DELIMITER,parquet-cascading3/src/test/java/org/apache/parquet/cascading/TestParquetTBaseScheme.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMergeMetadataFiles.java,CAS_DELIMITER",15,4,8,2.087852663857431,29,57.06666666666667,6,81.5877160493827,0.0,0.0,0.0,None,FALSE,FALSE,
af9fd052d1c208f191fbdf85873f965552465598,proflin,proflin.me@gmail.com,Fri Jan 29 11:38:34 2016 -0800,1454096314,"PARQUET - 432 : Complete a todo for method ColumnDescriptor . compareTo ( ) The ticket proposes to consider the case * path . length < o . path . length * in , for method ColumnDescriptor . compareTo ( ) . Author : proflin < proflin . me @ gmail . com > Closes #314 from proflin / PARQUET - 432 and squashes the following commits : 80ba94b [ proflin ] Addresses PR comments 6ccd00f [ proflin ] Revert Updates a4d2a4a [ proflin ] PARQUET - 432 : Complete a todo in method ColumnDescriptor . compareTo ( ) 694b76b [ proflin ] Updates",55,3,"parquet-column/src/main/java/org/apache/parquet/column/ColumnDescriptor.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/TestColumnDescriptor.java,CAS_DELIMITER",2,1,2,0.4798320236161285,28,67.0,2,110.50032986111111,2.0,1.9116025665065337,1.0,None,FALSE,FALSE,
c38386d6b5622915a2d42d989c56d37f17c673d6,Ryan Blue,blue@apache.org,Thu Jan 28 17:33:08 2016 -0800,1454031188,PARQUET - 393 : Update to parquet - format 2 . 3 . 1 . Author : Ryan Blue < blue @ apache . org > Closes #303 from rdblue / PARQUET - 393 - update - parquet - format - version and squashes the following commits : 0e4c798 [ Ryan Blue ] PARQUET - 393 : Add TIME MICROS and TIMESTAMP MICROS . ca4a741 [ Ryan Blue ] PARQUET - 393 : Update to parquet - format 2 . 3 . 1 .,14,3,"parquet-column/src/main/java/org/apache/parquet/schema/OriginalType.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/schema/Types.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuilders.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER",4,2,3,1.7033848993102918,31,885.0,13,159.9305005787037,80.0,41.42895609575599,33.0,None,FALSE,FALSE,
30ee10d2740fe1f28595989c6b21f22b75a147fc,proflin,proflin.me@gmail.com,Tue Jan 12 14:45:24 2016 -0800,1452638724,"PARQUET - 422 : Fix a potential bug in MessageTypeParser where we ignore… … and overwrite the initial value of a method parameter In org . apache . parquet . schema . MessageTypeParser , for addGroupType ( ) and addPrimitiveType ( ) , the initial value of this parameter t is ignored , and t is overwritten here . This often indicates a mistaken belief that the write to the parameter will be conveyed back to the caller . This is a bug found by FindBugs™ . Author : proflin < proflin . me @ gmail . com > Closes #308 from proflin / PARQUET - 422 and squashes the following commits : df1f908 [ proflin ] PARQUET - 422 : Fix a potential bug in MessageTypeParser where we ignore and overwrite the initial value of a method parameter",6,4,"parquet-column/src/main/java/org/apache/parquet/schema/MessageTypeParser.java,CAS_DELIMITER",1,1,1,0.0,27,216.0,1,259.9817361111111,1.0,0.9999545936397105,0.0,None,FALSE,FALSE,
84b2b74179da8e279e2fafdafd031748c285e1b7,proflin,proflin.me@gmail.com,Tue Jan 12 14:21:32 2016 -0800,1452637292,"PARQUET - 421 : Fix mismatch of javadoc names and method parameters in m . . . …odule encoding , column , and hadoop Codes change now and then , but some corresponding doc comments are left out . This PR fixes only the doc comments that should have been changed . It should be OK , since none codes are touched . @ rdblue could you take a look please ? Cheers . Author : proflin < proflin . me @ gmail . com > Closes #307 from proflin / Minor - - Fix - the - mismatch - of - the - parameters - and - their - doc - comments - in - module - encoding , - column , - and - hadoop and squashes the following commits : 34c7b01 [ proflin ] Minor : Fix the mismatch of the parameters and their doc comments in module encoding , column , and hadoop",16,17,"parquet-column/src/main/java/org/apache/parquet/column/page/DataPageV1.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/ValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/plain/BooleanPlainValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/schema/TypeConverter.java,CAS_DELIMITER,parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BitPacking.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleOutputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ParquetMetadata.java,CAS_DELIMITER",7,3,7,2.3530988492635023,31,184.0,10,172.19998677248677,0.0,0.0,0.0,None,FALSE,FALSE,
37f72dc079c4cd69b2de16f3532b55f8108d3ac8,Ryan Blue,blue@apache.org,Tue Jan 12 14:15:40 2016 -0800,1452636940,"PARQUET - 212 : Implement LIST read compatibility rules in Thrift This implements the read - side compatibility rules for 2 - level and 3 - level lists in Thrift . Thrift doesn't allow null elements inside lists , but 3 - level lists may have optional elements . This PR adds a property , parquet . thrift . ignore - null - elements , that allows thrift to read lists with optional elements by ignoring nulls . This is off by default , but is provided as an opt - in for compatibility with data written by Hive . Thrift's schema conversion does not change because a Thrift class ( or Scrooge etc . ) must be set in a file's metadata or provided when constructing a reader . This replaces and closes #144 . Author : Ryan Blue < blue @ apache . org > Closes #300 from rdblue / PARQUET - 212 - fix - thrift - 3 - level - lists and squashes the following commits : ac7c405 [ Ryan Blue ] PARQUET - 212 : Add tests for list of list cases from PARQUET - 364 . 356fdb7 [ Ryan Blue ] PARQUET - 212 : Rename isElementType = > isListElementType . 5d3b094 [ Ryan Blue ] PARQUET - 212 : Fix list handling with projection . b5f207f [ Ryan Blue ] PARQUET - 212 : Add Configuration to the ThriftRecordConverter ctor . b87eb65 [ Ryan Blue ] PARQUET - 212 : Add property to ignore nulls in lists . 3d1e92f [ Ryan Blue ] PARQUET - 212 : Update thrift reads for LIST compatibility rules . 0bf2b45 [ Ryan Blue ] PARQUET - 212 : Read non - thrift files if a Thrift class is supplied . 4e148dc [ Ryan Blue ] PARQUET - 212 : Add DirectWriterTest base class .",1126,114,"parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordConverter.java,CAS_DELIMITER,parquet-avro/src/test/java/org/apache/parquet/avro/TestArrayCompatibility.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/DirectWriterTest.java,CAS_DELIMITER,parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeRecordConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftReadSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/TBaseRecordConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftMetaData.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftRecordConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConverter.java,CAS_DELIMITER,parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestArrayCompatibility.java,CAS_DELIMITER",10,4,7,1.9700863134358513,28,357.3,23,131.15857407407407,79.0,41.50908345109521,16.75,None,FALSE,TRUE,
368588b5c5c4140f39ea8b9a8ceb3d1af0708804,Ryan Blue,blue@apache.org,Thu Jan 7 10:48:02 2016 -0600,1452185282,PARQUET - 413 : Fix Java 8 test failure . The footer merge tests rely the order of unmergable values . This uses a LinkedHashSet to ensure the order doesn't change . Author : Ryan Blue < blue @ apache . org > Closes #304 from rdblue / PARQUET - 413 - java - 8 - test - failure and squashes the following commits : 57a83a8 [ Ryan Blue ] PARQUET - 413 : Fix Java 8 test failure .,2,1,"parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER",1,1,1,0.0,31,903.0,10,29.751550925925926,78.0,40.85798833733654,30.0,None,FALSE,FALSE,
367fe13b46a0b4dda56b7f12273d6c9afb1da23f,Nezih Yigitbasi,nyigitbasi@netflix.com,Wed Dec 16 11:41:46 2015 -0800,1450294906,PARQUET - 318 : Remove unnecessary object mapper Author : Nezih Yigitbasi < nyigitbasi @ netflix . com > Closes #227 from nezihyigitbasi / 318 and squashes the following commits : b8e4ca9 [ Nezih Yigitbasi ] Remove unnecessary object mapper,21,10,"parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/ParquetMetadata.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java,CAS_DELIMITER",2,1,2,0.9629004147713269,28,228.0,5,200.3465914351852,5.0,3.4545079092031683,2.0,None,FALSE,FALSE,
fa7588c4c0f8d403e4815fa72e3b8a3bc98d73ec,Thomas Friedrich,tfriedr@us.ibm.com,Sat Dec 12 15:35:21 2015 -0800,1449963321,"PARQUET - 334 : UT test failure with Pig 0 . 15 I made a few updates to the original patch PARQUET - 334 - 1 . patch proposed by Daniel . As the inputschema is maintained in EvalFunc , any reference to the private class variable inputSchema should be changed to getInputSchema ( ) , and inputSchema can be removed because it will be null always . Author : Thomas Friedrich < tfriedr @ us . ibm . com > Closes #292 from tfriedr / parquet - 334 and squashes the following commits : 012563e [ Thomas Friedrich ] PARQUET 334 : UT test failure with Pig 0 . 15",2,54,"parquet-pig/src/main/java/org/apache/parquet/pig/summary/Summary.java,CAS_DELIMITER",1,1,1,0.0,27,283.0,1,229.01642361111112,1.0,0.6922876464830148,0.0,None,FALSE,FALSE,
49169033546d893dae3db903a2fa6af712f125c0,Ryan Blue,blue@apache.org,Fri Dec 11 13:17:04 2015 -0800,1449868624,"PARQUET - 353 : Release compression resources . This updates the use of CodecFactory in the output format and writer classes so that its lifecycle is tied to ParquetWriter and ParquetRecordWriter . When those classes are closed , the resources held by the CodecFactory associated with the instance are released . This is an alternative to and closes #282 . Author : Ryan Blue < blue @ apache . org > Closes #295 from rdblue / PARQUET - 353 - release - compressor - resources and squashes the following commits : a00f4b7 [ Ryan Blue ] PARQUET - 353 : Release compression resources .",43,25,"parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java,CAS_DELIMITER",3,1,1,1.0454449699285235,31,372.0,16,2.941273148148148,77.0,41.67582567206861,29.0,None,FALSE,FALSE,
efa48b214d30537bb184884ea30ce817bb350153,Ryan Blue,blue@apache.org,Tue Dec 8 14:45:48 2015 -0800,1449614748,"PARQUET - 382 : Add methods to append encoded data to files . This allows appending encoded data blocks to open ParquetFileWriters , which makes it possible to merge multiple Parquet files without re - encoding all of the records . This works by finding the column chunk for each column in the file schema and then streaming the encoded data from one file to the other . New starting offsets are tracked and the column chunk metadata in the footer is updated with the new starting positions . Author : Ryan Blue < blue @ apache . org > Closes #278 from rdblue / PARQUET - 382 - append - encoded - blocks and squashes the following commits : cb98552 [ Ryan Blue ] PARQUET - 382 : Add methods to append encoded data to files .",468,11,"parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterAppendBlocks.java,CAS_DELIMITER",3,1,2,1.0424280131057577,35,784.6666666666666,33,-117.49221450617284,112.0,102.51528354127895,52.0,None,FALSE,TRUE,
b45c4bdb496381b5f90df6872edca12e0a2e68ca,Ryan Blue,blue@apache.org,Tue Dec 8 14:45:48 2015 -0800,1449614748,"PARQUET - 382 : Add methods to append encoded data to files . This allows appending encoded data blocks to open ParquetFileWriters , which makes it possible to merge multiple Parquet files without re - encoding all of the records . This works by finding the column chunk for each column in the file schema and then streaming the encoded data from one file to the other . New starting offsets are tracked and the column chunk metadata in the footer is updated with the new starting positions . Author : Ryan Blue < blue @ apache . org > Closes #278 from rdblue / PARQUET - 382 - append - encoded - blocks and squashes the following commits : cb98552 [ Ryan Blue ] PARQUET - 382 : Add methods to append encoded data to files .",468,11,"parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterAppendBlocks.java,CAS_DELIMITER",3,1,2,1.0424280131057577,31,533.3333333333334,15,22.820671296296297,76.0,40.877885900908915,28.0,None,FALSE,TRUE,
1a5e5c6802a920cd8e379de0552dd289f680fa56,Daniel Weeks,dweeks@netflix.com,Tue Dec 8 14:41:38 2015 -0800,1449614498,"PARQUET - 99 : Add page size check properties This adds properties to set the min and max number of records that are passed between page checks , as well as a property that controls whether the next check will be based on records already seen or set to the minimum number of records between checks . * `parquet . page . size . row . check . min` - minimum number of records between page size checks * `parquet . page . size . row . check . max` - maximum number of records between page size checks * `parquet . page . size . check . estimate` - whether to estimate the number of records before the next check , or to always use the minimum number of records . This also updates the internal API to use ParquetProperties to carry encoding settings ( used in parquet - column ) to reduce the number of parameters passed through internal APIs . It also adds a builder for ParquetProperties to avoid needing to reference defaults in other modules . This closes #250 Author : Daniel Weeks < dweeks @ netflix . com > Author : Ryan Blue < blue @ apache . org > Closes #297 from rdblue / parquet - properties - update and squashes the following commits : c93b73e [ Ryan Blue ] PARQUET - 99 : Use ParquetProperties to carry encoding config . 18f8d3a [ Daniel Weeks ] Spacing 2090719 [ Daniel Weeks ] Update sizeCheck to write page properly if estimating is turned off 71336ee [ Daniel Weeks ] Fixed param name 5d99072 [ Daniel Weeks ] Update page size checking for v2 writer 3f7870c [ Daniel Weeks ] Rebase to resolve byte buffer conflicts 68794f0 [ Daniel Weeks ] Merge branch 'master' into page size check b49f03c [ Daniel Weeks ] Fixed reset of nextSizeCheck a057f46 [ Daniel Weeks ] Fixed inverted property logic e7cd54b [ Daniel Weeks ] Added property to toggle page size check estimation and initial row size checking Conflicts : parquet - column / src / main / java / org / apache / parquet / column / ParquetProperties . java parquet - column / src / main / java / org / apache / parquet / column / impl / ColumnWriteStoreV1 . java parquet - column / src / main / java / org / apache / parquet / column / impl / ColumnWriteStoreV2 . java parquet - column / src / main / java / org / apache / parquet / column / impl / ColumnWriterV1 . java parquet - column / src / main / java / org / apache / parquet / column / impl / ColumnWriterV2 . java parquet - column / src / test / java / org / apache / parquet / column / impl / TestCorruptDeltaByteArrays . java parquet - column / src / test / java / org / apache / parquet / column / mem / TestMemColumn . java parquet - column / src / test / java / org / apache / parquet / io / PerfTest . java parquet - column / src / test / java / org / apache / parquet / io / TestColumnIO . java parquet - column / src / test / java / org / apache / parquet / io / TestFiltered . java parquet - hadoop / src / main / java / org / apache / parquet / hadoop / InternalParquetRecordWriter . java parquet - hadoop / src / main / java / org / apache / parquet / hadoop / ParquetOutputFormat . java parquet - hadoop / src / main / java / org / apache / parquet / hadoop / ParquetRecordWriter . java parquet - hadoop / src / main / java / org / apache / parquet / hadoop / ParquetWriter . java parquet - pig / src / test / java / org / apache / parquet / pig / TupleConsumerPerfTest . java parquet - thrift / src / test / java / org / apache / parquet / thrift / TestParquetReadProtocol . java Resolution : Fixed changes that depended on the addition of an allocator argument Ignored adjacent changes that were flagged Passed page size at compressor instantiation instead of to the factory",439,200,"parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV1.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV2.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV1.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV2.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/impl/TestColumnReaderImpl.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/impl/TestCorruptDeltaByteArrays.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/mem/TestMemColumn.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/io/PerfTest.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/io/TestColumnIO.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/io/TestFiltered.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnChunkPageWriteStore.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestUtils.java,CAS_DELIMITER,parquet-pig/src/test/java/org/apache/parquet/pig/TupleConsumerPerfTest.java,CAS_DELIMITER,parquet-thrift/src/test/java/org/apache/parquet/thrift/TestParquetReadProtocol.java,CAS_DELIMITER",20,4,9,3.2962265775558737,35,258.9,107,-104.91423784722221,14.0,7.434084404216572,4.5,None,FALSE,TRUE,
56326400fcb5df7bd9336f143f7a3b7d601e5f58,Daniel Weeks,dweeks@netflix.com,Tue Dec 8 14:41:38 2015 -0800,1449614498,"PARQUET - 99 : Add page size check properties This adds properties to set the min and max number of records that are passed between page checks , as well as a property that controls whether the next check will be based on records already seen or set to the minimum number of records between checks . * `parquet . page . size . row . check . min` - minimum number of records between page size checks * `parquet . page . size . row . check . max` - maximum number of records between page size checks * `parquet . page . size . check . estimate` - whether to estimate the number of records before the next check , or to always use the minimum number of records . This also updates the internal API to use ParquetProperties to carry encoding settings ( used in parquet - column ) to reduce the number of parameters passed through internal APIs . It also adds a builder for ParquetProperties to avoid needing to reference defaults in other modules . This closes #250 Author : Daniel Weeks < dweeks @ netflix . com > Author : Ryan Blue < blue @ apache . org > Closes #297 from rdblue / parquet - properties - update and squashes the following commits : c93b73e [ Ryan Blue ] PARQUET - 99 : Use ParquetProperties to carry encoding config . 18f8d3a [ Daniel Weeks ] Spacing 2090719 [ Daniel Weeks ] Update sizeCheck to write page properly if estimating is turned off 71336ee [ Daniel Weeks ] Fixed param name 5d99072 [ Daniel Weeks ] Update page size checking for v2 writer 3f7870c [ Daniel Weeks ] Rebase to resolve byte buffer conflicts 68794f0 [ Daniel Weeks ] Merge branch 'master' into page size check b49f03c [ Daniel Weeks ] Fixed reset of nextSizeCheck a057f46 [ Daniel Weeks ] Fixed inverted property logic e7cd54b [ Daniel Weeks ] Added property to toggle page size check estimation and initial row size checking",435,216,"parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV1.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriteStoreV2.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV1.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnWriterV2.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/impl/TestColumnReaderImpl.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/impl/TestCorruptDeltaByteArrays.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/mem/TestMemColumn.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/io/PerfTest.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/io/TestColumnIO.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/io/TestFiltered.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestUtils.java,CAS_DELIMITER,parquet-pig/src/test/java/org/apache/parquet/pig/TupleConsumerPerfTest.java,CAS_DELIMITER,parquet-thrift/src/test/java/org/apache/parquet/thrift/TestParquetReadProtocol.java,CAS_DELIMITER",18,4,9,3.232152416540714,31,253.05555555555554,52,33.43391782407408,12.0,5.154173290179681,3.25,None,FALSE,TRUE,
a24d624aaabc14a455d18450d9127f88d1b4f8be,Ryan Blue,blue@apache.org,Tue Dec 8 10:39:47 2015 -0800,1449599987,"PARQUET - 305 : Update logging to SLF4J . This removes the Log implementation based on java . util . logging and replaces it with SLF4J . The compiler removal of debug log messages still works because Log . DEBUG and similar final constants are unchanged . This commit adds slf4j - simple as the test logger implementation . Configuration for slf4j - simple is in the root pom . Two modules can't use slf4j - simple , parquet - pig and parquet - thrift , and use slf4j - log4j12 instead because pig depends on log4j and tests die without it . Author : Ryan Blue < blue @ apache . org > Closes #290 from rdblue / PARQUET - 305 - update - logging and squashes the following commits : 89257e8 [ Ryan Blue ] PARQUET - 305 : Remove deprecation annotations on Log . 9f9b99a [ Ryan Blue ] PARQUET - 305 : Update logging to SLF4J .",15,72,"parquet-common/src/main/java/org/apache/parquet/Log.java,CAS_DELIMITER",1,1,1,0.0,27,206.0,1,224.81116898148147,75.0,39.889232523269435,8.0,None,FALSE,FALSE,
dcd1c33f0dba247b43418b922c1c3a2fc432dc11,Ryan Blue,blue@apache.org,Tue Dec 8 10:15:30 2015 -0800,1449598530,PARQUET - 352 : Add object model property to file footers . WriteSupport now has a getName getter method that is added to the footer if it returns a non - null string as writer . model . name . This is intended to help identify files written by object models incorrectly . Author : Ryan Blue < blue @ apache . org > Closes #289 from rdblue / PARQUET - 352 - add - object - model - property and squashes the following commits : 23f8f67 [ Ryan Blue ] PARQUET - 352 : Add object model property to file footers .,76,0,"parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java,CAS_DELIMITER,parquet-cascading/src/main/java/org/apache/parquet/cascading/TupleWriteSupport.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/DelegatingWriteSupport.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/WriteSupport.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/GroupWriteSupport.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriter.java,CAS_DELIMITER,parquet-pig/src/main/java/org/apache/parquet/pig/TupleWriteSupport.java,CAS_DELIMITER,parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java,CAS_DELIMITER,parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeWriteSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/TBaseWriteSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftBytesWriteSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftWriteSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/pig/TupleToThriftWriteSupport.java,CAS_DELIMITER",15,7,11,3.807394845948556,31,187.06666666666666,35,143.02296682098768,74.0,38.890306675867265,9.571428571428571,None,FALSE,TRUE,
c3936baa95fdf419754a544dd1810b107ea1616a,Ryan Blue,blue@apache.org,Tue Dec 8 10:15:30 2015 -0800,1449598530,PARQUET - 352 : Add object model property to file footers . WriteSupport now has a getName getter method that is added to the footer if it returns a non - null string as writer . model . name . This is intended to help identify files written by object models incorrectly . Author : Ryan Blue < blue @ apache . org > Closes #289 from rdblue / PARQUET - 352 - add - object - model - property and squashes the following commits : 23f8f67 [ Ryan Blue ] PARQUET - 352 : Add object model property to file footers .,76,0,"parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java,CAS_DELIMITER,parquet-cascading/src/main/java/org/apache/parquet/cascading/TupleWriteSupport.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/DelegatingWriteSupport.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/api/WriteSupport.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/GroupWriteSupport.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriter.java,CAS_DELIMITER,parquet-pig/src/main/java/org/apache/parquet/pig/TupleWriteSupport.java,CAS_DELIMITER,parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java,CAS_DELIMITER,parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeWriteSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/TBaseWriteSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftBytesWriteSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftWriteSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/pig/TupleToThriftWriteSupport.java,CAS_DELIMITER",15,7,11,3.807394845948556,35,202.73333333333332,64,-26.564852623456787,106.0,96.292734934846,14.714285714285714,None,FALSE,TRUE,
f2615d9a611db401cdedc022112c87ad938b5680,Reuben Kuhnert,reuben.kuhnert@cloudera.com,Tue Dec 8 10:02:31 2015 -0800,1449597751,PARQUET - 349 : VersionParser does not handle versions missing 'build' section This change reworks the regular expression in VersionParser . java to allow for missing 'version' and 'build' sections . Author : Reuben Kuhnert < reuben . kuhnert @ cloudera . com > Closes #283 from sircodesalotOfTheRound / fix - version - test and squashes the following commits : 0f4a22f [ Reuben Kuhnert ] PARQUET - 349 : VersionParser does not handle versions missing 'build' section .,20,3,"parquet-common/src/main/java/org/apache/parquet/VersionParser.java,CAS_DELIMITER,parquet-common/src/test/java/org/apache/parquet/VersionTest.java,CAS_DELIMITER",2,1,2,0.828055725379504,28,107.5,5,152.02962962962962,1.0,0.8186996227533073,0.0,None,FALSE,FALSE,
14097c64d243794610788d3ebb2e81ba8fd867c0,Ryan Blue,blue@apache.org,Fri Dec 4 11:47:38 2015 -0800,1449258458,"PARQUET - 387 : Improve NPE message when avro arrays contain null . Previously , the NPE had no error message but the Avro support accepts schemas that have nullable array elements . Author : Ryan Blue < blue @ apache . org > Closes #291 from rdblue / PARQUET - 387 - fix - npe - message and squashes the following commits : 39d3c83 [ Ryan Blue ] PARQUET - 387 : Update test case to verify help message . d6b6bd8 [ Ryan Blue ] PARQUET - 387 : Improve NPE message when avro arrays contain null .",37,5,"parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java,CAS_DELIMITER,parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWriteOldListBehavior.java,CAS_DELIMITER",2,1,2,0.4537163391869448,28,275.5,6,156.75891203703705,73.0,38.13186194075926,20.0,None,FALSE,FALSE,
630830476a6270e317e84229996a6bf92bd903ca,Chris Bannister,c.bannister@gmail.com,Mon Nov 30 16:26:37 2015 -0800,1448929597,PARQUET - 396 : Extend ParquetReader . Builder < T > In AvroParquetReader . Builder extend ParquetReader . Builder < T > Author : Chris Bannister < c . bannister @ gmail . com > Closes #294 from Zariel / PARQUET - 396 and squashes the following commits : 79c1d0e [ Chris Bannister ] PARQUET - 396 : Extend ParquetReader . Builder < T >,1,1,"parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetReader.java,CAS_DELIMITER",1,1,1,0.0,27,115.0,3,151.9973148148148,1.0,0.7324750195266283,0.0,None,FALSE,FALSE,
efafa61992658eab64c893e9eef49f545d75673c,Sergio Pena,sergio.pena@cloudera.com,Thu Nov 19 10:46:07 2015 -0800,1447958767,"PARQUET - 378 : Add thoroughly parquet test encodings A new test case TestTypeEncodings is added that test v1 and v2 encodings for all supported column types . This test case spans many pages and row groups , and reads each page individually from first - to - last and from last - to - first . Author : Sergio Pena < sergio . pena @ cloudera . com > Closes #274 from spena / parquet - 378 and squashes the following commits : b35c339 [ Sergio Pena ] PARQUET - 378 : Add thoroughly parquet test encodings",499,9,"parquet-hadoop/src/test/java/org/apache/parquet/encodings/FileEncodingsIT.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/statistics/RandomValues.java,CAS_DELIMITER",2,1,2,0.2209460250847226,30,135.5,1,30.929618055555554,1.0,0.7241519200737985,0.0,None,FALSE,FALSE,
440882c659967572311402c7fe534cf13d501cf4,Ryan Blue,blue@apache.org,Tue Nov 17 15:09:50 2015 -0800,1447801790,PARQUET - 364 : Fix compatibility for Avro lists of lists . This fixes lists of lists that have been written with Avro's 2 - level representation . The conversion setup logic missed the case where the inner field is repeated and cannot be the element in a 3 - level list . This also fixes the schema conversion for cases where an unknown writer used a 2 - level list of lists . This is based on @ liancheng's #264 but fixes the problem in a slightly different way . Author : Ryan Blue < blue @ apache . org > Closes #272 from rdblue / PARQUET - 364 - fix - avro - lists - of - lists and squashes the following commits : 41a70e0 [ Ryan Blue ] PARQUET - 364 : Fix compatibility for Avro lists of lists .,248,46,"parquet-avro/src/main/java/org/apache/parquet/avro/AvroIndexedRecordConverter.java,CAS_DELIMITER,parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordConverter.java,CAS_DELIMITER,parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java,CAS_DELIMITER,parquet-avro/src/test/java/org/apache/parquet/avro/TestArrayCompatibility.java,CAS_DELIMITER,parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java,CAS_DELIMITER",5,1,2,1.7013615316692667,27,646.6,15,134.72526157407407,72.0,38.15619257639204,19.0,None,FALSE,FALSE,
5a45ae3b1deb5117cb9e9a13141eeab1e9ad3d71,Mingyu Kim,mkim@palantir.com,Thu Oct 29 15:42:43 2015 -0700,1446158563,PARQUET - 241 : Fix ParquetInputFormat . getFooters ( ) order ParquetInputFormat . getFooters ( ) should return in the same order as what listStatus ( ) returns Author : Mingyu Kim < mkim @ palantir . com > Closes #164 from mingyukim / parquet - 241 and squashes the following commits : 86fe900 [ Mingyu Kim ] Address PR comments b0181e2 [ Mingyu Kim ] PARQUET - 241 : ParquetInputFormat . getFooters ( ) should return in the same order as what listStatus ( ) returns,92,16,"parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputFormat.java,CAS_DELIMITER",2,1,2,0.9698570179131005,28,643.0,3,148.60204282407406,0.0,0.0,0.0,None,FALSE,FALSE,
5294c64b342818e021800b38413f36f426e35b3c,Ryan Blue,blue@apache.org,Mon Oct 19 15:51:07 2015 -0700,1445295067,PARQUET - 373 : Fix flaky MemoryManager tests . Author : Ryan Blue < blue @ apache . org > Closes #269 from rdblue / PARQUET - 373 - fix - flaky - mem - manager - tests and squashes the following commits : 1b55889 [ Ryan Blue ] PARQUET - 373 : Fix flaky MemoryManager tests .,114,53,"parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMemoryManager.java,CAS_DELIMITER",1,1,1,0.0,27,132.0,3,91.24418981481482,71.0,38.97981193656621,26.0,None,FALSE,FALSE,
b1ea059a66c7d6d6bb4cb53d2005a9b7bb599ada,Alex Levenson,alexlevenson@twitter.com,Tue Oct 13 15:54:03 2015 -0700,1444776843,"PARQUET - 381 : Add feature to merge metadata ( summary ) files , and control which files are generated 1 ) Add helper to merge 2 summary files , useful for merging 2 directories of data into 1 2 ) Add more control over whether common metadata , metadata , or both is written Author : Alex Levenson < alexlevenson @ twitter . com > Closes #277 from isnotinvain / alexlevenson / merge - summary - files and squashes the following commits : 86232f5 [ Alex Levenson ] Address comments 96b9495 [ Alex Levenson ] Fix null extraMetaData 099c913 [ Alex Levenson ] Make deprecated method delegate to new method 7a98957 [ Alex Levenson ] Merge branch 'master' into alexlevenson / merge - summary - files ddaf4ff [ Alex Levenson ] Introduce job summary levels for controlling which metadata files are generated 87a2ebc [ Alex Levenson ] Update comments 9d2b8da [ Alex Levenson ] Add helper method for merging metadata files",478,29,"parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputCommitter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleParquetWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/GroupWriteSupport.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMergeMetadataFiles.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetOutputFormatJobSummaryLevel.java,CAS_DELIMITER",9,1,3,2.4615501875587324,28,322.55555555555554,24,60.36647505144034,37.0,17.137575067097615,6.0,None,FALSE,FALSE,
c3819688c48480ec75a9563c71f18ea755e34620,Reuben Kuhnert,sircodesalot@gmail.com,Fri Sep 18 15:08:49 2015 -0700,1442614129,"PARQUET - 355 : Add Statistics Test for Parquet Columns In response to PARQUET - 251 created an integration test that generates random values and compares the statistics against the values read from a parquet file . There are two tools classes `DataGenerationContext` and `RandomValueGenerators` which are located in the same package as the unit test . I'm sure there is a better place to put these , but I leave that to your discretion . Thanks Reuben Author : Reuben Kuhnert < sircodesalot @ gmail . com > Author : Ryan Blue < blue @ apache . org > Closes #255 from sircodesalotOfTheRound / stats - validation and squashes the following commits : 680e96a [ Reuben Kuhnert ] Merge pull request #1 from rdblue / PARQUET - 355 - stats - validation - tests 9f0033f [ Ryan Blue ] PARQUET - 355 : Use ColumnReaderImpl . 7d0b4fe [ Reuben Kuhnert ] PARQUET - 355 : Add Statistics Validation Test",723,3,"parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderImpl.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/statistics/RandomValues.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/statistics/TestStatistics.java,CAS_DELIMITER",3,2,2,1.0166097198001571,29,231.66666666666666,2,23.73355709876543,0.0,0.0,0.0,None,FALSE,FALSE,
0637e2fbcd401f47bb062d5c2d1cceddabf372b7,Nezih Yigitbasi,nyigitbasi@netflix.com,Thu Sep 17 11:46:41 2015 -0700,1442515601,PARQUET - 360 : Handle all map key types with cat tool's json dump When dumping a parquet map with `parquet - cat - - json` it throws a class cast exception as it doesn't properly handle all map key types . ``` java . lang . ClassCastException : [ B cannot be cast to java . lang . String at org . apache . parquet . tools . read . SimpleMapRecord . toJsonObject ( SimpleMapRecord . java : 34 ) at org . apache . parquet . tools . read . SimpleRecord . toJsonValue ( SimpleRecord . java : 119 ) at org . apache . parquet . tools . read . SimpleRecord . toJsonObject ( SimpleRecord . java : 112 ) at org . apache . parquet . tools . read . SimpleRecord . prettyPrintJson ( SimpleRecord . java : 106 ) at org . apache . parquet . tools . command . CatCommand . execute ( CatCommand . java : 76 ) at org . apache . parquet . tools . Main . main ( Main . java : 222 ) [ B cannot be cast to java . lang . String ``` Author : Nezih Yigitbasi < nyigitbasi @ netflix . com > Closes #259 from nezihyigitbasi / parquet - cat - json and squashes the following commits : d047502 [ Nezih Yigitbasi ] Add unit test e4cd545 [ Nezih Yigitbasi ] Get rid of deprecated methods bdc8fdf [ Nezih Yigitbasi ] Handle all map key types with cat tool's json dump,112,8,"parquet-tools/src/main/java/org/apache/parquet/tools/command/CatCommand.java,CAS_DELIMITER,parquet-tools/src/main/java/org/apache/parquet/tools/command/DumpCommand.java,CAS_DELIMITER,parquet-tools/src/main/java/org/apache/parquet/tools/command/HeadCommand.java,CAS_DELIMITER,parquet-tools/src/main/java/org/apache/parquet/tools/command/ShowSchemaCommand.java,CAS_DELIMITER,parquet-tools/src/main/java/org/apache/parquet/tools/read/SimpleMapRecord.java,CAS_DELIMITER,parquet-tools/src/test/java/org/apache/parquet/tools/read/TestSimpleMapRecord.java,CAS_DELIMITER",6,1,3,1.5892638576901108,28,111.83333333333333,7,106.8873572530864,4.0,3.1752112388112916,0.0,None,FALSE,TRUE,
f203d809d7b94501a2e5409c667ba86206480f90,Ryan Blue,blue@apache.org,Fri Sep 11 15:14:00 2015 -0700,1442009640,PARQUET - 363 : Allow empty schema groups . This removes the check added in PARQUET - 278 that rejects schema groups that have no fields . Selecting 0 columns from a file is allowed and used by Hive and SparkSQL to implement queries like `select count ( 1 ) . . . ` Author : Ryan Blue < blue @ apache . org > Closes #263 from rdblue / PARQUET - 363 - allow - empty - groups and squashes the following commits : ab370f1 [ Ryan Blue ] PARQUET - 363 : Update Type builder tests to allow empty groups . 926932b [ Ryan Blue ] PARQUET - 363 : Add write - side schema validation . 365f30d [ Ryan Blue ] PARQUET - 363 : Allow empty schema groups .,307,50,"parquet-column/src/main/java/org/apache/parquet/schema/GroupType.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/schema/TypeUtil.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/schema/Types.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/schema/TestMessageType.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuilders.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/schema/TestTypeUtil.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/ExampleParquetWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/example/GroupWriteSupport.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestUtils.java,CAS_DELIMITER",11,2,5,2.798781586298317,28,386.8181818181818,18,79.35916982323232,70.0,40.56076514876849,29.0,None,FALSE,FALSE,
9962a0fd02fe2ef06765271605b06729af8b2e59,Ryan Blue,blue@apache.org,Fri Sep 11 10:31:38 2015 -0700,1441992698,PARQUET - 335 : Remove Avro check for MAP KEY VALUE . This is not required by the map type spec . This does not affect data written by the Avro object model because this bug is in the conversion from a Parquet schema to an Avro schema . Files written with parquet - avro do not convert the underlying schema because they use the Avro schema . Author : Ryan Blue < blue @ apache . org > Closes #241 from rdblue / PARQUET - 335 - remove - key - value - check and squashes the following commits : 1fd9541 [ Ryan Blue ] PARQUET - 335 : Test that MAP KEY VALUE is not required . 247cc76 [ Ryan Blue ] PARQUET - 335 : Remove Avro check for MAP KEY VALUE .,20,1,"parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java,CAS_DELIMITER,parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java,CAS_DELIMITER",2,1,2,0.2761954276479391,27,383.0,6,101.69802083333333,69.0,39.57449506729336,18.0,None,FALSE,FALSE,
04f524d5ad91b1cdda66dfde4089f2f83f4528aa,Ryan Blue,blue@apache.org,Thu Aug 20 15:23:22 2015 -0700,1440109402,PARQUET - 361 : Add semver prerelease logic . This also adds more versions where PARQUET - 251 is fixed . Author : Ryan Blue < blue @ apache . org > Closes #261 from rdblue / PARQUET - 361 - add - semver - prerelease and squashes the following commits : c01142d [ Ryan Blue ] PARQUET - 361 : Add semver prerelease logic .,220,16,"parquet-column/src/main/java/org/apache/parquet/CorruptStatistics.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/CorruptStatisticsTest.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/SemanticVersion.java,CAS_DELIMITER,parquet-common/src/test/java/org/apache/parquet/SemanticVersionTest.java,CAS_DELIMITER",4,2,4,1.2793082852856705,28,103.75,9,34.008032407407406,68.0,40.10242710859991,19.5,None,FALSE,FALSE,
01fbf81e34a36cedf505f20b1c52306afceedc3e,Tianshuo Deng,tdeng@twitter.com,Thu Aug 20 14:21:12 2015 -0700,1440105672,"PARQUET - 343 Caching nulls on group node to improve write performance on wide schema sparse data For really wide schema with sparse data , If a group node is empty , it could have a huge number of leaves underneath it . Calling writeMull for each leaf every time when it's ancestor group node is null is in - effcient and is bad for data locality in the memory especially when the number of leaves is huge . Instead , null can be cached on the group node . Flushing is only triggered when a group node becomes non - null from null . This way , all the cached null values will be flushed to the leaf nodes in a tight loop and improves write performance . We tested this approach combined with PARQUET - 341 on a really large schema and gave us ~ 2X improvement on write performance Author : Tianshuo Deng < tdeng @ twitter . com > Closes #249 from tsdeng / batch null and squashes the following commits : 0a61646 [ Tianshuo Deng ] use curly braces even for 1 line if statements a8964c0 [ Tianshuo Deng ] optimize writeNullToLeaves 5309612 [ Tianshuo Deng ] optimize cacheNullForGroup ecbdfca [ Tianshuo Deng ] add comments ed692c0 [ Tianshuo Deng ] WIP 0cae1b6 [ Tianshuo Deng ] remove unused class 8e07db4 [ Tianshuo Deng ] refactor dead618 [ Tianshuo Deng ] reformat c3c0c70 [ Tianshuo Deng ] refactor 636ab52 [ Tianshuo Deng ] remove unused method 767b4fd [ Tianshuo Deng ] use parent definition level 8f251a0 [ Tianshuo Deng ] use IntArrayList c549c84 [ Tianshuo Deng ] fix 9583d04 [ Tianshuo Deng ] wIP d8cb878 [ Tianshuo Deng ] WIP 35f1fa1 [ Tianshuo Deng ] cache columnWriter for each parent 46fd464 [ Tianshuo Deng ] address comments 8c83964 [ Tianshuo Deng ] flush null directly to leaves",154,32,"parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/io/ValidatingRecordConsumer.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/io/api/RecordConsumer.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/io/TestColumnIO.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/io/TestFiltered.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java,CAS_DELIMITER,parquet-thrift/src/test/java/org/apache/parquet/thrift/TestParquetReadProtocol.java,CAS_DELIMITER",8,3,5,1.4031520238916229,28,292.875,16,81.7916261574074,268.0,101.88443084873492,77.66666666666667,Preventative,FALSE,FALSE,
3f36b7b50bdda3eeca632ad5440bb82b8e34cb40,Laurent Goujon,lgoujon@twitter.com,Thu Aug 20 13:52:56 2015 -0700,1440103976,PARQUET - 362 - Fix parquet buffered writer being oversensitive to union schema changes Parquet does prevent records with unknown union fields to be written as it would create a TProtocol violation . But it also prevents records with unions having one their field itself having an unknown field ( which is acceptable if it is a struct ) . Author : Laurent Goujon < lgoujon @ twitter . com > Closes #262 from laurentgo / fix - parquet - union - write - bug and squashes the following commits : d15ee74 [ Laurent Goujon ] Fix parquet buffered writer being oversentive to union changes,41,5,"parquet-thrift/src/main/java/org/apache/parquet/thrift/BufferedProtocolReadToWrite.java,CAS_DELIMITER,parquet-thrift/src/test/java/org/apache/parquet/thrift/TestProtocolReadToWrite.java,CAS_DELIMITER",2,1,2,0.7131467486384921,28,541.5,5,66.23950231481481,1.0,0.6416288714111122,0.0,Corrective,TRUE,FALSE,
2f956f46580e5b4752173e885d37a20fe31a78d8,Tianshuo Deng,tdeng@twitter.com,Wed Aug 5 16:29:00 2015 -0700,1438817340,"PARQUET - 341 improve write performance for wide schema sparse data In write path , when there are tons of sparse data , most of time is spent on writing nulls . Currently writing nulls has the same code path as writing values , which is reclusive traverse all the leaves when a group is null . Due to the fact that when a group is null all the leaves beneath it should be written with null value with the same repetition level and definition level , we can eliminate the recursion call to get the leaves This PR caches the leaves for each group node . So when a group node is null , their leaves can be flushed with null values directly . We tested it with a really wide schema on one of our production data . It improves the performance by ~ 20 % Author : Tianshuo Deng < tdeng @ twitter . com > Closes #247 from tsdeng / flush null directly and squashes the following commits : 253f2e3 [ Tianshuo Deng ] address comments 8676cd7 [ Tianshuo Deng ] flush null directly to leaves",36,6,"parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java,CAS_DELIMITER",2,2,2,0.37123232664087563,28,328.0,6,27.256354166666668,267.0,102.58818529362547,72.0,Preventative,FALSE,FALSE,
b86f68e39dc7b6a7c2bff1e4fea3bb7c28d103f0,Alex Levenson,alexlevenson@twitter.com,Fri Jul 31 16:57:19 2015 -0700,1438387039,"PARQUET - 346 : Minor fixes for PARQUET - 350 , PARQUET - 348 , PARQUET - 346 , PARQUET - 345 PARQUET - 346 : ThriftSchemaConverter throws for unknown struct or union type This is triggered when passing a StructType that comes from old file metadata PARQUET - 350 : ThriftRecordConverter throws NPE for unrecognized enum values This is just some better error reporting . PARQUET - 348 : shouldIgnoreStatistics too noisy This is just a case of way over logging something , to the point that it make the logs unreadable PARQUET - 345 ThriftMetaData toString ( ) should not try to load class reflectively This is a case where the error reporting itself crashes , which results in the real error message getting lost Author : Alex Levenson < alexlevenson @ twitter . com > Closes #252 from isnotinvain / alexlevenson / various - fixes and squashes the following commits : 9b5cb0e [ Alex Levenson ] Add comments , cleanup some minor use of ThriftSchemaConverter 376343e [ Alex Levenson ] Fix test d9d5dad [ Alex Levenson ] add license headers e26dc0c [ Alex Levenson ] Add tests 8d9dde0 [ Alex Levenson ] Fixes for PARQUET - 350 , PARQUET - 348 , PARQUET - 346 , PARQUET - 345",254,59,"parquet-column/src/main/java/org/apache/parquet/CorruptStatistics.java,CAS_DELIMITER,parquet-scrooge/src/test/java/org/apache/parquet/scrooge/ScroogeStructConverterTest.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/AbstractThriftWriteSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/TBaseWriteSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftBytesWriteSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftMetaData.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftRecordConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityRunner.java,CAS_DELIMITER,parquet-thrift/src/test/java/org/apache/parquet/thrift/TestProtocolReadToWrite.java,CAS_DELIMITER,parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftMetaData.java,CAS_DELIMITER,parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftRecordConverter.java,CAS_DELIMITER,parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftToPigCompatibility.java,CAS_DELIMITER,parquet-thrift/src/test/java/org/apache/parquet/thrift/struct/CompatibilityCheckerTest.java,CAS_DELIMITER",15,3,7,2.930240950494375,28,195.13333333333333,30,52.181739969135805,36.0,18.319622330559103,12.333333333333334,None,FALSE,FALSE,
454fc3655509f1f4f47ce44acaff7c1566ede108,Nezih Yigitbasi,nyigitbasi@netflix.com,Tue Jul 28 14:55:14 2015 -0700,1438120514,PARQUET - 342 : Updates to be Java 6 compatible Author : Nezih Yigitbasi < nyigitbasi @ netflix . com > Closes #248 from nezihyigitbasi / java6 - fixes and squashes the following commits : 2ab2598 [ Nezih Yigitbasi ] Updates to be Java 6 compatible,73,14,"parquet-common/src/main/java/org/apache/parquet/Files.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/SemanticVersion.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputOutputFormatWithPadding.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/TestInputOutputFormat.java,CAS_DELIMITER",4,2,3,1.6167737802333564,28,182.5,5,16.755515046296296,3.0,2.5740935953859827,0.5,None,FALSE,TRUE,
83406b73e70a251eec5daae34f1bd8d554cdddec,Chris Bannister,c.bannister@gmail.com,Mon Jul 20 09:59:29 2015 -0700,1437411569,PARQUET - 340 : MemoryManager : max memory can be truncated Using float will cause the max heap limit to be limited to 2147483647 due to math . round ( float ) if used with a large heap . This should be a double precision to prevent rounding to an int32 before storing into a long . Author : Chris Bannister < c . bannister @ gmail . com > Closes #246 from Zariel / default - mem - truncated and squashes the following commits : bf375f6 [ Chris Bannister ] MemoryManager : ensure max memory is not truncated,2,2,"parquet-hadoop/src/main/java/org/apache/parquet/hadoop/MemoryManager.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMemoryManager.java,CAS_DELIMITER",2,1,2,1.0,27,165.0,4,61.93983796296296,0.0,0.0,0.0,None,FALSE,FALSE,
8714dd031647be34d0d27f461894e7b194f25cd7,Alex Levenson,alexlevenson@twitter.com,Thu Jul 16 16:42:38 2015 -0700,1437090158,PARQUET - 336 : Fix ArrayIndexOutOfBounds in checkDeltaByteArrayProblem Author : Alex Levenson < alexlevenson @ twitter . com > Author : Alex Levenson < alex @ isnotinvain . com > Closes #242 from isnotinvain / patch - 1 and squashes the following commits : ce1f81e [ Alex Levenson ] Add tests 4688930 [ Alex Levenson ] Fix ArrayIndexOutOfBounds in checkDeltaByteArrayProblem,72,3,"parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/example/TestInputOutputFormat.java,CAS_DELIMITER",2,1,2,0.3003914173647819,28,266.0,4,43.64365162037037,35.0,17.801568002717044,5.0,None,FALSE,FALSE,
f79c9365d0ee89cb407b90cc084eece8fcf9a8a2,Jake Donham,jdonham@twitter.com,Thu Jul 16 16:41:04 2015 -0700,1437090064,PARQUET - 337 handle binary fields in set / map / list in parquet - scrooge https : / / issues . apache . org / jira / browse / PARQUET - 337 Author : Jake Donham < jdonham @ twitter . com > Closes #243 from jaked / PARQUET - 337 and squashes the following commits : 8129fe5 [ Jake Donham ] parquet - scrooge : handle binary fields in set / map / list,15,6,"parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeStructConverter.java,CAS_DELIMITER,parquet-scrooge/src/test/java/org/apache/parquet/scrooge/ScroogeStructConverterTest.java,CAS_DELIMITER",2,1,2,0.9852281360342516,27,283.5,7,69.2075636574074,0.0,0.0,0.0,None,FALSE,FALSE,
fcd568282b2a150f9f42953f12268dc88d09da89,Tianshuo Deng,tdeng@twitter.com,Mon Jul 13 10:36:18 2015 -0700,1436808978,PARQUET - 279 : Check empty struct in compatibility checker Add the empty struct check in the CompatibilityChecker util . Parquet currently does not support empty struct / group without leaves Author : Tianshuo Deng < tdeng @ twitter . com > Closes #194 from tsdeng / check empty struct and squashes the following commits : 35d77a1 [ Tianshuo Deng ] fix rebase d781cf3 [ Tianshuo Deng ] simplify constructor cd2fa8e [ Tianshuo Deng ] add State e75a6ac [ Tianshuo Deng ] use immutable FieldsPath 2bff920 [ Tianshuo Deng ] fix test 69b4b9c [ Tianshuo Deng ] minor fixes 2db8c4b [ Tianshuo Deng ] remove unused println 5107ce2 [ Tianshuo Deng ] fix comments 265e228 [ Tianshuo Deng ] wip,135,57,"parquet-common/src/main/java/org/apache/parquet/Strings.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityChecker.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityRunner.java,CAS_DELIMITER,parquet-thrift/src/test/java/org/apache/parquet/thrift/struct/CompatibilityCheckerTest.java,CAS_DELIMITER",5,2,4,1.1372876621727364,28,139.2,10,58.72266666666667,266.0,104.30565452025145,45.0,None,FALSE,FALSE,
4c7d7523088373be3c7ff203ea895d5a6d84083e,asingh,asingh@cloudera.com,Sat Jul 11 16:26:51 2015 -0700,1436657211,PARQUET - 329 : Restore ThriftReadSupport#THRIFT COLUMN FILTER KEY ThriftReadSupport#THRIFT COLUMN FILTER KEY was removed ( incompatible change ) Author : asingh < asingh @ cloudera . com > Closes #239 from SinghAsDev / PARQUET - 329 and squashes the following commits : 1e44a70 [ asingh ] Remove o . a . p . hadoop . thrift from semver excludes 4a1e572 [ asingh ] PARQUET - 329 : Restore ThriftReadSupport#THRIFT COLUMN FILTER KEY,10,10,"parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftReadSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/deprecated/DeprecatedFieldProjectionFilter.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/deprecated/PathGlobPattern.java,CAS_DELIMITER,parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection.java,CAS_DELIMITER",4,1,3,1.3567796494470397,27,183.75,8,67.17635127314814,2.0,1.8588794665398258,1.0,None,FALSE,FALSE,
043fcde300267e183972056a007bcf406e5c484a,Ryan Blue,blue@apache.org,Thu Jul 9 10:19:51 2015 -0700,1436462391,"PARQUET - 246 : File recovery and work - arounds This is another way to recover data written with the delta byte array problem in PARQUET - 246 . This builds on @ isnotinvain's strategy for solving the problem by adding a method to the encoding to detect it . This version is more similar to the fix for PARQUET - 251 and includes a CorruptDeltaByteArrays helper class that uses the writer version . Most of the file changes are to get the file writer version to Encoding and the ColumnReaderImpl . This also repairs the problem by using a new interface , RequiresPreviousReader , to pass the previous ValuesReader , which is slightly cleaner because the reader doesn't need to expose getter and setter methods . The problem affects pages written to different row groups , so it was necessary to detect the problem in parquet - hadoop and fail jobs that cannot reconstruct data . The work - around to recover is to set ""parquet . split . files"" to false so that files are read sequentially . This could be set automatically in isSplittable , but this would require reading all file footers before submitting jobs , which was recently fixed . I think it is a fair compromise to detect the error case and recommend a solution . This also includes tests for the problem to verify the fix . Replaces old pull requests : closes #217 closes #235 Author : Ryan Blue < blue @ apache . org > Closes #235 from rdblue / PARQUET - 246 - recover - files and squashes the following commits : 067d5ca [ Ryan Blue ] PARQUET - 246 : Refactor after review comments . 3236a3b [ Ryan Blue ] PARQUET - 246 : Fix ParquetInputFormat for delta byte [ ] corruption . 3107362 [ Ryan Blue ] PARQUET - 246 : Add tests for delta byte array fix . a10b157 [ Ryan Blue ] PARQUET - 246 : Fix reading for corrupt delta byte arrays . 5c9497c [ Ryan Blue ] PARQUET - 246 : Parse semantic version with full version .",624,54,"parquet-column/src/main/java/org/apache/parquet/CorruptDeltaByteArrays.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/CorruptStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReadStoreImpl.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/impl/ColumnReaderImpl.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/RequiresPreviousReader.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayReader.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/io/ColumnIOFactory.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/io/MessageColumnIO.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/impl/TestColumnReaderImpl.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/impl/TestCorruptDeltaByteArrays.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/mem/TestMemColumn.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/SemanticVersion.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/VersionParser.java,CAS_DELIMITER,parquet-common/src/test/java/org/apache/parquet/SemanticVersionTest.java,CAS_DELIMITER,parquet-common/src/test/java/org/apache/parquet/VersionTest.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java,CAS_DELIMITER,parquet-tools/src/main/java/org/apache/parquet/tools/command/DumpCommand.java,CAS_DELIMITER",20,4,12,3.2369960487754987,28,224.7,26,29.792623263888892,67.0,42.325733582456735,15.75,None,FALSE,TRUE,
741944332d5bd90112b610a8b5f2eeefe51e08bc,Tom White,tom@cloudera.com,Tue Jul 7 16:55:32 2015 +0100,1436284532,PARQUET - 327 . Show statistics in the dump output . Closes #237,13,0,"parquet-tools/src/main/java/org/apache/parquet/tools/command/DumpCommand.java,CAS_DELIMITER",1,1,1,0.0,28,345.0,4,-72.11885416666667,31.0,11.49177433337823,0.0,None,FALSE,FALSE,
f4e754e66e3661274df624bc328991cd88dd03d6,Thomas Friedrich,tfriedr@us.ibm.com,Fri Jul 3 10:53:22 2015 -0700,1435946002,PARQUET - 324 : row count incorrect if data file has more than 2 ^ 31 rows Need to change numRows counter from int to long to account for input files with more than 2 ^ 31 rows . Author : Thomas Friedrich < tfriedr @ us . ibm . com > Closes #233 from tfriedr / parquet - 324 and squashes the following commits : 0120205 [ Thomas Friedrich ] change numRows from int to long,1,1,"parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER",1,1,1,0.0,28,763.0,4,1.7636921296296297,0.0,0.0,0.0,None,FALSE,FALSE,
013b445ede8d9e7aad4915859d0c869b9b712f8d,Sergio Pena,sergio.pena@cloudera.com,Fri Jul 3 10:51:34 2015 -0700,1435945894,"PARQUET - 152 : Add validation on Encoding . DELTA BYTE ARRAY to allow FIX… PARQUET - 152 : Add validation on Encoding . DELTA BYTE ARRAY to allow FIXED LEN BYTE ARRAY types . * FIXED LEN BYTE ARRAY types are binary values that may use DELTA BYTE ARRAY encoding , so they should be allowed to be decoded using the same DELTA BYTE ARRAY encoding . @ rdblue @ nezihyigitbasi Could you review this fix ? I executed a test by writing a file that fall backs to DELTA BYTE ARRAY encoding , then read the file , and compare the read values with the written values , and it worked fine . Author : Sergio Pena < sergio . pena @ cloudera . com > Closes #225 from spena / parquet - 152 and squashes the following commits : 93fa03e [ Sergio Pena ] PARQUET - 152 : Add validation on Encoding . DELTA BYTE ARRAY to allow FIXED LEN BYTE ARRAY types .",3,2,"parquet-column/src/main/java/org/apache/parquet/column/Encoding.java,CAS_DELIMITER",1,1,1,0.0,27,291.0,1,66.77768518518519,0.0,0.0,0.0,None,FALSE,FALSE,
c334a1bca8338c92e76f0f1cf2ef4884e3eb5dbd,Ryan Blue,blue@apache.org,Wed Jul 1 17:30:29 2015 -0700,1435797029,"PARQUET - 290 : Add data model to Avro reader builder This PR currently includes #203 , which will be removed when it is merged . Author : Ryan Blue < blue @ apache . org > Closes #204 from rdblue / PARQUET - 290 - data - model - builder and squashes the following commits : d257a2c [ Ryan Blue ] PARQUET - 290 : Add Avro data model to reader builder .",61,3,"parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetReader.java,CAS_DELIMITER,parquet-avro/src/main/java/org/apache/parquet/avro/AvroReadSupport.java,CAS_DELIMITER,parquet-avro/src/main/java/org/apache/parquet/avro/SpecificDataSupplier.java,CAS_DELIMITER",3,1,1,0.947169235259032,27,78.66666666666667,6,50.137307098765426,66.0,41.953861232551816,17.0,None,FALSE,TRUE,
2f2c8b1cc6e6e731f7bc52b0988ea8316f475004,Ryan Blue,blue@apache.org,Wed Jul 1 17:18:41 2015 -0700,1435796321,"PARQUET - 289 : Allow ParquetReader . Builder subclasses . This adds a protected constructor for subclasses , a getReadSupport method for subclasses to override , and exposes the configuration for subclasses to modify inside of getReadSupport . Author : Ryan Blue < blue @ apache . org > Closes #203 from rdblue / PARQUET - 289 - extend - reader - builder and squashes the following commits : 692f159 [ Ryan Blue ] PARQUET - 289 : Allow ParquetReader . Builder subclasses .",17,2,"parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java,CAS_DELIMITER",1,1,1,0.0,28,195.0,2,0.9471412037037037,65.0,40.954517925200584,23.0,None,FALSE,FALSE,
a747456bfe077da467ff036172968a37f3b1e893,Ryan Blue,blue@apache.org,Wed Jul 1 16:53:34 2015 -0700,1435794814,PARQUET - 308 : Add ParquetWriter#getDataSize accessor . This returns the current file position plus the amount of data buffered in the current row group as an estimate of final data size . Author : Ryan Blue < blue @ apache . org > Closes #212 from rdblue / PARQUET - 308 - add - data - size - accessor and squashes the following commits : 1c0d798 [ Ryan Blue ] PARQUET - 308 : Add ParquetWriter#getDataSize accessor .,16,0,"parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java,CAS_DELIMITER",2,1,1,0.9886994082884974,27,333.0,5,7.644212962962963,64.0,39.955868001113785,22.0,None,FALSE,FALSE,
c7720ca4c232d317cfc800a04eda4a1d5a44a944,Ryan Blue,blue@apache.org,Wed Jul 1 16:46:23 2015 -0700,1435794383,"PARQUET - 325 : Always use row group size when padding is 0 . For block file systems , if the size left in the block is greater than the max padding , a row group will be targeted at the remaining size . However , when using 0 to turn padding off , the remaining bytes will always be greater than padding and row groups can be targeted at very tiny spaces . When padding is off , the next row group's size should always be the default size . Author : Ryan Blue < blue @ apache . org > Closes #234 from rdblue / PARQUET - 325 - padding - 0 - fix and squashes the following commits : f4b3c2b [ Ryan Blue ] PARQUET - 325 : Always use row group size when padding is 0 .",4,0,"parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER",1,1,1,0.0,28,703.0,5,0.008842592592592593,63.0,38.95624047164081,21.0,None,FALSE,FALSE,
9fde65345e677256975bcecdc027649f31450a57,Ryan Blue,blue@apache.org,Wed Jul 1 16:33:39 2015 -0700,1435793619,PARQUET - 320 : Fix semver problems for parquet - hadoop . Re - enables semver checks for Parquet packages by removing the parquet / * * exclusion that was matching unexpected classes . This also fixes all of the semver problems that have been committed since the check started excluding all Parquet classes . Author : Ryan Blue < blue @ apache . org > Closes #230 from rdblue / PARQUET - 320 - fix - semver - issues and squashes the following commits : a0e730d [ Ryan Blue ] PARQUET - 320 : Fix Thrift incompatibilities from ded56ffd . ba71f3f [ Ryan Blue ] PARQUET - 320 : Fix semver problems for parquet - hadoop .,239,100,"parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/DefaultEventsVisitor.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityChecker.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftType.java,CAS_DELIMITER,parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/TestFieldsPath.java,CAS_DELIMITER",10,2,7,2.2301722032576405,28,435.7,27,23.416082175925926,62.0,37.95687651259842,13.0,None,FALSE,FALSE,
e3b95020f777eb5e0651977f654c1662e3ea1f29,asingh,asingh@cloudera.com,Tue Jun 30 18:34:48 2015 -0700,1435714488,"PARQUET - 251 : Binary column statistics error when reuse byte [ ] among rows Author : asingh < asingh @ cloudera . com > Author : Alex Levenson < alexlevenson @ twitter . com > Author : Ashish Singh < asingh @ cloudera . com > Closes #197 from SinghAsDev / PARQUET - 251 and squashes the following commits : 68e0eae [ asingh ] Remove deprecated constructors from private classes 67e4e5f [ asingh ] Add removed public methods in Binary and deprecate them 0e71728 [ asingh ] Add comment for BinaryStatistics . setMinMaxFromBytes fbe873f [ Ashish Singh ] Merge pull request #4 from isnotinvain / PR - 197 - 3 9826ee6 [ Alex Levenson ] Some minor cleanup 7570035 [ asingh ] Remove test for stats getting ingnored for version 160 when type is int64 af43d28 [ Alex Levenson ] Address PR feedback 89ab4ee [ Alex Levenson ] put the headers in the right location 2838cc9 [ Alex Levenson ] Split out version checks to separate files , add some tests 5af9142 [ Alex Levenson ] Generalize tests , make Binary . fromString reused = false e00d9b7 [ asingh ] Rename isReused = > isBackingBytesReused d2ad939 [ asingh ] Rebase over latest trunk 857141a [ asingh ] Remove redundant junit dependency 32b88ed [ asingh ] Remove semver from hadoop - common 7a0e99e [ asingh ] Revert to fromConstantByteArray for ByteString c820ec9 [ asingh ] Add unit tests for Binary and to check if stats are ignored for version 160 9bbd1e5 [ asingh ] Improve version parsing 84a1d8b [ asingh ] Remove ignoring stats on write side and ignore it on read side 903f8e3 [ asingh ] Address some review comments . * Ignore stats for writer's version < 1 . 8 . 0 * Refactor shoudlIgnoreStatistics method a bit * Assume implementations other than parquet - mr were writing binary statistics correctly * Add toParquetStatistics method's original method signature to maintain backwards compatibility and mark it as deprecated 64c2617 [ asingh ] Revert changes for ignoring stats at RowGroupFilter level e861b18 [ asingh ] Ignore max min stats while reading 3a8cb8d [ asingh ] Fix typo 8e12618 [ asingh ] Fix usage of fromConstant versions of Binary constructors 860adf7 [ asingh ] Rename unmodified to constant and isReused instead of isUnmodifiable 0d127a7 [ asingh ] Add unmodfied and Reused versions for creating a Binary . Add copy ( ) to Binary . b4e2950 [ asingh ] Skip filtering based on stats when file was written with version older than 1 . 6 . 1 6fcee8c [ asingh ] Add getBytesUnsafe ( ) to Binary that returns backing byte [ ] if possible , else returns result of getBytes ( ) 30b07dd [ asingh ] PARQUET - 251 : Binary column statistics error when reuse byte [ ] among rows",1044,121,"parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java,CAS_DELIMITER,parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java,CAS_DELIMITER,parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWriteOldListBehavior.java,CAS_DELIMITER,parquet-benchmarks/src/main/java/org/apache/parquet/benchmarks/DataGenerator.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/CorruptStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/statistics/BinaryStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayReader.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayWriter.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/dictionary/PlainValuesDictionary.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/plain/BinaryPlainValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/example/data/simple/NanoTime.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/io/RecordConsumerLoggingWrapper.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/io/api/Binary.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveType.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/CorruptStatisticsTest.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/statistics/TestStatistics.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/values/dictionary/TestDictionary.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/io/api/TestBinary.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/SemanticVersion.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/VersionParser.java,CAS_DELIMITER,parquet-common/src/test/java/org/apache/parquet/SemanticVersionTest.java,CAS_DELIMITER,parquet-common/src/test/java/org/apache/parquet/VersionTest.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestColumnChunkPageWriteStore.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetWriterNewPage.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/writable/BinaryWritable.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/ParquetStringInspector.java,CAS_DELIMITER,parquet-pig/src/main/java/org/apache/parquet/pig/TupleWriteSupport.java,CAS_DELIMITER,parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoWriteSupport.java,CAS_DELIMITER,parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoWriteSupportTest.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetWriteProtocol.java,CAS_DELIMITER,parquet-tools/src/main/java/org/apache/parquet/tools/command/DumpCommand.java,CAS_DELIMITER",42,10,29,3.9425129382502417,28,243.9047619047619,53,44.30327573853616,1.0,0.9121152805426948,0.1,None,FALSE,TRUE,
1f3e72fa069536ae20f37b29575288ff65e66803,Steven She,steven@canopylabs.com,Thu Jun 25 21:48:00 2015 -0700,1435294080,PARQUET - 317 : Fix writeMetadataFile crash when a relative root path is used This commit ensures the fully - qualified path is used prior to calling mergeFooters ( . . ) . Author : Steven She < steven @ canopylabs . com > Closes #228 from stevencanopy / relative - metadata - path and squashes the following commits : 988772b [ Steven She ] use outputPath . getFileSystem ( . . . ) to get the FS for the path 1cea508 [ Steven She ] PARQUET - 317 : Fix writeMetadataFile crash when a relative root path is used,28,1,"parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java,CAS_DELIMITER",2,1,2,0.362051251733998,27,708.5,5,2.215989583333333,0.0,0.0,0.0,None,FALSE,FALSE,
cb04562742688f8a444a52c90b2183c4be528be6,Ryan Blue,blue@apache.org,Thu Jun 25 09:40:21 2015 -0700,1435250421,"PARQUET - 248 : Add ParquetWriter . Builder . This refactors the builder recently added to parquet - avro so that it can be used by all object models . The Builder class is abstract and implementations should extend it . This changes the API slightly from AvroParquetWriter , renaming withBlockSize to withRowGroupSize . The Avro builder has not been released so this isn't a breaking change . Author : Ryan Blue < blue @ apache . org > Closes #199 from rdblue / PARQUET - 248 - add - parquet - writer - builder and squashes the following commits : a1a25ee [ Ryan Blue ] PARQUET - 248 : Add write mode and max padding to writer builder . 622af4c [ Ryan Blue ] PARQUET - 248 : Add ParquetWriter . Builder .",242,86,"parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java,CAS_DELIMITER",2,2,2,0.7536570209971718,27,253.5,5,13.174571759259258,61.0,37.39731958759795,17.5,None,FALSE,TRUE,
5c2ba72f9b4897d4441eff34ff0591e74a1d94bb,Alex Levenson,alexlevenson@twitter.com,Wed Jun 24 16:02:30 2015 -0700,1435186950,"PARQUET - 284 : Clean up ParquetMetadataConverter makes all method static , removes unused thread - unsafe cache , etc . Turns out the ""cache"" was only read from * after * rebuilding what needed to be cached . . . so no performance gain there ( and no loss by getting rid of it ) However , I don't know if this will fix the issue mentioned in PARQUET - 284 , I don't think concurrent access to a HashMap will cause deadlock , it would just cause undefined behavior in reads or maybe ConcurrentModificationException UPDATE : I'm wrong , it can cause an infinite loop so this should fix the issue https : / / gist . github . com / rednaxelafx / 1081908 UPDATE2 : Put the cache back in , made it static + thread safe Author : Alex Levenson < alexlevenson @ twitter . com > Closes #220 from isnotinvain / alexlevenson / PARQUET - 284 and squashes the following commits : 4797b48 [ Alex Levenson ] Fix merge conflict issue 8ff5775 [ Alex Levenson ] Merge branch 'master' into alexlevenson / PARQUET - 284 ccd4776 [ Alex Levenson ] add encoding cache back in 9ea5a5f [ Alex Levenson ] Clean up ParquetMetadataConverter : make all method static , remove unused thread - unsafe cache",130,97,"parquet-hadoop/src/main/java/org/apache/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ColumnChunkPageWriteStore.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java,CAS_DELIMITER",5,1,3,1.5923765414148299,27,549.6,7,35.59961805555556,34.0,17.501020061247846,4.0,None,FALSE,FALSE,
46448e934250705b6ebd6f21caa09698d611dbfd,Alex Levenson,alexlevenson@twitter.com,Wed Jun 24 13:58:04 2015 -0700,1435179484,PARQUET - 201 : Fix ValidTypeMap being overly strict with respect to OriginalTypes Author : Alex Levenson < alexlevenson @ twitter . com > Closes #219 from isnotinvain / alexlevenson / PARQUET - 201 and squashes the following commits : 1cd8b58 [ Alex Levenson ] Merge branch 'master' into alexlevenson / PARQUET - 201 1d83e13 [ Alex Levenson ] Fix ValidTypeMap being overly strict with respect to OriginalTypes,87,108,"parquet-column/src/main/java/org/apache/parquet/filter2/predicate/PrimitiveToBoxedClass.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/filter2/predicate/SchemaCompatibilityValidator.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/filter2/predicate/ValidTypeMap.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestSchemaCompatibilityValidator.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/filter2/predicate/TestValidTypeMap.java,CAS_DELIMITER",5,1,2,1.7743628137685186,27,124.8,4,46.32575925925926,33.0,16.50365461562567,25.0,None,FALSE,FALSE,
412ab9669810921d04f9feabfbeafa906d4de506,Ryan Blue,blue@apache.org,Mon Jun 22 17:11:27 2015 -0700,1435018287,"PARQUET - 306 : Add row group alignment This adds `AlignmentStrategy` to the `ParquetFileWriter` that can alter the position of row groups and recommend a target size for the next row group . There are two strategies : `NoAlignment` and `PaddingAlignment` . Padding alignment is used for HDFS and no alignment is used for all other file systems . When HDFS - 3689 is available , we can add a strategy to use that . The amount of padding is controlled by a threshold between 0 and 1 that controls the fraction of the row group size that can be padded . This is interpreted as the maximum amount of padding that is acceptable , in terms of the row group size . For example , setting this to 5 % will write padding when the bytes left in a HDFS block are less than 5 % of the row group size . This defaults to 0 % , which prevents padding from being added and matches the current behavior . The threshold is controlled by a new OutputFormat configuration property , `parquet . writer . padding - thresh` . Author : Ryan Blue < blue @ apache . org > Closes #211 from rdblue / PARQUET - 306 - row - group - alignment and squashes the following commits : 0137ddf [ Ryan Blue ] PARQUET - 306 : Add MR test with padding . 6ce3f08 [ Ryan Blue ] PARQUET - 306 : Add parquet . writer . max - padding setting . f1dc659 [ Ryan Blue ] PARQUET - 306 : Base next row group size on bytes remaining . c6a3e97 [ Ryan Blue ] PARQUET - 306 : Add AlignmentStrategy to ParquetFileWriter .",692,77,"parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestInputOutputFormatWithPadding.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestParquetFileWriter.java,CAS_DELIMITER",6,1,2,1.8940575581840133,27,308.6666666666667,6,43.067631172839505,60.0,36.58150744329963,18.0,None,FALSE,FALSE,
89321a2dee438328e75a11954e972175c78f0a2a,Nezih Yigitbasi,nyigitbasi@netflix.com,Mon Jun 22 14:28:42 2015 -0700,1435008522,PARQUET - 311 : Fix NPE when debug logging metadata Fixes the issue reported at https : / / issues . apache . org / jira / browse / PARQUET - 311 Author : Nezih Yigitbasi < nyigitbasi @ netflix . com > Closes #221 from nezihyigitbasi / debug - log - fix and squashes the following commits : 59129ed [ Nezih Yigitbasi ] PARQUET - 311 : Fix NPE when debug logging metadata,33,2,"parquet-column/src/main/java/org/apache/parquet/column/statistics/BinaryStatistics.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java,CAS_DELIMITER",2,2,2,0.512709142030877,27,181.5,2,55.928472222222226,2.0,1.8142872693374557,0.5,None,FALSE,FALSE,
29283b775291bf03cd9a7e1aaa496faaa5757578,Nezih Yigitbasi,nyigitbasi@netflix.com,Mon Jun 22 12:37:37 2015 -0700,1435001857,PARQUET - 314 : Fix broken equals implementations Author : Nezih Yigitbasi < nyigitbasi @ netflix . com > Closes #223 from nezihyigitbasi / parquet - fixes and squashes the following commits : 5279e60 [ Nezih Yigitbasi ] Override Object . equals properly,18,6,"parquet-column/src/main/java/org/apache/parquet/column/ColumnDescriptor.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/statistics/Statistics.java,CAS_DELIMITER",2,1,2,0.9544340029249649,27,188.0,2,55.85133101851852,1.0,0.8146388030368646,0.0,None,FALSE,FALSE,
079bcd0339f30343c01c5fd3d5521be4b822d30f,Alex Levenson,alexlevenson@twitter.com,Thu Jun 18 17:50:28 2015 -0700,1434675028,PARQUET - 297 : Tests for PR 213 ( Version generator ) Adds tests for #213 How's this look @ rdblue @ kostya - sh ? Author : Alex Levenson < alexlevenson @ twitter . com > Closes #218 from isnotinvain / tests - for - pr - 213 and squashes the following commits : 8ee996b [ Alex Levenson ] Fix group indexes off by 1 b239a2a [ Alex Levenson ] Add license header : p 38fc78d [ Alex Levenson ] Add test for Version generator,62,0,"parquet-common/src/test/java/org/apache/parquet/VersionTest.java,CAS_DELIMITER",1,1,1,0.0,1,0.0,0,0.0,32.0,15.667603362203586,3.0,None,FALSE,FALSE,
ad443210312d2420efef6d03a0296d71e71feb22,Konstantin Shaposhnikov,Konstantin.Shaposhnikov@sc.com,Thu Jun 18 16:58:45 2015 -0700,1434671925,PARQUET - 297 : generate Version class using parquet - generator Author : Konstantin Shaposhnikov < Konstantin . Shaposhnikov @ sc . com > Author : Konstantin Shaposhnikov < k . shaposhnikov @ gmail . com > Closes #213 from kostya - sh / PARQUET - 297 2 and squashes the following commits : ddb469a [ Konstantin Shaposhnikov ] add comment about paddedByteCountFromBits coming from ByteUtils 6b47b04 [ Konstantin Shaposhnikov ] Change VersionGenerator to generate main ( ) method 10d0b38 [ Konstantin Shaposhnikov ] PARQUET - 297 : generate Version class using parquet - generator 11d29bc [ Konstantin Shaposhnikov ] parquet - generator : remove dependency on parquet - common,117,106,"parquet-common/src/main/java/org/apache/parquet/Version.java,CAS_DELIMITER,parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/ByteBasedBitPackingGenerator.java,CAS_DELIMITER,parquet-generator/src/main/java/org/apache/parquet/version/Generator.java,CAS_DELIMITER,parquet-generator/src/main/java/org/apache/parquet/version/VersionGenerator.java,CAS_DELIMITER",4,2,3,1.6081954607621887,28,90.5,2,26.016336805555557,1.0,0.8331498973410112,0.0,None,FALSE,TRUE,
4590f14e97beb6d10ffb7b5dd312c632af155ed3,Alex Levenson,alexlevenson@twitter.com,Wed Jun 17 09:17:23 2015 -0700,1434557843,PARQUET - 246 : fix incomplete state reset in DeltaByteArrayWriter . reset ( ) . . . thod Author : Alex Levenson < alexlevenson @ twitter . com > Author : Konstantin Shaposhnikov < Konstantin . Shaposhnikov @ sc . com > Author : kostya - sh < kostya - sh @ users . noreply . github . com > Closes #171 from kostya - sh / PARQUET - 246 and squashes the following commits : 75950c5 [ kostya - sh ] Merge pull request #1 from isnotinvain / PR - 171 a718309 [ Konstantin Shaposhnikov ] Merge remote - tracking branch 'refs / remotes / origin / master' into PARQUET - 246 0367588 [ Alex Levenson ] Add regression test for PR - 171 94e8fda [ Alex Levenson ] Merge branch 'master' into PR - 171 0a9ac9f [ Konstantin Shaposhnikov ] [ PARQUET - 246 ] bugfix : reset all DeltaByteArrayWriter state in reset ( ) method,25,15,"parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayWriter.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/values/deltastrings/TestDeltaByteArray.java,CAS_DELIMITER",2,1,2,0.16866093149667025,27,88.0,2,50.71228009259259,31.0,14.702512728748154,24.0,None,FALSE,FALSE,
2e62764c0c386632e87ee8d12d0505848df1015e,Christian Rolf,christian.rolf@adello.com,Fri Jun 5 10:32:54 2015 -0700,1433525574,PARQUET - 266 : Add support for lists of primitives to Pig schema converter Author : Christian Rolf < christian . rolf @ adello . com > Closes #209 from ccrolf / PigPrimitivesList and squashes the following commits : 5a69273 [ Christian Rolf ] Add support for lists of primitives to Pig schema converter,40,2,"parquet-pig/src/main/java/org/apache/parquet/pig/PigSchemaConverter.java,CAS_DELIMITER,parquet-pig/src/test/java/org/apache/parquet/pig/TestPigSchemaConverter.java,CAS_DELIMITER",2,1,2,0.74959525725948,27,373.5,3,29.82877314814815,0.0,0.0,0.0,None,FALSE,FALSE,
918609f2cc4e4de95445ce4fdd7dc952b9625017,Ryan Blue,blue@apache.org,Thu Jun 4 10:45:50 2015 -0700,1433439950,"PARQUET - 286 : Update String support to match upstream Avro . This adds getStringableClass , which determines what String representation upstream Avro would use . Specific and reflect will use an alternative String class if java - class is set that is instantiated using a constructor that takes a String . Otherwise , reflect will always use String and both specific and generic will use Utf8 or String depending on whether avro . java . string is set to ""string"" . The new string representations required two new converters : one for Utf8 and one for stringable classes ( those with constructors that take a single String ) . The converters have also been refactored so that all binary converters now implement dictionary support . Author : Ryan Blue < blue @ apache . org > Closes #201 from rdblue / PARQUET - 286 - avro - utf8 - support and squashes the following commits : beb5a44 [ Ryan Blue ] PARQUET - 286 : Add tests , support for stringable map keys . 0e9240f [ Ryan Blue ] PARQUET - 286 : Update string support to match upstream Avro .",594,80,"parquet-avro/src/main/java/org/apache/parquet/avro/AvroConverters.java,CAS_DELIMITER,parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordConverter.java,CAS_DELIMITER,parquet-avro/src/test/java/org/apache/parquet/avro/TestBackwardCompatibility.java,CAS_DELIMITER,parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java,CAS_DELIMITER,parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWriteOldListBehavior.java,CAS_DELIMITER,parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectReadWrite.java,CAS_DELIMITER,parquet-avro/src/test/java/org/apache/parquet/avro/TestStringBehavior.java,CAS_DELIMITER",7,1,2,1.9276929001806817,27,270.57142857142856,9,8.070496031746032,59.0,36.8350202974378,15.0,None,FALSE,FALSE,
d6f082b9be5d507ff60c6bc83a179cc44015ab97,Ryan Blue,blue@apache.org,Mon Jun 1 17:46:29 2015 -0700,1433205989,PARQUET - 285 : Implement 3 - level lists in Avro This includes the write - side the changes from #83 that implement the 3 - level list structure for parquet - avro . The old commit was https : / / github . com / rdblue / parquet - mr / commit / 3589a7367c829b9eabc36b2e2e1cab31685415eb . Author : Ryan Blue < blue @ apache . org > Closes #198 from rdblue / PARQUET - 285 - avro - nested - lists and squashes the following commits : 3498571 [ Ryan Blue ] PARQUET - 285 : Fix review issues . 67ed2f4 [ Ryan Blue ] PARQUET - 285 : Add tests for new list write behavior . 6ec9120 [ Ryan Blue ] PARQUET - 285 : Implement nested type rules for Avro . 109111f [ Ryan Blue ] PARQUET - 285 : Add a better conversion pattern for lists .,1162,212,"parquet-avro/src/main/java/org/apache/parquet/avro/AvroIndexedRecordConverter.java,CAS_DELIMITER,parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetWriter.java,CAS_DELIMITER,parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordConverter.java,CAS_DELIMITER,parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java,CAS_DELIMITER,parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java,CAS_DELIMITER,parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java,CAS_DELIMITER,parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java,CAS_DELIMITER,parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWriteOldBehavior.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/schema/ConversionPatterns.java,CAS_DELIMITER",9,2,3,1.9763193378921822,27,357.44444444444446,14,17.659301697530864,58.0,36.02128902301242,22.0,None,FALSE,TRUE,
4b5cda5a2c6ca613db5129d50ffffce2604ad9eb,Yash Datta,Yash.Datta@guavus.com,Mon Jun 1 14:21:53 2015 -0700,1433193713,PARQUET - 151 : Skip writing metadata file in case of no footers since schema cannot be determined . This fixes npe seen during mergeFooters in such a case . For this scenario onus of writing any summary files lies with the caller ( It might have some global schema available ) So for example spark does it when persisting empty RDD . Author : Yash Datta < Yash . Datta @ guavus . com > Closes #205 from saucam / footer bug and squashes the following commits : b2b3ddf [ Yash Datta ] PARQUET - 151 : Skip writing metadata file in case of no footers since schema cannot be determined . This fixes npe seen during mergeFooters in such a case . For this scenario onus of writing any summary files lies with the caller ( It might have some global schema available ),5,0,"parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputCommitter.java,CAS_DELIMITER",1,1,1,0.0,27,72.0,1,34.923738425925926,2.0,1.5091956077279822,2.0,None,FALSE,FALSE,
dd92a9db6b288def8159f30336f6793239882c9d,asingh,asingh@cloudera.com,Tue May 26 14:31:51 2015 -0700,1432675911,"PARQUET - 223 : Add builders for MAP and LIST types As of now , Parquet does not provide builders for Maps and Lists . This leaves margin for user errors . Having Map and List builders will make it easier for users to build these types . Author : asingh < asingh @ cloudera . com > Closes #148 from SinghAsDev / map and squashes the following commits : cc7da06 [ asingh ] Pull changes made by Ryan 825b5b8 [ asingh ] Remove non - functional changes bec675b [ asingh ] Remove required and optional version of methods that take pre - built Type 6dcaa78 [ asingh ] Address review comments and some clean up 544d1e4 [ asingh ] Add key ( Type ) and value ( Type ) variants to MapBuilder f2a1697 [ asingh ] Add listKey support 68c06f5 [ asingh ] Add support for null value in MapBuilder f31f2b0 [ asingh ] Add more tests to cover list and map value types in map builder f035439 [ asingh ] Add Map and List value types to map 1afa2c7 [ asingh ] Address review comments 484495b [ asingh ] PARQUET - 223 : Add builders for MAP and LIST types",1558,89,"parquet-column/src/main/java/org/apache/parquet/schema/Types.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/schema/TestTypeBuilders.java,CAS_DELIMITER",2,1,2,0.9968382479384441,27,643.5,2,28.930659722222224,0.0,0.0,0.0,None,FALSE,TRUE,
8769d0f2cc4b7555dc025b7c0e49a81346a1e2dd,Ryan Blue,blue@apache.org,Thu May 21 16:18:03 2015 -0700,1432250283,"PARQUET - 262 : Restore semver checks . Because 1 . 6 . 0 to 1 . 7 . 0 was a breaking rename , semver was turned off until the 1 . 7 . 0 artifacts were released . Now that they are available , the check needs to be restored . There were already 2 breaking changes that are fixed by this commit : * A field in AvroReadSupport was made final * An accessor method in ThriftSchemaConvertVisitor was removed Author : Ryan Blue < blue @ apache . org > Closes #200 from rdblue / PARQUET - 262 - restore - semver and squashes the following commits : 09aeaf4 [ Ryan Blue ] PARQUET - 262 : Restore semver checks .",10,1,"parquet-avro/src/main/java/org/apache/parquet/avro/AvroReadSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java,CAS_DELIMITER",2,2,2,0.8453509366224365,27,250.0,5,2.5595486111111114,57.0,35.77250786441669,9.0,None,FALSE,FALSE,
ded56ffd598e41e32817f6c1b091595fe7122e8b,Alex Levenson,alexlevenson@twitter.com,Tue May 19 19:36:04 2015 -0700,1432089364,"PARQUET - 287 : Keep a least 1 column from union members when projecting thrift unions Currently , the projection API allows you to select only some ""kinds"" of a union , or to drop a required union entirely . This becomes an issue when assembling these records , as they will be appear to be unions of an unknown type ( how do you coerce an empty struct into a union ? ) . The way this case is handled for primitives is by supplying a default value ( like 0 , or null ) . However , with a union , you have to choose what ""kind"" of the union it will act as , and in the interest of not being misleading , this PR reads one column to figure out what the correct ""kind"" is . In the future , the better solution is to filter these records out - - a projection is really a request for a filter in this case . But for now , this should get us correctness without involving the filter API . I think this PR needs some more tests before merging , but I wanted to get it out and get some feedback now . I also refactored how ThriftSchemaVisitor works to not be stateful , by explicitly passing state through the recursion - - this makes it much easier to reason about . * edit * This PR also includes a fix for PARQUET - 275 because I encountered it during testing . * edit 2 * This PR also includes a fix for PARQUET - 283 Author : Alex Levenson < alexlevenson @ twitter . com > Closes #189 from isnotinvain / alexlevenson / project - union and squashes the following commits : c710702 [ Alex Levenson ] Avoid instantiating ( unused ) empty group type c43a44c [ Alex Levenson ] Merge branch 'master' into alexlevenson / project - union d62ee8c [ Alex Levenson ] Merge branch 'master' into alexlevenson / project - union df51f41 [ Alex Levenson ] Fix tests 4d3f825 [ Alex Levenson ] Address review comments 6dd95f5 [ Alex Levenson ] Update tests to reflect changes d7cee7e [ Alex Levenson ] Add tests for nested maps 9c34b20 [ Alex Levenson ] Keep a sentinel column in map values 53e5580 [ Alex Levenson ] Remove debug println c525a65 [ Alex Levenson ] update docs to reflect set projection rules aefb637 [ Alex Levenson ] Do not allow partial projection of keys or set elements 8b4e791 [ Alex Levenson ] Add tests for maps of unions 35de282 [ Alex Levenson ] Add test for list < union > 098630f [ Alex Levenson ] Merge branch 'master' into alexlevenson / project - union 77cc9e9 [ Alex Levenson ] Add license header 63b80fd [ Alex Levenson ] more clean up 6341747 [ Alex Levenson ] Clean up ConvertedField dcd3ea9 [ Alex Levenson ] Merge branch 'master' into alexlevenson / project - union 9ce4781 [ Alex Levenson ] Some cleanup and comments 6964837 [ Alex Levenson ] Keep one sentinel column in projected unions that cannot be dropped entirely 37a9bef [ Alex Levenson ] Clean up visitor pattern for thrift types",1321,347,"parquet-thrift/src/main/java/org/apache/parquet/thrift/ConvertedField.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/KeepOnlyFirstPrimitiveFilter.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/FieldProjectionFilter.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/FieldsPath.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/DefaultEventsVisitor.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/amend/DefaultProtocolEventsGenerator.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/CompatibilityChecker.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/struct/ThriftType.java,CAS_DELIMITER,parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection.java,CAS_DELIMITER,parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConverter.java,CAS_DELIMITER,parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConverterProjectUnion.java,CAS_DELIMITER,parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/TestFieldsPath.java,CAS_DELIMITER",14,1,7,2.964059094006743,27,164.5,18,14.807123015873016,30.0,14.398647551884903,5.0,None,FALSE,TRUE,
181affd5c937755f54ff31ef056a6ec091e95f51,dongche1,dong1.chen@intel.com,Tue May 19 11:26:07 2015 -0700,1432059967,"PARQUET - 164 : Add a counter and increment when parquet memory manager kicks in Add a counter for writers , and increment it when memory manager scaling down row group size . Hive could use this counter to warn users . Author : dongche1 < dong1 . chen @ intel . com > Author : dongche < dong1 . chen @ intel . com > Author : root < root @ bdpe15 . sh . intel . com > Closes #120 from dongche / PARQUET - 164 and squashes the following commits : 9bcb1ba [ dongche ] Remove stats , and change returned callbacks map unmodifiable 3cbbeb9 [ dongche ] Merge remote branch 'upstream1 / master' into PARQUET - 164 bdef233 [ dongche ] Merge remote branch 'upstream1 / master' into PARQUET - 164 780be6d [ root ] revert change about callable and address comments 11f9163 [ dongche1 ] Merge remote branch 'upstream / master' into PARQUET - 164 55549a5 [ dongche1 ] Use callable and strict registerScallCallBack method . 74054aa [ dongche1 ] Use Runnable as a generic callback 8782a02 [ dongche1 ] Add a callback mechanism instead of shims . And rebase trunk b138b7f [ dongche1 ] Merge remote branch 'upstream / master' into PARQUET - 164 93a4678 [ dongche1 ] PARQUET - 164 : Add a counter and increment when parquet memory manager kicks in",69,3,"parquet-hadoop/src/main/java/org/apache/parquet/hadoop/MemoryManager.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER,parquet-hadoop/src/test/java/org/apache/parquet/hadoop/TestMemoryManager.java,CAS_DELIMITER",3,1,2,1.1271018129100785,27,205.66666666666666,3,21.801678240740742,1.0,0.7211572598246871,1.0,None,FALSE,TRUE,
a458e1a2f3cd1ccd692f1530b64d3143c9beda51,Ryan Blue,blue@apache.org,Mon May 18 10:08:32 2015 -0700,1431968912,PARQUET - 243 : Add Avro reflect support Author : Ryan Blue < blue @ apache . org > Closes #165 from rdblue / PARQUET - 243 - add - avro - reflect and squashes the following commits : a1a17b4 [ Ryan Blue ] PARQUET - 243 : Update for Tom's review comments . 16584d1 [ Ryan Blue ] PARQUET - 243 : Fix AvroWriteSupport bug . fa4a9ec [ Ryan Blue ] PARQUET - 243 : Add reflect tests . 4c50cd1 [ Ryan Blue ] PARQUET - 243 : Update write support for reflected objects . b50c482 [ Ryan Blue ] PARQUET - 243 : Update tests to run with new converters . 0b7a333 [ Ryan Blue ] PARQUET - 243 : Use common AvroConverters where possible . 2f6825d [ Ryan Blue ] PARQUET - 243 : Add reflect converters that behave more like Avro . 98f10df [ Ryan Blue ] PARQUET - 243 : Add Avro compatible record materializer .,2475,274,"parquet-avro/src/main/java/org/apache/parquet/avro/AvroCompatRecordMaterializer.java,CAS_DELIMITER,parquet-avro/src/main/java/org/apache/parquet/avro/AvroConverters.java,CAS_DELIMITER,parquet-avro/src/main/java/org/apache/parquet/avro/AvroIndexedRecordConverter.java,CAS_DELIMITER,parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetOutputFormat.java,CAS_DELIMITER,parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetReader.java,CAS_DELIMITER,parquet-avro/src/main/java/org/apache/parquet/avro/AvroParquetWriter.java,CAS_DELIMITER,parquet-avro/src/main/java/org/apache/parquet/avro/AvroReadSupport.java,CAS_DELIMITER,parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordConverter.java,CAS_DELIMITER,parquet-avro/src/main/java/org/apache/parquet/avro/AvroRecordMaterializer.java,CAS_DELIMITER,parquet-avro/src/main/java/org/apache/parquet/avro/AvroWriteSupport.java,CAS_DELIMITER,parquet-avro/src/main/java/org/apache/parquet/avro/GenericDataSupplier.java,CAS_DELIMITER,parquet-avro/src/main/java/org/apache/parquet/avro/ParentValueContainer.java,CAS_DELIMITER,parquet-avro/src/main/java/org/apache/parquet/avro/ReflectDataSupplier.java,CAS_DELIMITER,parquet-avro/src/test/java/org/apache/parquet/avro/TestBackwardCompatibility.java,CAS_DELIMITER,parquet-avro/src/test/java/org/apache/parquet/avro/TestReadWrite.java,CAS_DELIMITER,parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectInputOutputFormat.java,CAS_DELIMITER,parquet-avro/src/test/java/org/apache/parquet/avro/TestReflectReadWrite.java,CAS_DELIMITER,parquet-avro/src/test/java/org/apache/parquet/avro/TestSpecificReadWrite.java,CAS_DELIMITER",18,1,2,3.1841752617686807,27,117.66666666666667,10,11.526556069958849,56.0,34.991153142379055,12.0,None,FALSE,TRUE,
60edcf9df1bbe271b1414b04e914641937395d8a,Tianshuo Deng,tdeng@twitter.com,Fri May 15 13:07:14 2015 -0700,1431720434,"PARQUET - 278 : enforce non empty group on MessageType level As columnar format , parquet currently does not support empty struct / group without leaves . We should throw when constructing an empty GroupType to give a clear message . Author : Tianshuo Deng < tdeng @ twitter . com > Closes #195 from tsdeng / message type enforce non empty group and squashes the following commits : a286c58 [ Tianshuo Deng ] revert change to merge parquet pr a09f6ba [ Tianshuo Deng ] fix test ac63567 [ Tianshuo Deng ] fix tests aa2633c [ Tianshuo Deng ] enforce non empty group on MessageType level",58,5,"parquet-column/src/main/java/org/apache/parquet/schema/GroupType.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/schema/IncompatibleSchemaModificationException.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/schema/InvalidSchemaException.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/schema/TestMessageType.java,CAS_DELIMITER,parquet-pig/src/test/java/org/apache/parquet/pig/TestPigSchemaConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConverter.java,CAS_DELIMITER",6,3,4,2.0280862490285956,27,160.66666666666666,6,14.38242862654321,265.0,110.76910539310644,57.0,None,FALSE,TRUE,
136c5ffe80e558a87cde01baebf823b06e3cbe75,Cheng Lian,lian@databricks.com,Fri May 15 12:41:15 2015 -0700,1431718875,"PARQUET - 253 : Fixes Javadoc of AvroSchemaConverter Got confused by the original Javadoc at first and didn't realize `AvroSchemaConverter` is also capable to convert a Parquet schema to an Avro schema . < ! - - Reviewable : start - - > [ < img src = ""https : / / reviewable . io / review button . png"" height = 40 alt = ""Review on Reviewable"" / > ] ( https : / / reviewable . io / reviews / apache / incubator - parquet - mr / 173 ) < ! - - Reviewable : end - - > Author : Cheng Lian < lian @ databricks . com > Closes #173 from liancheng / avro - schema - converter - comment - fix and squashes the following commits : 47b11ce [ Cheng Lian ] Fixes Javadoc of AvroSchemaConverter",9,9,"parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java,CAS_DELIMITER",1,1,1,0.0,27,355.0,2,0.0005555555555555556,4.0,3.1088119461594546,1.0,None,FALSE,FALSE,
7680fae14c9f544d0585a7b150004a1e48fff53a,Cheng Lian,lian@databricks.com,Fri May 15 12:40:27 2015 -0700,1431718827,"PARQUET - 254 : Fixes exception message < ! - - Reviewable : start - - > [ < img src = ""https : / / reviewable . io / review button . png"" height = 40 alt = ""Review on Reviewable"" / > ] ( https : / / reviewable . io / reviews / apache / incubator - parquet - mr / 174 ) < ! - - Reviewable : end - - > Author : Cheng Lian < lian @ databricks . com > Closes #174 from liancheng / fix - exception - message and squashes the following commits : db816c2 [ Cheng Lian ] Fixes exception message",1,1,"parquet-avro/src/main/java/org/apache/parquet/avro/AvroSchemaConverter.java,CAS_DELIMITER",1,1,1,0.0,27,355.0,1,17.85329861111111,3.0,2.1088157714093323,0.0,None,FALSE,FALSE,
c7d56cffbb4668d0955ef00196e08f42f2efe363,Tianshuo Deng,tdeng@twitter.com,Tue May 12 11:15:40 2015 -0700,1431454540,PARQUET - 273 : remove usage of ReflectiveOperationException to support JAVA6 as commented here : https : / / github . com / apache / parquet - mr / commit / 52f3240d90f2397cd1850ab11674ba08a0ecb2a0#commitcomment - 11065301 Author : Tianshuo Deng < tdeng @ twitter . com > Closes #191 from tsdeng / remove usage of reflective operation exception and squashes the following commits : adbe37a [ Tianshuo Deng ] remove usage of ReflectiveOperationException to support JAVA6,21,5,"parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeStructConverter.java,CAS_DELIMITER",1,1,1,0.0,27,372.0,2,7.96318287037037,264.0,110.18309714941664,42.0,None,FALSE,FALSE,
890b387d713d04c22406db6d5a5fc9b51bec2df5,Tianshuo Deng,tdeng@twitter.com,Mon May 4 12:08:41 2015 -0700,1430766521,PARQUET - 252 : support nested container type for parquet - scrooge resubmit Author : Tianshuo Deng < tdeng @ twitter . com > Closes #185 from tsdeng / scrooge nested container and squashes the following commits : b29465f [ Tianshuo Deng ] retrigger jenkins 4542c1a [ Tianshuo Deng ] support nested container type for parquet - scrooge,282,186,"parquet-scrooge/src/main/java/org/apache/parquet/scrooge/ScroogeStructConverter.java,CAS_DELIMITER,parquet-scrooge/src/test/java/org/apache/parquet/scrooge/ScroogeStructConverterTest.java,CAS_DELIMITER",2,1,2,0.9095106630291534,27,227.5,4,5.314699074074074,263.0,110.24797160131766,41.0,None,FALSE,FALSE,
7fc7998398373a14b4cdc0ce18abdeb221b1ccf9,Alex Levenson,alexlevenson@twitter.com,Thu Apr 30 17:45:11 2015 -0700,1430441111,"PARQUET - 229 Add a strict thrift projection API with backwards compat support Currently , the thrift projection API accepts strings in a very general glob format that supports not only wildcards like ` * ` and ` ? ` and expansions ( ` { x , y , z } ` ) but also character classes ` [ abc ] ` , and negation . Because of this flexibility , it's hard to give users good error reporting , for example letting them know that when they requested columns `foo . bar . { a , b , c } ` there is actually no such column `foo . bar . c` . This PR introduces a new syntax that supports a more restrictive form of glob syntax and enforces that all * * expansions * * of a glob match a column , not just that all globs match a column . The new syntax is very simple and only has four special characters : ` { ` , ` } ` , ` , ` , and ` * ` It supports glob expansion , for example : `home . { phone , address } ` or `org . apache { - incubator , } . foo` And the wildcard ` * ` which is treated the same way as java regex treats ` ( . * ) ` , for example : `home . * ` or `org . apache * . foo` In the new syntax glob paths mean ""keep all the child fields of the field matched by this glob"" , just like variable access would work in a programming language . For example : `x . y . z` means keep field `z` and all of its children ( if any ) . So it's not necessary to do `x . y . z . * ` . However , `x . y . z` would not keep field `x . y . zoo` . If that was desired , then `x . y . z * ` could be used instead . Setting `""parquet . thrift . column . filter""` will result in the same behavior that it does currently in master , though a deprecation warning will be logged . The classes that implement the current behavior have been marked as deprecated , and using this will log a warning . Setting `""parquet . thrift . column . projection . globs""` will instead use this new syntax , and entry points in the various Builder's in the codebase is added as well . This PR does a little bit of cleanup as well , moving some shared methods to a `Strings` class and simplifying some of the class hierarchy in `ThriftSchemaConverterVisitor` . There are a few ` / / TODO Why ? ` added as well that I wanted to ask about . Author : Alex Levenson < alexlevenson @ twitter . com > Closes #150 from isnotinvain / alexlevenson / strict - projection and squashes the following commits : 6c58e1c [ Alex Levenson ] clean up docs 1aab666 [ Alex Levenson ] Merge branch 'master' into alexlevenson / strict - projection 92b6ba6 [ Alex Levenson ] Merge branch 'master' into alexlevenson / strict - projection ceaf6cd [ Alex Levenson ] update packages a28dc19 [ Alex Levenson ] Merge branch 'master' into alexlevenson / strict - projection ebc4761 [ Alex Levenson ] Remove unneeded TODO c2e12c5 [ Alex Levenson ] Update docs eecf5f3 [ Alex Levenson ] Merge branch 'master' into alexlevenson / strict - projection 671f0b5 [ Alex Levenson ] Merge branch 'master' into alexlevenson / strict - projection 298cad8 [ Alex Levenson ] Add warning 8b7e4bb [ Alex Levenson ] Add more comments to StrictFieldProjectionFilter 8f65ed2 [ Alex Levenson ] Add tests for strict projection filter c81d9e1 [ Alex Levenson ] Docs and cleanup for FieldProjectionFilter 71139a7 [ Alex Levenson ] Add tests for FieldsPath 7d17068 [ Alex Levenson ] Tests for WildcardPath 8a3d2af [ Alex Levenson ] Add some tests f3fd931 [ Alex Levenson ] More docs 0b190c3 [ Alex Levenson ] Add more comments 6e67df5 [ Alex Levenson ] Add a strict thrift projection API with backwards support for the current API",1811,233,"parquet-cascading/src/main/java/org/apache/parquet/cascading/ParquetValueScheme.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/Strings.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/glob/GlobExpander.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/glob/GlobNode.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/glob/GlobParser.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/glob/WildcardPath.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/hadoop/metadata/ColumnPath.java,CAS_DELIMITER,parquet-common/src/test/java/org/apache/parquet/glob/TestGlob.java,CAS_DELIMITER,parquet-common/src/test/java/org/apache/parquet/glob/TestWildcardPath.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftReadSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConvertVisitor.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftSchemaConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/FieldProjectionFilter.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/FieldsPath.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/StrictFieldProjectionFilter.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/deprecated/DeprecatedFieldProjectionFilter.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/projection/deprecated/PathGlobPattern.java,CAS_DELIMITER,parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection.java,CAS_DELIMITER,parquet-thrift/src/test/java/org/apache/parquet/thrift/TestThriftSchemaConverter.java,CAS_DELIMITER,parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/TestFieldsPath.java,CAS_DELIMITER,parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/TestStrictFieldProjectionFilter.java,CAS_DELIMITER,parquet-thrift/src/test/java/org/apache/parquet/thrift/projection/deprecated/PathGlobPatternTest.java,CAS_DELIMITER",22,3,13,4.096467773550983,27,71.18181818181819,10,1.1494402356902358,29.0,13.854234020743084,2.6666666666666665,Feature Addition,FALSE,TRUE,
22c6d087012fd55bc65e578a27f2edb66f4d3808,Alex Levenson,alexlevenson@twitter.com,Thu Apr 30 16:59:20 2015 -0700,1430438360,"PARQUET - 269 : Restore scrooge - maven - plugin to version 3 . 17 . 0 Scrooge has re - published scrooge - maven - plugin 3 . 17 . 0 , so we should be able to use it again . Lets see if travis is able to pick up the changes . Author : Alex Levenson < alexlevenson @ twitter . com > Closes #188 from isnotinvain / alexlevenson / restore - scrooge - plugin and squashes the following commits : fbec238 [ Alex Levenson ] Revert ""make a whitespace change to trigger tests"" 5ea3d26 [ Alex Levenson ] make a whitespace change to trigger tests bfe181f [ Alex Levenson ] Restore scrooge - maven - plugin to version 3 . 17 . 0",0,3,"parquet-scrooge/src/test/java/org/apache/parquet/scrooge/ScroogeStructConverterTest.java,CAS_DELIMITER",1,1,1,0.0,27,126.0,2,0.9668634259259259,28.0,12.854936257457485,4.0,None,FALSE,FALSE,
98f54c158acb12a26fa6f335b1665accd2aed347,"Nalezenec, Lukas",lukas.nalezenec@gmail.com,Thu Apr 30 12:33:56 2015 +0200,1430390036,"PARQUET - 175 reading custom protobuf class Changes to be committed : modified : parquet - protobuf / src / main / java / org / apache / parquet / proto / ProtoReadSupport . java modified : parquet - protobuf / src / test / java / org / apache / parquet / proto / ProtoInputOutputFormatTest . java modified : parquet - protobuf / src / test / resources / TestProtobuf . proto Author : Nalezenec , Lukas < lukas . nalezenec @ gmail . com > Closes #183 from lukasnalezenec / master and squashes the following commits : 796cd39 [ Nalezenec , Lukas ] PARQUET - 175 Allow setting of a custom protobuf class when reading parquet file using parquet - protobuf .",53,12,"parquet-protobuf/src/main/java/org/apache/parquet/proto/ProtoReadSupport.java,CAS_DELIMITER,parquet-protobuf/src/test/java/org/apache/parquet/proto/ProtoInputOutputFormatTest.java,CAS_DELIMITER",2,1,2,0.9500796252338518,27,93.0,2,2.473773148148148,0.0,0.0,0.0,None,FALSE,FALSE,
9993450ad1f023e0e2b59291361d0b3b9f0e1c8d,Alex Levenson,alexlevenson@twitter.com,Wed Apr 29 23:18:47 2015 -0700,1430374727,"PARQUET - 227 Enforce that unions have only 1 set value , tolerate bad records in read path See https : / / issues . apache . org / jira / browse / PARQUET - 227 Author : Alex Levenson < alexlevenson @ twitter . com > Closes #153 from isnotinvain / alexlevenson / double - union and squashes the following commits : ef4d36f [ Alex Levenson ] fix package names e201deb [ Alex Levenson ] Merge branch 'master' into alexlevenson / double - union 01694fa [ Alex Levenson ] Forgot a break in a switch statement 2f31321 [ Alex Levenson ] Merge branch 'master' into alexlevenson / double - union 9292274 [ Alex Levenson ] Add in ShouldNeverHappenException which I forgot to check in 8d61515 [ Alex Levenson ] Address first round of comments 4d71bcb [ Alex Levenson ] Merge branch 'master' into alexlevenson / double - union 8f9334c [ Alex Levenson ] Some cleanup and fixes 8153bc9 [ Alex Levenson ] Enforce that unions have only 1 set value , tolerate bad records in read path",620,35,"parquet-column/src/main/java/org/apache/parquet/io/api/RecordMaterializer.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/ShouldNeverHappenException.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/InternalParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/org/apache/parquet/hadoop/UnmaterializableRecordCounter.java,CAS_DELIMITER,parquet-scrooge/src/test/java/org/apache/parquet/scrooge/TestCorruptScroogeRecords.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/hadoop/thrift/ThriftReadSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/BufferedProtocolReadToWrite.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetProtocol.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/ParquetReadProtocol.java,CAS_DELIMITER,parquet-thrift/src/main/java/org/apache/parquet/thrift/ThriftRecordConverter.java,CAS_DELIMITER,parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestCorruptThriftRecords.java,CAS_DELIMITER,parquet-thrift/src/test/java/org/apache/parquet/hadoop/thrift/TestInputOutputFormat.java,CAS_DELIMITER,parquet-thrift/src/test/java/org/apache/parquet/thrift/TestProtocolReadToWrite.java,CAS_DELIMITER",13,5,8,2.8697279437278107,27,232.23076923076923,9,1.5899439102564104,27.0,11.869181745131955,6.6,None,FALSE,FALSE,
9d744f7136f23da9a5f9324432b300b5a68e3b39,Ryan Blue,blue@apache.org,Wed Apr 29 17:47:03 2015 -0700,1430354823,"PARQUET - 268 : Downgrade scrooge - maven - plugin . The 3 . 17 . 0 version no longer works because a transitive dependency has been purged . 3 . 18 . 0 is the natural upgrade , but fails with a configuration problem . The latest documentation on updates is for moving to 3 . 17 . 0 , so the easiest solution that works is to downgrade to 3 . 16 . 0 . The build is working . Author : Ryan Blue < blue @ apache . org > Closes #187 from rdblue / PARQUET - 268 - fix - scrooge - plugin - version and squashes the following commits : 2b90634 [ Ryan Blue ] PARQUET - 268 : Downgrade scrooge - maven - plugin .",3,0,"parquet-scrooge/src/test/java/org/apache/parquet/scrooge/ScroogeStructConverterTest.java,CAS_DELIMITER",1,1,1,0.0,27,123.0,1,2.066215277777778,55.0,35.24939554117291,4.0,None,FALSE,FALSE,
720b988fd8d7a50fbe922e6c73a3681b1c566331,Tianshuo Deng,tdeng@twitter.com,Mon Apr 27 15:37:21 2015 -0700,1430174241,"Revert ""PARQUET - 252 : Support nests container types for scrooge support"" This reverts commit f28aa71041181867a720134e26b64b03cbccb6ec .",186,281,"parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java,CAS_DELIMITER,parquet-scrooge/src/test/java/parquet/scrooge/ScroogeStructConverterTest.java,CAS_DELIMITER",2,1,2,0.9079771721249692,25,89.0,18,0.2102199074074074,262.0,110.16365480470787,40.0,None,FALSE,FALSE,
f28aa71041181867a720134e26b64b03cbccb6ec,Tianshuo Deng,tdeng@twitter.com,Mon Apr 27 10:34:38 2015 -0700,1430156078,"PARQUET - 252 : Support nests container types for scrooge support parquet should support nested container type for scrooge , like list < list > or list < map > Author : Tianshuo Deng < tdeng @ twitter . com > Closes #175 from tsdeng / support nests container types for scrooge support and squashes the following commits : bae3e68 [ Tianshuo Deng ] move set list and map inner elem name conversion to private static methods 48b4342 [ Tianshuo Deng ] catch ClassCastException fc25bd0 [ Tianshuo Deng ] remove hack / fix for nested name 429c61c [ Tianshuo Deng ] fix exception handling , use explicit imports f54e648 [ Tianshuo Deng ] comments 815ee29 [ Tianshuo Deng ] support nested scrooge type",281,186,"parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java,CAS_DELIMITER,parquet-scrooge/src/test/java/parquet/scrooge/ScroogeStructConverterTest.java,CAS_DELIMITER",2,1,2,0.9079771721249692,25,41.5,16,46.32388310185185,261.0,109.19141861943307,39.0,None,FALSE,FALSE,
b61362933f7a564d2ae0b7d6b9723f79f4948769,Ryan Blue,blue@apache.org,Tue Apr 7 13:43:06 2015 -0700,1428439386,PARQUET - 239 : Make AvroParquetReader#builder static . Fixes new API method added since 1 . 5 . 0 . Author : Ryan Blue < blue @ apache . org > Closes #158 from rdblue / PARQUET - 239 - fix - avro - builder and squashes the following commits : c8c64d7 [ Ryan Blue ] PARQUET - 239 : Make AvroParquetReader#builder static .,1,1,"parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java,CAS_DELIMITER",1,1,1,0.0,25,70.0,8,63.833391203703705,53.0,34.752881266316024,10.0,None,FALSE,FALSE,
920192a542ab9e9dd2fbf090e1efd3c4ec99977d,Ryan Blue,blue@apache.org,Tue Apr 7 13:14:13 2015 -0700,1428437653,"PARQUET - 235 : Fix parquet . metadata compatibility . ColumnPath and Canonicalizer were moved from parquet - hadoop to parquet - common in parquet . common . { internal , schema } , which broke compatibility and would require bumping the major version . This moves the classes back into parquet . hadoop . metadata and adds temporary exclusions for the move between modules . There are no breaking changes to the classes themselves , verified by copying them into parquet - hadoop and building . This also changes the previous version back to 1 . 5 . 0 rather than an RC ( which carries no compatibility guarantees , though this is compatible with both version ) . It also adds an exclusions for a false positive in Binary . Author : Ryan Blue < blue @ apache . org > Closes #166 from rdblue / PARQUET - 235 - fix - parquet - metadata and squashes the following commits : f56a57e [ Ryan Blue ] PARQUET - 235 : Fix parquet . metadata compatibility .",18,25,"parquet-column/src/main/java/parquet/filter2/predicate/FilterApi.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/filter2/predicate/Operators.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/filter2/predicate/SchemaCompatibilityValidator.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/filter2/predicate/ValidTypeMap.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/filter2/recordlevel/FilteringGroupConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/filter2/recordlevel/FilteringRecordMaterializer.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/filter2/recordlevel/IncrementallyUpdatedFilterPredicateBuilderBase.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/filter2/predicate/TestFilterApiMethods.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/filter2/predicate/TestValidTypeMap.java,CAS_DELIMITER,parquet-common/src/main/java/parquet/hadoop/metadata/Canonicalizer.java,CAS_DELIMITER,parquet-common/src/main/java/parquet/hadoop/metadata/ColumnPath.java,CAS_DELIMITER,parquet-generator/src/main/java/parquet/filter2/IncrementallyUpdatedFilterPredicateGenerator.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/filter2/statisticslevel/StatisticsFilter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkProperties.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/metadata/EncodingList.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/filter2/statisticslevel/TestStatisticsFilter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/metadata/TestColumnChunkMetaData.java,CAS_DELIMITER",22,4,12,4.403008940748609,26,211.45454545454547,207,53.20481744528618,52.0,33.75424574618752,12.25,None,FALSE,FALSE,
f272a6e96f0fe80b0c2b4643836006d840d5aa8a,Ryan Blue,blue@apache.org,Tue Apr 7 13:12:55 2015 -0700,1428437575,PARQUET - 234 : Add ParquetInputSplit methods for compatibility . Author : Ryan Blue < blue @ apache . org > Closes #159 from rdblue / PARQUET - 234 and squashes the following commits : b09d34d [ Ryan Blue ] PARQUET - 234 : Add ParquetInputSplit methods for compatibility .,50,0,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java,CAS_DELIMITER",1,1,1,0.0,25,51.0,23,60.87966435185185,51.0,32.75430468894954,15.0,None,FALSE,TRUE,
4950ad86a16e63fa26d51cd709e39666008c5fbc,Ryan Blue,blue@apache.org,Tue Apr 7 09:43:55 2015 -0700,1428425035,"PARQUET - 242 : Fix AvroReadSupport . setAvroDataSupplier . This should use the supplier class's name , rather than its toString representation or else loading the class doesn't work . Author : Ryan Blue < blue @ apache . org > Closes #161 from rdblue / PARQUET - 242 - fix - avro - data - supplier and squashes the following commits : ff5b7f8 [ Ryan Blue ] PARQUET - 242 : Add Avro data supplier test . 87a488b [ Ryan Blue ] PARQUET - 242 : Fix AvroReadSupport . setAvroDataSupplier .",44,1,"parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestAvroDataSupplier.java,CAS_DELIMITER",2,1,2,0.2623112196143366,25,56.5,18,3.3522280092592593,50.0,31.763385969579378,9.0,None,FALSE,FALSE,
ff7a4863152a4d3873ea038af73024e9999426ac,Ryan Blue,blue@apache.org,Mon Apr 6 15:49:39 2015 -0700,1428360579,"Revert ""PARQUET - 220 : Remove unnecessary warnings initializing ParquetRecordReader"" This reverts commit bfb314505469afcd5ea7b5bd15121acd50425318 .",13,30,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/util/ContextUtil.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/util/counters/BenchmarkCounter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapreduce/MapReduceCounterLoader.java,CAS_DELIMITER",4,1,4,1.8174069333231992,25,120.75,45,0.048449074074074075,49.0,30.80810201328227,14.0,None,FALSE,FALSE,
bfb314505469afcd5ea7b5bd15121acd50425318,Konstantin Shaposhnikov,Konstantin.Shaposhnikov@sc.com,Mon Apr 6 14:39:53 2015 -0700,1428356393,PARQUET - 220 : Remove unnecessary warnings initializing ParquetRecordReader Refactored to replace TaskInputOutputContext with TaskAttemptContext . ParquetRecordReader used to check that the passed context is instance of TaskInputOutputContext however the functionality it uses doesn't rely on this fact . This closes #152 when committed . It fixes the review feedback on that issue to include it in 1 . 6 . 0 . Author : Konstantin Shaposhnikov < Konstantin . Shaposhnikov @ sc . com > Closes #162 from rdblue / PARQUET - 152 - remove - counter - warning and squashes the following commits : 0a7780f [ Konstantin Shaposhnikov ] PARQUET - 220 : do not log unnecessary warnings on initializing ParquetRecordReader,30,13,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/util/ContextUtil.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/util/counters/BenchmarkCounter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapreduce/MapReduceCounterLoader.java,CAS_DELIMITER",4,1,4,1.8174069333231992,25,116.5,41,62.13963252314815,0.0,0.0,0.0,None,FALSE,FALSE,
4ed0bdf1c73fd82d3080d15085675de96d5be0aa,Ryan Blue,blue@apache.org,Tue Mar 31 16:49:30 2015 -0700,1427845770,"PARQUET - 214 : Fix Avro string regression . At some point , parquet - avro converted string fields to binary without the UTF8 annotation . The change in PARQUET - 139 to filter the file's schema using the requested projection causes a regression because the annotation is not present in some file schemas , but is present in the projection schema converted from Avro . This reverts the projection change to avoid a regression in a release . Fixing the projection as in PARQUET - 139 will need to be done as a follow - up . Author : Ryan Blue < blue @ apache . org > Closes #142 from rdblue / PARQUET - 214 - fix - avro - regression and squashes the following commits : 71e0207 [ Ryan Blue ] PARQUET - 214 : Add support for old avro . schema property . 95148f9 [ Ryan Blue ] PARQUET - 214 : Revert Schema projection change from PARQUET - 139 .",57,3,"parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestBackwardCompatibility.java,CAS_DELIMITER",2,1,2,0.6098403047164004,25,55.0,17,12.47324074074074,48.0,30.153596401668715,8.0,None,FALSE,FALSE,
0ab0013522df1dc03a68bce6e7539bbfd0ea67d9,Neville Li,neville@spotify.com,Tue Mar 31 16:34:47 2015 -0700,1427844887,"PARQUET - 210 : add JSON support for parquet - cat JSON output with this patch : ``` { ""int field"" : 99 , ""long field"" : 1099 , ""float field"" : 2099 . 5 , ""double field"" : 5099 . 5 , ""boolean field"" : true , ""string field"" : ""str99"" , ""nested"" : { ""numbers"" : [ 100 , 101 , 102 , 103 , 104 ] , ""name"" : ""name99"" , ""dict"" : { ""a"" : 100 , ""b"" : 200 , ""c"" : 300 } } } ``` Current output format : ``` int field = 99 long field = 1099 float field = 2099 . 5 double field = 5099 . 5 boolean field = true string field = str99 nested : . numbers : . . array = 100 . . array = 101 . . array = 102 . . array = 103 . . array = 104 . name = name99 . dict : . . map : . . . key = a . . . value = 100 . . map : . . . key = b . . . value = 200 . . map : . . . key = c . . . value = 300 ``` Author : Neville Li < neville @ spotify . com > Closes #140 from nevillelyh / neville / PARQUET - 210 and squashes the following commits : 45fd629 [ Neville Li ] PARQUET - 210 : add JSON support for parquet - cat",204,27,"parquet-tools/src/main/java/parquet/tools/command/CatCommand.java,CAS_DELIMITER,parquet-tools/src/main/java/parquet/tools/read/SimpleListRecord.java,CAS_DELIMITER,parquet-tools/src/main/java/parquet/tools/read/SimpleListRecordConverter.java,CAS_DELIMITER,parquet-tools/src/main/java/parquet/tools/read/SimpleMapRecord.java,CAS_DELIMITER,parquet-tools/src/main/java/parquet/tools/read/SimpleMapRecordConverter.java,CAS_DELIMITER,parquet-tools/src/main/java/parquet/tools/read/SimpleRecord.java,CAS_DELIMITER,parquet-tools/src/main/java/parquet/tools/read/SimpleRecordConverter.java,CAS_DELIMITER",7,1,2,2.78584910120525,24,101.71428571428571,11,9.492569444444444,2.0,1.8381008293992358,1.0,None,FALSE,TRUE,
4fea3ea6997c8135bc18a2bff31dc0a54e7bd82d,Nezih Yigitbasi,nyigitbasi@netflix.com,Tue Mar 31 11:23:42 2015 -0700,1427826222,"PARQUET - 165 : Add a new parquet - benchmark module PARQUET - 165 This PR is an initial version of a new ``parquet - benchmark`` module that we can build upon . The module already contains some simple benchmarks for read / writes , we can discuss how we can make those more representative . When run , various statistics will be printed for all the benchmarks in this module . For example , for the read benchmarks the output will look like : ``` # Run complete . Total time : 00 : 03 : 16 Benchmark Mode Samples Score Error Units p . b . ReadBenchmarks . read1MRowsBS256MPS4MUncompressed thrpt 1 0 . 248 ± NaN ops / s p . b . ReadBenchmarks . read1MRowsBS256MPS8MUncompressed thrpt 1 0 . 331 ± NaN ops / s p . b . ReadBenchmarks . read1MRowsBS512MPS4MUncompressed thrpt 1 0 . 309 ± NaN ops / s p . b . ReadBenchmarks . read1MRowsBS512MPS8MUncompressed thrpt 1 0 . 303 ± NaN ops / s p . b . ReadBenchmarks . read1MRowsDefaultBlockAndPageSizeGZIP thrpt 1 0 . 264 ± NaN ops / s p . b . ReadBenchmarks . read1MRowsDefaultBlockAndPageSizeSNAPPY thrpt 1 0 . 499 ± NaN ops / s p . b . ReadBenchmarks . read1MRowsDefaultBlockAndPageSizeUncompressed thrpt 1 0 . 360 ± NaN ops / s p . b . ReadBenchmarks . read1MRowsBS256MPS4MUncompressed avgt 1 3 . 623 ± NaN s / op p . b . ReadBenchmarks . read1MRowsBS256MPS8MUncompressed avgt 1 3 . 162 ± NaN s / op p . b . ReadBenchmarks . read1MRowsBS512MPS4MUncompressed avgt 1 3 . 231 ± NaN s / op p . b . ReadBenchmarks . read1MRowsBS512MPS8MUncompressed avgt 1 2 . 583 ± NaN s / op p . b . ReadBenchmarks . read1MRowsDefaultBlockAndPageSizeGZIP avgt 1 3 . 713 ± NaN s / op p . b . ReadBenchmarks . read1MRowsDefaultBlockAndPageSizeSNAPPY avgt 1 2 . 055 ± NaN s / op p . b . ReadBenchmarks . read1MRowsDefaultBlockAndPageSizeUncompressed avgt 1 2 . 904 ± NaN s / op p . b . ReadBenchmarks . read1MRowsBS256MPS4MUncompressed sample 1 2 . 772 ± NaN s / op p . b . ReadBenchmarks . read1MRowsBS256MPS8MUncompressed sample 1 2 . 538 ± NaN s / op p . b . ReadBenchmarks . read1MRowsBS512MPS4MUncompressed sample 1 2 . 496 ± NaN s / op p . b . ReadBenchmarks . read1MRowsBS512MPS8MUncompressed sample 1 2 . 416 ± NaN s / op p . b . ReadBenchmarks . read1MRowsDefaultBlockAndPageSizeGZIP sample 1 3 . 712 ± NaN s / op p . b . ReadBenchmarks . read1MRowsDefaultBlockAndPageSizeSNAPPY sample 1 1 . 772 ± NaN s / op p . b . ReadBenchmarks . read1MRowsDefaultBlockAndPageSizeUncompressed sample 1 2 . 819 ± NaN s / op p . b . ReadBenchmarks . read1MRowsBS256MPS4MUncompressed ss 1 2 . 416 ± NaN s p . b . ReadBenchmarks . read1MRowsBS256MPS8MUncompressed ss 1 2 . 564 ± NaN s p . b . ReadBenchmarks . read1MRowsBS512MPS4MUncompressed ss 1 2 . 547 ± NaN s p . b . ReadBenchmarks . read1MRowsBS512MPS8MUncompressed ss 1 3 . 094 ± NaN s p . b . ReadBenchmarks . read1MRowsDefaultBlockAndPageSizeGZIP ss 1 3 . 689 ± NaN s p . b . ReadBenchmarks . read1MRowsDefaultBlockAndPageSizeSNAPPY ss 1 1 . 983 ± NaN s p . b . ReadBenchmarks . read1MRowsDefaultBlockAndPageSizeUncompressed ss 1 2 . 928 ± NaN s ``` Author : Nezih Yigitbasi < nyigitbasi @ netflix . com > Closes #104 from nezihyigitbasi / benchmark - module and squashes the following commits : 90c72f5 [ Nezih Yigitbasi ] Add a new parquet - benchmark module",537,0,"parquet-benchmarks/src/main/java/parquet/benchmarks/BenchmarkConstants.java,CAS_DELIMITER,parquet-benchmarks/src/main/java/parquet/benchmarks/BenchmarkFiles.java,CAS_DELIMITER,parquet-benchmarks/src/main/java/parquet/benchmarks/BenchmarkUtils.java,CAS_DELIMITER,parquet-benchmarks/src/main/java/parquet/benchmarks/DataGenerator.java,CAS_DELIMITER,parquet-benchmarks/src/main/java/parquet/benchmarks/ReadBenchmarks.java,CAS_DELIMITER,parquet-benchmarks/src/main/java/parquet/benchmarks/WriteBenchmarks.java,CAS_DELIMITER",6,1,1,2.3614869114818196,1,0.0,0,0.0,0.0,0.0,0.0,None,FALSE,TRUE,
8bcfe6c55e2588c1047368b4edbf733d1c1d5381,Vassil Lunchev,vassil@leanplum.com,Tue Mar 24 19:33:03 2015 -0700,1427250783,PARQUET - 225 : Add support for INT64 delta encoding . Author : Vassil Lunchev < vassil @ leanplum . com > Closes #154 from lunchev : int64 and squashes the following commits : 84a40fe [ Vassil Lunchev ] INT64 support for Delta Encoding 4389af4 [ Vassil Lunchev ] splitting delta INT32 and delta INT64 e5e8fe2 [ Vassil Lunchev ] split delta encoding tests for INT32 and for INT64 eb4383a [ Ryan Blue ] PARQUET - 225 : Avoid multiple small copies in delta int / long encoding .,1141,252,"parquet-column/src/main/java/org/apache/parquet/column/Encoding.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/ParquetProperties.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForInteger.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForLong.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/org/apache/parquet/column/values/deltastrings/DeltaByteArrayWriter.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForIntegerTest.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/values/delta/DeltaBinaryPackingValuesWriterForLongTest.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java,CAS_DELIMITER,parquet-column/src/test/java/org/apache/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java,CAS_DELIMITER,parquet-common/src/main/java/org/apache/parquet/bytes/BytesUtils.java,CAS_DELIMITER,parquet-encoding/src/main/java/org/apache/parquet/bytes/BytesInput.java,CAS_DELIMITER,parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePackerForLong.java,CAS_DELIMITER,parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/BytePackerForLongFactory.java,CAS_DELIMITER,parquet-encoding/src/main/java/org/apache/parquet/column/values/bitpacking/Packer.java,CAS_DELIMITER,parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestBitPacking.java,CAS_DELIMITER,parquet-encoding/src/test/java/org/apache/parquet/column/values/bitpacking/TestByteBitPacking.java,CAS_DELIMITER,parquet-generator/src/main/java/org/apache/parquet/encoding/bitpacking/ByteBasedBitPackingGenerator.java,CAS_DELIMITER",21,4,11,3.5480194795231816,32,149.14285714285714,33,-137.99621362433862,0.0,0.0,0.0,None,FALSE,TRUE,
fd3085ed31d920e8ca6bba391e75d1423ed8b607,Neville Li,neville@spotify.com,Tue Mar 24 16:06:26 2015 -0700,1427238386,PARQUET - 204 : add parquet - schema directory support Author : Neville Li < neville @ spotify . com > Closes #136 from nevillelyh / neville / PARQUET - 204 and squashes the following commits : 633829b [ Neville Li ] PARQUET - 204 : add parquet - schema directory support 7aa8581 [ Neville Li ] PARQUET - 203 : consolidate PathFilter for hidden files,61,37,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/util/HiddenFileFilter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java,CAS_DELIMITER,parquet-tools/src/main/java/parquet/tools/command/ShowSchemaCommand.java,CAS_DELIMITER",7,2,4,2.5890750513085354,26,257.14285714285717,153,32.694054232804234,1.0,0.8713305877873027,0.5,None,FALSE,TRUE,
2e3c05359a0e21be44d307104eea3134afcef5f0,Tianshuo Deng,tdeng@twitter.com,Fri Mar 13 13:36:49 2015 -0700,1426279009,PARQUET - 197 : Gen parquet metadata from cascading retry of PARQUET - 197 fixed support for hadoop2 API Author : Tianshuo Deng < tdeng @ twitter . com > Closes #141 from tsdeng / gen parquet meta and squashes the following commits : d1211a0 [ Tianshuo Deng ] fix hadoop2 API 8686ce4 [ Tianshuo Deng ] gem parquet metadata,71,11,"parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java,CAS_DELIMITER,parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java,CAS_DELIMITER,parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputCommitter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/mapred/MapredParquetOutputCommitter.java,CAS_DELIMITER,parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java,CAS_DELIMITER",7,3,5,1.9299508699944603,25,105.0,81,6.831944444444445,260.0,114.34308825177604,37.0,None,FALSE,FALSE,
9ee3a16179cb65f5fe4170257ab7cde558f1dbeb,Alex Levenson,alexlevenson@twitter.com,Fri Mar 13 12:54:58 2015 -0700,1426276498,"PARQUET - 217 Use simpler heuristic in MemoryManager We found that the heuristic of throwing when : ``` minMemoryAllocation > 0 & & newSize / maxColCount < minMemoryAllocation ``` in MemoryManager is not really valid when you have many ( 3k + ) columns , due to the division by the number of columns . This check throws immediately when writing a single file with a 3GB heap and > 3K columns . This PR introduces a simpler heuristic , which is a min scale , and we throw when the MemoryManager's scale gets too small . By default I chose 25 % , but I'm happy to change that to something else . For backwards compatibility I've left the original check in , but it's not executed by default anymore , to get this behavior the min chunk size will have to be set in the hadoop configuration . I'm also open to removing it entirely if we don't think we need it anymore . What do you think ? @ danielcweeks @ rdblue @ dongche @ julienledem Author : Alex Levenson < alexlevenson @ twitter . com > Closes #143 from isnotinvain / alexlevenson / mem - manager - heuristic and squashes the following commits : acda66f [ Alex Levenson ] Add units to exception 10237c6 [ Alex Levenson ] Decouple DEFAULT MIN MEMORY ALLOCATION from DEFAULT PAGE SIZE 29c9881 [ Alex Levenson ] Use an absolute minimum on rowgroup size , only apply when scale < 1 8877125 [ Alex Levenson ] Merge branch 'master' into alexlevenson / mem - manager - heuristic e5117a0 [ Alex Levenson ] Merge branch 'master' into alexlevenson / mem - manager - heuristic 6ee5f46 [ Alex Levenson ] Use simpler heuristic in MemoryManager",5,5,"parquet-hadoop/src/main/java/parquet/hadoop/MemoryManager.java,CAS_DELIMITER",1,1,1,0.0,25,158.0,4,31.532905092592593,26.0,11.726065607251838,2.0,None,FALSE,FALSE,
77826fda8751bd5c0acbca5d0c3887e9a6b10f65,Alex Levenson,alexlevenson@twitter.com,Thu Mar 12 14:25:13 2015 -0700,1426195513,"PARQUET - 215 Discard records with unrecognized union members in the thrift write path Fixes Parquet - 215 , adds a test case for it , and fixes some tests that were quietly not doing anything previously to actually exercise the code they were intended to exercise . ( they were tests that catch exceptions and make assertions about them , but never enforced that the exception was actually thrown , and in one case , it never was ) . Author : Alex Levenson < alexlevenson @ twitter . com > Closes #146 from isnotinvain / alexlevenson / unrecognized - union and squashes the following commits : 7bec4a6 [ Alex Levenson ] Add license header b0d8e6c [ Alex Levenson ] Merge branch 'master' into alexlevenson / unrecognized - union e152bc8 [ Alex Levenson ] Update comment 97232b7 [ Alex Levenson ] Address comments c542199 [ Alex Levenson ] Go back to using boolean for isUnion 2e18dbd [ Alex Levenson ] Remove exclusion 0a60c46 [ Alex Levenson ] Support isUnion being unknown b0dfdf9 [ Alex Levenson ] Fix tests 68940d7 [ Alex Levenson ] Discard records with unrecognized union members in the thrift write path",174,11,"parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/struct/TestThriftType.java,CAS_DELIMITER",6,2,5,2.2490595078719737,25,203.83333333333334,81,21.42189236111111,25.0,10.741939567796294,2.0,Corrective,TRUE,FALSE,
b58789c5badc4f9680ec5724568af05a84670e22,Ryan Blue,blue@apache.org,Wed Mar 11 15:21:45 2015 -0700,1426112505,PARQUET - 180 : Update use of TBinaryProtocol#setReadLength . This is no longer supported in thrift 0 . 9 . 2 and was only used defensively . The reason to remove it now is to avoid linker errors when the wrong version of thrift is found in the classpath . Author : Ryan Blue < blue @ apache . org > Closes #118 from rdblue / PARQUET - 180 and squashes the following commits : 5100424 [ Ryan Blue ] PARQUET - 180 : Dynamic use of TBinaryProtocol#setReadLength .,12,1,"parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java,CAS_DELIMITER",1,1,1,0.0,25,158.0,12,34.11434027777778,47.0,30.322960849531214,3.0,None,FALSE,FALSE,
031a762d105bceda2049204ba54b8f8737f359b4,Ryan Blue,blue@apache.org,Wed Mar 11 15:11:16 2015 -0700,1426111876,PARQUET - 172 : Add parquet - thrift binary tests . These tests validate that there is no encoding problem with parquet - thrift or parquet - scrooge . See https : / / github . com / laurencer / parquet - mr - bug Author : Ryan Blue < blue @ apache . org > Closes #145 from rdblue / PARQUET - 172 - add - thrift - binary - test and squashes the following commits : 6856414 [ Ryan Blue ] PARQUET - 172 : Add parquet - thrift binary tests .,173,0,"parquet-scrooge/src/test/java/parquet/scrooge/ScroogeBinaryTest.java,CAS_DELIMITER,parquet-scrooge/src/test/java/parquet/scrooge/ScroogeStructConverterTest.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/hadoop/thrift/TestBinary.java,CAS_DELIMITER",3,2,2,1.174702705616299,25,4.666666666666667,5,12.298206018518519,46.0,29.32338310523536,2.0,None,FALSE,FALSE,
5acc6a5502bffaa66be7e859849856de0ea27acb,Viktor Szathmau00ccu0081ry,phraktle@gmail.com,Tue Mar 10 14:04:59 2015 +0100,1425992699,PARQUET - 97 : make ProtoParquetReader#builder static Author : Viktor Szathmáry < phraktle @ gmail . com > Closes #63 from phraktle / fix ppr factory and squashes the following commits : 8b67439 [ Viktor Szathmáry ] make ProtoParquetReader#builder static 9c8fcd5 [ Viktor Szathmáry ] make ProtoParquetReader#builder static,1,1,"parquet-protobuf/src/main/java/parquet/proto/ProtoParquetReader.java,CAS_DELIMITER",1,1,1,0.0,25,17.0,5,35.51525462962963,0.0,0.0,0.0,None,FALSE,FALSE,
3fc28541f001ce6e4a7afa91fec8d21bfeaa17db,Ryan Blue,blue@apache.org,Fri Mar 6 17:06:34 2015 -0800,1425690394,PARQUET - 193 : Implement nested types compatibility rules in Avro This depends on PARQUET - 191 and PARQUET - 192 . This replaces #83 . Author : Ryan Blue < blue @ apache . org > Closes #128 from rdblue / PARQUET - 193 - implement - compatilibity - avro and squashes the following commits : bd0491e [ Ryan Blue ] PARQUET - 193 : Implement nested types rules in Avro .,1261,39,"parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/AvroTestUtil.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestArrayCompatibility.java,CAS_DELIMITER",6,1,2,1.233659538449124,25,147.0,78,5.947862654320988,44.0,27.587983017034954,7.0,None,FALSE,TRUE,
12ee6b442bbf6557c06ecd7c1f7ae2fceeae55d6,Tianshuo Deng,tdeng@twitter.com,Fri Mar 6 16:38:49 2015 -0800,1425688729,"PARQUET - 208 : Revert PARQUET - 197 Revert ""PARQUET - 197 : fix parquet - cascading not writing parquet metadata . . . Author : Tianshuo Deng < tdeng @ twitter . com > Closes #139 from tsdeng / revert parquet 197 and squashes the following commits : a74b5c8 [ Tianshuo Deng ] Revert ""PARQUET - 197 : fix parquet - cascading not writing parquet metadata file""",6,57,"parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java,CAS_DELIMITER,parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java,CAS_DELIMITER,parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputCommitter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/mapred/MapredParquetOutputCommitter.java,CAS_DELIMITER,parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java,CAS_DELIMITER",7,3,5,1.7478910313134877,25,112.28571428571429,74,1.0290625,259.0,114.32605115565579,36.0,None,FALSE,FALSE,
5851e6da7a05b5d53a01803ccabc0f685fc36d52,Tianshuo Deng,tdeng@twitter.com,Thu Mar 5 15:56:58 2015 -0800,1425599818,"PARQUET - 197 : fix parquet - cascading not writing parquet metadata file Repro : run a scalding job that writes parquet files to a folder . no metadata and common metadata file is created Impact : potential performance problem if parquet metadata is read from client side , which is the case for sparkSQL casue : the metatdata writing logic is in the mapreduce API but not the mapred API of parquet . Author : Tianshuo Deng < tdeng @ twitter . com > Closes #131 from tsdeng / fix mapred output committer and squashes the following commits : 6e8d8eb [ Tianshuo Deng ] rename to MapredParquetOutputCommiter , add setAsOutputFormat method to set the outputCommiter ec758db [ Tianshuo Deng ] license 448b649 [ Tianshuo Deng ] fix parquet - cascading not writing parquet metadata file",57,6,"parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java,CAS_DELIMITER,parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java,CAS_DELIMITER,parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputCommitter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/mapred/MapredParquetOutputCommitter.java,CAS_DELIMITER,parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java,CAS_DELIMITER",7,3,5,1.7478910313134877,25,105.0,67,25.747572751322753,258.0,113.47283681670437,35.0,None,FALSE,TRUE,
258349426eecfbe5c135f91809bae80e60c6db6a,Tianshuo Deng,tdeng@twitter.com,Thu Mar 5 15:22:03 2015 -0800,1425597723,PARQUET - 162 : ParquetThrift should throw when unrecognized columns are passed to the column projection API ParquetThrift should throw when unrecognized columns are passed to the column projection API Author : Tianshuo Deng < tdeng @ twitter . com > Closes #123 from tsdeng / throw when projection filter matches nothing and squashes the following commits : 12c08da [ Tianshuo Deng ] make PathGlobPatternStatus static 4360b36 [ Tianshuo Deng ] fix tests a74f621 [ Tianshuo Deng ] clean up test 3c581f3 [ Tianshuo Deng ] refactor unit test 6a86de7 [ Tianshuo Deng ] format bdc625d [ Tianshuo Deng ] throw when projection filter matches nothing,140,71,"parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConvertVisitor.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/projection/FieldProjectionFilter.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/projection/PathGlobPattern.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java,CAS_DELIMITER",6,1,4,1.781323079514168,25,57.666666666666664,49,30.94377314814815,257.0,112.47623384480383,84.0,None,FALSE,FALSE,
998d6507ecabf025188d9f3e8c8367f810895a17,Mariappan Asokan,masokan@gmail.com,Wed Mar 4 18:24:21 2015 -0800,1425522261,"PARQUET - 134 patch - Support file write mode Julien , I changed the integer constants to enum as you requested . Please review the patch . Thanks . Author : Mariappan Asokan < masokan @ gmail . com > Closes #111 from masokan / master and squashes the following commits : 7a8aa6f [ Mariappan Asokan ] PARQUET - 134 patch - Support file write mode",91,6,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java,CAS_DELIMITER",3,1,2,1.5806204670262785,25,282.6666666666667,82,30.07037037037037,0.0,0.0,0.0,None,FALSE,FALSE,
ea81e9aac328b2a89226417e58d4d8366891a9f4,Ryan Blue,blue@apache.org,Wed Mar 4 17:56:52 2015 -0800,1425520612,PARQUET - 186 : Fix Precondition performance problem in SnappyUtil . This fixes the problem by adding string formatting to the preconditions . This avoids any string formatting unless the precondition throws an Exception . We should check for string operations in other tight loops as well . Author : Ryan Blue < blue @ apache . org > Closes #133 from rdblue / PARQUET - 186 - precondition - format - string and squashes the following commits : be0b8fe [ Ryan Blue ] PARQUET - 186 : Fix Precondition performance bug in SnappyUtil . 67f9bf2 [ Ryan Blue ] PARQUET - 186 : Add format string and args to Preconditions .,129,12,"parquet-common/src/main/java/parquet/Preconditions.java,CAS_DELIMITER,parquet-common/src/test/java/parquet/TestPreconditions.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyUtil.java,CAS_DELIMITER",3,2,3,1.141242296913756,25,20.666666666666668,9,20.034189814814813,43.0,26.68831323960793,8.0,None,FALSE,FALSE,
d084ad29e0a2f456407f655c99999e070bf529f9,Alex Levenson,alexlevenson@twitter.com,Wed Mar 4 17:26:44 2015 -0800,1425518804,"PARQUET - 160 : avoid wasting 64K per empty buffer . This buffer initializes itself to a default size when instantiated . This leads to a lot of unused small buffers when there are a lot of empty columns . Author : Alex Levenson < alexlevenson @ twitter . com > Author : julien < julien @ twitter . com > Author : Julien Le Dem < julien @ twitter . com > Closes #98 from julienledem / avoid wasting 64K per empty buffer and squashes the following commits : b0200dd [ julien ] add license a1b278e [ julien ] Merge branch 'master' into avoid wasting 64K per empty buffer 5304ee1 [ julien ] remove unused constant 81e399f [ julien ] Merge branch 'avoid wasting 64K per empty buffer' of github . com : julienledem / incubator - parquet - mr into avoid wasting 64K per empty buffer ccf677d [ julien ] Merge branch 'master' into avoid wasting 64K per empty buffer 37148d6 [ Julien Le Dem ] Merge pull request #2 from isnotinvain / PR - 98 b9abab0 [ Alex Levenson ] Address Julien's comment 965af7f [ Alex Levenson ] one more typo 9939d8d [ Alex Levenson ] fix typos in comments 61c0100 [ Alex Levenson ] Make initial slab size heuristic into a helper method , apply in DictionaryValuesWriter as well a257ee4 [ Alex Levenson ] Improve IndexOutOfBoundsException message 64d6c7f [ Alex Levenson ] update comments 8b54667 [ Alex Levenson ] Don't use CapacityByteArrayOutputStream for writing page chunks 6a20e8b [ Alex Levenson ] Remove initialSlabSize decision from InternalParquetRecordReader , use a simpler heuristic in the column writers instead 3a0f8e4 [ Alex Levenson ] Use simpler settings for column chunk writer b2736a1 [ Alex Levenson ] Some cleanup in CapacityByteArrayOutputStream 1df4a71 [ julien ] refactor CapacityByteArray to be aware of page size 95c8fb6 [ julien ] avoid wasting 64K per empty buffer .",430,318,"parquet-column/src/main/java/parquet/column/ParquetProperties.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreV1.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreV2.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnWriterV1.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnWriterV2.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/boundedint/BitWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesFactory.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/deltastrings/DeltaByteArrayWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/impl/TestColumnReaderImpl.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPackingColumn.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/boundedint/TestBoundedColumns.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/deltastrings/TestDeltaByteArray.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/PerfTest.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestFiltered.java,CAS_DELIMITER,parquet-encoding/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java,CAS_DELIMITER,parquet-encoding/src/main/java/parquet/bytes/ConcatenatingByteArrayCollector.java,CAS_DELIMITER,parquet-encoding/src/test/java/parquet/bytes/TestCapacityByteArrayOutputStream.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestColumnChunkPageWriteStore.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java,CAS_DELIMITER",44,5,29,3.982727170096004,25,147.5681818181818,477,27.925837542087514,24.0,9.854704826988073,4.8,None,FALSE,FALSE,
fa8957d7939b59e8d391fa17000b34e865de015d,Colin Marc,colinmarc@gmail.com,Wed Mar 4 12:49:50 2015 -0800,1425502190,"PARQUET - 187 : Replace JavaConversions . asJavaList with JavaConversions . seqAsJavaList The former was removed in 2 . 11 , but the latter exists in 2 . 9 , 2 . 10 and 2 . 11 . With this change , I can build on 2 . 11 without any issue . Author : Colin Marc < colinmarc @ gmail . com > Closes #121 from colinmarc / build - 211 and squashes the following commits : 8a29319 [ Colin Marc ] Replace JavaConversions . asJavaList with JavaConversions . seqAsJavaList .",1,1,"parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java,CAS_DELIMITER",1,1,1,0.0,25,57.0,8,29.83806712962963,18.0,8.12836278814698,1.0,None,FALSE,FALSE,
36a02dc549f32433d7329444455dbb1be2e67f20,Ryan Blue,blue@apache.org,Wed Mar 4 12:35:40 2015 -0800,1425501340,PARQUET - 188 : Change column ordering to match the field order . This was the behavior before the V2 pages were added . Author : Ryan Blue < blue @ apache . org > Closes #129 from rdblue / PARQUET - 188 - fix - column - metadata - order and squashes the following commits : 3c9fa5d [ Ryan Blue ] PARQUET - 188 : Change column ordering to match the field order .,72,8,"parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestColumnChunkPageWriteStore.java,CAS_DELIMITER",2,1,2,0.38431154412649704,25,121.0,25,29.828229166666667,42.0,25.699140054575565,12.0,None,FALSE,FALSE,
c82f703768eb8a122546de23e412a037aa1770b2,Ryan Blue,blue@apache.org,Wed Mar 4 12:26:52 2015 -0800,1425500812,PARQUET - 192 : Fix map null encoding This depends on PARQUET - 191 for the correct schema representation . Author : Ryan Blue < blue @ apache . org > Closes #127 from rdblue / PARQUET - 192 - fix - map - null - encoding and squashes the following commits : fffde82 [ Ryan Blue ] PARQUET - 192 : Fix parquet - avro maps with null values .,75,16,"parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestReadWrite.java,CAS_DELIMITER",2,1,2,0.9534158774525225,25,316.5,37,29.822118055555556,41.0,24.69942006960553,6.0,None,FALSE,FALSE,
f1b54876ab8893a5d9c0e3d7c1a9c884e683dc8a,Ryan Blue,blue@apache.org,Wed Mar 4 12:11:50 2015 -0800,1425499910,PARQUET - 191 : Fix map Type to Avro Schema conversion . Author : Ryan Blue < blue @ apache . org > Closes #126 from rdblue / PARQUET - 191 - fix - map - value - conversion and squashes the following commits : 33f6bbc [ Ryan Blue ] PARQUET - 191 : Fix map Type to Avro Schema conversion .,42,12,"parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java,CAS_DELIMITER",3,1,2,1.268022532211223,25,253.33333333333334,49,29.811678240740736,40.0,23.699869840686855,5.0,None,FALSE,FALSE,
f48bca0510703b0673709b10a806a9d54894a999,Ryan Blue,blue@apache.org,Mon Feb 9 23:07:35 2015 -0800,1423552055,PARQUET - 164 : Add warning when scaling row group sizes . Author : Ryan Blue < blue @ apache . org > Closes #119 from rdblue / PARQUET - 164 - add - memory - manager - warning and squashes the following commits : 241144f [ Ryan Blue ] PARQUET - 164 : Add warning when scaling row group sizes .,4,0,"parquet-hadoop/src/main/java/parquet/hadoop/MemoryManager.java,CAS_DELIMITER",1,1,1,0.0,25,154.0,3,4.35494212962963,39.0,23.647908206428006,11.0,None,FALSE,FALSE,
807915b4cacede6a8de49630469b673b7c248a6f,Yash Datta,Yash.Datta@guavus.com,Mon Feb 9 17:51:46 2015 -0800,1423533106,"PARQUET - 116 : Pass a filter object to user defined predicate in filter2 api Currently for creating a user defined predicate using the new filter api , no value can be passed to create a dynamic filter at runtime . This reduces the usefulness of the user defined predicate , and meaningful predicates cannot be created . We can add a generic Object value that is passed through the api , which can internally be used in the keep function of the user defined predicate for creating many different types of filters . For example , in spark sql , we can pass in a list of filter values for a where IN clause query and filter the row values based on that list . Author : Yash Datta < Yash . Datta @ guavus . com > Author : Alex Levenson < alexlevenson @ twitter . com > Author : Yash Datta < saucam @ gmail . com > Closes #73 from saucam / master and squashes the following commits : 7231a3b [ Yash Datta ] Merge pull request #3 from isnotinvain / alexlevenson / fix - binary - compat dcc276b [ Alex Levenson ] Ignore binary incompatibility in private filter2 class 7bfa5ad [ Yash Datta ] Merge pull request #2 from isnotinvain / alexlevenson / simplify - udp - state 0187376 [ Alex Levenson ] Resolve merge conflicts 25aa716 [ Alex Levenson ] Simplify user defined predicates with state 51952f8 [ Yash Datta ] PARQUET - 116 : Fix whitespace d7b7159 [ Yash Datta ] PARQUET - 116 : Make UserDefined abstract , add two subclasses , one accepting udp class , other accepting serializable udp instance 40d394a [ Yash Datta ] PARQUET - 116 : Fix whitespace 9a63611 [ Yash Datta ] PARQUET - 116 : Fix whitespace 7caa4dc [ Yash Datta ] PARQUET - 116 : Add ConfiguredUserDefined that takes a serialiazble udp directly 0eaabf4 [ Yash Datta ] PARQUET - 116 : Move the config object from keep method to a configure method in udp predicate f51a431 [ Yash Datta ] PARQUET - 116 : Adding type safety for the filter object to be passed to user defined predicate d5a2b9e [ Yash Datta ] PARQUET - 116 : Enforce that the filter object to be passed must be Serializable dfd0478 [ Yash Datta ] PARQUET - 116 : Add a test case for passing a filter object to user defined predicate 4ab46ec [ Yash Datta ] PARQUET - 116 : Pass a filter object to user defined predicate in filter2 api",194,19,"parquet-column/src/main/java/parquet/filter2/predicate/FilterApi.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/filter2/predicate/Operators.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/filter2/predicate/UserDefinedPredicate.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/filter2/predicate/TestFilterApiMethods.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/filter2/recordlevel/TestRecordLevelFilters.java,CAS_DELIMITER",5,2,3,1.9199247991432318,25,224.0,10,7.047743055555555,1.0,0.9631125981425205,0.5,None,FALSE,FALSE,
ce65dfb394623c34dd7919aba5c0687f1bcf39f2,Ryan Blue,blue@apache.org,Thu Feb 5 15:06:12 2015 -0800,1423177572,"PARQUET - 139 : Avoid reading footers when using task - side metadata This updates the InternalParquetRecordReader to initialize the ReadContext in each task rather than once for an entire job . There are two reasons for this change : 1 . For correctness , the requested projection schema must be validated against each file schema , not once using the merged schema . 2 . To avoid reading file footers on the client side , which is a performance bottleneck . Because the read context is reinitialized in every task , it is no longer necessary to pass the its contents to each task in ParquetInputSplit . The fields and accessors have been removed . This also adds a new InputFormat , ParquetFileInputFormat that uses FileSplits instead of ParquetSplits . It goes through the normal ParquetRecordReader and creates a ParquetSplit on the task side . This is to avoid accidental behavior changes in ParquetInputFormat . Author : Ryan Blue < blue @ apache . org > Closes #91 from rdblue / PARQUET - 139 - input - format - task - side and squashes the following commits : cb30660 [ Ryan Blue ] PARQUET - 139 : Fix deprecated reader bug from review fixes . 09cde8d [ Ryan Blue ] PARQUET - 139 : Implement changes from reviews . 3eec553 [ Ryan Blue ] PARQUET - 139 : Merge new InputFormat into ParquetInputFormat . 8971b80 [ Ryan Blue ] PARQUET - 139 : Add ParquetFileInputFormat that uses FileSplit . 87dfe86 [ Ryan Blue ] PARQUET - 139 : Expose read support helper methods . 057c7dc [ Ryan Blue ] PARQUET - 139 : Update reader to initialize read context in tasks .",168,404,"parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper.java,CAS_DELIMITER",9,3,5,2.435212413161463,25,253.0,187,2.9327662037037037,38.0,22.827461520735472,5.0,None,FALSE,TRUE,
05adc21b15dbe30d9bded0cde56f482f1c932d6f,Daniel Weeks,dweeks@netflix.com,Thu Feb 5 14:36:28 2015 -0800,1423175788,PARQUET - 177 : Added lower bound to memory manager resize PARQUET - 177 Author : Daniel Weeks < dweeks @ netflix . com > Closes #115 from danielcweeks / memory - manager - limit and squashes the following commits : b2e4708 [ Daniel Weeks ] Updated to base memory allocation off estimated chunk size 09d7aa3 [ Daniel Weeks ] Updated property name and default value 8f6cff1 [ Daniel Weeks ] Added low bound to memory manager resize,23,2,"parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/MemoryManager.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER",3,1,1,1.2994705707972523,25,166.33333333333334,50,2.9121180555555557,11.0,7.133018400552878,3.0,None,FALSE,TRUE,
668d031d7213d5e76cf39770ffce7f030c9bf056,Colin Marc,colinmarc@gmail.com,Thu Feb 5 11:37:06 2015 -0800,1423165026,"PARQUET - 181 : Scrooge Write Support ( take two ) This is similar to https : / / github . com / apache / incubator - parquet - mr / pull / 43 , but instead of making `ThriftWriteSupport` abstract , it keeps it around ( but deprecated ) and adds `AbstractThriftWriteSupport` . This is a little less elegant , but it seems to appease the semver overlords . Author : Colin Marc < colinmarc @ gmail . com > Closes #58 from colinmarc / scrooge - write - support - 2 and squashes the following commits : e2a0abd [ Colin Marc ] add write support to ParquetScroogeScheme 19cf1a8 [ Colin Marc ] Add ScroogeWriteSupport and ParquetScroogeOutputFormat .",406,100,"parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java,CAS_DELIMITER,parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeOutputFormat.java,CAS_DELIMITER,parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java,CAS_DELIMITER,parquet-scrooge/src/main/java/parquet/scrooge/ScroogeWriteSupport.java,CAS_DELIMITER,parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/AbstractThriftWriteSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/TBaseWriteSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftParquetWriter.java,CAS_DELIMITER",12,3,5,2.9583639769882146,25,79.08333333333333,84,1.858371913580247,17.0,7.437050087182024,2.3333333333333335,None,FALSE,TRUE,
80417356f04c5ee1cd6f636e9b043db3f2de24f2,Cheng Lian,lian@databricks.com,Tue Feb 3 12:53:37 2015 -0800,1422996817,"PARQUET - 173 : Fixes `StatisticsFilter` for `And` filter predicate < ! - - Reviewable : start - - > [ < img src = ""https : / / reviewable . io / review button . png"" height = 40 alt = ""Review on Reviewable"" / > ] ( https : / / reviewable . io / reviews / apache / incubator - parquet - mr / 108 ) < ! - - Reviewable : end - - > Author : Cheng Lian < lian @ databricks . com > Closes #108 from liancheng / PARQUET - 173 and squashes the following commits : d188f0b [ Cheng Lian ] Fixes test case be2c8a1 [ Cheng Lian ] Fixes `StatisticsFilter` for `And` filter predicate",7,3,"parquet-hadoop/src/main/java/parquet/filter2/statisticslevel/StatisticsFilter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/filter2/statisticslevel/TestStatisticsFilter.java,CAS_DELIMITER",2,1,2,0.9709505944546686,25,313.0,6,0.8406944444444444,2.0,1.633684397957862,0.0,None,FALSE,FALSE,
32a9c6d42a3a48314d3f9fe2956bfc8bf49ac5d5,Jim Carroll,jim@dontcallme.com,Thu Jan 29 17:32:54 2015 -0800,1422581574,PARQUET - 157 : Divide by zero fix There is a divide by zero error in logging code inside the InternalParquetRecordReader . I've been running with this fixed for a while but everytime I revert I hit the problem again . I can't believe anyone else hasn't had this problem . I submitted a Jira ticket a few weeks ago but didn't hear anything on the list so here's the fix . This also avoids compiling log statements in some cases where it's unnecessary inside the checkRead method of InternalParquetRecordReader . Also added a . gitignore entry to clean up a build artifact . Author : Jim Carroll < jim @ dontcallme . com > Closes #102 from jimfcarroll / divide - by - zero - fix and squashes the following commits : 423200c [ Jim Carroll ] Filter out parquet - scrooge build artifact from git . 22337f3 [ Jim Carroll ] PARQUET - 157 : Fix a divide by zero error when Parquet runs quickly . Also avoid compiling log statements in some cases where it's unnecessary .,12,9,"parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java,CAS_DELIMITER",1,1,1,0.0,23,205.0,9,49.14684027777778,0.0,0.0,0.0,None,FALSE,FALSE,
b4380f20059dc9e4ccfe2b709587e8069ac0fa34,Neville Li,neville@spotify.com,Thu Jan 29 17:31:04 2015 -0800,1422581464,PARQUET - 142 : add path filter in ParquetReader Currently parquet - tools command fails when input is a directory with SUCCESS file from mapreduce . Filtering those out like ParquetFileReader does fixes the problem . ``` parquet - cat / tmp / parquet write test Could not read footer : java . lang . RuntimeException : file : / tmp / parquet write test / SUCCESS is not a Parquet file ( too small ) $ tree / tmp / parquet write test / tmp / parquet write test ├── part - m - 00000 . parquet └── SUCCESS ``` Author : Neville Li < neville @ spotify . com > Closes #89 from nevillelyh / gh / path - filter and squashes the following commits : 7377a20 [ Neville Li ] PARQUET - 142 : add path filter in ParquetReader,7,1,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java,CAS_DELIMITER",1,1,1,0.0,23,198.0,17,146.2904861111111,0.0,0.0,0.0,None,FALSE,FALSE,
e505e1fea57e0ab9f1d5edab92546d778a5f41e0,Chris Albright,calbright@cj.com,Thu Jan 29 17:29:06 2015 -0800,1422581346,PARQUET - 124 : normalize path checking to prevent mismatch between URI and . . . . . . path Author : Chris Albright < calbright @ cj . com > Closes #79 from chrisalbright / master and squashes the following commits : b1b0086 [ Chris Albright ] Merge remote - tracking branch 'upstream / master' 9669427 [ Chris Albright ] PARQUET - 124 : Adding test ( Thanks Ryan Blue ) that proves mergeFooters was failing 8e342ed [ Chris Albright ] PARQUET - 124 : normalize path checking to prevent mismatch between URI and path,65,33,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java,CAS_DELIMITER",2,1,2,0.6880476235340796,23,276.0,56,74.62647569444444,0.0,0.0,0.0,None,FALSE,FALSE,
0751f97bf6677c3d55aa71542d572dc8fcb9e79a,Laurent Goujon,laurentgo@users.noreply.github.com,Wed Jan 28 16:07:48 2015 -0800,1422490068,"PARQUET - 174 : Replaces AssertionError constructor introduced in Java7 AssertionError ( String , Throwable ) was introduced in Java7 . Replacing it with AssertionError ( String ) + initCause ( Throwable ) Author : Laurent Goujon < laurentgo @ users . noreply . github . com > Closes #101 from laurentgo / fix - java7ism and squashes the following commits : c00fb7c [ Laurent Goujon ] Replaces AssertionError constructor introduced in Java7",1,1,"parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java,CAS_DELIMITER",1,1,1,0.0,23,194.0,8,71.96851851851852,0.0,0.0,0.0,None,FALSE,FALSE,
4bf9be34a87b51d07e0b0c9e74831bbcdbce0f74,Yash Datta,Yash.Datta@guavus.com,Mon Jan 26 18:21:11 2015 -0800,1422325271,"PARQUET - 136 : NPE thrown in StatisticsFilter when all values in a string / binary column trunk are null In case of all nulls in a binary column , statistics object read from file metadata is empty , and should return true for all nulls check for the column . Even if column has no values , it can be ignored . The other way is to fix this behaviour in the writer , but is that what we want ? Author : Yash Datta < Yash . Datta @ guavus . com > Author : Alex Levenson < alexlevenson @ twitter . com > Author : Yash Datta < saucam @ gmail . com > Closes #99 from saucam / npe and squashes the following commits : 5138e44 [ Yash Datta ] PARQUET - 136 : Remove unreachable block b17cd38 [ Yash Datta ] Revert ""PARQUET - 161 : Trigger tests"" 82209e6 [ Yash Datta ] PARQUET - 161 : Trigger tests aab2f81 [ Yash Datta ] PARQUET - 161 : Review comments for the test case 2217ee2 [ Yash Datta ] PARQUET - 161 : Add a test case for checking the correct statistics info is recorded in case of all nulls in a column c2f8d6f [ Yash Datta ] PARQUET - 161 : Fix the write path to write statistics object in case of only nulls in the column 97bb517 [ Yash Datta ] Revert ""revert TestStatisticsFilter . java"" a06f0d0 [ Yash Datta ] Merge pull request #1 from isnotinvain / alexlevenson / PARQUET - 161 - 136 b1001eb [ Alex Levenson ] Fix statistics isEmpty , handle more edge cases in statistics filter 0c88be0 [ Alex Levenson ] revert TestStatisticsFilter . java 1ac9192 [ Yash Datta ] PARQUET - 136 : Its better to not filter chunks for which empty statistics object is returned . Empty statistics can be read in case of 1 . pre - statistics files , 2 . files written from current writer that has a bug , as it does not write the statistics if column has all nulls e5e924e [ Yash Datta ] Revert ""PARQUET - 136 : In case of all nulls in a binary column , statistics object read from file metadata is empty , and should return true for all nulls check for the column"" 8cc5106 [ Yash Datta ] Revert ""PARQUET - 136 : fix hasNulls to cater to the case where all values are nulls"" c7c126f [ Yash Datta ] PARQUET - 136 : fix hasNulls to cater to the case where all values are nulls 974a22b [ Yash Datta ] PARQUET - 136 : In case of all nulls in a binary column , statistics object read from file metadata is empty , and should return true for all nulls check for the column",152,47,"parquet-column/src/main/java/parquet/column/statistics/BinaryStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/statistics/BooleanStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/statistics/DoubleStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/statistics/FloatStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/statistics/IntStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/statistics/LongStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/statistics/Statistics.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/filter2/statisticslevel/StatisticsFilter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/filter2/statisticslevel/TestStatisticsFilter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java,CAS_DELIMITER",11,2,5,3.010384876554332,23,186.27272727272728,99,157.92612373737379,0.0,0.0,0.0,None,FALSE,TRUE,
d70fdbc40195077057a1edb14ccd16a26435d007,Cheng Lian,lian@databricks.com,Fri Jan 23 16:20:10 2015 -0800,1422058810,"PARQUET - 168 : Fixes parquet - tools command line option description < ! - - Reviewable : start - - > [ < img src = ""https : / / reviewable . io / review button . png"" height = 40 alt = ""Review on Reviewable"" / > ] ( https : / / reviewable . io / reviews / apache / incubator - parquet - mr / 106 ) < ! - - Reviewable : end - - > Author : Cheng Lian < lian @ databricks . com > Closes #106 from liancheng / PARQUET - 168 and squashes the following commits : 4524f2d [ Cheng Lian ] Fixes command line option description",2,2,"parquet-tools/src/main/java/parquet/tools/Main.java,CAS_DELIMITER",1,1,1,0.0,1,457.0,3,94.30960648148148,1.0,0.6758893181518567,1.0,None,FALSE,FALSE,
52f3240d90f2397cd1850ab11674ba08a0ecb2a0,Tianshuo Deng,tdeng@twitter.com,Mon Jan 12 16:01:06 2015 -0800,1421107266,"PARQUET - 141 : upgrade to scrooge 3 . 17 . 0 , remove reflection based field info inspection . . . upgrade to scrooge 3 . 17 . 0 , remove reflection based field info inspection , support enum and requirement type correctly This PR is essential for scrooge write support https : / / github . com / apache / incubator - parquet - mr / pull / 58 Author : Tianshuo Deng < tdeng @ twitter . com > Closes #88 from tsdeng / scrooge schema converter upgrade and squashes the following commits : 77cc12a [ Tianshuo Deng ] delete empty line , retrigger jenkins 80d61ad [ Tianshuo Deng ] format 26e1fe1 [ Tianshuo Deng ] fix exception handling 706497d [ Tianshuo Deng ] support union 1b51f0f [ Tianshuo Deng ] upgrade to scrooge 3 . 17 . 0 , remove reflection based field info inspection , support enum and requirement type correctly",131,81,"parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConversionException.java,CAS_DELIMITER,parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java,CAS_DELIMITER,parquet-scrooge/src/test/java/parquet/scrooge/ScroogeStructConverterTest.java,CAS_DELIMITER",3,1,2,0.7067625855209744,17,11.0,9,134.36449845679013,256.0,119.11377058655735,35.0,None,FALSE,FALSE,
23db4eb88aa018da25563586bab322e7c1867ad5,dongche1,dong1.chen@intel.com,Mon Dec 29 09:17:34 2014 -0600,1419866254,"PARQUET - 108 : Parquet Memory Management in Java PARQUET - 108 : Parquet Memory Management in Java . When Parquet tries to write very large ""row groups"" , it may causes tasks to run out of memory during dynamic partitions when a reducer may have many Parquet files open at a given time . This patch implements a memory manager to control the total memory size used by writers and balance their memory usage , which ensures that we don't run out of memory due to writing too many row groups within a single JVM . Author : dongche1 < dong1 . chen @ intel . com > Closes #80 from dongche / master and squashes the following commits : e511f85 [ dongche1 ] Merge remote branch 'upstream / master' 60a96b5 [ dongche1 ] Merge remote branch 'upstream / master' 2d17212 [ dongche1 ] improve MemoryManger instantiation , change access level 6e9333e [ dongche1 ] change blocksize type from int to long e07b16e [ dongche1 ] Refine updateAllocation ( ) , addWriter ( ) . Remove redundant getMemoryPoolRatio 9a0a831 [ dongche1 ] log the inconsistent ratio config instead of thowing an exception 3a35d22 [ dongche1 ] Move the creation of MemoryManager . Throw exception instead of logging it aeda7bc [ dongche1 ] PARQUET - 108 : Parquet Memory Management in Java"" ; c883bba [ dongche1 ] PARQUET - 108 : Parquet Memory Management in Java 7b45b2c [ dongche1 ] PARQUET - 108 : Parquet Memory Management in Java 6d766aa [ dongche1 ] PARQUET - 108 : Parquet Memory Management in Java - - - address some comments 3abfe2b [ dongche1 ] parquet 108",385,15,"parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/MemoryManager.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestMemoryManager.java,CAS_DELIMITER",7,1,2,2.4786676696726224,24,126.0,106,88.98249503968255,0.0,0.0,0.0,None,FALSE,TRUE,
b7a82a918f0a595a96047f7eef2672fd95d5626c,Wolfgang Hoschek,whoschek@cloudera.com,Thu Dec 11 14:01:27 2014 -0800,1418335287,PARQUET - 145 InternalParquetRecordReader . close ( ) should not throw an exception if initialization has failed PARQUET - 145 InternalParquetRecordReader . close ( ) should not throw an exception if initialization has failed Author : Wolfgang Hoschek < whoschek @ cloudera . com > Closes #93 from whoschek / PARQUET - 145 - 3 and squashes the following commits : 52a6acb [ Wolfgang Hoschek ] PARQUET - 145 InternalParquetRecordReader . close ( ) should not throw an exception if initialization has failed,3,1,"parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java,CAS_DELIMITER",1,1,1,0.0,23,203.0,8,135.01560185185184,0.0,0.0,0.0,Corrective,TRUE,FALSE,
ccc29e4dde24584118211f27c71bb01bacc39326,julien,julien@twitter.com,Thu Dec 4 13:16:11 2014 -0800,1417727771,PARQUET - 117 : implement the new page format for Parquet 2 . 0 The new page format was defined some time ago : https : / / github . com / Parquet / parquet - format / pull / 64 https : / / github . com / Parquet / parquet - format / issues / 44 The goals are the following : - cut pages on record boundaries to facilitate skipping pages in predicate poush down - read rl and dl independently of data - optionally not compress data Author : julien < julien @ twitter . com > Closes #75 from julienledem / new page format and squashes the following commits : fbbc23a [ julien ] make mvn install display output only if it fails 4189383 [ julien ] save output lines as travis cuts after 10000 44d3684 [ julien ] fix parquet - tools for new page format 0fb8c15 [ julien ] Merge branch 'master' into new page format 5880cbb [ julien ] Merge branch 'master' into new page format 6ee7303 [ julien ] make parquet . column package not semver compliant 42f6c9f [ julien ] add tests and fix bugs 266302b [ julien ] fix write path 4e76369 [ julien ] read path 050a487 [ julien ] fix compilation e0e9d00 [ julien ] better ColumnWriterStore definition ecf04ce [ julien ] remove unnecessary change 2bc4d01 [ julien ] first stab at write path for the new page format,1682,726,"parquet-column/src/main/java/parquet/column/ColumnWriteStore.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/ColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/ParquetProperties.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreV1.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreV2.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnWriterV1.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnWriterV2.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/page/DataPage.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/page/DataPageV1.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/page/DataPageV2.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/page/DictionaryPage.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/page/Page.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/page/PageReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/page/PageWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/ValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/MessageColumnIO.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/impl/TestColumnReaderImpl.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/mem/TestMemPageStore.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/page/mem/MemPageReader.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/page/mem/MemPageStore.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/PerfTest.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestFiltered.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestColumnChunkPageWriteStore.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestParquetWriterNewPage.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java,CAS_DELIMITER,parquet-tools/src/main/java/parquet/tools/command/DumpCommand.java,CAS_DELIMITER",41,5,16,4.582644222973475,23,92.8780487804878,473,210.48743337850055,368.0,147.64238658336623,70.4,None,FALSE,TRUE,
b5f6a3bd86bfe0f186b07eb69480564d5fc854dc,Josh Wills,jwills@cloudera.com,Tue Dec 2 16:19:14 2014 +0000,1417537154,PARQUET - 140 : Allow clients to control the GenericData instance used to read Avro records Author : Josh Wills < jwills @ cloudera . com > Closes #90 from jwills / master and squashes the following commits : 044cf54 [ Josh Wills ] PARQUET - 140 : Allow clients to control the GenericData object that is used to read Avro records,124,27,"parquet-avro/src/main/java/parquet/avro/AvroDataSupplier.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroRecordMaterializer.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/SpecificDataSupplier.java,CAS_DELIMITER",6,1,1,2.1879817321390993,15,69.16666666666667,48,141.08442322530865,2.0,0.7725366607861242,2.0,None,FALSE,TRUE,
ad06e61143d6ad3d883907e75100014b9554c357,julien,julien@twitter.com,Tue Nov 25 10:48:54 2014 -0800,1416941334,PARQUET - 52 : refactor fallback mechanism See : https : / / issues . apache . org / jira / browse / PARQUET - 52 Context : In the ValuesWriter API there is a mechanism to return the Encoding actually used which allows to fallback to a different encoding . For example the dictionary encoding may fail if there are too many distinct values and the dictionary grows too big . In such cases the DictionaryValuesWriter was falling back to the Plain encoding . This can happen as well if the space savings are not satisfying when writing the first page and we prefer to fallback to a more light weight encoding . With Parquet 2 . 0 we are adding new encodings and the fall back is not necessarily Plain anymore . This Pull Request decouple the fallback mechanism from Dictionary and Plain encodings and allows to reuse the fallback logic with other encodings . One could imagine more than one level of fallback in the future by chaining the FallBackValuesWriter . Author : julien < julien @ twitter . com > Closes #74 from julienledem / fallback and squashes the following commits : b74a4ca [ julien ] Merge branch 'master' into fallback d9abd62 [ julien ] better naming aa90caf [ julien ] exclude values encoding from SemVer 10f295e [ julien ] better test setup c516bd9 [ julien ] improve test 780c4c3 [ julien ] license header f16311a [ julien ] javadoc aeb8084 [ julien ] add more test ; fix dic decoding 0793399 [ julien ] Merge branch 'master' into fallback 2638ec9 [ julien ] fix dictionary encoding labelling 2fd9372 [ julien ] consistent naming cf7a734 [ julien ] rewrite ParquetProperties to enable proper fallback bf1474a [ julien ] refactor fallback mechanism,748,351,"parquet-column/src/main/java/parquet/column/Encoding.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/ParquetProperties.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/RequiresFallback.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/PlainValuesDictionary.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/fallback/FallbackValuesWriter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/example/GroupWriteSupport.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestParquetWriter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestUtils.java,CAS_DELIMITER",11,2,7,2.775343520145997,23,217.9090909090909,147,121.3611311026936,367.0,148.22161632163338,120.5,None,FALSE,FALSE,
3aa6f11785a2f1b3b09df328a02a2c28dfa0bb57,Brock Noland,brock@apache.org,Thu Nov 20 09:19:25 2014 -0800,1416503965,PARQUET - 114 : Sample NanoTime class serializes and deserializes Timestamp incorrectly I ran the Parquet Column tests and they passed . FYI @ rdblue Author : Brock Noland < brock @ apache . org > Closes #71 from brockn / master and squashes the following commits : 69ba484 [ Brock Noland ] PARQUET - 114 - Sample NanoTime class serializes and deserializes Timestamp incorrectly,7,2,"parquet-column/src/main/java/parquet/example/data/simple/NanoTime.java,CAS_DELIMITER",1,1,1,0.0,19,57.0,1,278.8354282407407,9.0,4.809060295833953,0.0,None,FALSE,FALSE,
d105819a0e72765ff5ba4efa5622d727360ee2b8,Ryan Blue,blue@apache.org,Tue Nov 18 20:20:04 2014 -0800,1416370804,PARQUET - 132 : Add type parameter to AvroParquetInputFormat . Author : Ryan Blue < blue @ apache . org > Closes #84 from rdblue / PARQUET - 132 - parameterize - avro - inputformat and squashes the following commits : 63114b0 [ Ryan Blue ] PARQUET - 132 : Add type parameter to AvroParquetInputFormat .,1,1,"parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java,CAS_DELIMITER",1,1,1,0.0,15,70.0,7,335.52875,35.0,23.058484603859487,2.0,None,FALSE,FALSE,
251a495d2a72de7e892ade7f64980f51f2fcc0dd,elif dede,edede@twitter.com,Mon Nov 17 16:53:08 2014 -0800,1416271988,PARQUET - 135 : Input location is not getting set for the getStatistics in ParquetLoader when using two different loaders within a Pig script . Author : elif dede < edede @ twitter . com > Closes #86 from elifdd / parquetLoader error PARQUET - 135 and squashes the following commits : b0150ee [ elif dede ] fixed white space bdb381a [ elif dede ] PARQUET - 135 : Call setInput from getStatistics in ParquetLoader to fix ReduceEstimator errors in pig jobs,4,3,"parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/ParquetLoader.java,CAS_DELIMITER",2,2,2,0.863120568566631,23,208.5,48,60.21831597222223,0.0,0.0,0.0,None,FALSE,FALSE,
92e6d716069686583b852a6dcf12af986d6dc694,julien,julien@twitter.com,Fri Nov 7 11:02:27 2014 -0800,1415386947,PARQUET - 122 : make task side metadata true by default Author : julien < julien @ twitter . com > Closes #78 from julienledem / task side metadata default true and squashes the following commits : 32451a7 [ julien ] make task side metadata true by default,13,2,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER",1,1,1,0.0,23,635.0,51,63.02061342592592,366.0,150.4018444786471,101.0,None,FALSE,FALSE,
f1da5e927ed18aeec1610bec67f88facd6a470e1,Tom White,tom@cloudera.com,Mon Nov 3 14:11:03 2014 +0000,1415023863,"PARQUET - 121 : Allow Parquet to build with Java 8 There are test failures running with Java 8 due to http : / / openjdk . java . net / jeps / 180 which changed retrieval order for HashMap . Here's how I tested this : ```bash use - java8 mvn clean install - DskipTests - Dmaven . javadoc . skip = true mvn test mvn test - P hadoop - 2 ``` I also compiled the main code with Java 7 ( target = 1 . 6 bytecode ) , and compiled the tests with Java 8 , and ran them with Java 8 . The idea here is to simulate users who want to run Parquet with JRE 8 . ```bash use - java7 mvn clean install - DskipTests - Dmaven . javadoc . skip = true use - java8 find . - name test - classes | grep target / test - classes | grep - v 'parquet - scrooge' | xargs rm - rf mvn test - DtargetJavaVersion = 1 . 8 - Dmaven . main . skip = true - Dscala . maven . test . skip = true ``` A couple of notes about this : * The targetJavaVersion property is used since other Hadoop projects use the same name . * I couldn’t get parquet - scrooge to compile with target = 1 . 8 , which is why I introduced scala . maven . test . skip ( and updated scala - maven - plugin to the latest version which supports the property ) . Compiling with target = 1 . 8 should be fixed in another JIRA as it looks pretty involved . Author : Tom White < tom @ cloudera . com > Closes #77 from tomwhite / PARQUET - 121 - java8 and squashes the following commits : 8717e13 [ Tom White ] Fix tests to run under Java 8 . 35ea670 [ Tom White ] PARQUET - 121 . Allow Parquet to build with Java 8 .",61,8,"parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TestParquetStorer.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java,CAS_DELIMITER",4,2,3,1.5146748859094499,20,169.75,30,230.8173726851852,30.0,14.559011869416528,2.5,None,FALSE,FALSE,
a29815abf4f0e51b332a8af1b83ad344104c14d9,Matt Massie,massie@cs.berkeley.edu,Mon Nov 3 14:00:33 2014 +0000,1415023233,"PARQUET - 123 : Enable dictionary support in AvroIndexedRecordConverter If consumers are loading Parquet records into an immutable structure like an Apache Spark RDD , being able to configure string reuse in AvroIndexedRecordConverter can drastically reduce the overall memory footprint of strings . NOTE : This isn't meant to be a merge - able PR ( yet ) . I want to use this PR as a way to discuss : ( 1 ) if this is a reasonable approach and ( 2 ) to learn if PrimitiveConverter needs to be thread - safe as I'm currently using a ConcurrentHashMap . If there's agreement that this would be worthwhile , I'll create a JIRA and write some unit tests . Author : Matt Massie < massie @ cs . berkeley . edu > Closes #76 from massie / immutable - strings and squashes the following commits : 88ce5bf [ Matt Massie ] PARQUET - 123 : Enable dictionary support in AvroIndexedRecordConverter",33,4,"parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java,CAS_DELIMITER",2,1,2,0.8779620013943912,15,234.5,31,288.3687673611111,4.0,1.714004354995015,4.0,None,FALSE,FALSE,
ccfca8f714055cd9fbd00cf7e847b880132cae69,Daniel Weeks,dweeks@netflix.com,Wed Oct 29 11:10:16 2014 -0700,1414606216,PARQUET - 106 : Relax InputSplit Protections https : / / issues . apache . org / jira / browse / PARQUET - 106 Author : Daniel Weeks < dweeks @ netflix . com > Closes #67 from dcw - netflix / input - split2 and squashes the following commits : 2f2c0c7 [ Daniel Weeks ] Update ParquetInputSplit . java 12bd3c1 [ Daniel Weeks ] Update ParquetInputSplit . java 6c662ee [ Daniel Weeks ] Update ParquetInputSplit . java 5f9f02e [ Daniel Weeks ] Update ParquetInputSplit . java d19e1ac [ Daniel Weeks ] Merge branch 'master' into input - split2 c4172bb [ Daniel Weeks ] Merge remote - tracking branch 'upstream / master' 01a5e8f [ Daniel Weeks ] Relaxed protections on input split class d37a6de [ Daniel Weeks ] Resetting pom to main 0c1572e [ Daniel Weeks ] Merge remote - tracking branch 'upstream / master' 98c6607 [ Daniel Weeks ] Merge remote - tracking branch 'upstream / master' 96ba602 [ Daniel Weeks ] Disabled projects that don't compile,6,6,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java,CAS_DELIMITER",1,1,1,0.0,23,76.0,19,53.984375,10.0,7.682393351668638,2.0,None,FALSE,FALSE,
31fb4dfef212791f86f052ce8a3adeabaf830cf2,Tianshuo Deng,tdeng@twitter.com,Tue Oct 21 09:54:20 2014 -0700,1413910460,"PARQUET - 105 : use mvn shade plugin to create uber jar , support meta on a folder 1 . Make hadoop dependency from parquet - tools so it is provided . It can be used against different version of hadoop 2 . Use maven shade plugin to create a all in one jar , which can be used both locally or in hadoop 3 . Make parquet - meta command support both folder ( read summary file ) and a single file Author : Tianshuo Deng < tdeng @ twitter . com > Closes #69 from tsdeng / bundle parquet tools and squashes the following commits : d8dcd3e [ Tianshuo Deng ] print file offset , file path , and cancel autoCrop a2d1399 [ Tianshuo Deng ] support local mode 5009a85 [ Tianshuo Deng ] fix README 0756f81 [ Tianshuo Deng ] remove semver check for parquet tools 78c7f4b [ Tianshuo Deng ] use mvn shade plugin to create uber jar , support meta on a folder",29,25,"parquet-tools/src/main/java/parquet/tools/Main.java,CAS_DELIMITER,parquet-tools/src/main/java/parquet/tools/command/ShowMetaCommand.java,CAS_DELIMITER,parquet-tools/src/main/java/parquet/tools/command/ShowSchemaCommand.java,CAS_DELIMITER,parquet-tools/src/main/java/parquet/tools/util/MetadataUtils.java,CAS_DELIMITER",4,1,3,1.4201671640410554,1,301.75,9,203.8496064814815,255.0,132.58884610075984,0.0,None,FALSE,FALSE,
be1222ef4a3260ddcf516d73c6ceecd144a134cb,Ryan Blue,rblue@cloudera.com,Wed Oct 1 14:14:24 2014 -0700,1412198064,"PARQUET - 107 : Add option to disable summary metadata . This adds an option to the commitJob phase of the MR OutputCommitter , parquet . enable . summary - metadata ( default true ) , that can be used to disable the summary metadata files generated from the footers of all of the files produced . This enables more control over when those summary files are produced and makes it possible to rename MR outputs and then generate the summaries . Author : Ryan Blue < rblue @ cloudera . com > Closes #68 from rdblue / PARQUET - 107 - add - summary - metadata - option and squashes the following commits : 261e5e4 [ Ryan Blue ] PARQUET - 107 : Add option to disable summary metadata .",19,12,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputCommitter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER",2,1,1,0.6373874992221911,23,72.0,34,26.11224537037037,34.0,24.33098836009285,8.0,None,FALSE,FALSE,
da9129927bce90feb6d2860745263f4d74d0dfa8,Ryan Blue,rblue@cloudera.com,Wed Oct 1 13:44:45 2014 -0700,1412196285,PARQUET - 64 : Add new OriginalTypes in parquet - format 2 . 2 . 0 . This implements the restrictions for those types documented in the parquet - format logical types spec . This requires a release of parquet - format 2 . 2 . 0 with the new types . I'll rebase and update the dependency when it is released . Author : Ryan Blue < rblue @ cloudera . com > Closes #31 from rdblue / PARQUET - 64 - add - new - types and squashes the following commits : 10feab9 [ Ryan Blue ] PARQUET - 64 : Add new OriginalTypes in parquet - format 2 . 2 . 0 .,346,49,"parquet-column/src/main/java/parquet/schema/OriginalType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/Types.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/parser/TestParquetParser.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java,CAS_DELIMITER",6,2,5,1.9061201520488347,23,294.1666666666667,69,37.24345293209877,33.0,23.331999686961144,16.5,None,FALSE,FALSE,
0b17cbee9541998df66d33c8a99b675ced80d9aa,Tianshuo Deng,tdeng@twitter.com,Mon Sep 29 12:00:03 2014 -0700,1412017203,"PARQUET - 104 : Fix writing empty row group at the end of the file At then end of a parquet file , it may writes an empty rowgroup . This happens when : numberOfRecords mod sizeOfRowGroup = 0 Author : Tianshuo Deng < tdeng @ twitter . com > Closes #66 from tsdeng / fix empty row group and squashes the following commits : 10b93fb [ Tianshuo Deng ] rename e3a5896 [ Tianshuo Deng ] format 91fa0d4 [ Tianshuo Deng ] fix empty row group",34,30,"parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java,CAS_DELIMITER",1,1,1,0.0,18,166.0,12,39.910011574074076,254.0,135.95717054040725,57.0,None,FALSE,TRUE,
bf20abbf4825fa5892d8e15c066e768671a39289,Colin Marc,colinmarc@gmail.com,Thu Sep 25 16:45:56 2014 -0700,1411688756,"PARQUET - 96 : fill out some missing methods on parquet . example classes I'm slightly embarrassed to say that we use these , and we'd really like to stop needing a fork , so here we are . Author : Colin Marc < colinmarc @ gmail . com > Closes #59 from colinmarc / missing - group - methods and squashes the following commits : af8ea08 [ Colin Marc ] fill out some missing methods on parquet . example classes",34,1,"parquet-column/src/main/java/parquet/example/data/Group.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/GroupValueSource.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java,CAS_DELIMITER",3,1,2,1.4716774936810642,20,27.333333333333332,31,100.4755439814815,16.0,7.909981897045248,0.0,None,FALSE,FALSE,
3a082e8e390898646c094d20f4ec1eeba45b79ac,julien,julien@twitter.com,Thu Sep 25 11:25:53 2014 -0700,1411669553,PARQUET - 90 : integrate field ids in schema This integrates support for field is that was introduced in Parquet format . Thrift and Protobufs ids will now be saved in the Parquet schema . Author : julien < julien @ twitter . com > Closes #56 from julienledem / field ids and squashes the following commits : 62c2809 [ julien ] remove withOriginalType ; use Typles builder more 8ff0034 [ julien ] review feedback 084c8be [ julien ] binary compat 85d785c [ julien ] add proto id in schema ; fix schema parsing for ids d4be488 [ julien ] integrate field ids in schema,611,387,"parquet-column/src/main/java/parquet/schema/GroupType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/MessageType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/MessageTypeParser.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/PrimitiveType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/Type.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/Types.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/parser/TestParquetParser.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/schema/TestMessageType.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/ProtoSchemaConverter.java,CAS_DELIMITER,parquet-protobuf/src/test/java/parquet/proto/ProtoSchemaConverterTest.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConvertVisitor.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/projection/FieldsPath.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java,CAS_DELIMITER",16,5,10,3.4842536517239333,23,164.1875,185,186.82412832754628,365.0,157.51193566613935,69.0,None,FALSE,TRUE,
0c4f13a846b458e31cfcaafd8e83f0f4c1d04237,julien,julien@twitter.com,Thu Sep 25 10:12:58 2014 -0700,1411665178,PARQUET - 101 : fix meta data lookup when not using task . side . metadata Author : julien < julien @ twitter . com > Closes #64 from julienledem / PARQUET - 101 and squashes the following commits : 54ffbc9 [ julien ] fix meta data lookup when not using task . side . metadata,13,7,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java,CAS_DELIMITER",1,1,1,0.0,23,9.0,26,19.944583333333334,364.0,156.5219010496298,99.0,None,FALSE,FALSE,
59c58d0b829aa156f038cc900b803508f8849765,Ryan Blue,rblue@cloudera.com,Tue Sep 23 12:14:17 2014 -0700,1411499657,PARQUET - 82 : Check page size is valid when writing . Author : Ryan Blue < rblue @ cloudera . com > Closes #48 from rdblue / PARQUET - 82 - check - page - size and squashes the following commits : 9f31402 [ Ryan Blue ] PARQUET - 82 : Check page size is valid when writing .,20,0,"parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java,CAS_DELIMITER",1,1,1,0.0,20,101.0,20,152.84172453703704,32.0,22.71222272757984,6.0,None,FALSE,FALSE,
0eb96379518db4f84f7a95b651c6dc9a639cc9ac,Ryan Blue,rblue@cloudera.com,Mon Sep 22 15:07:04 2014 -0700,1411423624,PARQUET - 89 : Add hadoop - 2 test profile for Travis CI . This also fixes problems that prevented hadoop - 2 from passing : * Dynamically resolve counter methods in parquet - hadoop * Parameterize pig version with hadoop - 2 support * Update pig test for hadoop - 2 change ( no nulls allowed ) * Update parquet - hive to depend on hadoop - client The travis config will now run each test profile in a different run . Author : Ryan Blue < rblue @ cloudera . com > Closes #55 from rdblue / PARQUET - 89 - add - test - profiles and squashes the following commits : 006c6d8 [ Ryan Blue ] PARQUET - 89 : Add hadoop - 2 test profile for travis CI .,26,155,"parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/summary/TestSummary.java,CAS_DELIMITER,parquet-test-hadoop2/src/test/java/parquet/hadoop2/TestInputOutputFormat.java,CAS_DELIMITER",3,3,3,0.9886858080605461,23,148.33333333333334,27,325.75981867283946,31.0,21.752079552037525,1.6666666666666667,None,FALSE,FALSE,
3dc223cc85022e11dc6cd954784e715e3a49fe5c,Daniel Weeks,dweeks@netflix.com,Mon Sep 22 11:21:20 2014 -0700,1411410080,"PARQUET - 92 : Pig parallel control The parallelism for reading footers was fixed at '5' , which isn't optimal for using pig with S3 . Just adding a property to adjust the parallelism . JIRA : https : / / issues . apache . org / jira / browse / PARQUET - 92 Author : Daniel Weeks < dweeks @ netflix . com > Closes #57 from dcw - netflix / pig - parallel - control and squashes the following commits : e49087c [ Daniel Weeks ] Update ParquetFileReader . java ec4f8ca [ Daniel Weeks ] Added configurable control of parallelism d37a6de [ Daniel Weeks ] Resetting pom to main 0c1572e [ Daniel Weeks ] Merge remote - tracking branch 'upstream / master' 98c6607 [ Daniel Weeks ] Merge remote - tracking branch 'upstream / master' 96ba602 [ Daniel Weeks ] Disabled projects that don't compile",5,2,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER",1,1,1,0.0,23,428.0,38,16.992060185185185,9.0,7.338602689957195,1.0,None,FALSE,FALSE,
9cdcf3bbdf8f772d3fadf388b2db048598c155e9,Alex Levenson,alexlevenson@twitter.com,Mon Sep 22 11:11:08 2014 -0700,1411409468,"PARQUET - 94 : Fix bug in ParquetScroogeScheme constructor , minor cleanup I noticed that ParquetScroogeScheme's constructor ignores the provided klass argument . I also added in missing type parameters for the Config object where they were missing . Author : Alex Levenson < alexlevenson @ twitter . com > Closes #61 from isnotinvain / alexlevenson / parquet - scrooge - cleanup and squashes the following commits : 2b16007 [ Alex Levenson ] Fix bug in ParquetScroogeScheme constructor , minor cleanup",19,27,"parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java,CAS_DELIMITER,parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java,CAS_DELIMITER,parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java,CAS_DELIMITER",3,2,2,1.4938462544479019,18,107.33333333333333,26,12.023113425925926,23.0,11.325234159812469,1.0,None,FALSE,FALSE,
f637c4458a3b1dc4ecaa35957adf13ecfbe7d12d,Tianshuo Deng,tdeng@twitter.com,Wed Sep 10 10:37:51 2014 -0700,1410370671,"PARQUET - 87 : Add API for projection pushdown on the cascading scheme level JIRA : https : / / issues . apache . org / jira / browse / PARQUET - 87 Previously , the projection pushdown configuration is global , and not bind to a specific tap . After adding this API , projection pushdown can be done more ""naturally"" , which may benefit scalding . The code that uses this API would look like : ``` Scheme sourceScheme = new ParquetScroogeScheme ( new Config ( ) . withProjection ( projectionFilter ) ) ; Tap source = new Hfs ( sourceScheme , PARQUET PATH ) ; ``` Author : Tianshuo Deng < tdeng @ twitter . com > Closes #51 from tsdeng / projection from scheme and squashes the following commits : 2c72757 [ Tianshuo Deng ] make config class final 813dc1a [ Tianshuo Deng ] erge branch 'master' into projection from scheme b587b79 [ Tianshuo Deng ] make constructor of Config private , fix format 3aa7dd2 [ Tianshuo Deng ] remove builder 9348266 [ Tianshuo Deng ] use builder ( ) 7c91869 [ Tianshuo Deng ] make fields of Config private , create builder method for Config 5fdc881 [ Tianshuo Deng ] builder for setting projection pushdown and predicate pushdown a47f271 [ Tianshuo Deng ] immutable 3d514b1 [ Tianshuo Deng ] done",175,61,"parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java,CAS_DELIMITER,parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java,CAS_DELIMITER,parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java,CAS_DELIMITER,parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java,CAS_DELIMITER",5,3,4,1.671599990451393,18,126.6,59,50.323421296296296,253.0,138.94982587528335,42.333333333333336,None,FALSE,TRUE,
5f39948b2414ea2582892f6447566d7fe4909b4f,Tianshuo Deng,tdeng@twitter.com,Mon Sep 8 14:12:11 2014 -0700,1410210731,update scala 2 . 10 Try to upgrade to scala 2 . 10 Author : Tianshuo Deng < tdeng @ twitter . com > Closes #35 from tsdeng / update scala 2 10 and squashes the following commits : 1b7e55f [ Tianshuo Deng ] fix comment bed9de3 [ Tianshuo Deng ] remove twitter artifactory 2bce643 [ Tianshuo Deng ] publish fix 06b374e [ Tianshuo Deng ] define scala . binary . version fcf6965 [ Tianshuo Deng ] Merge branch 'master' into update scala 2 10 e91d9f7 [ Tianshuo Deng ] update version 5d18b88 [ Tianshuo Deng ] version 83df898 [ Tianshuo Deng ] update scala 2 . 10,2,1,"parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java,CAS_DELIMITER",1,1,1,0.0,17,30.0,5,144.12488425925926,252.0,138.34545064078935,33.0,None,FALSE,FALSE,
5dafd127f3de7c516ce9c1b7329087a01ab2fc57,julien,julien@twitter.com,Fri Sep 5 11:32:46 2014 -0700,1409941966,PARQUET - 84 : Avoid reading rowgroup metadata in memory on the client side . This will improve reading big datasets with a large schema ( thousands of columns ) Instead rowgroup metadata can be read in the tasks where each tasks reads only the metadata of the file it's reading Author : julien < julien @ twitter . com > Closes #45 from julienledem / skip reading row groups and squashes the following commits : ccdd08c [ julien ] fix parquet - hive 24a2050 [ julien ] Merge branch 'master' into skip reading row groups 3d7e35a [ julien ] adress review feedback 5b6bd1b [ julien ] more tests 323d254 [ julien ] sdd unit tests f599259 [ julien ] review feedback fb11f02 [ julien ] fix backward compatibility check 2c20b46 [ julien ] cleanup readFooters methods 3da37d8 [ julien ] fix read summary ab95a45 [ julien ] cleanup 4d16df3 [ julien ] implement task side metadata 9bb8059 [ julien ] first stab at integrating skipping row groups,1359,723,"parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputCommitter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedInputFormatTest.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestParquetInputSplit.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/ParquetLoader.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java,CAS_DELIMITER",21,3,8,3.180464048982874,23,176.52380952380952,402,99.30512070105821,363.0,159.49845863309358,51.333333333333336,None,FALSE,TRUE,
647b8a70f9b7c94cabf9a7ec7bce2e7cbbb4c05b,Ryan Blue,rblue@cloudera.com,Thu Sep 4 11:28:03 2014 -0700,1409855283,"PARQUET - 63 : Enable dictionary encoding for FIXED . This uses the existing dictionary support introduced for int96 . Encoding and ParquetProperties have been updated to use the dictionary supporting classes , when requested for write or present during read . This also fixes a bug in the fixed dictionary values writer , where the length was hard - coded for int96 , 12 bytes . Author : Ryan Blue < rblue @ cloudera . com > Closes #30 from rdblue / PARQUET - 63 - add - fixed - dictionary - support and squashes the following commits : bc34a34 [ Ryan Blue ] PARQUET - 63 : Enable dictionary encoding for FIXED .",32,17,"parquet-column/src/main/java/parquet/column/Encoding.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/ParquetProperties.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER",6,1,5,1.5998186513535884,20,263.8333333333333,155,118.90765625,30.0,21.555200237545893,25.0,None,FALSE,FALSE,
f8b06df7a56f92f4bc7dd564ad7ec026e3b4f3da,Tianshuo Deng,tdeng@twitter.com,Wed Sep 3 15:37:00 2014 -0700,1409783820,"do ProtocolEvents fixing only when there is required fields missing in the requested schema https : / / issues . apache . org / jira / browse / PARQUET - 61 This PR is trying to redo the https : / / github . com / apache / incubator - parquet - mr / pull / 7 In this PR , it fixes the protocol event in a more precise condition : Only when the requested schema missing some required fields that are present in the full schema So even if there a projection , as long as the projection is not getting rid of the required field , the protocol events amender will not be called . Could you take a look at this ? @ dvryaboy @ yan - qi Author : Tianshuo Deng < tdeng @ twitter . com > Closes #28 from tsdeng / fix protocol when required field missing and squashes the following commits : ba778b9 [ Tianshuo Deng ] add continue for readability d5639df [ Tianshuo Deng ] fix unused import 090e894 [ Tianshuo Deng ] format 13a609d [ Tianshuo Deng ] comment format ef1fe58 [ Tianshuo Deng ] little refactor , remove the hasMissingRequiredFieldFromProjection method 7c2c158 [ Tianshuo Deng ] format 83a5655 [ Tianshuo Deng ] do ProtocolEvents fixing only when there is required fields missing in the requested schema",35,2,"parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java,CAS_DELIMITER",1,1,1,0.0,23,824.0,20,36.040289351851854,251.0,138.39912249826608,82.0,Corrective,TRUE,FALSE,
d3cd97a8ad7f1c1df48bf42080d993b861158786,Daniel Weeks,dweeks@netflix.com,Thu Aug 28 11:30:50 2014 -0700,1409250650,PARQUET - 75 : Fixed string decode performance issue Switch to using 'UTF8 . decode' as opposed to 'new String' https : / / issues . apache . org / jira / browse / PARQUET - 75 Author : Daniel Weeks < dweeks @ netflix . com > Closes #40 from dcw - netflix / string - decode and squashes the following commits : 2cf53e7 [ Daniel Weeks ] Fixed string decode performance issue,2,2,"parquet-column/src/main/java/parquet/io/api/Binary.java,CAS_DELIMITER",1,1,1,0.0,23,222.0,16,29.869340277777777,8.0,6.776693312236766,1.0,None,FALSE,FALSE,
84ebe4c82405895706552ccf1becf6647886663f,Eric Snyder,snyderep@gmail.com,Wed Aug 20 14:09:38 2014 -0700,1408568978,PARQUET - 66 : Upcast blockSize to long to prevent integer overflow . Author : Eric Snyder < snyderep @ gmail . com > Closes #33 from snyderep / master and squashes the following commits : c99802e [ Eric Snyder ] PARQUET - 66 : Upcast blockSize to long to prevent integer overflow .,1,1,"parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java,CAS_DELIMITER",1,1,1,0.0,18,166.0,11,0.00011574074074074075,0.0,0.0,0.0,None,FALSE,FALSE,
792b1490db122e953c9120279ddc86407ffae3c0,julien,julien@twitter.com,Wed Aug 20 14:09:28 2014 -0700,1408568968,PARQUET - 67 : mechanism to add extra metadata in the footer this expands on the idea proposed by @ wesleypeck in https : / / github . com / Parquet / parquet - mr / pull / 185 Author : julien < julien @ twitter . com > Closes #32 from julienledem / extensible metadata and squashes the following commits : 72e0a50 [ julien ] mechanism to add extra metadata in the footer,209,28,"parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/api/DelegatingReadSupport.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/api/DelegatingWriteSupport.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/api/WriteSupport.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java,CAS_DELIMITER",6,1,3,2.2562695111952946,18,88.16666666666667,61,194.46233217592592,359.0,158.7106113507933,97.0,None,FALSE,TRUE,
54bb983271adcbcc1519ab9e2288871d69093708,Ryan Blue,rblue@cloudera.com,Wed Aug 20 14:02:01 2014 -0700,1408568521,"PARQUET - 62 : Fix binary dictionary write bug . The binary dictionary writers keep track of written values in memory to deduplicate and write dictionary pages periodically . If the written values are changed by the caller , then this corrupts the dictionary without an error message . This adds a defensive copy to fix the problem . Author : Ryan Blue < rblue @ cloudera . com > Closes #29 from rdblue / PARQUET - 62 - fix - dictionary - bug and squashes the following commits : 42b6920 [ Ryan Blue ] PARQUET - 62 : Fix binary dictionary write bug .",38,3,"parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java,CAS_DELIMITER",2,1,2,0.8014698931335287,19,575.5,65,110.03277777777778,28.0,20.181137116343052,24.0,None,FALSE,TRUE,
7b415faaed09eba1103ea30577ef1a32fba7048c,Daniel Weeks,dweeks@netflix.com,Wed Aug 20 13:52:42 2014 -0700,1408567962,"Parquet - 70 : Fixed storing pig schema to udfcontext for non projection case and moved . . . . . . column index access setting to udfcontext so as not to affect other loaders . I found an problem that affects both the Column name access and column index access due to the way the pig schema is stored by the loader . ##Column Name Access : The ParquetLoader was only storing the pig schema in the UDFContext when push projection is applied . In the full load case , the schema was not stored which triggered a full reload of the schema during task execution . You can see in initSchema references the UDFContext for the schema , but that is only set in push projection . However , the schema needs to be set in both the job context ( so the TupleReadSupport can access the schema ) and the UDFContext ( so the task side loader can access it ) , which is why it is set in both locations . This also meant the requested schema was never set to the task side either , which could cause other problems as well . ##Column Index Access : For index based access , the problem was that the column index access setting and the requested schema were not stored in the udfcontext and sent to the task side ( unless pushProjection was called ) . The schema was stored in the job context , but this would be overwritten if another loader was executed first . Also , the property to use column index access was only being set at the job context level , so subsequent loaders would use column index access even if they didn't request it . This fix now ensures that both the schema and column index access are set in the udfcontext and loaded in the initSchema method . JIRA : https : / / issues . apache . org / jira / browse / PARQUET - 70 - Dan Author : Daniel Weeks < dweeks @ netflix . com > Closes #36 from dcw - netflix / pig - schema - context and squashes the following commits : f896a25 [ Daniel Weeks ] Moved property loading into setInput 8f3dc28 [ Daniel Weeks ] Changed to set job conf settings in both front and backend d758de0 [ Daniel Weeks ] Updated to use isFrontend ( ) for setting context properties b7ef96a [ Daniel Weeks ] Fixed storing pig schema to udfcontext for non projection case and moved column index access setting to udfcontext so as not to affect other loaders .",23,12,"parquet-pig/src/main/java/parquet/pig/ParquetLoader.java,CAS_DELIMITER",1,1,1,0.0,20,212.0,39,22.823321759259258,7.0,5.9042668293134595,6.0,None,FALSE,FALSE,
0d497c4547934485f2aa9e2e9ead46f26fab7bd2,Alex Levenson,alexlevenson@twitter.com,Mon Aug 18 10:38:11 2014 -0700,1408383491,PARQUET - 73 : Add support for FilterPredicates to cascading schemes Author : Alex Levenson < alexlevenson @ twitter . com > Closes #34 from isnotinvain / alexlevenson / filter - cascading - scheme and squashes the following commits : cd69a8e [ Alex Levenson ] Add support for FilterPredicates to cascading schemes,96,38,"parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java,CAS_DELIMITER,parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java,CAS_DELIMITER,parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java,CAS_DELIMITER,parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java,CAS_DELIMITER",4,2,2,1.6665118445950509,18,126.0,32,277.0354311342593,22.0,10.947894175551065,0.0,None,FALSE,FALSE,
3a396d3a4000bd2575e5314cdea0ba1e2367804c,Ryan Blue,rblue@cloudera.com,Mon Aug 4 19:04:18 2014 -0700,1407204258,PARQUET - 59 : Fix parquet - scrooge test on hadoop - 2 . Author : Ryan Blue < rblue @ cloudera . com > Closes #27 from rdblue / PARQUET - 59 - fix - scrooge - test - on - hadoop - 2 and squashes the following commits : ac34369 [ Ryan Blue ] PARQUET - 59 : Fix parquet - scrooge test on hadoop - 2 .,2,2,"parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java,CAS_DELIMITER",1,1,1,0.0,17,207.0,14,179.14934027777778,27.0,19.837554312700618,0.0,None,FALSE,FALSE,
21d871b54940ad8e552fac54808fe0b31872ade8,James Scott,jim.scott@urbanairship.com,Wed Jul 30 14:19:00 2014 -0700,1406755140,PARQUET - 56 : Added an accessor for the Long column type . I noticed there was a missing accessor for the Long column type in the example Group . Author : James Scott < jim . scott @ urbanairship . com > Closes #25 from scottjab / getLong and squashes the following commits : f96bb83 [ James Scott ] Added support for getting Longs in the sample group object .,11,0,"parquet-column/src/main/java/parquet/example/data/GroupValueSource.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java,CAS_DELIMITER",2,1,2,0.9940302114769565,19,19.5,19,167.9305150462963,0.0,0.0,0.0,None,FALSE,FALSE,
b0e26ee6f20a00a0d0769408575744c51a016018,Alex Levenson,alexlevenson@twitter.com,Wed Jul 30 13:49:00 2014 -0700,1406753340,Only call put ( ) when needed in SchemaCompatibilityValidator#validateColumn ( ) This is some minor cleanup suggested by @ tsdeng Author : Alex Levenson < alexlevenson @ twitter . com > Closes #24 from isnotinvain / alexlevenson / columnTypesEncountered and squashes the following commits : 7f05d90 [ Alex Levenson ] Only call put ( ) when needed in SchemaCompatibilityValidator#validateColumn ( ),4,1,"parquet-column/src/main/java/parquet/filter2/predicate/SchemaCompatibilityValidator.java,CAS_DELIMITER",1,1,1,0.0,23,172.0,1,0.9652893518518518,21.0,10.26264072551344,21.0,Perfective,FALSE,FALSE,
fc2c29df71c8455346a00b43dd1c4f118c335d2c,Matthieu Martin,ma.tt.b.ma.rt.in+parquet@gmail.com,Tue Jul 29 10:15:42 2014 -0700,1406654142,PARQUET - 19 : Fix NPE when an empty file is included in a Hive query that uses CombineHiveInputFormat Make sure the valueObj instance variable is always initialized . This change is neeeded when running a Hive query that uses the CombineHiveInputFormat and the first file in the combined split is empty . This can lead to a NullPointerException because the valueObj is null when the CombineHiveInputFormat calls the createValue method . Author : Matthieu Martin < ma . tt . b . ma . rt . in + parquet @ gmail . com > Closes #19 from matt - martin / fix for empty files NPE with CombineHiveInputFormat and squashes the following commits : 6c3a7f5 [ Matthieu Martin ] Make sure the valueObj instance variable is always initialized . This change is neeeded when running a Hive query that uses the CombineHiveInputFormat and the first file in the combined split is empty . This can lead to a NullPointerException because the valueObj is null when the CombineHiveInputFormat calls the createValue method .,3,3,"parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper.java,CAS_DELIMITER",1,1,1,0.0,18,238.0,1,169.08246527777777,1.0,0.9713662267827808,0.0,None,FALSE,FALSE,
17864dfc0711d52d5af330469a1c2bd76128d46e,Daniel Weeks,dweeks@netflix.com,Mon Jul 28 18:07:07 2014 -0700,1406596027,"Column index access support This patch adds the ability to use column index based access to parquet files in pig , which allows for rename capability similar to other file formats . This is achieved by using the parametrized loader with an alternate schema . Example : # File Schema : { c1 : int , c2 : float , c3 : chararray } p = LOAD ' / data / parquet / ' USING parquet . pig . ParquetLoader ( 'n1 : int , n2 : float , n3 : chararray' , 'true' ) ; In this example , the names from the requested schema will be translated to the column positions from the file and will produce tuples based on the index position . Two test cases are included that exercise index based access for both full file reads and column projected reads . Note : This patch also disables the enforcer plugin on the pig project per discussion at the parquet meetup . The justification for this is that the enforcer is too strict for internal classes and results in dead code because duplicating methods is required to add parameters where there is only one usage of the constructor / method . The interface for the pig loader is imposed by LoadFunc and StoreFunc by the pig project and the implementations internals should not be used directly . Author : Daniel Weeks < dweeks @ netflix . com > Closes #12 from dcw - netflix / column - index - access and squashes the following commits : 1b5c5cf [ Daniel Weeks ] Refactored based on rewview comments 12b53c1 [ Daniel Weeks ] Fixed some formatting and the missing filter method sig e5553f1 [ Daniel Weeks ] Adding back default constructor to satisfy other project requirements 69d21e0 [ Daniel Weeks ] Merge branch 'master' into column - index - access f725c6f [ Daniel Weeks ] Removed enforcer for pig support d182dc6 [ Daniel Weeks ] Introduces column index access 1c3c0c7 [ Daniel Weeks ] Fixed test with strict checking off f3cb495 [ Daniel Weeks ] Added type persuasion for primitive types with a flag to control strict type checking for conflicting schemas , which is strict by default .",306,51,"parquet-pig/src/main/java/parquet/pig/ParquetLoader.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/convert/TupleRecordMaterializer.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java,CAS_DELIMITER",9,1,3,2.450977607911283,20,126.55555555555556,137,222.79378215020577,6.0,5.234841074248243,5.0,Feature Addition,FALSE,TRUE,
4a07b3f545aaf60f0b1d6bba91ee22d214dfaff8,Sandy Ryza,sandy.ryza@cloudera.com,Wed Jul 23 14:29:35 2014 +0100,1406122175,PARQUET - 25 . Pushdown predicates only work with hardcoded arguments . Pull request for Sandy Ryza's fix for PARQUET - 25 . Author : Sandy Ryza < sandy . ryza @ cloudera . com > Closes #22 from tomwhite / PARQUET - 25 - unbound - record - filter - configurable and squashes the following commits : a9d3fdc [ Sandy Ryza ] PARQUET - 25 . Pushdown predicates only work with hardcoded arguments .,9,3,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER",1,1,1,0.0,21,403.0,48,4.602384259259259,0.0,0.0,0.0,Corrective,TRUE,FALSE,
f284238631cb1026b4977f6f0b7ef342260d35c5,Daniel Weeks,dweeks@netflix.com,Fri Jul 18 18:35:12 2014 -0700,1405733712,PARQUET - 22 : Backport of HIVE - 6938 adding rename support for parquet This patch was included in hive after the moving the Serde to hive ( included in hive 0 . 14 + ) . Backport is required for use with previous versions . Author : Daniel Weeks < dweeks @ netflix . com > Closes #13 from dcw - netflix / backport - hive - 6938 - rename and squashes the following commits : 453367b [ Daniel Weeks ] Backport of HIVE - 6938 adding rename support for parquet,28,3,"parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport.java,CAS_DELIMITER",1,1,1,0.0,18,17.0,3,150.23693287037037,5.0,4.363283549423756,0.0,None,FALSE,FALSE,
fb0104896815d55183f61c24b78c277dbae3987e,Ryan Blue,rblue@cloudera.com,Fri Jul 18 16:19:25 2014 -0700,1405725565,"PARQUET - 18 : Fix all - null value pages with dict encoding . TestDictionary#testZeroValues demonstrates the problem , where a page of all null values is decoded using the DicitonaryValuesReader . Because there are no non - null values , the page values section is 0 byte , but the DictionaryValuesReader assumes there is at least one encoded value and attempts to read a bit width . The test passes a byte array to initFromPage with the offset equal to the array's length . The fix is to detect that there are no input bytes to read . To avoid adding validity checks to the read path , this sets the internal decoder to one that will throw an exception if any reads are attempted . Author : Ryan Blue < rblue @ cloudera . com > Closes #18 from rdblue / PARQUET - 18 - fix - nulls - with - dictionary and squashes the following commits : 0711766 [ Ryan Blue ] PARQUET - 18 : Fix all - null value pages with dict encoding .",28,5,"parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java,CAS_DELIMITER",2,1,2,0.9833761901392237,19,291.5,39,198.9815798611111,26.0,19.550483570737,23.0,None,FALSE,FALSE,
5dffe3521588016cf3519792953b0879054c3bfd,Matthieu Martin,ma.tt.b.ma.rt.in+parquet@gmail.com,Fri Jul 18 16:02:09 2014 -0700,1405724529,"PARQUET - 4 : Use LRU caching for footers in ParquetInputFormat . Reopening https : / / github . com / Parquet / parquet - mr / pull / 403 against the new Apache repository . Author : Matthieu Martin < ma . tt . b . ma . rt . in + parquet @ gmail . com > Closes #2 from matt - martin / master and squashes the following commits : 99bb5a3 [ Matthieu Martin ] Minor javadoc and whitespace changes . Also added the FileStatusWrapper class to ParquetInputFormat to make sure that the debugging log statements print out meaningful paths . 250a398 [ Matthieu Martin ] Be less aggressive about checking whether the underlying file has been appended to / overwritten / deleted in order to minimize the number of namenode interactions . d946445 [ Matthieu Martin ] Add javadocs to parquet . hadoop . LruCache . Rename cache ""entries"" as cache ""values"" to avoid confusion with java . util . Map . Entry ( which contains key value pairs whereas our old ""entries"" really only refer to the values ) . a363622 [ Matthieu Martin ] Use LRU caching for footers in ParquetInputFormat .",510,10,"parquet-hadoop/src/main/java/parquet/hadoop/LruCache.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestLruCache.java,CAS_DELIMITER",4,1,2,1.8873182509661475,21,121.5,67,28.089354745370372,0.0,0.0,0.0,None,FALSE,FALSE,
2d8ebdbe00786823658bcdd2817e6b5afee15b25,Tom White,tom@cloudera.com,Wed Jul 16 14:50:29 2014 +0100,1405518629,"PARQUET - 9 : Filtering records across multiple blocks Update of the minimal fix discussed in https : / / github . com / apache / incubator - parquet - mr / pull / 1 , with the recursive call changed to to a loop . Author : Tom White < tom @ cloudera . com > Author : Steven Willis < swillis @ compete . com > Closes #9 from tomwhite / filtering - records - across - multiple - blocks and squashes the following commits : afb08a4 [ Tom White ] Minimal fix 9e723ee [ Steven Willis ] Test for filtering records across multiple blocks",63,3,"parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java,CAS_DELIMITER",2,2,2,0.7455178428108287,20,202.5,19,98.47405671296296,29.0,16.18758771994249,14.5,None,FALSE,FALSE,
4ad7303dc25c998fbb23dacb5bcf950f89ef6a6f,WangTao,barneystinson@aliyun.com,Thu Jul 10 16:08:48 2014 -0700,1405033728,Minor fix Spell and comment issue . Author : WangTao < barneystinson @ aliyun . com > Closes #10 from WangTaoTheTonic / minorFix and squashes the following commits : 0727a8f [ WangTao ] Minor fix,6,6,"parquet-column/src/main/java/parquet/schema/GroupType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/Type.java,CAS_DELIMITER",2,1,1,0.9182958340544896,20,110.5,34,16.242604166666666,0.0,0.0,0.0,Corrective,TRUE,FALSE,
9ad5485c3310a8c51510ea50e24834b6cf98c45c,Daniel Weeks,dweeks@netflix.com,Tue Jun 24 10:19:27 2014 -0700,1403630367,"PARQUET - 2 : Adding Type Persuasion for Primitive Types Original from the old repo : https : / / github . com / Parquet / parquet - mr / pull / 410 JIRA : https : / / issues . apache . org / jira / browse / PARQUET - 2 These changes allow primitive types to be requested as different types than what is stored in the file format using a flag to turn off strict type checking ( default is on ) . Types are cast to the requested type where possible and will suffer precision loss for casting where necessary ( e . g . requesting a double as an int ) . No performance penalty is imposed for using the type defined in the file type . A flag exists to A 6x6 test case is provided to test conversion between the primitive types . Author : Daniel Weeks < dweeks @ netflix . com > Closes #3 from dcw - netflix / type - persuasion and squashes the following commits : 97f4e9a [ Daniel Weeks ] Added documentation as suggested by code review 1c3c0c7 [ Daniel Weeks ] Fixed test with strict checking off f3cb495 [ Daniel Weeks ] Added type persuasion for primitive types with a flag to control strict type checking for conflicting schemas , which is strict by default .",305,23,"parquet-column/src/main/java/parquet/io/ColumnIOFactory.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/GroupType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/MessageType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/PrimitiveType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/Type.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java,CAS_DELIMITER",10,3,5,2.3819192935565767,20,156.9,191,111.91055208333334,4.0,3.633367498672855,1.3333333333333333,None,FALSE,TRUE,
54f9b1044d23c53a153743441b44bfbd631ff0e6,Katya Gonina,kgonina@twitter.com,Wed May 21 16:47:40 2014 -0700,1400716060,Cleaning up + testing small & large values,64,33,"parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java,CAS_DELIMITER",2,2,2,0.5100930822965021,20,263.5,24,0.07219907407407408,11.0,10.169921083047706,4.0,Perfective,FALSE,FALSE,
4fee0a7cb53e37d6866f5dc52c51b09ccea330a9,Katya Gonina,kgonina@twitter.com,Wed May 21 16:03:15 2014 -0700,1400713395,Bug fix - resetting stats after writing page . Fixed unit test to test reading footer,61,157,"parquet-column/src/main/java/parquet/column/ColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java,CAS_DELIMITER",4,2,4,1.2492939826450233,20,226.0,102,13.80526041666667,10.0,9.170718141809317,4.5,Corrective,TRUE,FALSE,
7e4346b2120d13a958aa93df26dfc265a8756b2b,Katya Gonina,kgonina@twitter.com,Wed May 21 14:04:09 2014 -0700,1400706249,merging with fix null stats branch,75,22,"parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java,CAS_DELIMITER",5,3,5,1.9955646587429365,20,246.4,136,48.77375694444444,9.0,8.172629364977082,4.0,Corrective,TRUE,FALSE,
8091a1b511aa66ff3775644a757bd30a8c869faf,Tianshuo Deng,tdeng@twitter.com,Tue May 20 23:31:33 2014 -0700,1400653893,fix null stats,6,1,"parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java,CAS_DELIMITER",1,1,1,0.0,20,216.0,41,49.43347222222222,250.0,164.26144835142642,81.0,Corrective,TRUE,FALSE,
fb7dba1ad4bef40ffe6dbe59f6f9ace9ecd1c131,Daniel Weeks,dweeks@netflix.com,Tue May 20 17:18:29 2014 -0700,1400631509,Updated test and remove shortcut return statement in loader,7,7,"parquet-pig/src/main/java/parquet/pig/ParquetLoader.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java,CAS_DELIMITER",2,1,2,0.37123232664087563,17,180.0,48,0.04377314814814815,3.0,2.9769010144705663,3.0,Preventative,FALSE,FALSE,
24076a4a44ab08534e4528ff4b08e8eec60ddcb7,Daniel Weeks,dweeks@netflix.com,Tue May 20 16:15:27 2014 -0700,1400627727,Fixed issue with column pruning when using requested schema,36,2,"parquet-pig/src/main/java/parquet/pig/ParquetLoader.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java,CAS_DELIMITER",2,1,2,0.4854607607459134,17,163.0,46,76.11072916666667,2.0,1.9772553422757908,2.0,Corrective,TRUE,TRUE,
10dc714bdbb9f7209538d412dc1fcf2219cc9afb,Daniel Weeks,dweeks@netflix.com,Mon May 19 09:53:02 2014 -0700,1400518382,Added test for null padding,45,0,"parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java,CAS_DELIMITER",1,1,1,0.0,17,121.0,9,149.69032407407408,1.0,0.9840568805846226,1.0,Feature Addition,FALSE,FALSE,
70bb0ea0009f25f7ff432c177f94aa40dbd0ebe4,Katya Gonina,kgonina@twitter.com,Fri May 16 17:24:01 2014 -0700,1400286241,"fixes for converting from bytes , toString ( ) methods , writing stats to Footer , unit testing for MAX / MIN VALUE",175,12,"parquet-column/src/main/java/parquet/column/statistics/BinaryStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/statistics/BooleanStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/statistics/DoubleStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/statistics/FloatStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/statistics/IntStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/statistics/LongStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/statistics/Statistics.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/statistics/TestStatistics.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java,CAS_DELIMITER",9,2,3,2.1133000985941117,20,133.33333333333334,30,73.10577160493828,8.0,7.272884578251986,5.0,Corrective,TRUE,FALSE,
cc28822843f97a6c791dfc2cb1c860c2e731d22a,Daniel Weeks,dweeks@netflix.com,Tue May 13 11:57:34 2014 -0700,1400007454,Added padding for columns not found in file schema,16,13,"parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java,CAS_DELIMITER",1,1,1,0.0,12,189.0,18,265.7387037037037,0.0,0.0,0.0,Feature Addition,FALSE,FALSE,
882740f032fb57b48a5bc775da609532084c7fe4,Andre Kelpe,efeshundertelf@googlemail.com,Mon May 12 16:10:15 2014 +0200,1399903815,"return NullCounter when read via Cascading , but not within a cluster side job",7,4,"parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapred/MapRedCounterLoader.java,CAS_DELIMITER",1,1,1,0.0,11,46.0,1,249.7970486111111,0.0,0.0,0.0,None,FALSE,FALSE,
041146e6b0eb0dca699cf66991a19d3991bfe3e6,Maxwell Swadling,maxwell.swadling@nicta.com.au,Mon May 12 10:55:19 2014 +1000,1399856119,Fixed hadoop WriteSupportClass loading,3,9,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER",1,1,1,0.0,18,140.0,26,104.34445601851851,0.0,0.0,0.0,Corrective,TRUE,FALSE,
c98d8af5c26a5622b2b830fc3410e8f8ae1f83e7,Katya Gonina,kgonina@twitter.com,Fri May 9 14:01:19 2014 -0700,1399669279,"adding back the parquet - hadoop methods that don't have statistics parameters , for backward comp",95,0,"parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java,CAS_DELIMITER",3,1,3,1.5107968496736262,20,177.66666666666666,72,21.291354166666668,7.0,6.404750425590186,3.0,Feature Addition,FALSE,TRUE,
0e334ca38b9f76b5b5df6a56510400b7b151f5af,Ryan Blue,rblue@cloudera.com,Wed Apr 30 15:36:23 2014 -0700,1398897383,Use parameterized to test with and without dictionary .,20,1,"parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER",1,1,1,0.0,20,389.0,39,33.95425925925926,13.0,10.899369338746341,10.0,Preventative,FALSE,FALSE,
9a38aecccf96ceee20779d838aa395262270ea36,julien,julien@twitter.com,Tue Apr 29 15:52:45 2014 -0700,1398811965,fix metadata concurency problem,73,33,"parquet-hadoop/src/main/java/parquet/hadoop/metadata/Canonicalizer.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkProperties.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnPath.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/metadata/EncodingList.java,CAS_DELIMITER",4,1,1,1.6604019175918063,20,64.75,8,113.37935763888888,358.0,184.27520376865874,96.0,Corrective,TRUE,FALSE,
7640224b3fee25e3c347f1ffdabdf5392212256b,Katya Gonina,kgonina@twitter.com,Wed Apr 23 16:02:12 2014 -0700,1398294132,Adding back the Page ( ) and writePage ( ) methods for backward - compatibility The methods now pass an empty Stats object downstream,79,1,"parquet-column/src/main/java/parquet/column/page/Page.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/page/PageWriter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java,CAS_DELIMITER",4,2,3,1.905546967702421,20,17.25,40,25.759496527777777,6.0,5.671030550595971,3.5,Feature Addition,FALSE,TRUE,
ac2b15ebb0d4d5140587e11a0e7a71f898293668,Tianshuo Deng,tdeng@twitter.com,Mon Apr 21 13:52:18 2014 -0700,1398113538,change name to checkBelongingToANewHDFSBlock,5,5,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER",1,1,1,0.0,20,269.0,45,0.018159722222222223,249.0,172.66586799026555,56.0,Feature Addition,FALSE,FALSE,
9f672d69432e6339fc69c6848b384bd6bb744051,Tianshuo Deng,tdeng@twitter.com,Mon Apr 21 13:10:10 2014 -0700,1398111010,use mid point of a row group to decide to create a split or not,83,44,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/metadata/BlockMetaData.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java,CAS_DELIMITER",3,1,3,1.3013812496419146,20,159.33333333333334,67,2.958645833333333,247.0,170.67566812622093,54.0,Feature Addition,FALSE,FALSE,
05c3e2706a356ea878177faf93ed108a348bc7ae,Miguel Ping,miguel.ping@gmail.com,Mon Apr 21 12:57:05 2014 +0100,1398081425,ensure SimpleRecord#getValues ( ) is unmodifiable This avoids modification from the outside,2,1,"parquet-tools/src/main/java/parquet/tools/read/SimpleRecord.java,CAS_DELIMITER",1,1,1,0.0,1,238.0,3,6.027523148148148,1.0,0.9837545120722988,1.0,None,FALSE,FALSE,
0189ff1757a3b3f0c9c268ed68cee6387d3e5187,Ryan Blue,rblue@cloudera.com,Fri Apr 18 15:44:46 2014 -0700,1397861086,Fix more code review finds .,20,5,"parquet-column/src/main/java/parquet/schema/PrimitiveType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/Types.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER",3,2,2,1.4269608142719163,20,328.6666666666667,66,2.126736111111111,25.0,23.088074362955396,13.0,Corrective,TRUE,FALSE,
70707e4bd2f5b41a08d4b5a306d5876473532e01,Tianshuo Deng,tdeng@twitter.com,Fri Apr 18 14:20:48 2014 -0700,1397856048,"use getStartingPos for BlockMetadata , which returns the startingPos for the first Column",2,7,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER",1,1,1,0.0,20,259.0,42,0.002789351851851852,246.0,170.65677987189073,53.0,None,FALSE,FALSE,
9705f4905a5077ec7208a0fa3e230668157fe471,Tianshuo Deng,tdeng@twitter.com,Fri Apr 18 14:16:47 2014 -0700,1397855807,"1 . check row groups are sorted ; 2 . add getStartingPos for BlockMetadata , which returns the startingPos for the first Column",18,1,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/metadata/BlockMetaData.java,CAS_DELIMITER",2,1,2,0.9494520153879484,20,132.0,45,61.00061921296297,245.0,169.65770509945244,52.0,Feature Addition,FALSE,FALSE,
00d631c15d147e7e7a07d65fe50999c878a921a8,Tianshuo Deng,tdeng@twitter.com,Fri Apr 18 14:08:37 2014 -0700,1397855317,make SplitInfo contain the hdfsBlock,16,21,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER",1,1,1,0.0,20,254.0,40,0.011840277777777778,244.0,168.65957076126156,51.0,None,FALSE,FALSE,
8e348e60b822d86a7e0862902c315beb56388725,Tianshuo Deng,tdeng@twitter.com,Fri Apr 18 13:51:34 2014 -0700,1397854294,create a getStartingPos in ColumnChunkMetaData,27,28,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java,CAS_DELIMITER",4,1,3,1.8040687997196911,20,241.5,101,8.038015046296294,243.0,167.6634335018171,50.0,Feature Addition,FALSE,FALSE,
83e34bec54298265c50e366fae364c02a9e2dfe3,Tianshuo Deng,tdeng@twitter.com,Fri Apr 18 09:53:48 2014 -0700,1397840028,add non - negative check in generateSplits method,2,2,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER",1,1,1,0.0,20,257.0,38,0.0031018518518518517,241.0,165.71677856953056,48.0,Feature Addition,FALSE,FALSE,
ac816d91e2c30f7bceacb8601ae13a0ab0107277,Tianshuo Deng,tdeng@twitter.com,Fri Apr 18 09:49:20 2014 -0700,1397839760,min split size default to 0,1,1,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER",1,1,1,0.0,20,257.0,37,0.6485763888888889,240.0,164.71776569870985,47.0,None,FALSE,FALSE,
c825e89c84fa78222baae7a35c4843b2ef199869,Ryan Blue,rblue@cloudera.com,Fri Apr 18 09:22:58 2014 -0700,1397838178,"Remove unchecked casts from Types . Builder . This simplifies the logic so that either a return object is supplied when a Builder is constructed , or the expected type is supplied so that the code can check the return type is valid .",39,20,"parquet-column/src/main/java/parquet/schema/Types.java,CAS_DELIMITER",1,1,1,0.0,20,569.0,7,2.7923958333333334,24.0,22.10366031766315,21.0,None,FALSE,FALSE,
9814332cc3fed776eab8ebd03bbbc241ec562c15,Tianshuo Deng,tdeng@twitter.com,Thu Apr 17 18:58:50 2014 -0700,1397786330,add more tests so the hdfsSize is not multiple of rowGroup size,95,12,"parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java,CAS_DELIMITER",1,1,1,0.0,20,119.0,16,0.03017361111111111,239.0,163.91310892740603,46.0,Feature Addition,FALSE,FALSE,
7845cc76fb72aef6908ae16a89df92e60b171f66,Tianshuo Deng,tdeng@twitter.com,Thu Apr 17 18:15:23 2014 -0700,1397783723,1 . remove unused readSupportClass parameter from generateSplit method ; 2 . double check split min max to be postive in the getSplits method ; 3 . explicit import java . util . xx in test,9,6,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java,CAS_DELIMITER",2,1,2,0.9709505944546686,20,186.5,51,0.007824074074074074,238.0,162.92256972283374,45.0,Preventative,FALSE,FALSE,
fca4cc9fcb3dbfd622e11861e0b7a8f2a3ac26d1,Tianshuo Deng,tdeng@twitter.com,Thu Apr 17 18:08:07 2014 -0700,1397783287,move parseMessageType out of the loop,2,1,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER",1,1,1,0.0,20,256.0,35,0.0011574074074074073,237.0,161.924138248826,44.0,None,FALSE,FALSE,
2056bfab8080ff013905268fbccbde835b9ae63e,Tianshuo Deng,tdeng@twitter.com,Thu Apr 17 18:06:27 2014 -0700,1397783187,"separate out getParquetInputSplit method in the SplitInfo class , reduce LOC in the generateSplit method",29,23,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER",1,1,1,0.0,20,250.0,34,0.004398148148148148,236.0,160.92449483585142,43.0,None,FALSE,FALSE,
83493c59396479659d3d260d53498faf2d7518ac,Tianshuo Deng,tdeng@twitter.com,Thu Apr 17 18:00:07 2014 -0700,1397782807,maxSplitSize should always be positive,26,2,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java,CAS_DELIMITER",2,1,2,0.5916727785823275,20,171.0,47,0.6142013888888889,235.0,159.92583783129032,42.0,None,FALSE,FALSE,
23958b8fde926368176dd8ade908938e17f713c0,Tianshuo Deng,tdeng@twitter.com,Thu Apr 17 17:38:07 2014 -0700,1397781487,check maxSplit size must be greater or equal to minSplitSize,7,1,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER",1,1,1,0.0,20,244.0,32,0.00829861111111111,234.0,158.9304612921401,41.0,None,FALSE,FALSE,
dd8c32a41670e831a09558bf3f2697f54fb5fcfa,Tianshuo Deng,tdeng@twitter.com,Thu Apr 17 17:26:10 2014 -0700,1397780770,fix missing space,1,1,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER",1,1,1,0.0,20,244.0,31,0.00038194444444444446,233.0,157.93295004962255,40.0,Corrective,TRUE,FALSE,
0a96b2c66c1367a88d750357c6d6527b2efbbb08,Tianshuo Deng,tdeng@twitter.com,Thu Apr 17 17:25:37 2014 -0700,1397780737,local variable of hdfsBlock,2,1,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER",1,1,1,0.0,20,243.0,30,1.1891666666666667,232.0,156.93306355042975,39.0,None,FALSE,FALSE,
b55eea04135d41a67b8c5d321f993ccf35a17c99,julien,julien@twitter.com,Thu Apr 17 15:28:58 2014 -0700,1397773738,make ParquetFileWriter throw IOException in invalid state case,11,7,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER",1,1,1,0.0,20,173.0,29,16.09834490740741,357.0,186.64139642166992,95.0,None,FALSE,FALSE,
3321b67329a895171d47e321279901d0dc346aad,Tianshuo Deng,tdeng@twitter.com,Thu Apr 17 11:12:21 2014 -0700,1397758341,fix enum to be upper case,1,1,"parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java,CAS_DELIMITER",1,1,1,0.0,17,30.0,4,6.73400462962963,230.0,155.00940240799758,32.0,Corrective,TRUE,FALSE,
796b7dd3d6fa9ec70e36d9502c0f79bbd94550fb,Tianshuo Deng,tdeng@twitter.com,Thu Apr 17 10:40:05 2014 -0700,1397756405,do not call schema converter to generate projected schema when the projectionFilterStrubg or projectionSchemaStr is specified,5,4,"parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java,CAS_DELIMITER",1,1,1,0.0,17,171.0,19,111.59295138888889,229.0,154.01588374381961,80.0,None,FALSE,FALSE,
5d06526d49451135bd5c3befc06a64624431de02,Tianshuo Deng,tdeng@twitter.com,Wed Apr 16 12:53:13 2014 -0700,1397677993,"generate splits by min max size , and align to HDFS block when possible",273,101,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java,CAS_DELIMITER",2,1,2,0.9849093522089645,20,81.5,42,70.12273148148148,228.0,153.2763604947113,38.0,None,FALSE,FALSE,
3fad81609562f2819639f4fdb02d6d6481a7165b,Neal Sidhwaney,nealsid+github@gmail.com,Tue Apr 15 19:00:26 2014 -0400,1397602826,Fix output bug during parquet - dump command It was outputting the current definition level as both the repetition & definition level for the current value .,1,1,"parquet-tools/src/main/java/parquet/tools/command/DumpCommand.java,CAS_DELIMITER",1,1,1,0.0,1,640.0,2,56.14716435185185,0.0,0.0,0.0,Corrective,TRUE,FALSE,
d093f497007e140c9ee0350b88d5b93b00ab9382,julien,julien@twitter.com,Tue Apr 15 15:41:40 2014 -0700,1397601700,reverse codec changes,2,5,"parquet-hadoop/src/main/java/parquet/hadoop/metadata/CompressionCodecName.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/codec/CodecConfigTest.java,CAS_DELIMITER",2,1,2,0.9852281360342516,18,10.5,9,0.46167824074074076,356.0,186.20653807935196,94.0,None,FALSE,FALSE,
110fe216e493ebe52eea32275a7fc0896552ab3c,julien,julien@twitter.com,Tue Apr 15 14:40:55 2014 -0700,1397598055,fix test runtime dep missing from pig,2,2,"parquet-hadoop/src/test/java/parquet/hadoop/codec/CodecConfigTest.java,CAS_DELIMITER",1,1,1,0.0,18,5.0,4,75.89600694444445,355.0,185.2184360647217,93.0,Corrective,TRUE,FALSE,
acaac8bb700debdec66d0a633a60be503b7a20b4,Ryan Blue,rblue@cloudera.com,Tue Apr 15 14:21:55 2014 -0700,1397596915,Implement code review changes .,168,151,"parquet-column/src/main/java/parquet/schema/DecimalMetadata.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/GroupType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/MessageTypeParser.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/PrimitiveType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/Type.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/Types.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java,CAS_DELIMITER,parquet-common/src/main/java/parquet/Preconditions.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER",9,3,4,2.599241852355482,20,187.66666666666666,107,2.4037718621399176,23.0,21.261393616525467,8.0,None,FALSE,TRUE,
86501c2352413feb8a4128362d862c89e6cbb1f7,Ryan Blue,rblue@cloudera.com,Tue Apr 15 09:45:09 2014 -0700,1397580309,Add INT32 and INT64 as supported types for DECIMAL .,156,47,"parquet-column/src/main/java/parquet/schema/Types.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java,CAS_DELIMITER",2,1,2,0.5097916692607785,20,462.5,12,0.9495486111111111,22.0,20.27180677248436,19.0,Feature Addition,FALSE,FALSE,
f5c3151d057708a7377430b6c51621071656d10e,Miguel Ping,miguel.ping@gmail.com,Tue Apr 15 12:17:27 2014 +0100,1397560647,"Expose values in SimpleRecord This allows for quick'n dirty integration with clojure / pigpen in local mode , without the hassle of reimplementing file reading .",4,0,"parquet-tools/src/main/java/parquet/tools/read/SimpleRecord.java,CAS_DELIMITER",1,1,1,0.0,1,234.0,2,55.65898148148148,0.0,0.0,0.0,None,FALSE,FALSE,
f8877f1648b607a288af159c810b32049a49e086,julien,julien@twitter.com,Mon Apr 14 18:32:47 2014 -0700,1397525567,cleanup log messages for default codec,3,0,"parquet-hadoop/src/main/java/parquet/hadoop/metadata/CompressionCodecName.java,CAS_DELIMITER",1,1,1,0.0,16,13.0,3,131.10570601851853,354.0,184.45308644611566,92.0,Perfective,FALSE,FALSE,
9ef1be6697ed432e5de5d5d7aa2f5810e134350a,julien,julien@twitter.com,Mon Apr 14 18:29:27 2014 -0700,1397525367,cleanup log messages in tests,6,4,"parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPackingColumn.java,CAS_DELIMITER",1,1,1,0.0,4,27.0,6,320.0645486111111,353.0,183.45372840343518,137.0,Perfective,FALSE,FALSE,
de0bfe3a7b9cddf4e949e6ebfd97d9c16bd143fc,julien,julien@twitter.com,Mon Apr 14 16:34:41 2014 -0700,1397518481,cleanup log messages in tests,7,7,"parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java,CAS_DELIMITER",1,1,1,0.0,8,2.0,2,0.02318287037037037,352.0,182.47561550453776,2.0,Perfective,FALSE,FALSE,
ddca03c2754bd67b3aa9f37a5d404814ed79b4bd,julien,julien@twitter.com,Mon Apr 14 16:01:18 2014 -0700,1397516478,cleanup log messages in tests,32,26,"parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestBitPacking.java,CAS_DELIMITER,parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestByteBitPacking.java,CAS_DELIMITER,parquet-encoding/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java,CAS_DELIMITER",3,1,1,1.2641741758256733,8,0.0,3,279.2962847222222,351.0,181.48191955159285,1.0,Perfective,FALSE,FALSE,
9ef22e630907eeb85600ab3ef53257fb575a0f8e,Ryan Blue,rblue@cloudera.com,Mon Apr 14 10:57:48 2014 -0700,1397498268,"Fix maximum precision calculation , account for sign bit .",5,5,"parquet-column/src/main/java/parquet/schema/Types.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java,CAS_DELIMITER",2,1,2,0.9709505944546686,20,462.5,10,1.9309895833333335,21.0,19.32079497868503,18.0,Corrective,TRUE,FALSE,
73d7558bdaf966a9fbfae7fc1c8f0ba727a98de9,Ryan Blue,rblue@cloudera.com,Sat Apr 12 12:35:17 2014 -0700,1397331317,Simplify Types API by moving repetition .,26,47,"parquet-column/src/main/java/parquet/schema/MessageTypeParser.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/PrimitiveType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/Types.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER",5,2,3,1.9465508593673628,20,271.6,65,0.5660625,19.0,17.415894141157086,9.0,None,FALSE,FALSE,
299e0ca760ccc0608ba7b0ebd3461f4ec5e606f8,Ryan Blue,rblue@cloudera.com,Sat Apr 12 12:05:20 2014 -0700,1397329520,Add Types builder API documentation . Also add check that scale < = precision and test .,285,4,"parquet-column/src/main/java/parquet/schema/Types.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java,CAS_DELIMITER",2,1,2,0.42469574390206355,20,329.0,5,0.890474537037037,18.0,16.41680898214824,15.0,Feature Addition,FALSE,FALSE,
63ffdce40355d8c75dae6a6888ca315889737f1c,Ryan Blue,rblue@cloudera.com,Fri Apr 11 15:17:20 2014 -0700,1397254640,Add test for decimal with unsupported primitive types .,18,0,"parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java,CAS_DELIMITER",1,1,1,0.0,20,358.0,3,0.008703703703703703,17.0,15.452635950794052,14.0,Feature Addition,FALSE,FALSE,
3af02db83a4b18f814a400bfe8569c31de4932b7,Ryan Blue,rblue@cloudera.com,Fri Apr 11 15:04:48 2014 -0700,1397253888,Add more tests for type builders .,199,0,"parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java,CAS_DELIMITER",1,1,1,0.0,20,159.0,2,0.02238425925925926,16.0,14.452972702894236,13.0,Feature Addition,FALSE,FALSE,
a1d7260a4ace24a8d6f514149271ad998019eb5e,Ryan Blue,rblue@cloudera.com,Fri Apr 11 14:32:34 2014 -0700,1397251954,Fix primitive type equality for fixed with different lengths .,12,0,"parquet-column/src/main/java/parquet/schema/PrimitiveType.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java,CAS_DELIMITER",2,1,2,0.9182958340544896,20,191.5,25,0.016527777777777777,15.0,13.453777502111597,12.0,Corrective,TRUE,FALSE,
163bf6bd3436ee8d558524b09d7cc9e4df8a0275,Ryan Blue,rblue@cloudera.com,Fri Apr 11 14:08:46 2014 -0700,1397250526,"Add support for DECIMAL type annotation . Changes : * Add Types builder API to consolidate type building , consistency checks * Update schema parser to support precision and scale on DECIMAL : required binary aDecimal ( DECIMAL ( 9 , 2 ) ) ; * Update writeToStringBuilder methods to add precision and scale * Add DECIMAL conversion in ParquetMetadataConverter * Add precision , scale conversion in ParquetMetadataConverter * Add OriginalTypeMeta to hold type annotation metadata ( e . g . , scale ) * Add more testing to ensure compatibility",809,84,"parquet-column/src/main/java/parquet/schema/GroupType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/MessageTypeParser.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/OriginalType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/OriginalTypeMeta.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/PrimitiveType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/Type.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/Types.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/parser/TestParquetParser.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/schema/TestTypeBuilders.java,CAS_DELIMITER,parquet-common/src/main/java/parquet/Preconditions.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java,CAS_DELIMITER",12,3,6,2.917346209404966,20,51.25,90,162.60728395061727,14.0,12.45432651276083,4.0,Feature Addition,FALSE,TRUE,
6417baede9f9e9b4cb711d7120ee31499a19b5ea,Tianshuo Deng,tdeng@twitter.com,Thu Apr 10 17:35:23 2014 -0700,1397176523,"1 . upgrade scrooge dep to 3 . 12 . 1 2 . fix bug when an enum field is optional , scroogeSchemaConverter would fail",8,3,"parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java,CAS_DELIMITER,parquet-scrooge/src/test/java/parquet/scrooge/ScroogeStructConverterTest.java,CAS_DELIMITER",2,1,2,0.4394969869215134,17,13.5,5,63.08759259259259,227.0,153.9473335025921,31.0,Corrective,TRUE,FALSE,
67c1e11364455dfa8b48dcc013398657d080376e,julien,julien@twitter.com,Wed Apr 9 18:35:55 2014 -0700,1397093755,use own test fixtures,5,6,"parquet-thrift/src/test/java/parquet/thrift/pig/TestParquetThriftStorer.java,CAS_DELIMITER",1,1,1,0.0,1,80.0,2,0.19516203703703705,350.0,181.80921447503712,53.0,Corrective,TRUE,FALSE,
a13ae411677847137c93aec573abe6b0601079ff,julien,julien@twitter.com,Tue Apr 8 18:57:39 2014 -0700,1397008659,cleanup,8,11,"parquet-thrift/src/main/java/parquet/thrift/pig/ParquetThriftStorer.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/pig/TupleToThriftWriteSupport.java,CAS_DELIMITER",2,1,1,0.4854607607459134,1,76.0,2,0.014733796296296297,348.0,180.07402534796682,51.0,Perfective,FALSE,FALSE,
b8149e92dd283d98132319d506248c3204718302,julien,julien@twitter.com,Tue Apr 8 18:36:26 2014 -0700,1397007386,ParquetThriftStorer,217,0,"parquet-thrift/src/main/java/parquet/thrift/pig/ParquetThriftStorer.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/pig/TupleToThriftWriteSupport.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/pig/TestParquetThriftStorer.java,CAS_DELIMITER",3,1,2,1.5811002035617696,1,0.0,0,0.0,347.0,179.07794463216527,50.0,None,FALSE,FALSE,
f98de7588149bba0d731f38232b4a8fdde14b94a,julien,julien@twitter.com,Tue Apr 8 14:31:06 2014 -0700,1396992666,adding comments,8,2,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER",1,1,1,0.0,20,306.0,34,3.9197800925925925,346.0,178.12281029614184,91.0,Feature Addition,FALSE,FALSE,
93359c0f2cac705cc7b2fbf3c057d74142025b37,Katya Gonina,kgonina@twitter.com,Tue Apr 8 12:41:22 2014 -0700,1396986082,Added length check for comparing two byte arrays,1,1,"parquet-column/src/main/java/parquet/io/api/Binary.java,CAS_DELIMITER",1,1,1,0.0,20,162.0,14,6.80917824074074,5.0,4.902450033142039,4.0,Feature Addition,FALSE,FALSE,
16d38e2d32f1d09bd10a8455bdcf11905f8cdd72,Ryan Blue,rblue@cloudera.com,Mon Apr 7 12:29:25 2014 -0700,1396898965,"Fix bug #350 , fixed length argument out of order .",1,1,"parquet-column/src/main/java/parquet/column/ParquetProperties.java,CAS_DELIMITER",1,1,1,0.0,19,244.0,9,19.76361111111111,12.0,10.511942158700236,9.0,Corrective,TRUE,FALSE,
05327c1cacd598106b8d8228927a5a8884faaec9,Katya Gonina,kgonina@twitter.com,Fri Apr 4 16:45:02 2014 -0700,1396655102,Added hashCode ( ) method for Statistics class,8,0,"parquet-column/src/main/java/parquet/column/statistics/Statistics.java,CAS_DELIMITER",1,1,1,0.0,20,213.0,4,2.978391203703704,4.0,3.953425913659097,3.0,Feature Addition,FALSE,FALSE,
30810ff61f5bd033b0bf90bbccd574c331b62d2f,julien,julien@twitter.com,Fri Apr 4 16:26:37 2014 -0700,1396653997,fix header bug,19,2,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER",1,1,1,0.0,20,289.0,33,7.989143518518518,345.0,178.1507499903181,90.0,Corrective,TRUE,FALSE,
5b8af1f8097e7729c41cd86562b6706cefe2c56d,Tianshuo Deng,tdeng@twitter.com,Thu Apr 3 11:14:47 2014 -0700,1396548887,set reading length in ThriftBytesWriteSupport to avoid potential OOM caused by corrupted data,12,2,"parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java,CAS_DELIMITER",1,1,1,0.0,14,145.0,9,90.69145833333333,226.0,155.0709783404369,79.0,None,FALSE,FALSE,
f9a867689a18e33cb95fbd21b10fcd5b648739be,Dmitriy Ryaboy,dvryaboy@gmail.com,Wed Apr 2 22:10:46 2014 -0700,1396501846,stop using strings and b64 for compressed input splits,31,20,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestParquetInputSplit.java,CAS_DELIMITER",2,1,2,0.3966277727783789,20,93.0,17,5.620393518518518,8.0,5.472846346284623,4.0,None,FALSE,FALSE,
253eb6a182b1abe746aa792eae9ddf9389d99b61,Szehon Ho,szehon@cloudera.com,Wed Apr 2 11:04:45 2014 -0700,1396461885,select * from parquet hive table containing map columns runs into exception . Issue #341 .,25,13,"parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/AbstractParquetMapInspector.java,CAS_DELIMITER",1,1,1,0.0,18,0.0,1,51.116527777777776,0.0,0.0,0.0,None,FALSE,FALSE,
c54cad5e4a54dbbae417bc1561c623b1267f2079,Dmitriy Ryaboy,dvryaboy@gmail.com,Tue Apr 1 18:51:00 2014 -0700,1396403460,compress kv pairs in ParquetInputSplits,4,4,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java,CAS_DELIMITER",1,1,1,0.0,20,141.0,15,5.089409722222222,7.0,4.4858834369528635,3.0,None,FALSE,FALSE,
82ec5842372645535e1602df8c51ec05d683d5bd,tongjiechen,tongjie.chen@gmail.com,Tue Apr 1 18:00:41 2014 -0700,1396400441,issue #324 remove additional tab,1,1,"parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector.java,CAS_DELIMITER",1,1,1,0.0,19,12.0,3,6.15275462962963,5.0,4.906459809956467,5.0,Feature Addition,FALSE,FALSE,
9f43945682e73992bb3958ec8d478873b20b5b0e,Katya Gonina,kgonina@twitter.com,Tue Apr 1 17:16:09 2014 -0700,1396397769,Refactored the * Statistics classes to reuse more code . Added Binary compareTo methods,174,230,"parquet-column/src/main/java/parquet/column/statistics/BinaryStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/statistics/BooleanStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/statistics/DoubleStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/statistics/FloatStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/statistics/IntStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/statistics/LongStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/statistics/Statistics.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/api/Binary.java,CAS_DELIMITER",8,1,2,2.9749373050521424,20,117.625,28,6.257942708333334,3.0,2.985570465078853,2.0,Feature Addition,FALSE,TRUE,
7b5e2ecf2cbc54ed9e53445ba52e2fc6efd3745e,Katya Gonina,kgonina@twitter.com,Tue Apr 1 13:07:21 2014 -0700,1396382841,"Addresses some initial comments . Javadocs , removed StatsHelper",113,46,"parquet-column/src/main/java/parquet/column/UnknownColumnTypeException.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/statistics/Statistics.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/statistics/StatsHelper.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER",7,2,5,1.3353933830231826,20,107.42857142857143,116,4.850763888888889,1.0,0.9868845373255842,0.5,Feature Addition,FALSE,FALSE,
621cf4e92be3dd3f2dd1a92a8dd12f244a7d7be3,Katya Gonina,kgonina@twitter.com,Thu Mar 27 16:42:15 2014 -0700,1395963735,Added statistics to Parquet pages and rowGroups,1701,64,"parquet-column/src/main/java/parquet/column/ColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/UnknownColumnTypeException.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/page/Page.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/page/PageWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/statistics/BinaryStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/statistics/BooleanStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/statistics/DoubleStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/statistics/FloatStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/statistics/IntStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/statistics/LongStatistics.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/statistics/Statistics.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/statistics/StatisticsClassException.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/statistics/StatsHelper.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/mem/TestMemPageStore.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/statistics/TestStatistics.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER,parquet-common/src/main/java/parquet/bytes/BytesUtils.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkProperties.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/metadata/TestColumnChunkMetaData.java,CAS_DELIMITER",31,3,14,4.018418778428307,20,56.96774193548387,293,92.02909908900835,0.0,0.0,0.0,Feature Addition,FALSE,TRUE,
125529bbb0a8e49d6b78d60472121eb20d53a9f8,tongjiechen,tongjie.chen@gmail.com,Wed Mar 26 14:20:43 2014 -0700,1395868843,"issue #324 , move ParquetStringInspector to org . apache . hadoop . hive . serde2 . objectinspector . primitive package",12,7,"parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetPrimitiveInspectorFactory.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/ParquetStringInspector.java,CAS_DELIMITER",3,1,3,1.2108100261060328,19,1.3333333333333333,5,0.0,4.0,3.988985428551243,4.0,None,FALSE,FALSE,
05dea98103d8115a50302be4bda7c957c0dd9d9e,tongjiechen,tongjie.chen@gmail.com,Wed Mar 26 14:20:43 2014 -0700,1395868843,"issue #324 , move ParquetStringInspector to org . apache . hadoop . hive . serde2 . objectinspector . primitive package",15,6,"parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetPrimitiveInspectorFactory.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/ParquetStringInspector.java,CAS_DELIMITER",3,1,3,1.221694907636328,19,-1.6666666666666667,2,29.501743827160496,2.0,1.9920460161088158,2.0,None,FALSE,FALSE,
3d4311fd2d4ab7a2ae3ee326a974bbdc6c62b538,tongjiechen,tongjie.chen@gmail.com,Tue Mar 25 11:27:08 2014 -0700,1395772028,remove originalType check for typeEquals of GroupType and add tests for HiveSchemaConverter,26,3,"parquet-column/src/main/java/parquet/schema/GroupType.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter.java,CAS_DELIMITER",3,2,3,0.787667201427305,18,24.666666666666668,16,14.826909722222224,1.0,0.9981559309725292,0.5,Feature Addition,FALSE,FALSE,
860e123b8b8df55eaa81c0e4192373bdd7fd2497,tongjiechen,tongjie.chen@gmail.com,Tue Mar 25 11:27:08 2014 -0700,1395772028,remove originalType check for typeEquals of GroupType and add tests for HiveSchemaConverter,27,4,"parquet-column/src/main/java/parquet/schema/GroupType.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter.java,CAS_DELIMITER",3,2,3,0.7538275145266042,18,32.333333333333336,19,0.0,3.0,3.001235368305272,2.0,Feature Addition,FALSE,FALSE,
737a5d5d8447ef410819f71c8ed112c3af694a3c,tongjiechen,tongjie.chen@gmail.com,Mon Mar 24 19:16:06 2014 -0700,1395713766,"issue #290 , hive map conversion to parquet schema",3,2,"parquet-column/src/main/java/parquet/schema/GroupType.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter.java,CAS_DELIMITER",2,2,2,0.7219280948873623,18,41.5,13,120.39094328703703,0.0,0.0,0.0,None,FALSE,FALSE,
4246d18a5fd8d87b29740a56ec3616f14320f07c,Dmitriy Ryaboy,dvryaboy@gmail.com,Sun Mar 23 22:39:11 2014 -0700,1395639551,close gzip stream in finally,11,4,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java,CAS_DELIMITER",1,1,1,0.0,14,134.0,13,0.12179398148148148,6.0,3.564654606823347,2.0,None,FALSE,FALSE,
1920abc2b5c2c4007e44b2c452870e24f7a0e17a,Dmitriy Ryaboy,dvryaboy@gmail.com,Sun Mar 23 19:43:48 2014 -0700,1395629028,compress schemas in input splits,102,8,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestParquetInputSplit.java,CAS_DELIMITER",2,1,2,0.976020648236615,14,42.5,12,37.12752893518518,5.0,2.565427366244155,1.0,None,FALSE,FALSE,
9899e5ba66d3c9d0a8611b9dc914ed79ca7d70f0,julien,julien@twitter.com,Thu Mar 20 10:41:40 2014 -0700,1395337300,fix filesystem resolution,1,1,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java,CAS_DELIMITER",1,1,1,0.0,15,146.0,14,169.98876157407406,344.0,181.22455889503,89.0,Corrective,TRUE,FALSE,
603c0dc927c2b1aa46dba6675b24a375cfb3fc1c,Ryan Blue,rblue@cloudera.com,Tue Feb 25 11:21:41 2014 -0800,1393356101,Fix avro schema conv for arrays of optional type for #312 .,36,5,"parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java,CAS_DELIMITER",2,1,2,0.6006085754131871,15,243.5,21,35.373020833333335,10.0,9.662435950505813,1.0,Corrective,TRUE,TRUE,
5e74bbed3698e94a2b7d3e3353880bdf5f5d3205,Ryan Blue,rblue@cloudera.com,Mon Feb 24 11:50:31 2014 -0800,1393271431,Add Configuration constructor in thrift writer for #295 .,7,0,"parquet-thrift/src/main/java/parquet/thrift/ThriftParquetWriter.java,CAS_DELIMITER",1,1,1,0.0,18,45.0,2,25.819340277777776,11.0,10.690265571645106,0.0,Feature Addition,FALSE,FALSE,
a5d2de14fda5215cece2b25ab2dd1e73396ec25e,Ryan Blue,rblue@cloudera.com,Mon Feb 24 11:37:38 2014 -0800,1393270658,"Add avro constructors with Configuration for #295 . To avoid doubling the number of constructors in ParquetWriter , this creates more defaults that subclasses can use . The new AvroParquetWriter constructors call the most specific constructor directly and use the default constants from ParquetWriter to match the default behavior of its constructors . Also fixed a few doc mistakes .",43,8,"parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java,CAS_DELIMITER",2,2,2,0.8739810481273578,18,160.5,27,23.686267361111113,9.0,8.687803572873554,0.0,Corrective,TRUE,FALSE,
509e26883b30a2d505c64b28633be2e628cd1f56,Mickau00c3u00abl Lacour,m.lacour@criteo.com,Mon Feb 24 15:46:28 2014 +0100,1393253188,Better writing of a loop,5,9,"parquet-cascading/src/main/java/parquet/cascading/TupleWriteSupport.java,CAS_DELIMITER",1,1,1,0.0,18,107.0,2,2.595972222222222,0.0,0.0,0.0,Perfective,FALSE,FALSE,
70eada470f069ea27c5e2d47d1004fec56f7dcca,jalkjaer,j.alkjaer@gmail.com,Sat Feb 22 01:28:16 2014 +0100,1393028896,NULL tuples cause NPE when writing,4,0,"parquet-cascading/src/main/java/parquet/cascading/TupleWriteSupport.java,CAS_DELIMITER",1,1,1,0.0,18,103.0,1,25.325671296296296,0.0,0.0,0.0,None,FALSE,FALSE,
ed08077daa9c780a8dfea360a638bcab50269bbc,Tom White,tom@cloudera.com,Wed Feb 19 10:40:23 2014 -0800,1392835223,Don't fail if no default value specified for a new value in the read schema .,3,0,"parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java,CAS_DELIMITER",1,1,1,0.0,15,190.0,20,28.29454861111111,28.0,20.176931957488694,20.0,Corrective,TRUE,FALSE,
712e6d796c41a44a751dcf441f0db4dae87eb693,Brock Noland,brock@apache.org,Tue Feb 18 13:54:01 2014 -0600,1392753241,fix compile error in previous commit,3,0,"parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport.java,CAS_DELIMITER",1,1,1,0.0,18,14.0,2,0.022893518518518518,8.0,7.075839679647762,8.0,Corrective,TRUE,FALSE,
8cc8bdc05260d0f5f60b3435da7d0f0edef6a786,Wesley Peck,wesley.peck@arrisi.com,Tue Feb 18 13:28:31 2014 -0600,1392751711,Merge the parquet - tools project into parquet - mr .,2611,0,"parquet-tools/src/main/java/parquet/tools/Main.java,CAS_DELIMITER,parquet-tools/src/main/java/parquet/tools/command/ArgsOnlyCommand.java,CAS_DELIMITER,parquet-tools/src/main/java/parquet/tools/command/CatCommand.java,CAS_DELIMITER,parquet-tools/src/main/java/parquet/tools/command/Command.java,CAS_DELIMITER,parquet-tools/src/main/java/parquet/tools/command/DumpCommand.java,CAS_DELIMITER,parquet-tools/src/main/java/parquet/tools/command/HeadCommand.java,CAS_DELIMITER,parquet-tools/src/main/java/parquet/tools/command/Registry.java,CAS_DELIMITER,parquet-tools/src/main/java/parquet/tools/command/ShowMetaCommand.java,CAS_DELIMITER,parquet-tools/src/main/java/parquet/tools/command/ShowSchemaCommand.java,CAS_DELIMITER,parquet-tools/src/main/java/parquet/tools/read/SimpleReadSupport.java,CAS_DELIMITER,parquet-tools/src/main/java/parquet/tools/read/SimpleRecord.java,CAS_DELIMITER,parquet-tools/src/main/java/parquet/tools/read/SimpleRecordConverter.java,CAS_DELIMITER,parquet-tools/src/main/java/parquet/tools/read/SimpleRecordMaterializer.java,CAS_DELIMITER,parquet-tools/src/main/java/parquet/tools/util/MetadataUtils.java,CAS_DELIMITER,parquet-tools/src/main/java/parquet/tools/util/PrettyPrintWriter.java,CAS_DELIMITER",15,1,4,3.047323500342285,1,174.06666666666666,15,0.0,5.0,3.9549417354344025,1.0,Non Functional,FALSE,TRUE,
81028366038e22cff7a3f62e8eab6d00758f978e,Wesley Peck,wesley.peck@arrisi.com,Tue Feb 18 13:28:31 2014 -0600,1392751711,Merge the parquet - tools project into parquet - mr .,2611,0,"parquet-tools/src/main/java/parquet/tools/Main.java,CAS_DELIMITER,parquet-tools/src/main/java/parquet/tools/command/ArgsOnlyCommand.java,CAS_DELIMITER,parquet-tools/src/main/java/parquet/tools/command/CatCommand.java,CAS_DELIMITER,parquet-tools/src/main/java/parquet/tools/command/Command.java,CAS_DELIMITER,parquet-tools/src/main/java/parquet/tools/command/DumpCommand.java,CAS_DELIMITER,parquet-tools/src/main/java/parquet/tools/command/HeadCommand.java,CAS_DELIMITER,parquet-tools/src/main/java/parquet/tools/command/Registry.java,CAS_DELIMITER,parquet-tools/src/main/java/parquet/tools/command/ShowMetaCommand.java,CAS_DELIMITER,parquet-tools/src/main/java/parquet/tools/command/ShowSchemaCommand.java,CAS_DELIMITER,parquet-tools/src/main/java/parquet/tools/read/SimpleReadSupport.java,CAS_DELIMITER,parquet-tools/src/main/java/parquet/tools/read/SimpleRecord.java,CAS_DELIMITER,parquet-tools/src/main/java/parquet/tools/read/SimpleRecordConverter.java,CAS_DELIMITER,parquet-tools/src/main/java/parquet/tools/read/SimpleRecordMaterializer.java,CAS_DELIMITER,parquet-tools/src/main/java/parquet/tools/util/MetadataUtils.java,CAS_DELIMITER,parquet-tools/src/main/java/parquet/tools/util/PrettyPrintWriter.java,CAS_DELIMITER",15,1,4,3.047323500342285,1,0.0,0,0.0,4.0,2.9549417354344025,0.0,Non Functional,FALSE,FALSE,
c48e8c1324562937cdca552657afb4e090f119f2,Brock Noland,brock@apache.org,Tue Feb 18 13:21:03 2014 -0600,1392751263,HIVE - 6456 - Implement Parquet schema evolution,3,0,"parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport.java,CAS_DELIMITER",1,1,1,0.0,18,11.0,1,8.169513888888888,7.0,6.076235454334648,7.0,None,FALSE,FALSE,
af2380fbcf5d440315d0a5335975197586ebf929,Ryan Blue,rblue@cloudera.com,Fri Feb 14 13:16:24 2014 -0800,1392412584,"Add NanoTime to example . This adds NanoTime to the example objects , stored as an int96 , for testing .",80,2,"parquet-column/src/main/java/parquet/example/data/Group.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/NanoTime.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER",4,1,3,1.332873884751926,19,75.5,55,2.893064236111111,8.0,7.922178844634062,8.0,Feature Addition,FALSE,TRUE,
2403257ff4c412465e4bfc4af5f0e745b5d96565,Ryan Blue,rblue@cloudera.com,Fri Feb 14 09:51:05 2014 -0800,1392400265,"Use toStringUsingUTF8 to fix tests . Binary values will not necessarily decode with UTF8 , but the ExpectationValidatingRecordConsumer can decode because its inputs are controlled for testing .",1,1,"parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java,CAS_DELIMITER",1,1,1,0.0,19,-1.0,12,2.8245601851851854,7.0,6.925245009575262,7.0,Corrective,TRUE,FALSE,
3fc099fd7b315a2daecf2f832071f8b91006ecf8,Ryan Blue,rblue@cloudera.com,Fri Feb 14 09:10:13 2014 -0800,1392397813,Factoring out common Binary impl in dictionary writer .,32,42,"parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER",1,1,1,0.0,19,685.0,41,3.6864583333333334,6.0,5.925777830401747,6.0,None,FALSE,TRUE,
d7c7395b44144d05ff4dcb464bdcc4e90056c3c6,Ryan Blue,rblue@cloudera.com,Fri Feb 14 09:08:45 2014 -0800,1392397725,Merge Fixed dictionary with Binary dictionary .,46,61,"parquet-column/src/main/java/parquet/column/Encoding.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/PlainValuesDictionary.java,CAS_DELIMITER",2,1,2,0.1844518631409876,19,315.5,41,3.685439814814815,5.0,4.925794163900565,5.0,Corrective,TRUE,TRUE,
6b2eef9d99600f4fc48a9ba40e15fea3e5e748ad,Ryan Blue,rblue@cloudera.com,Fri Feb 14 09:07:03 2014 -0800,1392397623,Delegate fixed and int96 types to convertBINARY .,2,34,"parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java,CAS_DELIMITER",1,1,1,0.0,19,340.0,30,3.6842592592592593,4.0,3.9258098616139985,4.0,Corrective,TRUE,FALSE,
cc59a4077dc880bb5de5555954906bda64369678,Tom White,tom@cloudera.com,Wed Feb 12 12:07:04 2014 +0000,1392206824,Don't deep copy immutable primitive types .,15,1,"parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java,CAS_DELIMITER",1,1,1,0.0,15,156.0,17,27.922372685185184,25.0,17.598665462254537,17.0,None,FALSE,FALSE,
56387e33db7df5f50b5754b756d1551af2735fe3,Ryan Blue,rblue@cloudera.com,Tue Feb 11 14:03:43 2014 -0800,1392156223,"Remove int96 references from RecordConsumer and Converters . This commit removes int96 - specific code from the RecordConsumer and the Converters . Implementations are responsible for checking the Type of columns . Because Binary is used for int96 values , it is no longer assumed that a Binary is printable as a UTF8 string in methods like Binary#toString .",34,71,"parquet-column/src/main/java/parquet/example/data/simple/Int96Value.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/MessageColumnIO.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/api/Binary.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/api/PrimitiveConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/api/RecordConsumer.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/PrimitiveType.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/ConverterConsumer.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java,CAS_DELIMITER",12,1,6,3.0441932356676666,19,60.333333333333336,134,1.3959924768518517,3.0,2.9555298150540716,3.0,None,FALSE,TRUE,
0d111b1defc6cc5100470dd1162b6eece86fdbd8,Tianshuo Deng,tdeng@twitter.com,Tue Feb 11 13:19:34 2014 -0800,1392153574,remove fieldCount from marker,3,9,"parquet-column/src/main/java/parquet/io/MessageColumnIO.java,CAS_DELIMITER",1,1,1,0.0,18,77.0,26,0.6021527777777778,224.0,169.6182445173781,79.0,None,FALSE,FALSE,
02f50f7ea0b417a8b963b8b2b081b16190ffc9ef,Tianshuo Deng,tdeng@twitter.com,Mon Feb 10 22:52:28 2014 -0800,1392101548,rename var,3,3,"parquet-column/src/main/java/parquet/io/MessageColumnIO.java,CAS_DELIMITER",1,1,1,0.0,18,77.0,25,0.001875,223.0,168.83218263327305,78.0,None,FALSE,FALSE,
1be4d6c9ac35c133d5e257839c65aa83155a4455,Tianshuo Deng,tdeng@twitter.com,Mon Feb 10 22:49:46 2014 -0800,1392101386,"bugfix : reorder fields in thrift struct caused writting nulls . fixed it by keeping track of which fields are being written in each level , and only write nulls when current level is finished in MessageColumnIO",82,34,"parquet-column/src/main/java/parquet/io/MessageColumnIO.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadWriteAndProjection.java,CAS_DELIMITER",3,2,3,1.138886709153396,18,99.33333333333333,56,47.00769290123457,222.0,167.8328445128999,77.0,Corrective,TRUE,FALSE,
34b90d7b86c600804038048e905f0f3587aba687,Ryan Blue,rblue@cloudera.com,Mon Feb 10 16:41:43 2014 -0800,1392079303,"Removing Int96 class , using Binary instead . This removes all references to the Int96 class and uses Binary instead . Int96 calls are still used at the RecordConsumer and Converter level , specifically used by PrimitiveType . PrimitiveTypeName . INT96 .",98,267,"parquet-column/src/main/java/parquet/column/ColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/ColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/Dictionary.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/Encoding.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/ParquetProperties.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/ValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/ValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/PlainValuesDictionary.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/Int96PlainValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/DummyRecordConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/Group.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/GroupValueSource.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple//Int96Value.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/Primitive.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/MessageColumnIO.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/api/Int96.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/api/PrimitiveConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/api/RecordConsumer.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/PrimitiveType.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/ConverterConsumer.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER",33,1,14,4.631008345261256,19,112.96969696969697,433,6.741837822671158,2.0,1.9626495112773739,2.0,None,FALSE,TRUE,
083c51317f4cde839c2a948e6fa5c2b62221be31,Brock Noland,brock@apache.org,Mon Feb 10 11:14:31 2014 -0600,1392052471,Convert ParquetHiveSerDe back to SerDe interface to support Hive 0 . 10,2,2,"parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe.java,CAS_DELIMITER",1,1,1,0.0,18,274.0,1,0.08164351851851852,6.0,5.196245840833987,6.0,None,FALSE,FALSE,
38241cc7e85e943d404f186fe684bf2ceb855de6,Brock Noland,brock@apache.org,Mon Feb 10 09:16:57 2014 -0600,1392045417,Ports HIVE - 5783 to the parquet - hive module so that patches can be ported between the two code bases with ease . Note that the code base in Hive itself should be considered the golden copy and any changes made there and then ported to the parquet - hive module .,1301,2018,"parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/parquet/hive/HiveBindingFactory.java,CAS_DELIMITER,parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/parquet/hive/TestHiveBindingFactory.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/IOConstants.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/MapredParquetInputFormat.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/MapredParquetOutputFormat.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/ArrayWritableGroupConverter.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/DataWritableGroupConverter.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/DataWritableRecordConverter.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/ETypeConverter.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/HiveGroupConverter.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/convert/HiveSchemaConverter.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/DataWritableReadSupport.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/read/ParquetRecordReaderWrapper.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/AbstractParquetMapInspector.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ArrayWritableObjectInspector.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/DeepParquetHiveMapInspector.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveArrayInspector.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/StandardParquetHiveMapInspector.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetByteInspector.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetPrimitiveInspectorFactory.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetShortInspector.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/serde/primitive/ParquetStringInspector.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/writable/BigDecimalWritable.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/writable/BinaryWritable.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriteSupport.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/write/DataWritableWriter.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/org/apache/hadoop/hive/ql/io/parquet/write/ParquetRecordWriterWrapper.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetInputFormat.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetOutputFormat.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestHiveSchemaConverter.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestMapredParquetInputFormat.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestMapredParquetOutputFormat.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/TestParquetSerDe.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/serde/TestAbstractParquetMapInspector.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/serde/TestDeepParquetHiveMapInspector.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/serde/TestParquetHiveArrayInspector.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/test/java/org/apache/hadoop/hive/ql/io/parquet/serde/TestStandardParquetHiveMapInspector.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestMapredParquetInputFormat.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestMapredParquetOuputFormat.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/UtilitiesTestMethods.java,CAS_DELIMITER",44,1,15,4.5143660224117745,18,8.204545454545455,20,14.20141414141414,5.0,4.197257915028639,5.0,None,FALSE,TRUE,
68b531441eb4fc19d00d2a18ff61bef140fd25ee,Tianshuo Deng,tdeng@twitter.com,Thu Feb 6 14:29:15 2014 -0800,1391725755,"better error messages , create ParquetScroogeInputFormat class",49,19,"parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeInputFormat.java,CAS_DELIMITER,parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java,CAS_DELIMITER,parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java,CAS_DELIMITER,parquet-scrooge/src/test/java/parquet/scrooge/ScroogeStructConverterTest.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftInputFormat.java,CAS_DELIMITER",5,2,3,1.8892748378645356,17,58.6,19,86.86549537037038,221.0,168.36969966145907,53.0,Feature Addition,FALSE,FALSE,
aadaae5be5d207f73b54b89e11d73ea06fa45171,Tom White,tom@cloudera.com,Tue Feb 4 16:28:18 2014 +0000,1391531298,Revert change making field final that failed compatibility test .,1,1,"parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java,CAS_DELIMITER",1,1,1,0.0,15,89.0,12,0.006446759259259259,23.0,15.937800774616548,15.0,Corrective,TRUE,FALSE,
0185b491c9e0264a591611259a4233e068390f0c,Tom White,tom@cloudera.com,Tue Feb 4 16:19:01 2014 +0000,1391530741,Minor changes following Julien's review,3,1,"parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java,CAS_DELIMITER",1,1,1,0.0,15,87.0,11,14.246168981481482,22.0,14.938007924803845,14.0,None,FALSE,FALSE,
77a355af4b7828daeffcdf312108ad9f1fa738d7,Ryan Blue,rblue@cloudera.com,Mon Feb 3 18:17:27 2014 -0800,1391480247,Extending example and group classes for int96 . This commit gets TestColumnIO#testOneOfEach passing with an int96 column .,85,3,"parquet-column/src/main/java/parquet/example/DummyRecordConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/Group.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/GroupValueSource.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/Primitive.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/convert/Int96Value.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/api/Int96.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER",9,1,6,2.7836829104555743,19,57.888888888888886,73,110.54894161522634,1.0,0.9999305920831407,1.0,Preventative,FALSE,FALSE,
7043a64617eb25608498f502feb6c76c58b15242,Ryan Blue,rblue@cloudera.com,Mon Feb 3 17:40:58 2014 -0800,1391478058,Initial int96 implementation . This primarily adds int96 calls throughout the read and write paths . Int96 is mostly a place - holder class that wraps a ByteBuffer . This adds int96 support to the PLAIN and PLAIN DICTIONARY encodings . Existing tests are passing .,372,6,"parquet-column/src/main/java/parquet/column/ColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/ColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/Dictionary.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/Encoding.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/ParquetProperties.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/ValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/ValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/PlainValuesDictionary.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/Int96PlainValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/MessageColumnIO.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/api/Binary.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/api/Int96.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/api/PrimitiveConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/api/RecordConsumer.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/PrimitiveType.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/ConverterConsumer.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER",27,1,9,4.1351062549243265,19,117.66666666666667,373,90.50574802812073,0.0,0.0,0.0,Feature Addition,FALSE,FALSE,
83bb4b89b433df79049411a7642b615821c03654,E. Sammer,esammer@cloudera.com,Sun Feb 2 22:08:09 2014 -0800,1391407689,Added ParquetWriter ( ) that takes an instance of Hadoop's Configuration .,38,4,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java,CAS_DELIMITER",1,1,1,0.0,18,208.0,17,4.248252314814815,0.0,0.0,0.0,Feature Addition,FALSE,FALSE,
a1b7a315726ebf3038ef4160aede0fe8e91024f6,allanyan,hailunyan@gmail.com,Thu Jan 30 18:46:04 2014 -0800,1391136364,use utility method from Configuration class to load class to avoid ClassNotFoundException,2,5,"parquet-hadoop/src/main/java/parquet/hadoop/util/ConfigurationUtil.java,CAS_DELIMITER",1,1,1,0.0,18,59.0,3,0.3727662037037037,1.0,0.9989797646727292,1.0,None,FALSE,FALSE,
8ecb0b22d80cae8f962b0de573fd276bbcac3385,allanyan,hailunyan@gmail.com,Thu Jan 30 09:49:17 2014 -0800,1391104157,"first use current thread's classloader to load a class , if current thread does not have a classloader , use the class's current classloader to load a class . This will make sure a class not packaged in parquet but on classpath loaded properly . Otherwise , for example , if you set your own ReadSupport class to the Configuration object and expect it to be loaded by ParquetInputFormat , it will fail and throw ClassNotFoundException .",5,1,"parquet-hadoop/src/main/java/parquet/hadoop/util/ConfigurationUtil.java,CAS_DELIMITER",1,1,1,0.0,18,55.0,2,0.7351504629629629,0.0,0.0,0.0,Corrective,TRUE,FALSE,
2d9cf95dfa0cbc2c969ff4c61f6cdae16cac87d6,Aniket Mokashi,amokashi@twitter.com,Mon Jan 27 18:24:37 2014 -0800,1390875877,make setup calls static in tests,9,9,"parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestAbstractParquetMapInspector.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestDeepParquetHiveMapInspector.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestParquetHiveArrayInspector.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestStandardParquetHiveMapInspector.java,CAS_DELIMITER",4,1,1,1.974937501201927,15,94.5,12,4.106481481481482,39.0,30.397558997278242,4.0,Preventative,FALSE,FALSE,
76bbf4a88645abc657ba6e4c2dc636712f03b944,Mickael Lacour,m.lacour@criteo.com,Mon Jan 27 17:39:18 2014 +0100,1390840758,[ CASCADING ] Provide the sink implementation in order to write some parquet files with ParquetTupleScheme,139,12,"parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java,CAS_DELIMITER,parquet-cascading/src/main/java/parquet/cascading/TupleWriteSupport.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER",3,2,2,1.0553015656396585,18,134.0,36,19.538070987654322,23.0,13.543580854173367,0.0,None,FALSE,FALSE,
02f7707e13755b6ab9e4c5a5bd8cf98152488631,Lukas,lukas.nalezenec@gmail.com,Sun Jan 26 14:36:57 2014 +0100,1390743417,ProtoMessageConverter case,12,29,"parquet-protobuf/src/main/java/parquet/proto/ProtoMessageConverter.java,CAS_DELIMITER",1,1,1,0.0,1,363.0,2,0.0159375,44.0,40.17018634690185,20.0,None,FALSE,FALSE,
496e3fd019ad524b165242ee6fc914d9cdcbf174,Lukas,lukas.nalezenec@gmail.com,Sun Jan 26 14:11:35 2014 +0100,1390741895,Scalar Converters are part of Message converter,409,532,"parquet-protobuf/src/main/java/parquet/proto/ProtoMessageConverter.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto//ProtoRecordConverter.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/converters/ParentValueContainer.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/converters/ProtoBinaryConverter.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/converters/ProtoBooleanConverter.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/converters/ProtoDoubleConverter.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/converters/ProtoEnumConverter.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/converters/ProtoFloatConverter.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/converters/ProtoIntConverter.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/converters/ProtoLongConverter.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/converters/ProtoMessageConverter.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/converters/ProtoStringConverter.java,CAS_DELIMITER,parquet-protobuf/src/test/java/parquet/proto//ProtoRecordConverterTest.java,CAS_DELIMITER",13,1,4,2.9390077203388714,1,0.8461538461538461,28,12.83608351139601,42.0,38.171958723441534,18.0,None,FALSE,FALSE,
8cc4cecd580438643c3423bf147c476c8ad606e0,Lukas,lukas.nalezenec@gmail.com,Sat Jan 25 18:08:48 2014 +0100,1390669728,New ProtoWriteSupport,252,155,"parquet-protobuf/src/main/java/parquet/proto/ProtoWriteSupport.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/converters/ProtoMessageConverter.java,CAS_DELIMITER,parquet-protobuf/src/test/java/parquet/proto/ProtoWriteSupportTest.java,CAS_DELIMITER",3,1,3,0.6025303884855183,1,63.0,16,5.480011574074074,41.0,37.25180975991509,17.0,Feature Addition,FALSE,TRUE,
6edfa7e6ee517536dbde935c0c6cfc68e7155b44,Lukas,lukas.nalezenec@gmail.com,Sat Jan 25 00:32:42 2014 +0100,1390606362,ProtoWriteSupport unit tests,143,0,"parquet-protobuf/src/test/java/parquet/proto/ProtoWriteSupportTest.java,CAS_DELIMITER",1,1,1,0.0,1,0.0,0,0.0,40.0,36.320186263485375,16.0,Preventative,FALSE,FALSE,
e4329cde9f32e8f3cea88d82420d0ab920348d02,Aniket Mokashi,amokashi@twitter.com,Thu Jan 23 15:51:17 2014 -0800,1390521077,move from junit3 to junit4,28,18,"parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestParquetSerDe.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestAbstractParquetMapInspector.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestDeepParquetHiveMapInspector.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestParquetHiveArrayInspector.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestStandardParquetHiveMapInspector.java,CAS_DELIMITER",5,1,2,2.3104673089512584,15,74.4,10,5.796377314814815,38.0,29.671857940272503,3.0,Preventative,FALSE,FALSE,
555837ad2df87cf19d269919e6dbb809c3b060bb,Tom White,tom@cloudera.com,Wed Jan 22 11:36:14 2014 +0000,1390390574,"Support field renaming for Avro read schemas , by means of field aliases . Avro 1 . 7 . 6 is required since it fixes https : / / issues . apache . org / jira / browse / AVRO - 1433 But note that this is only to allow the test to run correctly .",16,6,"parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java,CAS_DELIMITER",2,1,2,0.4394969869215134,15,207.5,31,0.0,27.0,20.454461318863387,19.0,Corrective,TRUE,FALSE,
808de5d963b4186d69b2ae39c00ed5f5bb08b2cc,Tom White,tom@cloudera.com,Wed Jan 22 11:36:14 2014 +0000,1390390574,"Support field renaming for Avro read schemas , by means of field aliases . Avro 1 . 7 . 6 is required since it fixes https : / / issues . apache . org / jira / browse / AVRO - 1433 But note that this is only to allow the test to run correctly .",16,6,"parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java,CAS_DELIMITER",2,1,2,0.4394969869215134,15,202.5,29,-7.060225694444445,26.0,19.454461318863387,18.0,Corrective,TRUE,FALSE,
ab54b702f1039d827a1a0a04299368338e2554ac,Tom White,tom@cloudera.com,Tue Jan 21 10:24:32 2014 +0000,1390299872,Add tests for reading Parquet files using the default Avro schema .,255,37,"parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestReadWrite.java,CAS_DELIMITER",4,1,2,1.096640362893079,15,188.75,42,39.69936053240741,21.0,14.369566827639861,13.0,Feature Addition,FALSE,FALSE,
942cfe26cceb69cc420e5019f854213c654ec844,Lukas,lukas.nalezenec@gmail.com,Sun Jan 19 00:31:15 2014 +0100,1390087875,Dictionary enum conversion,39,6,"parquet-protobuf/src/main/java/parquet/proto/converters/ProtoEnumConverter.java,CAS_DELIMITER",1,1,1,0.0,1,0.0,3,12.24957175925926,39.0,35.87256244109999,15.0,None,FALSE,FALSE,
3c0ab7a908e7e503660781c94f463c8f3f314ec3,Lukas,lukas.nalezenec@gmail.com,Sun Jan 19 00:29:39 2014 +0100,1390087779,List cannot be empty,4,8,"parquet-protobuf/src/main/java/parquet/proto/ProtoWriteSupport.java,CAS_DELIMITER",1,1,1,0.0,1,70.0,8,0.017372685185185185,38.0,34.87266323261177,14.0,None,FALSE,FALSE,
da17462e59a01b01017b0a90a2e850e2743ce663,Lukas,lukas.nalezenec@gmail.com,Sun Jan 19 00:04:38 2014 +0100,1390086278,Matching parquet and pbfields by index,35,24,"parquet-protobuf/src/main/java/parquet/proto/ProtoWriteSupport.java,CAS_DELIMITER",1,1,1,0.0,1,59.0,7,2.2182175925925924,37.0,33.8741916251347,13.0,None,FALSE,FALSE,
b25de9814b5d20afe380a0fe1e59d3329102e1d0,Aniket Mokashi,amokashi@twitter.com,Fri Jan 17 20:44:30 2014 -0800,1390020270,style : junit . framework to org . junit,8,8,"parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestParquetSerDe.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestAbstractParquetMapInspector.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestDeepParquetHiveMapInspector.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestParquetHiveArrayInspector.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestStandardParquetHiveMapInspector.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestThriftParquetReaderWriter.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java,CAS_DELIMITER",8,2,5,3.0,15,101.625,23,79.47564670138888,37.0,29.05160210520571,3.5,None,FALSE,FALSE,
6763f71bdb48cc3f955825ed5e2090ca10688d54,Lukas,lukas.nalezenec@gmail.com,Thu Jan 16 18:50:24 2014 +0100,1389894624,storage of repeated fields without extra level,125,130,"parquet-protobuf/src/main/java/parquet/proto/ProtoSchemaConverter.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/ProtoWriteSupport.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/converters/ProtoArrayConverter.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/converters/ProtoMessageConverter.java,CAS_DELIMITER,parquet-protobuf/src/test/java/parquet/proto/ProtoSchemaConverterTest.java,CAS_DELIMITER,parquet-protobuf/src/test/java/parquet/proto/converters/ProtoRecordConverterTest.java,CAS_DELIMITER",6,1,4,1.9645386341237334,1,-0.8333333333333334,21,11.781180555555556,36.0,33.064339128972456,12.0,None,FALSE,FALSE,
e29d26bebca603e00c8f437ef46befd9ef0d7a02,Tom White,tom@cloudera.com,Thu Jan 16 15:14:27 2014 +0000,1389885267,Use a default Avro read schema when none specified in Parquet - Avro .,233,42,"parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java,CAS_DELIMITER",2,1,2,0.9908140079951208,15,145.5,17,114.15244791666666,20.0,13.507635106495439,12.0,None,FALSE,TRUE,
a2691a742379c023acb2e7a3d6ae7bd08f92a8be,Lukas,lukas.nalezenec@gmail.com,Thu Jan 16 10:43:40 2014 +0100,1389865420,Exception message,2,2,"parquet-column/src/main/java/parquet/io/api/Converter.java,CAS_DELIMITER",1,1,1,0.0,1,0.0,1,313.5620601851852,35.0,32.09257482601539,0.0,None,FALSE,FALSE,
01bba92984f12d111042cb54332d906d3d8add4c,Tom White,tom@cloudera.com,Wed Jan 15 14:10:51 2014 +0000,1389795051,"Support promotion of int , long and float to wider types . This is specified in http : / / avro . apache . org / docs / current / spec . html#Schema + Resolution",30,0,"parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java,CAS_DELIMITER",1,1,1,0.0,15,104.0,15,27.939016203703705,19.0,12.535182774694517,11.0,None,FALSE,FALSE,
94d703c7cad93228ddee626622841953eae665b1,Tom White,tom@cloudera.com,Wed Jan 15 13:58:51 2014 +0000,1389794331,Fill in default values for new fields in the read schema that were not in the write schema . Some of the implementation was inspired by https : / / issues . apache . org / jira / browse / AVRO - 1228 .,24,1,"parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java,CAS_DELIMITER",2,1,2,0.24229218908241482,15,184.0,26,13.961174768518518,24.0,17.671145742082803,16.0,Feature Addition,FALSE,FALSE,
ac8968ec23bc59937f56394648a2797fcbf486e4,ledbit,lbitincka@gmail.com,Wed Jan 8 12:36:31 2014 -0800,1389213391,prettify a few lines,3,1,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java,CAS_DELIMITER",1,1,1,0.0,14,83.0,11,1.8705208333333334,3.0,2.984834557237347,2.0,None,FALSE,FALSE,
40f9b24c036733e2d02afcb1b8c78c3feb28a5f9,Tianshuo Deng,tdeng@twitter.com,Tue Jan 7 22:06:18 2014 -0800,1389161178,name fix,2,2,"parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java,CAS_DELIMITER",1,1,1,0.0,17,922.0,19,0.014282407407407407,220.0,178.58333076968097,75.0,Corrective,TRUE,FALSE,
46b1ad00a8169943d9d8b4096cdd21260a55b73a,Tianshuo Deng,tdeng@twitter.com,Tue Jan 7 21:45:44 2014 -0800,1389159944,"fix bug : when enum index being written is the last index defined in the Enum , a DecodingSchemaMismatchException is thrown . maintain enum loopup table in EnumType",38,15,"parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java,CAS_DELIMITER",5,1,3,1.827073222392812,17,413.4,66,42.89145833333333,219.0,177.58904990126,74.0,Corrective,TRUE,FALSE,
af880ec55c070b9239f073b36e6b95e888b4a684,ledbit,lbitincka@gmail.com,Mon Jan 6 15:42:58 2014 -0800,1389051778,Make ParquetInputSplit extend FileSplit,14,72,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java,CAS_DELIMITER",2,1,2,0.5185697317883058,14,169.5,16,0.010486111111111111,1.0,0.9999712717537985,1.0,None,FALSE,FALSE,
5c6876accde093e56efb244345f1b77e3bce7144,ledbit,lbitincka@gmail.com,Mon Jan 6 15:27:52 2014 -0800,1389050872,"Revert ""Make ParquetInputSplit extend FileSplit"" This reverts commit f232e7793f85d1cd4c2121c8d14df73a217e4df3 .",72,14,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java,CAS_DELIMITER",2,1,2,0.5185697317883058,14,140.5,14,0.012824074074074075,0.0,0.0,0.0,None,FALSE,FALSE,
f232e7793f85d1cd4c2121c8d14df73a217e4df3,Ledion Bitincka,lbitincka@ronnie.sv.splunk.com,Mon Jan 6 15:09:24 2014 -0800,1389049764,Make ParquetInputSplit extend FileSplit,14,72,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java,CAS_DELIMITER",2,1,2,0.5185697317883058,14,169.5,12,43.26296875,0.0,0.0,0.0,None,FALSE,FALSE,
09914752a40cc7f950695b66395d1fe783a97224,Lukas,lukas.nalezenec@gmail.com,Mon Jan 6 20:41:14 2014 +0100,1389037274,Code style - small fixes,8,9,"parquet-protobuf/src/main/java/parquet/proto/ProtoParquetReader.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/ProtoParquetWriter.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/converters/ProtoBooleanConverter.java,CAS_DELIMITER",3,1,2,1.3328204045850196,1,0.0,6,7.280162037037037,34.0,31.88692953039511,11.0,Corrective,TRUE,FALSE,
2207cb95ba17bfabdd9e03ef035aa1349f162fd6,Lukas,lukas.nalezenec@gmail.com,Mon Jan 6 20:38:19 2014 +0100,1389037099,switches on enums,52,48,"parquet-protobuf/src/main/java/parquet/proto/ProtoSchemaConverter.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/ProtoWriteSupport.java,CAS_DELIMITER",2,1,1,0.934068055375491,1,-5.5,9,8.059756944444445,33.0,30.88709600871572,10.0,None,FALSE,FALSE,
81ab42663de1c0976fea942374227808443662ed,Lukas,lukas.nalezenec@gmail.com,Mon Jan 6 18:31:52 2014 +0100,1389029512,Make package java . parquet . proto . converters ( mostly ) package protected,16,15,"parquet-protobuf/src/main/java/parquet/proto/ProtoRecordMaterializer.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/converters/ParentValueContainer.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/converters/ProtoArrayConverter.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/converters/ProtoBinaryConverter.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/converters/ProtoBooleanConverter.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/converters/ProtoDoubleConverter.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/converters/ProtoEnumConverter.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/converters/ProtoFloatConverter.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/converters/ProtoIntConverter.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/converters/ProtoLongConverter.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/converters/ProtoMessageConverter.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/converters/ProtoRecordConverter.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/converters/ProtoStringConverter.java,CAS_DELIMITER,parquet-protobuf/src/test/java/parquet/proto/converters/ProtoRecordConverterTest.java,CAS_DELIMITER",14,1,3,3.6796874392795544,1,0.14285714285714285,17,9.103231646825398,32.0,29.894074594018807,9.0,None,FALSE,FALSE,
4dae164fe36075b8470a1cd9d7ac365982a48e29,Lukas,lukas.nalezenec@gmail.com,Sun Jan 5 16:31:34 2014 +0100,1388935894,unused method in TestUtils,3,5,"parquet-protobuf/src/test/java/parquet/proto/ProtoRecordConverterTest.java,CAS_DELIMITER,parquet-protobuf/src/test/java/parquet/proto/TestUtils.java,CAS_DELIMITER",2,1,1,0.8112781244591328,1,13.0,5,9.198292824074073,31.0,28.977468780183425,8.0,Preventative,FALSE,FALSE,
622a4000f69dcc87947e1566835fc51b3be46aaf,Tianshuo Deng,tdeng@twitter.com,Thu Jan 2 17:39:05 2014 -0800,1388713145,"handler only handle ignored field , exception during will be thrown as SkippableException",47,103,"parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/FieldIgnoredHandler.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java,CAS_DELIMITER",6,1,3,1.950345901339519,14,241.83333333333334,48,12.604909336419754,218.0,178.66999205797708,73.0,None,FALSE,FALSE,
0261cd6a7525fa37229d6c4f8df1d6409332646d,Aniket Mokashi,amokashi@twitter.com,Thu Jan 2 17:19:57 2014 -0800,1388711997,upgrade parquet - mr to elephant - bird 4 . 4,55,35,"parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestThriftToPigCompatibility.java,CAS_DELIMITER",3,1,1,0.521639047677643,18,232.0,20,126.55572145061728,36.0,29.048728141188768,4.0,None,FALSE,FALSE,
8ed45d07603a354f4e05a454a841995f5d558eb1,Lukas,lukas.nalezenec@gmail.com,Sun Dec 29 19:14:58 2013 +0100,1388340898,Unnecessary unboxing,4,4,"parquet-protobuf/src/main/java/parquet/proto/ProtoWriteSupport.java,CAS_DELIMITER",1,1,1,0.0,1,-5.0,4,0.00375,30.0,28.49936218830172,7.0,None,FALSE,FALSE,
63b710dad7aa9e87cab013d701b100aa0178ec38,Lukas,lukas.nalezenec@gmail.com,Sun Dec 29 19:09:34 2013 +0100,1388340574,Code cleanup - Enum comparsions,55,57,"parquet-protobuf/src/main/java/parquet/proto/ProtoSchemaConverter.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/ProtoWriteSupport.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/converters/ProtoMessageConverter.java,CAS_DELIMITER",3,1,2,1.5042155786271256,1,-2.3333333333333335,9,2.471103395061728,29.0,27.499641243412228,6.0,Perfective,FALSE,TRUE,
7c0d29037f59ec37c1f652df9cc4fc1bef76ea82,Lukas,lukas.nalezenec@gmail.com,Fri Dec 27 22:41:15 2013 +0100,1388180475,Code cleanup,14,18,"parquet-protobuf/src/main/java/parquet/proto/ProtoWriteSupport.java,CAS_DELIMITER,parquet-protobuf/src/test/java/parquet/proto/ProtoInputOutputFormatTest.java,CAS_DELIMITER,parquet-protobuf/src/test/java/parquet/proto/TestUtils.java,CAS_DELIMITER,parquet-protobuf/src/test/java/parquet/proto/utils/WriteUsingMR.java,CAS_DELIMITER",4,1,3,1.792654957849531,1,-1.25,11,0.9340393518518518,28.0,26.63310270821138,5.0,Perfective,FALSE,FALSE,
36c3b66f327c823ee3a68fafb3744bc23321dea4,Tianshuo Deng,tdeng@twitter.com,Thu Dec 26 20:13:32 2013 -0800,1388117612,format,1,12,"parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java,CAS_DELIMITER",3,1,2,1.198183947911799,17,45.0,34,38.63594135802469,217.0,180.50208768593282,72.0,None,FALSE,FALSE,
b9e272aecbcbfb500245720eec41566fd918a18a,Tianshuo Deng,tdeng@twitter.com,Thu Dec 26 19:59:30 2013 -0800,1388116770,fix test,1,0,"parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java,CAS_DELIMITER",1,1,1,0.0,17,211.0,12,0.014918981481481481,216.0,179.5061292621813,29.0,Corrective,TRUE,FALSE,
ebc87de72be2249ce749b6893021b9c48f6a93c8,Tianshuo Deng,tdeng@twitter.com,Thu Dec 26 19:38:01 2013 -0800,1388115481,format,3,4,"parquet-scrooge/src/main/java/parquet/scrooge/ScroogeRecordConverter.java,CAS_DELIMITER,parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java,CAS_DELIMITER,parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java,CAS_DELIMITER",3,1,2,1.3787834934861756,17,97.0,17,34.79913580246914,215.0,178.5122759037298,28.0,None,FALSE,FALSE,
1d1dd2fa7832a51133c8003451334c1f4068cfe8,Tianshuo Deng,tdeng@twitter.com,Thu Dec 26 19:26:14 2013 -0800,1388114774,"1 . refactor : maket ThriftSchemaConverter pluggable , can use ThriftStructConverter or ScroogeStructConvert to convert class to ThriftType 2 . support scrooge read projection pushdown 3 . add scroogeReadSupport",233,131,"parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java,CAS_DELIMITER,parquet-scrooge/src/main/java/parquet/scrooge/ScroogeReadSupport.java,CAS_DELIMITER,parquet-scrooge/src/main/java/parquet/scrooge/ScroogeStructConverter.java,CAS_DELIMITER,parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java,CAS_DELIMITER,parquet-scrooge/src/test/java/parquet/scrooge/ScroogeStructConverterTest.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java,CAS_DELIMITER",8,2,5,2.3716846192573837,17,61.5,64,69.19231481481482,214.0,177.51562501881537,49.0,None,FALSE,FALSE,
565638f859d07256bc9f22218a54c04ae48f162f,Tianshuo Deng,tdeng@twitter.com,Thu Dec 26 16:17:12 2013 -0800,1388103432,refactor,217,354,"parquet-scrooge/src/main/java/parquet/scrooge/EnumConverter.java,CAS_DELIMITER,parquet-scrooge/src/main/java/parquet/scrooge/ScroogeEnumDesc.java,CAS_DELIMITER,parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java,CAS_DELIMITER,parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java,CAS_DELIMITER,parquet-scrooge/src/test/java/parquet/scrooge/ScroogeSchemaConverterTest.java,CAS_DELIMITER",5,1,2,1.6162120033490486,17,139.2,36,72.36623148148149,213.0,176.56901051061033,26.0,None,FALSE,FALSE,
47cd5723c39fd87c4aac676bebf67a6d6c931e43,Lukas,lukas.nalezenec@gmail.com,Fri Dec 27 00:51:42 2013 +0100,1388101902,Method ProtoParquetInputFormat . setRequestedProjection signature,28,18,"parquet-protobuf/src/main/java/parquet/proto/ProtoParquetInputFormat.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/ProtoRecordConverter.java,CAS_DELIMITER,parquet-protobuf/src/test/java/parquet/proto/ProtoInputOutputFormatTest.java,CAS_DELIMITER,parquet-protobuf/src/test/java/parquet/proto/utils/ReadUsingMR.java,CAS_DELIMITER,parquet-protobuf/src/test/java/parquet/proto/utils/WriteUsingMR.java,CAS_DELIMITER",5,1,3,2.208770523932803,1,-0.4,8,0.0886550925925926,27.0,25.6965813445917,4.0,None,FALSE,FALSE,
c7c39c3f5a12d3b823813bd6307d2e0e2ed98fce,Lukas,lukas.nalezenec@gmail.com,Fri Dec 27 00:50:48 2013 +0100,1388101848,Repeated Messages test,28,2,"parquet-protobuf/src/main/java/parquet/proto/converters/ProtoMessageConverter.java,CAS_DELIMITER,parquet-protobuf/src/test/java/parquet/proto/ProtoRecordConverterTest.java,CAS_DELIMITER",2,1,2,0.4689955935892812,1,0.0,3,0.04144097222222222,26.0,24.696623362902418,3.0,Preventative,FALSE,FALSE,
1f4a9db0b7216e5d7d5444aa86ae56ecdfda1b71,Lukas,lukas.nalezenec@gmail.com,Fri Dec 27 00:01:29 2013 +0100,1388098889,Code cleanup,26,10,"parquet-protobuf/src/main/java/parquet/proto/ProtoReadSupport.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/ProtoSchemaConverter.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/converters/ProtoMessageConverter.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/converters/ProtoStringConverter.java,CAS_DELIMITER,parquet-protobuf/src/test/java/parquet/proto/ProtoInputOutputFormatTest.java,CAS_DELIMITER",5,1,3,2.0271929804517845,1,0.0,7,0.03264583333333333,25.0,23.698832183383473,2.0,Perfective,FALSE,FALSE,
919db0ba56e7bce8d22c9a5a69d2b29e674a24ec,Lukas,lukas.nalezenec@gmail.com,Thu Dec 26 23:40:46 2013 +0100,1388097646,Consistent naming protoXYZ,35,42,"parquet-protobuf/src/main/java/parquet/proto/ProtoParquetOutputFormat.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/ProtoParquetReader.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/ProtoParquetWriter.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/ProtoReadSupport.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/ProtoRecordConverter.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/ProtoRecordMaterializer.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/ProtoSchemaConverter.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/ProtoWriteSupport.java,CAS_DELIMITER,parquet-protobuf/src/main/java/parquet/proto/converters/ProtoEnumConverter.java,CAS_DELIMITER,parquet-protobuf/src/test/java/parquet/proto/ProtoInputOutputFormatTest.java,CAS_DELIMITER,parquet-protobuf/src/test/java/parquet/proto/ProtoRecordConverterTest.java,CAS_DELIMITER,parquet-protobuf/src/test/java/parquet/proto/ProtoSchemaConverterTest.java,CAS_DELIMITER,parquet-protobuf/src/test/java/parquet/proto/TestUtils.java,CAS_DELIMITER,parquet-protobuf/src/test/java/parquet/proto/utils/WriteUsingMR.java,CAS_DELIMITER",14,1,4,3.6305066266622075,1,0.0,12,0.09058531746031744,24.0,22.699720753618738,1.0,None,FALSE,FALSE,
b273684b5a4efdd49a5bc3e0e5aa70ad3abbb155,Lukas,lukas.nalezenec@gmail.com,Thu Dec 26 21:00:45 2013 +0100,1388088045,ConverterTest,140,4,"src/test/java/parquet/proto/ProtoSchemaConverterTest.java,CAS_DELIMITER,src/test/java/parquet/proto/ProtobufferRecordConverterTest.java,CAS_DELIMITER,src/test/java/parquet/proto/TestUtils.java,CAS_DELIMITER",3,1,1,0.4139808936552185,1,90.33333333333333,7,3.933915895061728,22.0,20.706266929521895,22.0,Preventative,FALSE,FALSE,
985002ee33ffe6c199ff6471b3df89394bb22f14,Lukas,lukas.nalezenec@gmail.com,Thu Dec 26 21:00:30 2013 +0100,1388088030,Code cleanup,11,13,"src/main/java/parquet/proto/converters/ProtoEnumConverter.java,CAS_DELIMITER,src/main/java/parquet/proto/converters/ProtoMessageConverter.java,CAS_DELIMITER,src/main/java/parquet/proto/converters/ProtobufStringConverter.java,CAS_DELIMITER,src/test/java/parquet/proto/utils/ReadUsingMR.java,CAS_DELIMITER",4,1,2,1.8727298369794545,1,92.25,10,16.77980034722222,21.0,19.706276231810126,21.0,Perfective,FALSE,FALSE,
96f230019ae8e91f0eacf1490481a73161b4d8a2,Lukas,lukas.nalezenec@gmail.com,Thu Dec 26 16:22:11 2013 +0100,1388071331,#projection test - fix - cannot use inner class as mapper,62,48,"src/test/java/parquet/proto/utils/ReadUsingMR.java,CAS_DELIMITER,src/test/java/parquet/proto/utils/WriteUsingMR.java,CAS_DELIMITER",2,1,1,0.9527431707334315,1,89.0,2,0.002650462962962963,20.0,18.71610756100305,20.0,Corrective,TRUE,FALSE,
5997bf5ce0f588c7ea8ad0e6786d7dc3105908b5,Lukas,lukas.nalezenec@gmail.com,Thu Dec 26 16:18:22 2013 +0100,1388071102,#projection test,209,103,"src/main/java/parquet/proto/ProtoParquetInputFormat.java,CAS_DELIMITER,src/test/java/parquet/proto/ProtoInputOutputFormatTest.java,CAS_DELIMITER,src/test/java/parquet/proto/utils/ReadUsingMR.java,CAS_DELIMITER,src/test/java/parquet/proto/utils/WriteUsingMR.java,CAS_DELIMITER",4,1,3,1.696948243416872,1,52.0,3,17.3865625,19.0,17.71623518873371,19.0,Preventative,FALSE,FALSE,
f7a90232cab0da9121c327ad0b43c2d39811fb53,Lukas,lukas.nalezenec@gmail.com,Thu Dec 26 14:15:12 2013 +0100,1388063712,correct byte [ ] storage,14,8,"src/main/java/parquet/proto/ProtoWriteSupport.java,CAS_DELIMITER,src/main/java/parquet/proto/converters/ProtoBinaryConverter.java,CAS_DELIMITER",2,1,2,0.8453509366224365,1,111.5,8,30.27780671296296,18.0,16.72012037785384,18.0,None,FALSE,FALSE,
9af41250a6852df1a0705c23b3655f0e504f3b6f,Aniket Mokashi,amokashi@twitter.com,Fri Dec 20 16:26:44 2013 -0800,1387585604,turn on parquet 2 . 0 flags,9,12,"parquet-column/src/main/java/parquet/column/ParquetProperties.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest.java,CAS_DELIMITER",2,1,2,0.9983636725938131,18,365.5,35,0.5899016203703704,35.0,28.92780899817434,20.0,None,FALSE,FALSE,
dc7addc32651005e67e7d50b70247ec1127e3304,Aniket Mokashi,amokashi@twitter.com,Fri Dec 20 16:18:58 2013 -0800,1387585138,update with correct junit imports,9,19,"parquet-column/src/test/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/deltastrings/TestDeltaByteArray.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/codec/CodecConfigTest.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/ParquetLoader.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java,CAS_DELIMITER",8,3,6,2.886839296671271,17,158.5,111,26.333530092592593,34.0,27.92816912500061,13.666666666666666,Preventative,FALSE,FALSE,
3c91e46cb37600a78532233e888c7f27a42d9fea,julien,julien@twitter.com,Fri Dec 20 16:05:34 2013 -0800,1387584334,refactor dictionary page handling,7,7,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER",1,1,1,0.0,14,288.0,31,0.2089236111111111,336.0,200.62465772895172,84.0,None,FALSE,FALSE,
f2e607efe4683f5a111dafe602951206b6ce4726,julien,julien@twitter.com,Fri Dec 20 15:37:55 2013 -0800,1387582675,add unit test,64,0,"parquet-hadoop/src/test/java/parquet/hadoop/metadata/TestColumnChunkMetaData.java,CAS_DELIMITER",1,1,1,0.0,1,0.0,0,0.0,335.0,199.63119405902214,83.0,Feature Addition,FALSE,FALSE,
52ffcfe6eea65f54b4d06ee5a6680497f4905b2a,Lukas,lukas.nalezenec@gmail.com,Sat Dec 21 00:14:36 2013 +0100,1387581276,remove commented code,1,2,"src/main/java/parquet/proto/converters/ProtoMessageConverter.java,CAS_DELIMITER",1,1,1,0.0,1,186.0,2,49.32371527777778,17.0,15.961971940053731,17.0,None,FALSE,FALSE,
1f75813a03305c30da1d2f9326affc92e541443a,Lukas,lukas.nalezenec@gmail.com,Sat Dec 21 00:05:07 2013 +0100,1387580707,junit test for enum schema conversion,8,2,"src/main/java/parquet/proto/converters/ProtoEnumConverter.java,CAS_DELIMITER,src/test/java/parquet/proto/ProtoSchemaConverterTest.java,CAS_DELIMITER",2,1,2,0.8812908992306927,1,81.0,5,24.68747106481481,16.0,14.96224328896895,16.0,Preventative,FALSE,FALSE,
5051acc8d2ba103a7b544383f275c18ad913df7f,Aniket Mokashi,amokashi@twitter.com,Fri Dec 20 14:33:23 2013 -0800,1387578803,fix minor typo in Encoding reader,2,1,"parquet-column/src/main/java/parquet/column/Encoding.java,CAS_DELIMITER",1,1,1,0.0,15,305.0,33,0.0013425925925925925,32.0,25.932849857655242,17.0,Corrective,TRUE,FALSE,
c1b616132a7625ffb0b7b3230e0738b06b49a1a3,Aniket Mokashi,amokashi@twitter.com,Fri Dec 20 14:31:27 2013 -0800,1387578687,add delta length byte arrays and delta byte arrays encodings,916,56,"parquet-column/src/main/java/parquet/column/Encoding.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/ValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/boundedint/ZeroIntegerValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/deltalengthbytearray/DeltaLengthByteArrayValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/deltastrings/DeltaByteArrayReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/deltastrings/DeltaByteArrayWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/RandomStr.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/Utils.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/boundedint/TestBoundedColumns.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/deltalengthbytearray/TestDeltaLengthByteArray.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/deltalengthbytearray/benchmark/BenchmarkDeltaLengthByteArray.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/deltastrings/TestDeltaByteArray.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/deltastrings/benchmark/BenchmarkDeltaByteArray.java,CAS_DELIMITER",27,1,17,4.058277481640427,15,71.33333333333333,195,34.650885631001366,31.0,24.932928498660633,16.0,Feature Addition,FALSE,TRUE,
13942364d47d493fe10c66c17644d8284a84cbc7,Lukas,lukas.nalezenec@gmail.com,Fri Dec 20 22:41:52 2013 +0100,1387575712,CodeStyle,76,70,"src/main/java/parquet/proto/ProtoParquetOutputFormat.java,CAS_DELIMITER,src/main/java/parquet/proto/ProtoWriteSupport.java,CAS_DELIMITER,src/main/java/parquet/proto/ProtobufferRecordConverter.java,CAS_DELIMITER,src/test/java/parquet/proto/ProtoInputOutputFormatTest.java,CAS_DELIMITER,src/test/java/parquet/proto/ProtoSchemaConverterTest.java,CAS_DELIMITER,src/test/java/parquet/proto/TestUtils.java,CAS_DELIMITER",6,1,2,1.6775681081963252,1,125.33333333333333,14,10.742978395061728,15.0,13.964467323268396,15.0,None,FALSE,FALSE,
16b2f7362bfcf64eb23a28933098d32ce19cddaf,Lukas,lukas.nalezenec@gmail.com,Fri Dec 20 22:10:12 2013 +0100,1387573812,ProtoSchemaConverter Code Style,45,47,"src/test/java/parquet/proto/ProtoSchemaConverterTest.java,CAS_DELIMITER",1,1,1,0.0,1,101.0,1,0.40399305555555554,14.0,12.965253224222316,14.0,None,FALSE,FALSE,
dba65be43fd824266f947570ac310775187cef83,Lukas,lukas.nalezenec@gmail.com,Fri Dec 20 21:59:42 2013 +0100,1387573182,tests for Input and Output Formats,181,4,"src/main/java/parquet/proto/ProtobufferRecordConverter.java,CAS_DELIMITER,src/test/java/parquet/proto/ProtoInputOutputFormatTest.java,CAS_DELIMITER",2,1,2,0.3464612800308676,1,34.0,1,29.02480324074074,13.0,11.965493854458666,13.0,Preventative,FALSE,FALSE,
273728238acad7800a074b11ad3ef0beb3a4af4d,julien,julien@twitter.com,Fri Dec 20 11:04:43 2013 -0800,1387566283,optimize consecutive row groups scans,232,78,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER",1,1,1,0.0,14,134.0,30,1.8095833333333333,334.0,198.69528105699644,82.0,None,FALSE,TRUE,
978e396663297338a186bac466f5ee7319943c6e,Lukas,lukas.nalezenec@gmail.com,Fri Dec 20 12:28:27 2013 +0100,1387538907,ProtoSchemaConverterUnitTest,119,4,"src/main/java/parquet/proto/ProtoSchemaConverter.java,CAS_DELIMITER,src/test/java/parquet/proto/ProtoSchemaConverterTest.java,CAS_DELIMITER",2,1,2,0.6775807218599569,1,61.0,3,23.408778935185186,12.0,10.977510767977932,12.0,Preventative,FALSE,FALSE,
d617084a4552621c887b078447de3ab725e47f63,Tianshuo Deng,tdeng@twitter.com,Thu Dec 19 14:50:43 2013 -0800,1387493443,formatting and license header,46,91,"parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchMarkTest.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest.java,CAS_DELIMITER",8,1,3,1.9585228176385459,15,232.875,99,0.013518518518518517,211.0,177.46888961986951,75.0,None,FALSE,FALSE,
c81778533dd1c963f0cf7b8e704afd7c6259907e,Tianshuo Deng,tdeng@twitter.com,Thu Dec 19 14:31:15 2013 -0800,1387492275,delta int bin pack,1202,1,"parquet-column/src/main/java/parquet/column/Encoding.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingConfig.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/delta/DeltaBinaryPackingValuesWriterTest.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchMarkTest.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkIntegerOutputSize.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/delta/benchmark/BenchmarkReadingRandomIntegers.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/delta/benchmark/RandomWritingBenchmarkTest.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/delta/benchmark/SmallRangeWritingBenchmarkTest.java,CAS_DELIMITER,parquet-common/src/main/java/parquet/bytes/BytesUtils.java,CAS_DELIMITER,parquet-encoding/src/main/java/parquet/bytes/BytesInput.java,CAS_DELIMITER",12,3,6,2.953428177343126,15,96.33333333333333,138,32.61366994598765,210.0,176.47446030524722,27.666666666666668,None,FALSE,FALSE,
4a18684068266d8f8130e7f1ecf098fc039a672e,Aniket Mokashi,amokashi@twitter.com,Thu Dec 19 12:15:35 2013 -0800,1387484135,"changes for code review comments - enum as params , shortname for writerversion",50,31,"parquet-column/src/main/java/parquet/column/ParquetProperties.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/PerfTest.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestFiltered.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestMapredParquetInputFormat.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java,CAS_DELIMITER",16,5,8,3.1429622861741477,18,87.5,229,0.8015972222222222,30.0,23.994183567457096,7.8,None,FALSE,FALSE,
f2e7baae6817aae3440edef23f6379d7270f998f,Brock Noland,brock@cloudera.com,Thu Dec 19 11:02:40 2013 -0600,1387472560,"Resolves issue #251 by doing additional checks if Hive returns ""Unknown"" as a version .",42,3,"parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/parquet/hive/HiveBindingFactory.java,CAS_DELIMITER,parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/parquet/hive/TestHiveBindingFactory.java,CAS_DELIMITER",2,1,2,0.9709505944546686,1,114.5,4,22.001597222222223,4.0,3.779430273940844,4.0,Feature Addition,FALSE,FALSE,
67a7a9d242a4831e8e79a1606c0f7304a802ed6e,Aniket Mokashi,amokashi@twitter.com,Wed Dec 18 17:01:17 2013 -0800,1387414877,Add writer version flag to parquet and make initial changes for supported parquet 2 . 0 encodings,209,76,"parquet-column/src/main/java/parquet/column/ParquetProperties.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/PerfTest.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestFiltered.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestMapredParquetInputFormat.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java,CAS_DELIMITER",16,5,8,2.6780643737661753,18,79.1875,213,57.90176866319444,29.0,23.03704547607328,6.8,Feature Addition,FALSE,TRUE,
0888bdeacf422a6def35239abd69f0ad8b580abc,julien,julien@twitter.com,Wed Dec 18 15:38:55 2013 -0800,1387409935,adress comments,48,15,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java,CAS_DELIMITER",2,1,2,0.11759466565886476,14,128.0,36,1.0942708333333333,333.0,198.30372326217312,81.0,None,FALSE,FALSE,
392a801878836e50d992353910dceb802393a6f5,Tianshuo Deng,tdeng@twitter.com,Wed Dec 18 14:37:48 2013 -0800,1387406268,refactor,118,102,"parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ReadWriteErrorHandler.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java,CAS_DELIMITER",6,1,3,2.1906460150561946,14,245.66666666666666,43,68.77127700617284,209.0,175.88289991252572,70.0,None,FALSE,FALSE,
be43f8847748bf810142f1c9df500b085e87b21c,Tom White,tom@cloudera.com,Wed Dec 18 15:38:40 2013 +0000,1387381120,"Make setting requested projection and avro schema more independent , so that you only need to set the Avro schema if it is different to the writer's schema .",97,42,"parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java,CAS_DELIMITER",7,1,2,2.378366854597172,15,140.42857142857142,72,37.396717923280434,18.0,12.236395195015529,10.0,None,FALSE,FALSE,
a34507d54550a794e55cee68d39b483793954561,Tianshuo Deng,tdeng@twitter.com,Tue Dec 17 15:59:40 2013 -0800,1387324780,pretty print json for compatibility checker,1,1,"parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java,CAS_DELIMITER",1,1,1,0.0,1,96.0,6,70.22383101851852,208.0,175.26904978351232,69.0,None,FALSE,FALSE,
e83778a2588dfb14e1b225ad5c5cae817291a655,julien,julien@twitter.com,Tue Dec 17 13:23:10 2013 -0800,1387315390,make summary files read in parallel ; improve memory footprint of metadata,80,55,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/metadata/BlockMetaData.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java,CAS_DELIMITER",3,1,2,0.9097860396322267,14,82.0,37,107.52914351851852,332.0,197.67052909869446,80.0,None,FALSE,FALSE,
ea9fd2049243400cd8b75943b3fda56a95295367,Tom White,tom@cloudera.com,Tue Dec 17 10:54:28 2013 +0000,1387277668,Fix syntax error in test that Pig 0 . 12 complains about .,1,1,"parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java,CAS_DELIMITER",1,1,1,0.0,15,82.0,8,76.57424768518518,17.0,11.26501545192302,2.0,Corrective,TRUE,FALSE,
0a01dae77c560e3309766ddf1a0cae4600d4cc39,Tom White,tom@cloudera.com,Tue Dec 17 10:38:12 2013 +0000,1387276692,Use ContextUtil in tests to avoid dependency on parts of new MR API that are incompatible between MR1 and MR2 .,20,17,"parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java,CAS_DELIMITER,parquet-cascading/src/test/java/parquet/cascading/TestParquetTupleScheme.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/codec/CodecConfigTest.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetOutputFormat.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/PerfTest2.java,CAS_DELIMITER,parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java,CAS_DELIMITER",8,6,6,2.881373217320365,17,135.625,39,72.49563657407407,15.0,9.265307474368415,1.6666666666666667,Feature Addition,FALSE,FALSE,
0df24f071e70b19aad5e9c45f16a14b379313f5d,Tom White,tom@cloudera.com,Tue Dec 17 10:10:43 2013 +0000,1387275043,Rename ParquetInputFormat#addInputPathRecursively to avoid clash with non - static Hadoop 2 method of same name on FileInputFormat .,3,3,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER",1,1,1,0.0,14,165.0,28,98.48603009259259,16.0,10.265660257253998,7.0,Feature Addition,FALSE,FALSE,
e29c2dfa1b92c4daacf242f7003ca5e0bd583aad,Tianshuo Deng,tdeng@twitter.com,Mon Dec 16 10:50:00 2013 -0800,1387219800,fix when field index is greater than zero,42,7,"parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java,CAS_DELIMITER",4,1,3,1.4794202424194798,14,373.5,51,37.98638888888889,206.0,173.7657010654826,67.0,Corrective,TRUE,FALSE,
f2f8e42e95f4d1851f5bcc6dc82e03a159f8abd1,Alex Kozlov,alexvk@cloudera.com,Mon Dec 16 10:04:41 2013 -0800,1387217081,Fix to read a new avro schema . . .,166,60,"parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java,CAS_DELIMITER",5,1,2,1.2900547003240537,15,123.2,42,93.75173148148147,0.0,0.0,0.0,Corrective,TRUE,FALSE,
da4b7fd73b9c6179b2b521dfce40c96490cf4ec4,Tianshuo Deng,tdeng@twitter.com,Sun Dec 15 13:32:54 2013 -0800,1387143174,refactor,105,77,"parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java,CAS_DELIMITER",1,1,1,0.0,13,945.0,13,0.004050925925925926,205.0,173.12513880324875,66.0,None,FALSE,FALSE,
564f370e84e3ac920a5f5d2bb160293d64609e73,Tianshuo Deng,tdeng@twitter.com,Sun Dec 15 13:27:04 2013 -0800,1387142824,"add tests , fix bug",94,53,"parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java,CAS_DELIMITER",2,1,2,0.2761954276479391,13,533.5,23,0.006828703703703704,204.0,172.12677292290476,65.0,Corrective,TRUE,FALSE,
3d4513f0073de5026e75643a725f9a22bf2f677f,Tianshuo Deng,tdeng@twitter.com,Sun Dec 15 13:17:14 2013 -0800,1387142234,add checkEnum,64,17,"parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/DecodingSchemaMismatchException.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java,CAS_DELIMITER",3,1,2,1.0810560429075162,13,344.0,21,1.357530864197531,203.0,171.12950894294858,64.0,Feature Addition,FALSE,FALSE,
5bb9e8d9a5aa6dbb459e2d7243cfda40f095bb9e,julien,julien@twitter.com,Fri Dec 13 18:00:43 2013 -0800,1386986443,integrate parquet format 2 . 0,25,10,"parquet-column/src/main/java/parquet/column/Encoding.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/metadata/EncodingList.java,CAS_DELIMITER",2,2,2,0.18717625687320816,15,170.0,32,87.50061342592593,331.0,197.94725326237392,105.5,None,FALSE,FALSE,
8269a6f5bd54a80328d77b2c42443c709b373953,Tianshuo Deng,tdeng@twitter.com,Fri Dec 13 12:24:58 2013 -0800,1386966298,handle extra field in data,324,104,"parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ProtocolReadToWrite.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java,CAS_DELIMITER",3,1,2,0.638669275475185,12,277.6666666666667,23,50.8806712962963,202.0,170.9436963902601,63.0,None,FALSE,TRUE,
c590038425156af6a99f5424d8ccecd4526f071f,Lukas,lukas.nalezenec@gmail.com,Thu Dec 12 17:13:16 2013 +0100,1386864796,Obsolete test removed,0,251,"src/test/java/parquet/proto/BugHuntingTest.java,CAS_DELIMITER,src/test/java/parquet/proto/ProtoTest.java,CAS_DELIMITER,src/test/java/parquet/proto/TestSandbox.java,CAS_DELIMITER",3,1,1,1.345334642253432,1,83.66666666666667,4,33.23477237654321,11.0,10.197033223863462,11.0,Preventative,FALSE,FALSE,
051725362f48c5b6490a15ae5241967a81b523f9,Lukas,lukas.nalezenec@gmail.com,Thu Dec 12 17:09:03 2013 +0100,1386864543,TestUtils refactoring,11,5,"src/test/java/parquet/proto/ProtoTest.java,CAS_DELIMITER,src/test/java/parquet/proto/TestUtils.java,CAS_DELIMITER",2,1,1,0.5435644431995964,1,156.5,2,49.847766203703706,10.0,9.197109242672969,10.0,Preventative,FALSE,FALSE,
08a204ddb8cfda6b41309af911c5a4511fd426df,Lukas,lukas.nalezenec@gmail.com,Thu Dec 12 17:00:34 2013 +0100,1386864034,Depricated init override removed,5,4,"src/main/java/parquet/proto/ProtoReadSupport.java,CAS_DELIMITER",1,1,1,0.0,1,65.0,2,38.99619212962963,9.0,8.197246044598808,9.0,None,FALSE,FALSE,
e2d819c2ae6ab5573606e32f325c0743c6ec0c2f,Lukas,lukas.nalezenec@gmail.com,Thu Dec 12 16:59:33 2013 +0100,1386863973,Loading correct pbClass to ProtoSchemaConverter,6,3,"src/main/java/parquet/proto/ProtoWriteSupport.java,CAS_DELIMITER",1,1,1,0.0,1,186.0,4,32.76084490740741,8.0,7.197260505301236,8.0,None,FALSE,FALSE,
e36b2f0b4c724cdc610eb3b6879b795fe301f24c,Tianshuo Deng,tdeng@twitter.com,Wed Dec 11 17:51:34 2013 -0800,1386813094,implement error handler,134,2,"parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java,CAS_DELIMITER",2,1,2,0.9985955373409132,12,340.0,17,92.36808449074074,201.0,170.65418443920396,62.0,None,FALSE,TRUE,
760367b9fe669ca1a7e75c850a1f455ab1bbbc2c,Brock Noland,brock@cloudera.com,Sun Dec 8 16:23:05 2013 -0600,1386541385,Update reference to 0 . 10 in Hive012Binding javadoc and remove some trailing whitespace I noticed when while updating the javadoc .,5,5,"parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/src/main/java/parquet/hive/internal/Hive010Binding.java,CAS_DELIMITER,parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/src/main/java/parquet/hive/internal/Hive012Binding.java,CAS_DELIMITER",2,1,2,0.9709505944546686,1,56.0,4,11.224108796296296,3.0,2.8879364715257245,3.0,Non Functional,FALSE,FALSE,
ca01d15d79f8c6197e38c24fa6543f591f6efdc7,julien,julien@twitter.com,Fri Dec 6 12:45:55 2013 -0800,1386362755,make the cache use a SoftReference,5,3,"parquet-pig/src/main/java/parquet/pig/ParquetLoader.java,CAS_DELIMITER",1,1,1,0.0,14,159.0,34,0.04708333333333333,330.0,199.39533835508047,51.0,None,FALSE,FALSE,
a39ad4cdf231adaf7ce18c10bce406eea529fc16,julien,julien@twitter.com,Fri Dec 6 11:38:07 2013 -0800,1386358687,fix loader cache,10,10,"parquet-pig/src/main/java/parquet/pig/ParquetLoader.java,CAS_DELIMITER",1,1,1,0.0,14,159.0,33,43.120046296296294,329.0,198.41138296743517,50.0,Corrective,TRUE,FALSE,
92a47b2d9eb76ca3ee0756a934e807b8aa72b49a,Remy Pecqueur,r.pecqueur@criteo.com,Fri Dec 6 16:18:03 2013 +0100,1386343083,Fix hive map and array inspectors with null containers - This can happen if the data was not generated by Hive - Also add unit tests on these,414,4,"parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/AbstractParquetMapInspector.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/DeepParquetHiveMapInspector.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/StandardParquetHiveMapInspector.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestAbstractParquetMapInspector.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestDeepParquetHiveMapInspector.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestParquetHiveArrayInspector.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/serde/TestStandardParquetHiveMapInspector.java,CAS_DELIMITER",8,1,2,2.463055229247661,2,0.0,4,4.912442129629629,22.0,16.314910015440955,22.0,Corrective,TRUE,FALSE,
2e3a37018bf9b92224975fab5e2708d6c2c5328b,Tianshuo Deng,tdeng@twitter.com,Thu Dec 5 11:51:16 2013 -0800,1386273076,restore getCompression methods in ParquetOutputFormat for compatibility,9,2,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/codec/CodecConfig.java,CAS_DELIMITER",2,1,2,0.8453509366224365,16,104.5,22,0.009988425925925927,200.0,172.1892421134686,37.0,None,FALSE,FALSE,
f7b2cd78fc1b8f0c22edf1d5537fe37dc6c28d50,Tianshuo Deng,tdeng@twitter.com,Thu Dec 5 11:36:53 2013 -0800,1386272213,make CodecConfig a factory,110,115,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/codec/CodecConfig.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/codec/CompressionCodecNotSupportedException.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/codec/MapReduceCodecConfig.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/codec/MapredCodecConfig.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/codec/CodecConfigTest.java,CAS_DELIMITER",7,1,4,2.0943134546450515,16,51.57142857142857,30,0.5705456349206349,199.0,171.19332670075718,36.0,None,FALSE,FALSE,
716a030d9cd05b47dd0e78dadb5311ab0594adf6,Tianshuo Deng,tdeng@twitter.com,Wed Dec 4 16:42:54 2013 -0800,1386204174,remove lzo test and lzo dependency,40,29,"parquet-hadoop/src/main/java/parquet/hadoop/codec/HadoopCodecConfig.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/codec/HadoopCodecConfigTest.java,CAS_DELIMITER",2,1,2,0.9986359641585718,16,46.0,1,0.03553240740740741,197.0,169.51318423222435,34.0,Preventative,FALSE,FALSE,
407a52d538c31f65e3ba313c1d7be4fb5f9831b8,Tianshuo Deng,tdeng@twitter.com,Wed Dec 4 15:00:34 2013 -0800,1386198034,fix missing codec,266,93,"parquet-hadoop/src/main/java/parquet/hadoop/CodecFactory.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/codec/CompressionCodecNotSupportedException.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/codec/HadoopCodecConfig.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/codec/MapReduceCodecConfig.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/codec/MapredCodecConfig.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/metadata/CompressionCodecName.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/codec/MapReduceCodecConfigTest.java,CAS_DELIMITER",9,1,5,2.830366135686691,16,36.666666666666664,33,41.26462962962963,196.0,168.54177502459183,33.0,Corrective,TRUE,FALSE,
3b829a21759d3a2e47f95a2cb880e4abfc4ba6fe,Tianshuo Deng,tdeng@twitter.com,Tue Dec 3 22:50:46 2013 -0800,1386139846,refactor get codec logic to remove duplication in DeprecatedParquetOutputFormat,84,47,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java,CAS_DELIMITER",2,1,2,0.8877250163956498,16,143.5,22,9.377077546296297,195.0,167.81136048212872,32.0,None,FALSE,FALSE,
7dfd436245c4ff9ced2bf9ab07cb0fe4289734a0,Tianshuo Deng,tdeng@twitter.com,Tue Dec 3 16:28:56 2013 -0800,1386116936,format,1,1,"parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java,CAS_DELIMITER",1,1,1,0.0,15,159.0,10,0.044224537037037034,194.0,166.91701398866437,61.0,None,FALSE,FALSE,
e1ce0632157706beed11f3ecf12590cd33bc711a,Tianshuo Deng,tdeng@twitter.com,Tue Dec 3 14:35:54 2013 -0800,1386110154,check if pig is loaded when writing pig metadata,16,1,"parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java,CAS_DELIMITER",1,1,1,0.0,8,129.0,8,0.6766319444444444,192.0,164.94800706235887,59.0,None,FALSE,FALSE,
b297c73c1082728ad9626d17ce0f7abe6abaa36b,julien,julien@twitter.com,Tue Dec 3 11:54:55 2013 -0800,1386100495,optimize chunk scan ; fix compressed size,41,7,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER",2,1,1,0.4820661480830931,14,115.0,53,88.43392361111111,328.0,198.4269618104107,78.0,Corrective,TRUE,FALSE,
4d13df5a42a3212914e2da6c9e479607aeff5ddc,Tianshuo Deng,tdeng@twitter.com,Wed Nov 27 10:23:28 2013 -0800,1385576608,encapuslate getFooter into a separate method,9,5,"parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java,CAS_DELIMITER",1,1,1,0.0,14,263.0,10,0.8008449074074074,190.0,165.38099496684274,8.0,None,FALSE,FALSE,
60c651262e87540bd06f884b25c66ede491c34b7,Brock Noland,brock@cloudera.com,Wed Nov 27 11:00:22 2013 -0600,1385571622,"Updates Hive 0 . 12 compatability patch by adressing all comments from Julien's review plus a few additional cleanups , specifically : * If hive is version 0 . 12 or newer return 0 . 12 binding * Adds javadoc and inheritDoc statements where appropiate * Add's link to Hive * Binding implementations describing where code came from * Renames Deprecated { Input , Output } Format to Mapred { Input , Output } Format * Creates shell classes Deprecated { Input , Output } Format inheriting from Mapred { Input , Output } Format * Moves TestMapred { Input , Output } Format to the JUnit 4 API * Replaces Apache licenses in files touched with the version capped at a shorter line length * Add's debug log statements to the binding layers to log items of interest",750,602,"parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/src/main/java/parquet/hive/internal/Hive010Binding.java,CAS_DELIMITER,parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/src/main/java/parquet/hive/internal/Hive012Binding.java,CAS_DELIMITER,parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/parquet/hive/HiveBindingFactory.java,CAS_DELIMITER,parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/parquet/hive/TestHiveBindingFactory.java,CAS_DELIMITER,parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/HiveBinding.java,CAS_DELIMITER,parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/internal/AbstractHiveBinding.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetInputFormat.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/MapredParquetOutputFormat.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/read/DataWritableReadSupport.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestMapredParquetInputFormat.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestMapredParquetOuputFormat.java,CAS_DELIMITER",13,1,9,2.7993361136820525,1,29.384615384615383,9,0.6202644230769233,2.0,1.9760421823676992,2.0,Feature Addition,FALSE,FALSE,
f18bc49046d51e1700d419e401ad49093322771d,Tianshuo Deng,tdeng@twitter.com,Tue Nov 26 15:10:15 2013 -0800,1385507415,"enable globing files for parquetTupleScheme , refactor unit tests and remove binary test fixture",150,58,"parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java,CAS_DELIMITER,parquet-cascading/src/test/java/parquet/cascading/TestParquetTupleScheme.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java,CAS_DELIMITER",3,2,3,0.4221086297342186,14,158.33333333333334,15,124.51444444444445,189.0,164.6994028430081,18.5,Corrective,TRUE,FALSE,
d2ccc72cb739ada1ce3d5ae9af7032952908352c,Brock Noland,brock@cloudera.com,Tue Nov 26 13:30:13 2013 -0600,1385494213,"Breaks parquet - hive up into several submodules , creating infrastructure to handle various versions of Hive going forward . * parquet - hive - storage - handler - this is almost all the previous code * parquet - hive - binding - contains the various binding modules for specific hive versions * parquet - hive - binding - interface - the interface the storage handler compiles to * parquet - hive - binding - factory - factory which can depend on interface , 0 . 10 , and 0 . 12 * parquet - hive - 0 . 10 - binding - binding layer for 0 . 10 ( and 0 . 11 ) * parquet - hive - 0 . 12 - binding - binding layer for 0 . 12 ( and 0 . 13 )",462,80,"parquet-hive/parquet-hive-binding/parquet-hive-0.10-binding/src/main/java/parquet/hive/internal/Hive010Binding.java,CAS_DELIMITER,parquet-hive/parquet-hive-binding/parquet-hive-0.12-binding/src/main/java/parquet/hive/internal/Hive012Binding.java,CAS_DELIMITER,parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/main/java/parquet/hive/HiveBindingFactory.java,CAS_DELIMITER,parquet-hive/parquet-hive-binding/parquet-hive-binding-factory/src/test/java/parquet/hive/TestHiveBindingFactory.java,CAS_DELIMITER,parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/HiveBinding.java,CAS_DELIMITER,parquet-hive/parquet-hive-binding/parquet-hive-binding-interface/src/main/java/parquet/hive/internal/AbstractHiveBinding.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/DataWritableGroupConverter.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/DataWritableRecordConverter.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/ETypeConverter.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/HiveGroupConverter.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/convert/HiveSchemaConverter.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/read/DataWritableReadSupport.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/AbstractParquetMapInspector.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/DeepParquetHiveMapInspector.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/StandardParquetHiveMapInspector.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetByteInspector.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetPrimitiveInspectorFactory.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetShortInspector.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/serde/primitive/ParquetStringInspector.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/writable/BigDecimalWritable.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/writable/BinaryWritable.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/write/DataWritableWriteSupport.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/main/java/parquet/hive/write/DataWritableWriter.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestHiveSchemaConverter.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/TestParquetSerDe.java,CAS_DELIMITER,parquet-hive/parquet-hive-storage-handler/src/test/java/parquet/hive/UtilitiesTestMethods.java,CAS_DELIMITER",34,1,14,2.678343535573248,1,0.0,0,0.0,1.0,0.9808466184305109,1.0,None,FALSE,FALSE,
493bb9fd70a008e7c083509d93a419c99fd7bc26,dave2718,hardcastle.dave@gmail.com,Fri Nov 22 02:31:12 2013 -0800,1385116272,Changing read and write methods in ParquetInputSplit so that they can deal with large schemas ( avoiding use of writeUTF and readUTF which are limited to 65536 characters ) .,5,4,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java,CAS_DELIMITER",1,1,1,0.0,10,130.0,7,125.16949074074074,0.0,0.0,0.0,None,FALSE,FALSE,
f4ad9dfc394f1336e68444944e41772d6d435744,Aniket Mokashi,amokashi@twitter.com,Wed Nov 20 14:50:10 2013 -0800,1384987810,refactor encoded values changes and test that resetDictionary works,73,57,"parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java,CAS_DELIMITER",2,1,2,0.39124356362925566,13,526.0,59,0.05525462962962963,28.0,23.560656463592874,13.0,Preventative,FALSE,FALSE,
6b5d2d1399c62c5d58436befd72a09491e29904b,Tianshuo Deng,tdeng@twitter.com,Wed Nov 20 13:30:36 2013 -0800,1384983036,fix bug : set raw data size to 0 after reset,23,0,"parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java,CAS_DELIMITER",2,1,2,0.2580186686648155,13,514.5,57,19.492644675925924,188.0,166.13624565634962,73.0,Corrective,TRUE,FALSE,
0334948eadddfac9891277d673117e6b4bec0d7e,Brock Noland,brock@cloudera.com,Tue Nov 19 10:26:37 2013 -0600,1384878397,parquet - hive should ship and uber jar * Creates parquet - hive - bundle which is an uber jar of dependencies required for Hive . * Removes runtime dependency on commons - lang * Marks Hadoop and Hive dependencies as optional so they don't have to be excluded by dependees,7,10,"parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java,CAS_DELIMITER",3,1,3,1.289608558348151,15,57.0,25,73.6862075617284,0.0,0.0,0.0,Feature Addition,FALSE,FALSE,
8af5a22fd64699fe6c7063870a82704c81dd8bff,Nong Li,nong@cloudera.com,Wed Nov 13 17:32:55 2013 -0800,1384392775,Fix Binary . equals ( ) .,2,1,"parquet-column/src/main/java/parquet/io/api/Binary.java,CAS_DELIMITER",1,1,1,0.0,15,96.0,10,35.3362037037037,6.0,4.737403218746115,2.0,Corrective,TRUE,FALSE,
402e96dfb58077cdf3e6bf2e496bdca6bad11743,Lukas,lukas.nalezenec@gmail.com,Sat Nov 9 22:43:56 2013 +0100,1384033436,Wrong merge,1,0,"src/main/java/parquet/proto/ProtoWriteSupport.java,CAS_DELIMITER",1,1,1,0.0,1,185.0,3,6.254826388888889,7.0,6.829589865521511,7.0,Corrective,TRUE,FALSE,
59bd08b9a98483dec17ca10f9dd3d9eaae1ce774,Wesley Peck,wesley.peck@arrisi.com,Wed Nov 6 14:19:34 2013 -0500,1383765574,One of the constructors in ParquetWriter ignores the enable dictionary and validating flags .,1,1,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java,CAS_DELIMITER",1,1,1,0.0,13,150.0,13,57.86833333333333,3.0,2.7440540036001333,2.0,None,FALSE,FALSE,
0d47734c372a5322e17feea56bf426226b6bebb5,Remy Pecqueur,r.pecqueur@criteo.com,Mon Nov 4 14:25:13 2013 +0100,1383571513,Add test on DeprecatedParquetInputFormat . getSplit ( ),131,16,"parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java,CAS_DELIMITER",3,1,2,1.2979439915485704,15,290.3333333333333,43,31.064155092592596,21.0,16.48056973110241,21.0,Feature Addition,FALSE,FALSE,
1bec97fa188a450a52289a4836b71edfa607e017,Lukas,lukas.nalezenec@gmail.com,Sun Nov 3 17:06:03 2013 +0100,1383494763,Projections in read support,4,9,"src/main/java/parquet/proto/ProtoReadSupport.java,CAS_DELIMITER",1,1,1,0.0,1,70.0,1,10.84568287037037,6.0,5.945349571795631,6.0,None,FALSE,FALSE,
2e78704e82f62822f1183131340cbd59c7b7831f,Lukas,lukas.nalezenec@gmail.com,Sun Nov 3 16:36:59 2013 +0100,1383493019,Code cleanup,4,15,"src/main/java/parquet/proto/ProtoWriteSupport.java,CAS_DELIMITER",1,1,1,0.0,1,196.0,2,0.6550810185185185,4.0,3.9456484371474865,4.0,Perfective,FALSE,FALSE,
a7de264ff2fa559ca5d5e6b8a33e3a5d2590952f,Lukas,lukas.nalezenec@gmail.com,Sun Nov 3 00:53:40 2013 +0100,1383436420,Specification of written protobuffer class in output format,33,5,"src/main/java/parquet/proto/ProtoParquetOutputFormat.java,CAS_DELIMITER,src/main/java/parquet/proto/ProtoWriteSupport.java,CAS_DELIMITER",2,1,1,0.9677884628267679,1,111.0,2,10.170416666666666,3.0,2.952646854551129,3.0,None,FALSE,FALSE,
198f5540fdbca63bbd73943a30be79dd9761af4a,Tianshuo Deng,tdeng@twitter.com,Fri Nov 1 15:32:44 2013 -0700,1383345164,revert revert . . use rawDataByteSize as buffered size in DictionaryValuesWriter,4,3,"parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER",1,1,1,0.0,13,606.0,36,0.015590277777777778,136.0,120.92893931672943,22.0,None,FALSE,FALSE,
7427a895ef33a8b8703e8c7af9a17ffb15fe2bb2,Tianshuo Deng,tdeng@twitter.com,Fri Nov 1 15:10:17 2013 -0700,1383343817,"revert fixing page cutting , fix bug , raw data size should be long",4,5,"parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER",1,1,1,0.0,13,607.0,35,0.04363425925925926,135.0,119.93355025207907,21.0,Corrective,TRUE,FALSE,
edfd7d96f939f5602d9338575d6fa5ad243b8b2e,Tianshuo Deng,tdeng@twitter.com,Fri Nov 1 14:04:57 2013 -0700,1383339897,return raw data size as bufferSize in dictionaryValuesWriter,4,3,"parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER",1,1,1,0.0,13,605.0,33,0.010972222222222222,133.0,117.94684179566426,19.0,None,FALSE,FALSE,
492da11c61dfc6d58a8b093affa2b8b6e7054df1,Tianshuo Deng,tdeng@twitter.com,Fri Nov 1 13:49:09 2013 -0700,1383338949,remove hash lookup and unused comments,30,35,"parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER",1,1,1,0.0,13,610.0,32,0.98125,132.0,116.94999765002167,18.0,None,FALSE,FALSE,
d33aa40c7e9e9f577bfe05f0a15eb9687ad22cba,Tianshuo Deng,tdeng@twitter.com,Thu Oct 31 14:13:23 2013 -0700,1383254003,"bug fix : separate fallBackDictionaryEncodedData to a method , will always be called when fallbacking to plainEncoding",29,10,"parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER",1,1,1,0.0,13,594.0,30,0.016481481481481482,130.0,115.23076309733466,16.0,Corrective,TRUE,FALSE,
bee675509d8fc7f927d410b4815e95f457ee1fa2,Tianshuo Deng,tdeng@twitter.com,Thu Oct 31 13:49:39 2013 -0700,1383252579,improve binary fallback,43,3,"parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java,CAS_DELIMITER",2,1,2,0.978070970973496,13,488.0,48,0.07241898148148149,129.0,114.23539103993728,15.0,None,FALSE,FALSE,
c9b768f4d2a942dd29cecfd3871549794d337b25,Tianshuo Deng,tdeng@twitter.com,Thu Oct 31 12:05:22 2013 -0700,1383246322,improve long fallback,42,3,"parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java,CAS_DELIMITER",2,1,2,0.9910760598382222,13,468.5,46,0.054496527777777776,128.0,113.25553201137244,14.0,None,FALSE,FALSE,
245d43ea7eb45f11d0c3822eb3704eccf429dc04,Tianshuo Deng,tdeng@twitter.com,Thu Oct 31 11:43:09 2013 -0700,1383244989,"use primitve array for int , float , double , get rid of auto boxing , unboxing",21,20,"parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER",1,1,1,0.0,13,566.0,27,0.07813657407407408,127.0,112.25978152185246,13.0,None,FALSE,FALSE,
3c99aa31c350d4b87e31c5d1dfd740f6938b5b47,Tianshuo Deng,tdeng@twitter.com,Thu Oct 31 09:50:38 2013 -0700,1383238238,improve fallback for double,44,11,"parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java,CAS_DELIMITER",2,1,2,0.9456603046006402,13,451.5,43,1.7774652777777777,126.0,111.2810940316092,12.0,None,FALSE,FALSE,
d942b454af8bf930394744311a523a76802cb7c5,Tianshuo Deng,tdeng@twitter.com,Wed Oct 30 16:07:36 2013 -0700,1383174456,format,1,1,"parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java,CAS_DELIMITER",1,1,1,0.0,9,84.0,10,0.0008217592592592593,125.0,110.48082480528863,11.0,None,FALSE,FALSE,
1afdf14faa875b268aca616e323957040a9695f8,Tianshuo Deng,tdeng@twitter.com,Wed Oct 30 16:06:25 2013 -0700,1383174385,"minor fix , the length used in RLEValuesReader",1,1,"parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java,CAS_DELIMITER",1,1,1,0.0,9,84.0,9,14.992453703703704,124.0,109.48104528824464,10.0,Corrective,TRUE,FALSE,
4d55b59776ff9be7a97c8bff605204f9c625747a,Tianshuo Deng,tdeng@twitter.com,Tue Oct 29 15:11:05 2013 -0700,1383084665,improve fallback for float,45,3,"parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java,CAS_DELIMITER",2,1,2,0.9798687566511527,13,430.5,41,0.04399884259259259,123.0,108.75751512082714,9.0,None,FALSE,FALSE,
be6a4aeed809a0a78cbf0c156ace3ed8c1a12af9,Tianshuo Deng,tdeng@twitter.com,Tue Oct 29 14:56:51 2013 -0700,1383083811,fix bug : reverse dictionary lookup for fallbacking to plain encoding,14,2,"parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER",1,1,1,0.0,13,526.0,24,0.04026620370370371,122.0,107.76012634631356,8.0,Corrective,TRUE,FALSE,
11f30faffbc095068d23e8173fb3387e99b1a341,Tianshuo Deng,tdeng@twitter.com,Tue Oct 29 13:58:52 2013 -0700,1383080332,"fix bug , add rawDataByteSize for dictionaryValuesWriter to decide if fall back to Plain encoding or not",18,1,"parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER",1,1,1,0.0,13,509.0,23,0.027962962962962964,121.0,106.77065484858383,7.0,Corrective,TRUE,FALSE,
81a1af0c47219598a6ebf4c86a2e0d43d028706d,Tianshuo Deng,tdeng@twitter.com,Tue Oct 29 13:18:36 2013 -0700,1383077916,improve fallback for IntDictionaryWriter,42,2,"parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java,CAS_DELIMITER",2,1,2,0.7732266742876346,13,396.0,37,31.60632523148148,120.0,105.77789098947603,6.0,None,FALSE,FALSE,
e337bd2f9c54b58245e3e050372a32c555b2417f,Lukas,lukas.nalezenec@gmail.com,Sun Oct 27 21:24:46 2013 +0100,1382905486,Protobuf conversion over Java types,12,11,"src/main/java/parquet/proto/ProtoSchemaConverter.java,CAS_DELIMITER",1,1,1,0.0,1,131.0,1,4.025347222222222,1.0,0.9890919492318825,1.0,None,FALSE,FALSE,
3b63d13250862534a1ae6532750e3a343987ce36,Arash Aghevli,aaghevli@twitter.com,Thu Oct 24 09:42:42 2013 -0700,1382632962,fix comment,2,2,"parquet-pig/src/main/java/parquet/pig/ParquetLoader.java,CAS_DELIMITER",1,1,1,0.0,14,159.0,31,0.5471064814814814,4.0,3.9935639145543806,4.0,Corrective,TRUE,FALSE,
8edc1029818ab9b5e3b712eae3546e54eda6a1a6,Tianshuo Deng,tdeng@twitter.com,Thu Oct 24 08:36:19 2013 -0700,1382628979,throw ParquetEncodingException,2,2,"parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java,CAS_DELIMITER",1,1,1,0.0,1,39.0,7,0.8903935185185186,119.0,106.12534174499513,57.0,None,FALSE,FALSE,
93780e026d08c7541ca7af703aebc9d26e52e68f,Arash Aghevli,aaghevli@twitter.com,Wed Oct 23 20:33:18 2013 -0700,1382585598,use a new string in order to enforce weak reference on the key,2,2,"parquet-pig/src/main/java/parquet/pig/ParquetLoader.java,CAS_DELIMITER",1,1,1,0.0,14,159.0,29,0.001724537037037037,2.0,1.999558220042441,2.0,Feature Addition,FALSE,FALSE,
5f29f4374ee0b4925b7fdc36945a9a104389e964,Arash Aghevli,aaghevli@twitter.com,Wed Oct 23 20:30:49 2013 -0700,1382585449,use a new string in order to enforce weak reference on the key,3,1,"parquet-pig/src/main/java/parquet/pig/ParquetLoader.java,CAS_DELIMITER",1,1,1,0.0,14,157.0,28,0.15787037037037038,1.0,0.9995676654313647,1.0,Feature Addition,FALSE,FALSE,
ab4cb69e09b109f82e92de8ed21925d75751eef0,Arash Aghevli,aaghevli@twitter.com,Wed Oct 23 16:43:29 2013 -0700,1382571809,Make the ParquetLoader . inputFormatCache HashMap a WeakHashMap in order to free memory for long running processes that do not leverage caching,2,2,"parquet-pig/src/main/java/parquet/pig/ParquetLoader.java,CAS_DELIMITER",1,1,1,0.0,14,157.0,27,33.32465277777778,0.0,0.0,0.0,None,FALSE,FALSE,
5c46f055890eb86652e9b573c686190769599c29,Lukas,lukas.nalezenec@gmail.com,Wed Oct 23 21:48:16 2013 +0200,1382557696,initial commit,1475,0,"src/main/java/parquet/proto/ProtoParquetInputFormat.java,CAS_DELIMITER,src/main/java/parquet/proto/ProtoParquetOutputFormat.java,CAS_DELIMITER,src/main/java/parquet/proto/ProtoParquetReader.java,CAS_DELIMITER,src/main/java/parquet/proto/ProtoParquetWriter.java,CAS_DELIMITER,src/main/java/parquet/proto/ProtoReadSupport.java,CAS_DELIMITER,src/main/java/parquet/proto/ProtoRecordMaterializer.java,CAS_DELIMITER,src/main/java/parquet/proto/ProtoSchemaConverter.java,CAS_DELIMITER,src/main/java/parquet/proto/ProtoWriteSupport.java,CAS_DELIMITER,src/main/java/parquet/proto/ProtobufferRecordConverter.java,CAS_DELIMITER,src/main/java/parquet/proto/converters/ParentValueContainer.java,CAS_DELIMITER,src/main/java/parquet/proto/converters/ProtoArrayConverter.java,CAS_DELIMITER,src/main/java/parquet/proto/converters/ProtoBinaryConverter.java,CAS_DELIMITER,src/main/java/parquet/proto/converters/ProtoBooleanConverter.java,CAS_DELIMITER,src/main/java/parquet/proto/converters/ProtoDoubleConverter.java,CAS_DELIMITER,src/main/java/parquet/proto/converters/ProtoEnumConverter.java,CAS_DELIMITER,src/main/java/parquet/proto/converters/ProtoFloatConverter.java,CAS_DELIMITER,src/main/java/parquet/proto/converters/ProtoIntConverter.java,CAS_DELIMITER,src/main/java/parquet/proto/converters/ProtoLongConverter.java,CAS_DELIMITER,src/main/java/parquet/proto/converters/ProtoMessageConverter.java,CAS_DELIMITER,src/main/java/parquet/proto/converters/ProtobufStringConverter.java,CAS_DELIMITER,src/test/java/parquet/proto/BugHuntingTest.java,CAS_DELIMITER,src/test/java/parquet/proto/ProtoTest.java,CAS_DELIMITER,src/test/java/parquet/proto/TestSandbox.java,CAS_DELIMITER,src/test/java/parquet/proto/TestUtils.java,CAS_DELIMITER",24,1,3,4.093493058261324,1,0.0,0,0.0,0.0,0.0,0.0,Feature Addition,FALSE,FALSE,
005bc68b000ad37cff5c0f0400d4ef18fe8af80f,Tianshuo Deng,tdeng@twitter.com,Wed Oct 23 11:14:09 2013 -0700,1382552049,add null check for EnumWriteProtocol,7,2,"parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java,CAS_DELIMITER",1,1,1,0.0,1,34.0,6,224.7080439814815,118.0,105.35725706443652,56.0,Feature Addition,FALSE,FALSE,
943591829c87898788558ec323a38c6946b7eb6e,Remy Pecqueur,r.pecqueur@criteo.com,Wed Oct 23 18:59:56 2013 +0200,1382547596,Fix requested schema when recreating splits in hive,1,1,"parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java,CAS_DELIMITER",1,1,1,0.0,10,366.0,23,64.31052083333333,20.0,15.922019126325885,20.0,Corrective,TRUE,FALSE,
5601394e85387a69f171884792ad683a39c7eec1,julien,julien@twitter.com,Fri Oct 18 15:18:50 2013 -0700,1382134730,make static field final,1,1,"parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java,CAS_DELIMITER",1,1,1,0.0,14,24.0,8,0.1958101851851852,324.0,211.11744348302352,49.0,None,FALSE,FALSE,
0a76cc29b703fc95949736910a5a63ce9c1c0814,julien,julien@twitter.com,Fri Oct 18 10:36:52 2013 -0700,1382117812,Fix #198 : simplify TupleWriteSupport constructor,32,18,"parquet-pig/src/main/java/parquet/pig/ParquetStorer.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java,CAS_DELIMITER",5,2,3,1.712935039619369,14,98.0,36,137.4076574074074,323.0,210.1936861761008,48.5,Corrective,TRUE,FALSE,
22cf7fe9d8ef12e33b3fa43fae86fc7e8680271f,Remy Pecqueur,r.pecqueur@criteo.com,Thu Oct 17 18:00:03 2013 +0200,1382025603,Inspect keys only for a few types in parquet hive maps,173,53,"parquet-hive/src/main/java/parquet/hive/serde/AbstractParquetMapInspector.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/DeepParquetHiveMapInspector.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/StandardParquetHiveMapInspector.java,CAS_DELIMITER",4,1,1,1.7231579526669374,15,4.0,10,1.536791087962963,19.0,15.139692431637062,19.0,None,FALSE,FALSE,
256a3a1eb328e6f02eebc82eb37d91ad69e475d5,Nong Li,nong@cloudera.com,Tue Oct 15 16:17:17 2013 -0700,1381879037,"Fix issue 193 : RLE decoder reading past the end of the stream . If literal groups are not padded to groups of 8 , the decoder reads past the end .",15,19,"parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java,CAS_DELIMITER",5,1,3,1.6801597132270814,9,130.6,38,68.82638657407406,5.0,4.058226860810153,1.0,Corrective,TRUE,TRUE,
73c86295a70e6ce98ed22ab213aafb105365e475,Frank Austin Nothaft,fnothaft@berkeley.edu,Mon Oct 14 15:43:22 2013 -0700,1381790602,Misunderstood previous comment . Fixed binary predicate .,2,1,"parquet-column/src/main/java/parquet/filter/ColumnPredicates.java,CAS_DELIMITER",1,1,1,0.0,14,186.0,11,0.28447916666666667,12.0,11.45957929226177,12.0,Corrective,TRUE,FALSE,
10f266aef9faf78fb8cd07f488674c67f3bbf3a3,Frank Austin Nothaft,fnothaft@berkeley.edu,Mon Oct 14 08:53:43 2013 -0700,1381766023,Cleaning method signature for binary case .,2,2,"parquet-column/src/main/java/parquet/filter/ColumnPredicates.java,CAS_DELIMITER",1,1,1,0.0,14,186.0,10,2.990451388888889,11.0,10.468119589517567,11.0,Perfective,FALSE,FALSE,
422dfe05d5583318cc5116a688fc7e5676cafd89,Frank Austin Nothaft,fnothaft@berkeley.edu,Fri Oct 11 09:07:28 2013 -0700,1381507648,"Updated files to add applyFunctionToBinary , and add specific interfaces for primitive types .",46,13,"parquet-column/src/main/java/parquet/filter/ColumnPredicates.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestFiltered.java,CAS_DELIMITER",2,1,2,0.41868431052685634,14,228.5,19,14.32521412037037,10.0,9.550411424818082,10.0,Feature Addition,FALSE,FALSE,
4bdaec06595f35d4b7bb4c1baf35ca0d16b25619,Remy Pecqueur,r.pecqueur@criteo.com,Thu Oct 10 16:57:37 2013 +0200,1381417057,Fix #177 : Inspect key when accessing maps,19,4,"parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java,CAS_DELIMITER",1,1,1,0.0,15,154.0,7,7.934456018518518,17.0,13.379141854107937,17.0,Corrective,TRUE,FALSE,
c5f68c51cb72503e7f9c483e009d94ed66aac335,Remy Pecqueur,r.pecqueur@criteo.com,Thu Oct 10 15:48:11 2013 +0200,1381412891,Extract primitive inspectors and instantiate them only once,248,126,"parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetByteInspector.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetPrimitiveInspectorFactory.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetShortInspector.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/primitive/ParquetStringInspector.java,CAS_DELIMITER",5,1,2,2.1621835141121197,15,27.6,8,1.5772476851851853,16.0,12.380560308321561,16.0,None,FALSE,TRUE,
20201427905781726ebf946a0840b19cddf88bbb,julien,julien@twitter.com,Wed Oct 9 10:28:47 2013 -0700,1381339727,refactor serde to remove some unecessary boxing and include dictionary awareness,161,223,"parquet-column/src/main/java/parquet/io/api/Binary.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/DataWritableGroupConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java,CAS_DELIMITER",10,2,6,1.96920832177303,15,143.0,68,79.0991574074074,322.0,212.73757677536494,65.0,None,FALSE,TRUE,"[""d9e5f0bc2d7482062db72bddcb3eeefda05b2143""]"
5cad37ba0be6dcbc6ede9ee31007022a9e0ff362,Tianshuo Deng,tdeng@twitter.com,Tue Oct 8 10:17:51 2013 -0700,1381252671,"remove unused command from CompatibilityRunner , add comment for rules used in compatibility checking , add license header",120,78,"parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java,CAS_DELIMITER",3,1,2,1.4786939212876096,1,130.33333333333334,34,0.8610802469135802,116.0,107.39067605497591,54.0,Feature Addition,FALSE,FALSE,
dc425e481b3a833d83317258b7d00f04a9afe3b0,Tianshuo Deng,tdeng@twitter.com,Mon Oct 7 14:27:11 2013 -0700,1381181231,show field name when they are not compatible,1,1,"parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java,CAS_DELIMITER",1,1,1,0.0,1,199.0,18,0.04689814814814815,115.0,106.61689770495494,53.0,None,FALSE,FALSE,
714335de4ba559645408adf692a6a90aceb8adae,Tianshuo Deng,tdeng@twitter.com,Mon Oct 7 13:06:51 2013 -0700,1381176411,compare json,57,0,"parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java,CAS_DELIMITER",2,1,2,0.9890934397021431,1,77.0,12,4.440607638888888,113.0,104.63201788609224,51.0,None,FALSE,FALSE,
0a36e35cf6c52a9e79fdfbbb8584a8adc3a17b6c,Wesley Peck,wesley.peck@arrisi.com,Mon Oct 7 12:17:20 2013 -0500,1381166240,Fixes #189 : NPE in DictionaryValuesWriter .,1,1,"parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER",1,1,1,0.0,13,503.0,21,3.9663194444444443,2.0,1.9678166262254795,0.0,Corrective,TRUE,FALSE,
cfd63fd61cb8b05a61b65fbd8021f19d6d19a493,Frank Austin Nothaft,fnothaft@berkeley.edu,Thu Oct 3 18:23:50 2013 -0700,1380849830,Fixed issue with test case that was causing runtime error . Was trying to call getInteger on long . . .,6,6,"parquet-column/src/test/java/parquet/io/TestFiltered.java,CAS_DELIMITER",1,1,1,0.0,14,265.0,8,4.321238425925926,5.0,4.866441410343619,5.0,Corrective,TRUE,FALSE,
989e9dc13556213acf92758caaa7093679b4d52d,David Z. Chen,david.z.chen@outlook.com,Thu Oct 3 11:57:59 2013 -0700,1380826679,Plumb OriginalType through to ConvertedType in file in ParquetMetadataConverter .,52,2,"parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER",1,1,1,0.0,15,62.0,25,8.325925925925926,30.0,28.92671033010854,4.0,None,FALSE,TRUE,
b3b0bbb67490d9a2a15c5307fec60c831e94de60,julien,julien@twitter.com,Thu Oct 3 11:05:50 2013 -0700,1380823550,fix indent,2,1,"parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER",1,1,1,0.0,13,502.0,20,0.012453703703703703,321.0,214.14098983876738,127.0,Corrective,TRUE,FALSE,
7247538c6bb70f608eb408e02f196211f65bef5b,Tianshuo Deng,tdeng@twitter.com,Thu Oct 3 10:55:16 2013 -0700,1380822916,compatibility runner print more detailed info,9,3,"parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java,CAS_DELIMITER",2,1,1,0.9182958340544896,1,132.5,18,0.7511284722222222,112.0,104.73191213140393,50.0,None,FALSE,FALSE,
ff4d13a771565d307a803098fe0c7e9a5b91e820,julien,julien@twitter.com,Thu Oct 3 10:47:54 2013 -0700,1380822474,add null check,1,1,"parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER",1,1,1,0.0,13,502.0,19,14.982118055555556,320.0,213.14602447304972,126.0,Feature Addition,FALSE,FALSE,
fdb07254ca5ab8698653a7adb9ea2a74e2b09c06,Tianshuo Deng,tdeng@twitter.com,Wed Oct 2 18:09:29 2013 -0700,1380762569,add tests for list set map,48,25,"parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java,CAS_DELIMITER",2,1,2,0.18116640155354563,1,130.0,23,0.010810185185185185,111.0,103.92008377998759,49.0,Feature Addition,FALSE,FALSE,
2ed9b5037a1a4b9e5ad704d9d0b5c783b9882ec1,Tianshuo Deng,tdeng@twitter.com,Wed Oct 2 17:53:55 2013 -0700,1380761635,fail when required field is added,28,18,"parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java,CAS_DELIMITER",2,1,2,0.9876925088958034,1,125.0,21,0.02935185185185185,110.0,102.9229718499419,48.0,Corrective,TRUE,TRUE,
2731c0fe26ebae217f8616d4e1cedf9e3b765d78,Tianshuo Deng,tdeng@twitter.com,Wed Oct 2 17:11:39 2013 -0700,1380759099,refactor tests,19,29,"parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java,CAS_DELIMITER",2,1,2,0.41381685030363374,1,130.0,19,0.005335648148148148,109.0,101.93073393638528,47.0,Preventative,FALSE,FALSE,
2b62da3e29716295d87a31bbc497a9a8217e4fc2,Tianshuo Deng,tdeng@twitter.com,Wed Oct 2 17:03:58 2013 -0700,1380758638,requirement check,97,52,"parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java,CAS_DELIMITER",2,1,2,0.7504928681718372,1,107.5,17,0.015671296296296298,108.0,100.93213045418584,46.0,Feature Addition,FALSE,FALSE,
6f0f23627674edcef5cd4d816dbe2816a5ce0edf,Tianshuo Deng,tdeng@twitter.com,Wed Oct 2 16:41:24 2013 -0700,1380757284,fix tests,5,3,"parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java,CAS_DELIMITER",2,1,2,0.8112781244591328,1,106.5,15,0.0021643518518518518,107.0,99.93618944206412,45.0,Corrective,TRUE,FALSE,
0d39e1ce31a0a0d6e94032bcd4f07ef2fae2fd48,Tianshuo Deng,tdeng@twitter.com,Wed Oct 2 16:38:17 2013 -0700,1380757097,add compatibility report,71,12,"parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java,CAS_DELIMITER",2,1,2,0.8514808683852091,1,77.0,13,0.02552662037037037,106.0,98.93674412200866,44.0,Feature Addition,FALSE,TRUE,"[""6f0f23627674edcef5cd4d816dbe2816a5ce0edf""]"
64b2f7268878cc19d246383f62900c8c2a275e27,Tianshuo Deng,tdeng@twitter.com,Wed Oct 2 16:10:46 2013 -0700,1380755446,fix,1,0,"parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java,CAS_DELIMITER",1,1,1,0.0,1,126.0,9,0.0005439814814814814,105.0,97.94158923515143,43.0,Corrective,TRUE,FALSE,
2fb1f7d79693fea18933092c8993be60b476f265,Tianshuo Deng,tdeng@twitter.com,Wed Oct 2 16:09:59 2013 -0700,1380755399,accept visitor,2,14,"parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java,CAS_DELIMITER",1,1,1,0.0,1,138.0,8,0.001238425925925926,104.0,96.94172568047115,42.0,None,FALSE,FALSE,
5427f4434ee24062c83f35fe154b071491a322be,Tianshuo Deng,tdeng@twitter.com,Wed Oct 2 16:08:12 2013 -0700,1380755292,list checker,5,0,"parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java,CAS_DELIMITER",1,1,1,0.0,1,133.0,7,0.0007291666666666667,103.0,95.9420329197671,41.0,None,FALSE,FALSE,
5bf612787838361fa2922d07aaa6833a4ee595a3,Tianshuo Deng,tdeng@twitter.com,Wed Oct 2 16:07:09 2013 -0700,1380755229,SetChecker,8,0,"parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java,CAS_DELIMITER",1,1,1,0.0,1,125.0,6,0.001851851851851852,102.0,94.94221182086217,40.0,None,FALSE,FALSE,
001e3deef9c2f3f8e6f257b3e497da2934e6b1bf,Tianshuo Deng,tdeng@twitter.com,Wed Oct 2 16:04:29 2013 -0700,1380755069,map checker,29,19,"parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java,CAS_DELIMITER",1,1,1,0.0,1,115.0,5,0.008472222222222223,101.0,93.94266110226218,39.0,None,FALSE,TRUE,
bd311f54b0c7b043a4164413e35d014e3cc41683,Tianshuo Deng,tdeng@twitter.com,Wed Oct 2 15:52:17 2013 -0700,1380754337,fix test,93,1,"parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java,CAS_DELIMITER",2,1,2,0.14854949043034824,1,25.0,6,0.017152777777777777,100.0,92.94469340689731,38.0,Corrective,TRUE,TRUE,"[""2ed9b5037a1a4b9e5ad704d9d0b5c783b9882ec1""]"
5bd87b1c579017ebd76382335bf258f51598bae8,Tianshuo Deng,tdeng@twitter.com,Wed Oct 2 15:37:48 2013 -0700,1380753468,check compatible,44,0,"parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java,CAS_DELIMITER",2,1,1,0.8453509366224365,1,22.5,3,0.015243055555555555,98.0,90.94707574677528,36.0,None,FALSE,FALSE,
f325418daa9ebb103eda6a08e8f16522267f56a7,Tianshuo Deng,tdeng@twitter.com,Wed Oct 2 15:15:51 2013 -0700,1380752151,generate json,38,1,"parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityRunner.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java,CAS_DELIMITER",3,1,2,0.560279318984369,1,11.666666666666666,2,0.02625385802469136,97.0,89.9506073462041,35.0,None,FALSE,TRUE,
6d9d2b334db9db4896599f07e9a545961422db5f,Tianshuo Deng,tdeng@twitter.com,Wed Oct 2 14:19:25 2013 -0700,1380748765,add test,28,0,"parquet-thrift/src/test/java/parquet/thrift/struct/CompatibilityCheckerTest.java,CAS_DELIMITER",1,1,1,0.0,1,0.0,0,0.0,96.0,88.9595809502042,34.0,Feature Addition,FALSE,FALSE,
4e6863aaeb765f62322ed79bb7e82c930cb6e364,Tianshuo Deng,tdeng@twitter.com,Wed Oct 2 14:18:52 2013 -0700,1380748732,add checker,7,0,"parquet-thrift/src/main/java/parquet/thrift/struct/CompatibilityChecker.java,CAS_DELIMITER",1,1,1,0.0,1,0.0,0,0.0,95.0,87.9596673694671,33.0,Feature Addition,FALSE,FALSE,
d24f4a7add1855675a3c2d19f7c9ab435ccfb028,Tianshuo Deng,tdeng@twitter.com,Wed Oct 2 14:17:42 2013 -0700,1380748662,fix,20,15,"parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java,CAS_DELIMITER,parquet-scrooge/src/test/java/parquet/scrooge/ScroogeSchemaConverterTest.java,CAS_DELIMITER",2,1,2,0.9275265884316759,14,213.5,23,6.024230324074074,94.0,86.95984846392145,25.0,Corrective,TRUE,FALSE,
d9e5f0bc2d7482062db72bddcb3eeefda05b2143,Remy Pecqueur,r.pecqueur@criteo.com,Wed Oct 2 18:32:00 2013 +0200,1380731520,Implement correctly Settable inspectors - Array inspector implements correctly set and resize - Map inspector implements settable - Root ( and struct ) inspector implements settable - Inspectors will now inspect basic objects because Hive sometimes does that,200,86,"parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java,CAS_DELIMITER",3,1,1,1.5730432433254977,15,113.0,21,9.737418981481483,15.0,11.594679335176643,15.0,None,FALSE,FALSE,
763dfde36cd67c9f539cbd0db54b4dcdf3d15b77,Remy Pecqueur,r.pecqueur@criteo.com,Wed Oct 2 18:28:31 2013 +0200,1380731311,"Fix for columns list missing from the conf - In this case , assume that the schema and requested schema correspond to the file schema",34,28,"parquet-hive/src/main/java/parquet/hive/read/DataWritableReadSupport.java,CAS_DELIMITER",1,1,1,0.0,2,40.0,5,105.05616898148148,14.0,10.594739542521182,14.0,Corrective,TRUE,FALSE,
a8d99d9be812e17e86cfad2a13966c754ce7c287,Colin Marc,colinmarc@gmail.com,Tue Oct 1 14:50:34 2013 -0700,1380664234,add an assertion to check the output created by reading with ParquetTBaseScheme,5,0,"parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java,CAS_DELIMITER",1,1,1,0.0,14,124.0,7,10.746238425925926,15.0,14.40089185742731,6.0,Feature Addition,FALSE,FALSE,
9aad6416a4c7448727bcb71db739d7a1bc8a392f,David Z. Chen,david.z.chen@outlook.com,Tue Oct 1 14:42:44 2013 -0700,1380663764,Move reflection checks for specific Avro Fixed type into FieldFixedConverter constructor .,18,3,"parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java,CAS_DELIMITER",1,1,1,0.0,15,90.0,12,1.0374074074074073,29.0,28.071569544698747,25.0,Corrective,TRUE,FALSE,
753473cdc63a4105e0f74cd8b747a1a705710dff,David Z. Chen,david.z.chen@outlook.com,Tue Oct 1 14:07:33 2013 -0700,1380661653,Change syntax for fixed len byte array to placing length parameter after type name rather after field name .,13,7,"parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/MessageTypeParser.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/PrimitiveType.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java,CAS_DELIMITER",4,3,3,1.8149798205164813,15,103.25,35,6.3146325231481475,28.0,27.07338916524781,13.0,Corrective,TRUE,FALSE,
6ec199d4333a5aea8db5777c3d35da36a922f93c,Wesley Peck,wesley.peck@motorola.com,Tue Oct 1 13:04:35 2013 -0500,1380650675,Disable the time read counter check in DeprecatedInputFormatTest . This mirrors the commit 6dfd97551fc1b8606704dcf656b185b34ceffcd4 which disabled the check in TestInputOutputFormat .,1,1,"parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedInputFormatTest.java,CAS_DELIMITER",1,1,1,0.0,13,179.0,2,26.875775462962963,0.0,0.0,0.0,Preventative,FALSE,FALSE,
7802a9ab00a81853cbc95e04a46cc2eb721046e2,Wesley Peck,wesley.peck@motorola.com,Tue Oct 1 12:57:51 2013 -0500,1380650271,"Update ParquetReader to take Configuration as a constructor argument . This enables schema projection for both AvroParquetReader and ThriftParquetReader by allowing configuration of AVRO REQUESTED PROJECTION , THRIFT COLUMN FILTER KEY , and PARQUET READ SCHEMA .",102,1,"parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftParquetReader.java,CAS_DELIMITER",4,3,4,1.8285799747058582,15,98.0,26,28.992589699074074,1.0,1.000012810920079,0.3333333333333333,None,FALSE,FALSE,
3778e45fcc084f0559ea1d43deb36cf4c6a1527b,Frank Austin Nothaft,fnothaft@berkeley.edu,Sun Sep 29 10:41:15 2013 -0700,1380476475,Pulling in clean modifications for adding ColumnPredicate functions .,130,2,"parquet-column/src/main/java/parquet/filter/ColumnPredicates.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestFiltered.java,CAS_DELIMITER",2,1,2,0.9918703867024696,14,145.5,12,2.390341435185185,4.0,3.9231809790281065,4.0,Feature Addition,FALSE,FALSE,
2c5e07f02fd8edbfcabfab5813e486f9a192ba6b,David Z. Chen,david.z.chen@outlook.com,Fri Sep 27 17:22:15 2013 -0700,1380327735,Add support to AvroWriteSupport for writing out records with maps containing Utf8 - type keys .,31,3,"parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestReadWrite.java,CAS_DELIMITER",2,1,2,0.672294817075638,15,194.5,31,7.251192129629629,26.0,25.345641821785932,22.0,Feature Addition,FALSE,FALSE,
52c32a3a296892a4fa94a040f242313620518258,Frank Austin Nothaft,fnothaft@berkeley.edu,Fri Sep 27 08:31:11 2013 -0700,1380295871,Removing predicate functions to prepare for pushing or / not filters . Limits number of features pushed .,1,58,"parquet-column/src/main/java/parquet/filter/ColumnPredicates.java,CAS_DELIMITER",1,1,1,0.0,14,154.0,4,0.6000347222222222,3.0,2.9453454570494753,3.0,None,FALSE,FALSE,
8be341f6bc9e7a64ceee86a570bc84c0e6787d76,Frank Austin Nothaft,fnothaft@berkeley.edu,Fri Sep 27 08:31:11 2013 -0700,1380295871,Removing predicate functions to prepare for pushing or / not filters . Limits number of features pushed .,1,58,"parquet-column/src/main/java/parquet/filter/ColumnPredicates.java,CAS_DELIMITER",1,1,1,0.0,14,211.0,8,0.6000347222222222,9.0,8.914330819290658,9.0,None,FALSE,FALSE,
4b2cb26341eefb679cd599c75952509aa76af55a,Frank Austin Nothaft,fnothaft@berkeley.edu,Thu Sep 26 18:07:08 2013 -0700,1380244028,"Added unit tests for predicates . Got predicates compiling , and passing on tests .",57,19,"parquet-column/src/main/java/parquet/filter/ColumnPredicates.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/filter/NotRecordFilter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/filter/OrRecordFilter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestFiltered.java,CAS_DELIMITER",4,1,2,1.3871216514586349,14,106.0,11,11.284279513888889,2.0,1.9501075553515927,2.0,Feature Addition,FALSE,FALSE,
c6a4d18717ca05c9cc4f169a3c2a3098f0e0a967,Frank Austin Nothaft,fnothaft@berkeley.edu,Thu Sep 26 18:07:08 2013 -0700,1380244028,"Added unit tests for predicates . Got predicates compiling , and passing on tests .",57,19,"parquet-column/src/main/java/parquet/filter/ColumnPredicates.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/filter/NotRecordFilter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/filter/OrRecordFilter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestFiltered.java,CAS_DELIMITER",4,1,2,1.3871216514586349,14,176.0,22,5.253955439814814,8.0,7.928873428805302,8.0,Feature Addition,FALSE,FALSE,
835f12eae78c762322dd6b77481a5aca47637ec7,Tianshuo Deng,tdeng@twitter.com,Thu Sep 26 17:07:46 2013 -0700,1380240466,refactor code,122,108,"parquet-scrooge/src/main/java/parquet/scrooge/EnumConverter.java,CAS_DELIMITER,parquet-scrooge/src/main/java/parquet/scrooge/ScroogeEnumDesc.java,CAS_DELIMITER,parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java,CAS_DELIMITER",3,1,1,1.2590826167444726,14,81.33333333333333,12,0.09488811728395062,93.0,87.27819308241062,24.0,None,FALSE,FALSE,
bfcb120889ce52409093536f24000d75da0594d3,Tianshuo Deng,tdeng@twitter.com,Thu Sep 26 10:17:51 2013 -0700,1380215871,"implemented map with nested structure , TODO : tests failing since the default requirement can not be determined",28,37,"parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java,CAS_DELIMITER,parquet-scrooge/src/test/java/parquet/scrooge/ScroogeSchemaConverterTest.java,CAS_DELIMITER",2,1,2,0.871683617119982,14,250.0,20,0.039768518518518516,92.0,86.34223268404705,23.0,None,FALSE,FALSE,
6ffc1b9fe17309b409b54c7b053bf511768a29e4,Tianshuo Deng,tdeng@twitter.com,Thu Sep 26 09:20:35 2013 -0700,1380212435,implemented conversion for enum,113,2,"parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java,CAS_DELIMITER,parquet-scrooge/src/test/java/parquet/scrooge/ScroogeSchemaConverterTest.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java,CAS_DELIMITER",3,2,3,1.3243520370269426,14,175.66666666666666,22,0.6913695987654321,91.0,85.35107774918596,27.0,None,FALSE,FALSE,
d0fc6a0d16d89f903859f69be3d08666f2fa50ed,David Z. Chen,david.z.chen@outlook.com,Wed Sep 25 18:37:12 2013 -0700,1380159432,Correct schema syntaxes for TestHiveSchemaConverter .,2,3,"parquet-hive/src/test/java/parquet/hive/TestHiveSchemaConverter.java,CAS_DELIMITER",1,1,1,0.0,10,125.0,3,36.6697337962963,25.0,24.478226356498126,0.0,Preventative,FALSE,FALSE,
5410381c14187990675c62b6627eb0adcc45193c,Tianshuo Deng,tdeng@twitter.com,Wed Sep 25 16:47:19 2013 -0700,1380152839,convert set and unit tests,18,0,"parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java,CAS_DELIMITER,parquet-scrooge/src/test/java/parquet/scrooge/ScroogeSchemaConverterTest.java,CAS_DELIMITER",2,1,2,0.9910760598382222,14,205.5,16,0.004803240740740741,90.0,84.50288770101045,21.0,Preventative,FALSE,FALSE,
f45b384e7d0d2d9d501f0dfd278c247dec31a369,Tianshuo Deng,tdeng@twitter.com,Wed Sep 25 16:40:24 2013 -0700,1380152424,convert list and unit tests,135,1,"parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java,CAS_DELIMITER,parquet-scrooge/src/test/java/parquet/scrooge/ScroogeSchemaConverterTest.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/struct/ThriftField.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java,CAS_DELIMITER",4,2,3,1.2879948260185519,14,101.75,18,55.1182494212963,89.0,83.50393357472218,25.5,Preventative,FALSE,FALSE,
d9ced33ef44c87b11b1bee0808de2e2362bd5323,Tianshuo Deng,tdeng@twitter.com,Wed Sep 25 15:03:39 2013 -0700,1380146619,test optional map,173,0,"parquet-scrooge/src/test/java/parquet/scrooge/ScroogeSchemaConverterTest.java,CAS_DELIMITER",1,1,1,0.0,14,28.0,5,0.014907407407407407,88.0,82.51838181534049,19.0,Preventative,FALSE,FALSE,
0822e32631e50c751f4b1a8b33111d6f2a50a56f,Tianshuo Deng,tdeng@twitter.com,Wed Sep 25 14:42:11 2013 -0700,1380145331,add unit test for primitive value for maps,11,3,"parquet-scrooge/src/test/java/parquet/scrooge/ScroogeSchemaConverterTest.java,CAS_DELIMITER",1,1,1,0.0,14,20.0,4,0.021284722222222222,87.0,81.52154739260331,18.0,Feature Addition,FALSE,FALSE,
49f3ad17a066dde80e9d7f84fc859a1afb791c02,David Z. Chen,david.z.chen@outlook.com,Wed Sep 25 14:21:58 2013 -0700,1380144118,Add support for reading FIXED LEN BYTE ARRAY to Pig support .,143,96,"parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java,CAS_DELIMITER",4,2,3,1.1000141993776609,15,130.0,33,7.359670138888889,23.0,22.48982646865797,10.5,Corrective,TRUE,FALSE,
6a6613fc746bf409eff1372fa7d92cb556db9f44,Tianshuo Deng,tdeng@twitter.com,Wed Sep 25 14:11:32 2013 -0700,1380143492,tests all primitive key types in map,1,2,"parquet-scrooge/src/test/java/parquet/scrooge/ScroogeSchemaConverterTest.java,CAS_DELIMITER",1,1,1,0.0,14,21.0,3,0.004664351851851852,86.0,80.52600929202742,17.0,Preventative,FALSE,FALSE,
ca7da658ca18ef6775557ebba9776ece5a21554f,Tianshuo Deng,tdeng@twitter.com,Wed Sep 25 14:04:49 2013 -0700,1380143089,basic support for map,44,11,"parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java,CAS_DELIMITER,parquet-scrooge/src/test/java/parquet/scrooge/ScroogeSchemaConverterTest.java,CAS_DELIMITER",2,1,2,0.6429383500409614,14,91.5,9,8.927442129629629,85.0,79.52697436254152,16.0,None,FALSE,FALSE,
24d72673d1ae3cba9cf90312550b32f954e343ec,David Z. Chen,david.z.chen@outlook.com,Wed Sep 25 04:08:39 2013 -0700,1380107319,Remove print statements .,1,10,"parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/api/RecordConsumer.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER",4,3,4,1.4911148500551858,15,69.75,66,4.44441261574074,22.0,21.51552259477946,11.666666666666666,None,FALSE,FALSE,
a79eab750d002eb91efbe4cc02abb009b9db1ee9,David Z. Chen,david.z.chen@outlook.com,Wed Sep 25 03:58:39 2013 -0700,1380106719,Complete support for supporting FIXED LEN BYTE ARRAY for Avro SpecificRecord . Add syntax to specify type length for FLBA type fields to MessageTypeParser .,30,19,"parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/MessageTypeParser.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/PrimitiveType.java,CAS_DELIMITER",3,2,2,1.53857913895598,15,106.66666666666667,25,72.13306712962962,21.0,20.51592302512944,15.0,Corrective,TRUE,FALSE,
1b326b7fee6616cb63016dbce2a07daf2b0213b1,David Z. Chen,david.z.chen@outlook.com,Mon Sep 23 04:29:01 2013 -0700,1379935741,Fix reflection for converting fixed Binary to Avro SpecificFixed . Ensure that FIXED values are written using the FLBA PlainValuesReader when dictionary is enabled .,23,11,"parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java,CAS_DELIMITER",6,2,3,1.899880592869601,15,141.66666666666666,72,2.337314814814815,19.0,18.625176062393212,13.0,Corrective,TRUE,FALSE,
3b7359b347edb1d3ed780e7872f6bdf3efc2e2c7,David Z. Chen,david.z.chen@outlook.com,Sun Sep 22 22:29:30 2013 -0700,1379914170,Re - enable tests for writing FIXED for Avro Specific records . Preliminary end - to - end for writing FIXED but write is still not completely correct yet .,13,15,"parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java,CAS_DELIMITER",3,1,2,1.4488156357251847,15,152.66666666666666,18,2.205474537037037,18.0,17.637675279578282,16.0,Corrective,TRUE,FALSE,
3105009fe85cb78922e9f70ac52297cccc9101c9,Colin Marc,colinmarc@gmail.com,Fri Sep 20 21:55:44 2013 -0500,1379732144,add read and write tests for ParquetTBaseScheme,148,5,"parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java,CAS_DELIMITER",1,1,1,0.0,14,20.0,5,5.884074074074074,13.0,12.821376237869192,4.0,Feature Addition,FALSE,FALSE,
e242085ac3f79d377ed62fd2620fbeaf9a61c969,Colin Marc,colinmarc@gmail.com,Fri Sep 20 21:54:38 2013 -0500,1379732078,add an empty constructor for ParquetTBaseScheme ( which only works for reads ),15,1,"parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java,CAS_DELIMITER",1,1,1,0.0,14,57.0,9,5.299826388888889,12.0,11.821402703668408,3.0,Feature Addition,FALSE,TRUE,
e6fab0681a31aa60af07136aba65b3e69c8f45e3,David Z. Chen,david.z.chen@outlook.com,Fri Sep 20 17:33:37 2013 -0700,1379723617,Document why FIXED LEN BYTE ARRAY is not supported with Avro specific schema right now .,33,29,"parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java,CAS_DELIMITER",3,1,2,0.7939924338116537,15,151.33333333333334,15,0.6733101851851853,17.0,16.742744365234355,15.0,Corrective,TRUE,FALSE,
3b5d32bcab01886a5a4b3c1378809fc5af9cc434,David Z. Chen,david.z.chen@outlook.com,Fri Sep 20 12:35:12 2013 -0700,1379705712,Add new Vin field to Avro TestSpecificInputOutputFormat .,2,0,"parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java,CAS_DELIMITER",1,1,1,0.0,11,192.0,3,61.84917824074074,16.0,15.752113308727067,14.0,Feature Addition,FALSE,FALSE,
a73e73c8c0f5314aed0bc7f8ccd9454f461e28be,Aniket Mokashi,amokashi@twitter.com,Fri Sep 20 09:24:37 2013 -0700,1379694277,changes as per code review comments for test,1,3,"parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java,CAS_DELIMITER",1,1,1,0.0,14,116.0,6,0.6787384259259259,18.0,15.953382996165008,11.0,Preventative,FALSE,FALSE,
ebe07c6fb3f3ea3a50511fac4bd71ba683043b73,Aniket Mokashi,amokashi@twitter.com,Fri Sep 20 08:55:59 2013 -0700,1379692559,changes as per code review comments,2,3,"parquet-pig/src/main/java/parquet/pig/ParquetLoader.java,CAS_DELIMITER",1,1,1,0.0,14,158.0,26,0.6588541666666666,17.0,14.954156941806025,10.0,None,FALSE,FALSE,
e37cd2b70fcc8471451f134e37d2b25a5b36464f,David Z. Chen,david.z.chen@outlook.com,Thu Sep 19 21:42:30 2013 -0700,1379652150,Add fixed field to parquet - avro TestSpecificReadWrite .,9,6,"parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java,CAS_DELIMITER",1,1,1,0.0,8,180.0,3,75.60920138888889,15.0,14.778501466099154,13.0,Corrective,TRUE,FALSE,
cc59cb82675499870e9b0433c350f01a3522c2c9,David Z. Chen,david.z.chen@outlook.com,Thu Sep 19 17:54:27 2013 -0700,1379638467,Use ValuesWriter and ValuesReader specific to FIXED LEN BYTE ARRAY rather than overloading on a FixedBinary class .,104,360,"parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/ColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/ColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/Encoding.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/ValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/ValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/Group.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/GroupValueSource.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/FixedBinaryValue.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/Primitive.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/MessageColumnIO.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/api/FixedBinary.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/api/PrimitiveConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/api/RecordConsumer.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/ConverterConsumer.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER",27,2,11,3.805122373607884,15,73.07407407407408,250,0.6116173696844995,14.0,13.784822722941867,10.0,Corrective,TRUE,TRUE,
6da759455251c47813202cfac29056a8e3f6e834,Aniket Mokashi,amokashi@twitter.com,Thu Sep 19 17:07:14 2013 -0700,1379635634,fix problem with projection pushdown in parquetloader,111,16,"parquet-pig/src/main/java/parquet/pig/ParquetLoader.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java,CAS_DELIMITER",3,1,2,1.095596466201982,14,111.33333333333333,42,11.59392361111111,16.0,13.97803560578075,9.0,Corrective,TRUE,FALSE,
20f3f46cbd9c6fe3e162690802a6696a64ca7232,Tianshuo Deng,tdeng@twitter.com,Thu Sep 19 11:21:01 2013 -0700,1379614861,continue renaming,20,20,"parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java,CAS_DELIMITER",1,1,1,0.0,10,-51.0,19,0.012615740740740742,83.0,78.79502291213228,5.0,None,FALSE,FALSE,
310e55170d1cea2846fcdc5ecd56c394b70c799c,Colin Marc,colinmarc@gmail.com,Thu Sep 19 13:10:01 2013 -0500,1379614201,throw the writeSupportClass as part of the exception message if instantiation fails,4,3,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER",1,1,1,0.0,13,149.0,16,0.023599537037037037,11.0,10.865094157396664,8.0,Corrective,TRUE,FALSE,
1c99a117f1d4860891d4ad04242cf71581ef7137,Tianshuo Deng,tdeng@twitter.com,Thu Sep 19 11:02:51 2013 -0700,1379613771,rename variables for readability,39,36,"parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java,CAS_DELIMITER",1,1,1,0.0,10,-54.0,18,42.72944444444445,82.0,77.7976124991015,4.0,None,FALSE,FALSE,
bbf34480888124fd875150e15ac4064067675600,Colin Marc,colinmarc@gmail.com,Thu Sep 19 12:36:02 2013 -0500,1379612162,add overloaded getFooConfiguration ( JobContext ) methods to ParquetOutputFormat,29,0,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER",1,1,1,0.0,13,120.0,15,2.7177083333333334,10.0,9.865788100108086,7.0,Feature Addition,FALSE,FALSE,
a48f56f85ab758796ba072b8140fed6f712dd8fb,David Z. Chen,david.z.chen@outlook.com,Thu Sep 19 06:23:53 2013 -0700,1379597033,Re - add FIXED LEN BYTE ARRAY to oneOfEach and plumb through FIXED support for example Group . Test still fails and need to solve read issues .,111,13,"parquet-column/src/main/java/parquet/example/data/Group.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/GroupValueSource.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/FixedBinaryValue.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/Primitive.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER",8,1,5,2.5259385752225767,15,47.875,52,100.31676359953704,13.0,12.802681792054251,7.0,Corrective,TRUE,FALSE,
8305bdb1937a24bc7e778ec497ceafb8b883be42,David Z. Chen,david.z.chen@outlook.com,Thu Sep 19 03:01:24 2013 -0700,1379584884,Add FixedBinary type by creating a wrapper class around Binary and plumb FixedBinary through for read and write support for FIXED LEN BYTE ARRAY . Undo change to add FIXED field to oneOfEach schema for parquet - column TestColumnIO for now .,187,28,"parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/ColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/ColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/ValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/ValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/MessageColumnIO.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/api/Binary.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/api/FixedBinary.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/api/PrimitiveConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/api/RecordConsumer.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/ConverterConsumer.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER",20,2,8,2.7024799506850945,15,73.3,190,13.882021990740743,12.0,11.807541696193692,8.5,Corrective,TRUE,FALSE,
562e8111552be8fbbe701c02dddfa3a3496a5f47,julien,julien@twitter.com,Wed Sep 18 11:13:39 2013 -0700,1379528019,make binary dictionary encoding use fastutils ; fix tests,94,364,"parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java,CAS_DELIMITER",2,1,2,0.20800614931091582,13,530.5,32,5.554456018518518,319.0,218.3429028278043,125.0,Corrective,TRUE,FALSE,
e8c2a399a79cfd2905dd8d8e7c0e58bec68ece7b,julien,julien@twitter.com,Wed Sep 18 10:02:16 2013 -0700,1379523736,better log messages,4,3,"parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java,CAS_DELIMITER",1,1,1,0.0,13,148.0,4,5.450833333333334,318.0,217.36389039716482,77.0,Perfective,FALSE,TRUE,
08b45b0c1c5a8b7766544ba01dd9861d8b0fbfb4,David Z. Chen,david.z.chen@outlook.com,Wed Sep 18 03:14:08 2013 -0700,1379499248,Add fixed len byte array to oneOfEach in TestColumnIO .,9,13,"parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER",1,1,1,0.0,13,262.0,24,0.9683101851851852,11.0,10.839180309174925,5.0,Corrective,TRUE,FALSE,
4f1493b0aa663111871404b026064ea35a5234e2,David Z. Chen,david.z.chen@outlook.com,Tue Sep 17 18:04:30 2013 -0700,1379466270,Fix broken tests . Test failures encountered previously were due to broken tests .,14,10,"parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestReadWrite.java,CAS_DELIMITER",2,1,1,0.5435644431995964,15,139.0,16,37.208836805555556,10.0,9.850362635295198,10.0,Corrective,TRUE,FALSE,
f8ac0f01deb15cf7b54ec9355dd57f6b96471b0d,David Z. Chen,david.z.chen@outlook.com,Tue Sep 17 14:41:09 2013 -0700,1379454069,"Initial end - to - end write and read support for Avro FIXED fields without runtime exceptions , but still with data representation issues .",8,7,"parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/Encoding.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java,CAS_DELIMITER",4,2,4,1.965596230357602,15,166.5,47,15.84345775462963,9.0,8.854118613802433,6.5,Corrective,TRUE,FALSE,
232d521dc0860e0e657970d5bbab241d7a58d283,Tianshuo Deng,tdeng@twitter.com,Tue Sep 17 11:00:59 2013 -0700,1379440859,use class . getName,1,1,"parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java,CAS_DELIMITER",1,1,1,0.0,14,186.0,7,0.8893055555555556,81.0,77.2050678663848,15.0,None,FALSE,FALSE,
eb35ba800654231865401503f971d19183257f30,Frank Austin Nothaft,fnothaft@berkeley.edu,Tue Sep 17 10:17:51 2013 -0700,1379438271,Added functionality to allow users to implement functions to be used as predicates .,58,1,"parquet-column/src/main/java/parquet/filter/ColumnPredicates.java,CAS_DELIMITER",1,1,1,0.0,14,154.0,6,-12.01625,7.0,7.134938103829051,7.0,Feature Addition,FALSE,FALSE,
58051d0629121332a8f96e00d2e9603583cbd564,Frank Austin Nothaft,fnothaft@berkeley.edu,Tue Sep 17 10:17:51 2013 -0700,1379438271,Added functionality to allow users to implement functions to be used as predicates .,58,1,"parquet-column/src/main/java/parquet/filter/ColumnPredicates.java,CAS_DELIMITER",1,1,1,0.0,8,97.0,2,73.13375,1.0,0.999931860300362,1.0,Feature Addition,FALSE,FALSE,
1f630137267fed0b81871bd8eb0b315a6f009a35,Frank Austin Nothaft,fnothaft@berkeley.edu,Tue Sep 17 09:42:02 2013 -0700,1379436122,Added two boolean options for record filters .,114,0,"parquet-column/src/main/java/parquet/filter/NotRecordFilter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/filter/OrRecordFilter.java,CAS_DELIMITER",2,1,1,0.9991117320927687,1,0.0,0,0.0,0.0,0.0,0.0,Feature Addition,FALSE,FALSE,
308c1b41960e5c430a60b02db74ad4f03567b855,Frank Austin Nothaft,fnothaft@berkeley.edu,Tue Sep 17 09:42:02 2013 -0700,1379436122,Added two boolean options for record filters .,114,0,"parquet-column/src/main/java/parquet/filter/NotRecordFilter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/filter/OrRecordFilter.java,CAS_DELIMITER",2,1,1,0.9991117320927687,14,57.0,4,-9.350763888888888,6.0,6.135433867913916,6.0,Feature Addition,FALSE,FALSE,
4e82ab632d39b236d302ff4283cae0a94f7cdbc0,David Z. Chen,david.z.chen@outlook.com,Tue Sep 17 03:59:46 2013 -0700,1379415586,Add methods to write fixed Binary without prepending length .,75,3,"parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/ColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/MessageColumnIO.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/api/PrimitiveConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/api/RecordConsumer.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/ConverterConsumer.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER",11,2,6,3.3683607216094806,13,64.54545454545455,106,106.14162457912457,8.0,7.86476230330206,5.5,Corrective,TRUE,FALSE,
b11e2a005014ecd827855dde9ce4d50b1f58aa4b,David Z. Chen,david.z.chen@outlook.com,Mon Sep 16 19:02:18 2013 -0700,1379383338,Plumb type length for FIXED types through to reading pages .,162,25,"parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestReadWrite.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/ColumnDescriptor.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/Encoding.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/ValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/FixedLenByteArrayPlainValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/PrimitiveColumnIO.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/MessageType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/PrimitiveType.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER",14,3,9,3.1363460258754032,15,93.07142857142857,139,47.418871527777775,7.0,6.872677611750868,3.6666666666666665,Corrective,TRUE,FALSE,
5aa7a682910bd138511aac0191b13fed9716f1e0,Colin Marc,colinmarc@gmail.com,Mon Sep 16 17:22:32 2013 -0700,1379377352,accidentally deleted a space,1,1,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER",1,1,1,0.0,13,120.0,14,3.719375,9.0,8.93879777827831,6.0,None,FALSE,FALSE,
dd02df03c3ed08d03a0333af68f43c7f2b59df6d,Tianshuo Deng,tdeng@twitter.com,Mon Sep 16 15:49:18 2013 -0700,1379371758,added map test,19,2,"parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java,CAS_DELIMITER,parquet-scrooge/src/test/java/parquet/scrooge/ScroogeSchemaConverterTest.java,CAS_DELIMITER",2,1,2,0.5916727785823275,14,83.0,7,0.06140625,80.0,76.36690163594103,14.0,Feature Addition,FALSE,FALSE,
9a5eea0cbaf1083412b2a057c6190814f196292c,Tianshuo Deng,tdeng@twitter.com,Mon Sep 16 14:52:37 2013 -0700,1379368357,working on map,8,3,"parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java,CAS_DELIMITER",1,1,1,0.0,14,146.0,5,0.010162037037037037,79.0,75.3747764295828,13.0,None,FALSE,FALSE,
234a1cbfcfd2dc0af57be4091f82b28acee4d0db,Tianshuo Deng,tdeng@twitter.com,Mon Sep 16 14:37:59 2013 -0700,1379367479,extracted key and value type from map and optional map,23,11,"parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java,CAS_DELIMITER",1,1,1,0.0,14,134.0,4,0.005127314814814815,78.0,74.37678180349486,12.0,None,FALSE,FALSE,
e2fec1c3c1840645a26943c918292a621e91f3f1,Tianshuo Deng,tdeng@twitter.com,Mon Sep 16 14:30:36 2013 -0700,1379367036,add optional map field to thrift file,6,13,"parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java,CAS_DELIMITER",1,1,1,0.0,14,141.0,3,0.015324074074074073,77.0,73.37777961947972,11.0,Feature Addition,FALSE,FALSE,
3c65205c5056c51d912dd7297be90eb3feb7165e,Tianshuo Deng,tdeng@twitter.com,Mon Sep 16 14:08:32 2013 -0700,1379365712,field requirement depends on if the getter returns option,3,3,"parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java,CAS_DELIMITER",1,1,1,0.0,14,141.0,2,2.9971875,76.0,72.38071997970262,10.0,Feature Addition,FALSE,FALSE,
249581dd38d82e5b36f39a25e45e84f109c12e69,Tianshuo Deng,tdeng@twitter.com,Mon Sep 16 13:49:08 2013 -0700,1379364548,add TestCase for scrooge schema converter,15,0,"parquet-scrooge/src/test/java/parquet/scrooge/ScroogeSchemaConverterTest.java,CAS_DELIMITER",1,1,1,0.0,1,0.0,0,0.0,75.0,71.38326829277665,9.0,Feature Addition,FALSE,FALSE,
78b3f86774685d5d8beb1b12880fd127de9a6222,Tianshuo Deng,tdeng@twitter.com,Mon Sep 16 13:40:23 2013 -0700,1379364023,"update scrooge denepdency , add unit tests for reading in scrooge",93,0,"parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java,CAS_DELIMITER",1,1,1,0.0,14,93.0,6,0.0026967592592592594,74.0,70.38440107167428,8.0,Feature Addition,FALSE,FALSE,
2a2696dcee58fb7fd6d9072b97f0411b5ceb9470,Tianshuo Deng,tdeng@twitter.com,Mon Sep 16 13:36:30 2013 -0700,1379363790,format,21,41,"parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java,CAS_DELIMITER",1,1,1,0.0,14,113.0,5,0.004398148148148148,73.0,69.384896432837,7.0,None,FALSE,FALSE,
04784c2e024cd3db1165150448f19ef4532793d6,Tianshuo Deng,tdeng@twitter.com,Mon Sep 16 13:30:10 2013 -0700,1379363410,test pass,21,205,"parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java,CAS_DELIMITER",1,1,1,0.0,14,297.0,4,2.9705439814814816,72.0,68.3856922831098,6.0,Preventative,FALSE,FALSE,
b4c45d3a5fa2972a0fbb214179350c55a7051927,Tianshuo Deng,tdeng@twitter.com,Mon Sep 16 10:31:59 2013 -0700,1379352719,"fix bug , missing break in thriftSchemaConverter",1,0,"parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java,CAS_DELIMITER",1,1,1,0.0,14,-101.0,20,2.960185185185185,71.0,67.4077512734655,29.0,Corrective,TRUE,FALSE,
3803d2d478ef73e1bccc2d887daad4b30647d854,David Z. Chen,david.z.chen@outlook.com,Mon Sep 16 05:47:09 2013 -0700,1379335629,Plumb FIXED type length from Avro schema through to Parquet metadata .,40,9,"parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/PrimitiveType.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER",3,3,3,1.4488156357251847,14,133.0,45,12.675447530864197,6.0,5.882901974315568,2.6666666666666665,Corrective,TRUE,FALSE,
93d6770be153472c0da28dd2b9b3fc8797604703,Colin Marc,colinmarc@gmail.com,Sun Sep 15 00:41:07 2013 -0700,1379230867,add a simple test for DeprecatedOutputFormat,106,0,"parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedOutputFormatTest.java,CAS_DELIMITER",1,1,1,0.0,1,0.0,0,0.0,6.0,5.978837914638713,4.0,Feature Addition,FALSE,FALSE,
521d08127d3355273fa00d2d0a4819069813f0c8,Colin Marc,colinmarc@gmail.com,Sun Sep 15 00:40:09 2013 -0700,1379230809,add some convenience methods ( from ParquetOutputFormat ),26,5,"parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java,CAS_DELIMITER",1,1,1,0.0,1,94.0,1,2.08712962962963,5.0,4.978848872030279,3.0,Feature Addition,FALSE,FALSE,
f6f3eaa01e0a503d78eb028be64554ca0a0f85c3,Tianshuo Deng,tdeng@twitter.com,Fri Sep 13 14:12:35 2013 -0700,1379106755,broken tests for scroogeRead,50,22,"parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java,CAS_DELIMITER,parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java,CAS_DELIMITER",2,1,2,0.943601631299382,14,205.0,4,0.11337962962962964,70.0,66.91135890662319,5.0,Preventative,FALSE,FALSE,
9ae1d88da88554b643e201c04484c4b5177157ad,Colin Marc,colinmarc@gmail.com,Fri Sep 13 13:08:29 2013 -0700,1379102909,add Sink functionality to parquet . cascading . ParquetTBaseScheme,31,21,"parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java,CAS_DELIMITER,parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java,CAS_DELIMITER,parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java,CAS_DELIMITER",3,1,2,1.419556298571613,14,54.333333333333336,13,60.61015432098765,3.0,2.9951908033670676,0.0,Feature Addition,FALSE,FALSE,
99b6dfcc7c82c09e098fa8583442bafc1d8a3151,Tianshuo Deng,tdeng@twitter.com,Fri Sep 13 11:44:44 2013 -0700,1379097884,remove julien's TODO,2,3,"parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConvertVisitor.java,CAS_DELIMITER",1,1,1,0.0,14,0.0,1,2.044351851851852,69.0,65.92938160408555,28.0,None,FALSE,TRUE,
64e6d82f69249c0e3a2747b3f6b59d39cd2df873,Tianshuo Deng,tdeng@twitter.com,Fri Sep 13 11:42:09 2013 -0700,1379097729,[ style ] add spaces around =,2,4,"parquet-column/src/main/java/parquet/schema/ConversionPatterns.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java,CAS_DELIMITER",2,2,2,0.9182958340544896,14,461.0,23,1.4114988425925925,68.0,64.92969168000246,15.0,Feature Addition,FALSE,FALSE,
e2d3bb299a29b7df44cef06a555bd1e5c5b775f5,Tianshuo Deng,tdeng@twitter.com,Fri Sep 13 11:33:08 2013 -0700,1379097188,[ style ] fix if . . . else in ConversionPatterns,32,31,"parquet-column/src/main/java/parquet/schema/ConversionPatterns.java,CAS_DELIMITER",1,1,1,0.0,13,102.0,5,7.014039351851852,67.0,63.93075681257435,2.0,Corrective,TRUE,FALSE,
a7ba48ba7caf2ef58868dca8bc710f66eac199f5,Tianshuo Deng,tdeng@twitter.com,Fri Sep 13 11:29:19 2013 -0700,1379096959,created ScroogeSchemaConverter,149,8,"parquet-scrooge/src/main/java/parquet/scrooge/ScroogeRecordConverter.java,CAS_DELIMITER,parquet-scrooge/src/main/java/parquet/scrooge/ScroogeSchemaConverter.java,CAS_DELIMITER,parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java,CAS_DELIMITER",5,2,4,1.167114460152595,14,76.2,34,30.113009259259258,66.0,62.93120042170399,15.0,Feature Addition,FALSE,TRUE,
1d928046faec8f83fd0ed112e602eefbca396d31,David Z. Chen,david.z.chen@outlook.com,Fri Sep 13 11:00:21 2013 -0700,1379095221,Add typeLength to ColumnDescriptor .,44,21,"parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/ColumnDescriptor.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER",4,3,4,1.5722933030455133,13,104.0,61,58.05138310185185,5.0,4.927207610301572,1.6666666666666667,Feature Addition,FALSE,FALSE,
7adc26426d67cb3046a4db4c5f265f02ea2d420a,Colin Marc,colinmarc@gmail.com,Fri Sep 13 00:06:38 2013 -0700,1379055998,add another getRecordWriter overload,5,1,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER",1,1,1,0.0,13,116.0,13,0.06547453703703704,2.0,1.9996457375562824,2.0,Feature Addition,FALSE,FALSE,
ce6bfcc103e94a3c2f9f62eea588805ffe59bc2c,Colin Marc,colinmarc@gmail.com,Thu Sep 12 22:34:41 2013 -0700,1379050481,add a DeprecatedParquetOutputFormat to mirror DeprecatedParquetInputFormat,94,0,"parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetOutputFormat.java,CAS_DELIMITER",1,1,1,0.0,1,0.0,0,0.0,1.0,0.9999955606488301,1.0,Feature Addition,FALSE,FALSE,
c1f3512b1e78137f01cdc11221ab64242a6fe1b6,Colin Marc,colinmarc@gmail.com,Thu Sep 12 22:32:21 2013 -0700,1379050341,change some ParquetOutputFormat interfaces to mirror ParquetInputFormat ( and be useful for writing a DeprecatedOutputFormat ),71,54,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER",1,1,1,0.0,13,99.0,12,3.293877314814815,0.0,0.0,0.0,None,FALSE,FALSE,
0570f46ce688f9361f4264c36cc3723074e459e8,julien,julien@twitter.com,Thu Sep 12 21:55:14 2013 -0700,1379048114,better fallback mechanism,105,29,"parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java,CAS_DELIMITER",2,1,2,0.9635359835770289,13,492.5,30,3.2123321759259262,316.0,217.70536716642212,124.0,Perfective,FALSE,FALSE,
d9ce72660790484784897905f34ebbd2a6a278d9,Tianshuo Deng,tdeng@twitter.com,Thu Sep 12 12:56:45 2013 -0700,1379015805,add test in scrooge [ only maven passed ],50,3,"parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java,CAS_DELIMITER",1,1,1,0.0,1,216.0,1,0.015914351851851853,65.0,62.086217686409015,3.0,Feature Addition,FALSE,FALSE,
5393833758daf1bc67e759f03de3507fca0aca65,Tianshuo Deng,tdeng@twitter.com,Thu Sep 12 12:33:50 2013 -0700,1379014430,migrated tests to parquet - scrooge [ tests passed ],216,0,"parquet-scrooge/src/test/java/parquet/scrooge/ParquetScroogeSchemeTest.java,CAS_DELIMITER",1,1,1,0.0,1,0.0,0,0.0,64.0,61.08880714482202,2.0,Preventative,FALSE,FALSE,
7b68b4738d50f1ca12f9ebf048d28db20682b984,Tianshuo Deng,tdeng@twitter.com,Thu Sep 12 09:37:06 2013 -0700,1379003826,sucess : compile scrooge generated classes in parquet - thrift,29,30,"parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java,CAS_DELIMITER",4,1,4,1.5894654055738902,14,162.5,37,3.014947916666667,63.0,60.108447953049975,25.0,None,FALSE,FALSE,
079e295072516c46fff087d3d38ee3310f6a1b5b,Tianshuo Deng,tdeng@twitter.com,Wed Sep 11 10:40:52 2013 -0700,1378921252,rename,3,11,"parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConvertVisitor.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java,CAS_DELIMITER",2,1,1,0.863120568566631,14,-46.0,18,0.00036458333333333335,62.0,59.25920063690754,24.0,None,FALSE,TRUE,
2b2837f55ad92211c1da450195672ae02230b82c,Tianshuo Deng,tdeng@twitter.com,Wed Sep 11 10:39:49 2013 -0700,1378921189,refactor matching filter,46,54,"parquet-thrift/src/main/java/parquet/thrift/SchemaConvertVisitor.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java,CAS_DELIMITER",2,1,1,0.14144054254182067,14,86.5,18,0.00755787037037037,61.0,58.259313945337006,23.0,None,FALSE,TRUE,
ffbdf6dd649775eff7a26ce78244395a934902a0,Tianshuo Deng,tdeng@twitter.com,Wed Sep 11 10:28:56 2013 -0700,1378920536,visitor pattern for schemaConverter,267,148,"parquet-thrift/src/main/java/parquet/thrift/SchemaConvertVisitor.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java,CAS_DELIMITER",2,1,1,0.9477610774938039,14,27.0,16,0.3649826388888889,60.0,57.260467714835805,22.0,None,FALSE,TRUE,
5ca767137557e8a54040f35481a3041245783417,David Z. Chen,david.z.chen@outlook.com,Tue Sep 10 18:27:10 2013 -0700,1378862830,Re - enable test for fixed type fields in Avro TestReadWrite .,4,5,"parquet-avro/src/test/java/parquet/avro/TestReadWrite.java,CAS_DELIMITER",1,1,1,0.0,3,162.0,9,0.0937037037037037,4.0,3.9632510232462916,4.0,Corrective,TRUE,FALSE,
365d84ef8706aae8aaabeb6062dd24357ececbd5,Tianshuo Deng,tdeng@twitter.com,Tue Sep 10 16:57:47 2013 -0700,1378857467,"prepare for commit , remove format diff",54,74,"parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java,CAS_DELIMITER",1,1,1,0.0,14,74.0,15,0.035925925925925924,59.0,56.370114917011016,21.0,None,FALSE,FALSE,
d7b00834098a7f3b705656e9c0e12b077084e8c0,David Z. Chen,david.z.chen@outlook.com,Tue Sep 10 16:12:14 2013 -0700,1378854734,Add empty map and array to test Avro schema all - minus - fixed and add empty map and array fields to parquet - avro test that tests fields of all ( except fixed ) types .,62,54,"parquet-avro/src/test/java/parquet/avro/TestReadWrite.java,CAS_DELIMITER",1,1,1,0.0,3,154.0,8,4.585127314814815,3.0,2.9642594176942123,3.0,Corrective,TRUE,FALSE,
eff7237c798a1057c9be4148dbd555a790bea3bb,Tianshuo Deng,tdeng@twitter.com,Tue Sep 10 16:06:03 2013 -0700,1378854363,remove converted Type,61,101,"parquet-thrift/src/main/java/parquet/thrift/ParquetReadProtocol.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java,CAS_DELIMITER",3,1,1,0.5187552219877792,14,363.6666666666667,33,0.726207561728395,58.0,55.375423727924435,20.0,None,FALSE,FALSE,
073e20295c0620c3cb7374bc822c267e34296300,Tianshuo Deng,tdeng@twitter.com,Tue Sep 10 15:42:24 2013 -0700,1378852944,fix test path,1,1,"parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java,CAS_DELIMITER",1,1,1,0.0,14,228.0,20,1.8977314814814814,57.0,54.37780599707787,28.0,Corrective,TRUE,FALSE,
133b2528a56c06ea5c3bd16fa50963edaf76f644,julien,julien@twitter.com,Tue Sep 10 15:38:10 2013 -0700,1378852690,add missing file,32,0,"parquet-thrift/src/main/java/parquet/thrift/SkippableException.java,CAS_DELIMITER",1,1,1,0.0,1,0.0,0,0.0,315.0,217.67024270393452,48.0,Feature Addition,FALSE,FALSE,
f702fdfb5b8b46e90ef14daa58d80cb59f1d26a4,Tianshuo Deng,tdeng@twitter.com,Tue Sep 10 14:51:56 2013 -0700,1378849916,better naming,7,9,"parquet-thrift/src/main/java/parquet/thrift/projection/amend/DefaultEventsVisitor.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/projection/amend/DefaultProtocolEventsGenerator.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsAmender.java,CAS_DELIMITER",3,1,1,1.2987949406953985,14,7.0,5,0.0016358024691358025,56.0,53.38279417422374,19.0,Perfective,FALSE,FALSE,
b81238938165d7179357041bad40ca510cb9c687,Tianshuo Deng,tdeng@twitter.com,Tue Sep 10 14:48:24 2013 -0700,1378849704,inline some classes,37,50,"parquet-thrift/src/main/java/parquet/thrift/projection/amend/DefaultEventsVisitor.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsAmender.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsGenerator.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/projection/amend/ReadFieldBeginProtocol.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/projection/amend/StringProtocol.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/projection/amend/StructBeginProtocol.java,CAS_DELIMITER",6,1,1,1.9555339698126286,14,23.333333333333332,14,0.10026620370370369,55.0,52.38313672432212,18.0,None,FALSE,FALSE,
8aadc0ac6ef8e229baee584385002c488c042207,Tianshuo Deng,tdeng@twitter.com,Tue Sep 10 14:25:39 2013 -0700,1378848339,"fix bug , use a new list for fixed events",4,4,"parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/projection/amend/DefaultEventsVisitor.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsGenerator.java,CAS_DELIMITER",3,1,2,1.5,14,294.3333333333333,19,0.08641975308641975,54.0,51.38529911421311,17.0,Corrective,TRUE,TRUE,
b4a8eb1e95ca30db1c14eb17e08bf2ca8fd200cf,julien,julien@twitter.com,Tue Sep 10 11:25:31 2013 -0700,1378837531,fix test,2,2,"parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java,CAS_DELIMITER",1,1,1,0.0,12,41.0,7,1.1167361111111112,314.0,216.74497717147048,47.0,Corrective,TRUE,FALSE,
3e160d9c95ac9cdb058f9f917dae1276f462c82f,Tianshuo Deng,tdeng@twitter.com,Tue Sep 10 11:23:12 2013 -0700,1378837392,add license headers,74,66,"parquet-thrift/src/main/java/parquet/thrift/projection/amend/DummyCreatorVisitor.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsAmender.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsGenerator.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/projection/amend/ReadFieldBeginProtocol.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/projection/amend/StringProtocol.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/projection/amend/StructBeginProtocol.java,CAS_DELIMITER",6,1,1,2.2227603491907946,14,48.666666666666664,9,0.02948302469135802,52.0,49.40197842652529,15.0,Feature Addition,FALSE,FALSE,
6f374b74e3766da468e1b481247070cd7c7593d1,Tianshuo Deng,tdeng@twitter.com,Tue Sep 10 11:14:46 2013 -0700,1378836886,store thriftType in converter [ fix merge error ],5,1,"parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java,CAS_DELIMITER",1,1,1,0.0,14,815.0,14,0.03373842592592593,51.0,48.40273243518758,14.0,Corrective,TRUE,FALSE,
c59e82f53fde512934a3fa37bccdfa12f915c349,Tianshuo Deng,tdeng@twitter.com,Tue Sep 10 11:01:36 2013 -0700,1378836096,implemented all dummy values,70,12,"parquet-thrift/src/main/java/parquet/thrift/projection/amend/DummyCreatorVisitor.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsGenerator.java,CAS_DELIMITER",2,1,1,0.09501724567107638,14,71.0,3,0.01885416666666667,50.0,47.40388463710178,13.0,None,FALSE,FALSE,
1bf9d5f350bba42490e40d2312f2879ee0caf82e,Tianshuo Deng,tdeng@twitter.com,Tue Sep 10 10:34:27 2013 -0700,1378834467,extracted inner classes from ProtocolEventsGenerator,159,118,"parquet-thrift/src/main/java/parquet/thrift/projection/amend/DummyCreatorVisitor.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsGenerator.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/projection/amend/ReadFieldBeginProtocol.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/projection/amend/StringProtocol.java,CAS_DELIMITER",4,1,1,1.781734239663768,14,41.75,1,0.0014351851851851852,49.0,46.40620902209465,12.0,None,FALSE,FALSE,
7dfa864c3382f3223a9331672b0f77ef874e6ca0,Tianshuo Deng,tdeng@twitter.com,Tue Sep 10 10:26:11 2013 -0700,1378833971,"visitor pattern for string , test passed",195,134,"parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/projection/ProtocolEventsGenerator.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsAmender.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/projection/amend/ProtocolEventsGenerator.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/projection/amend/StructBeginProtocol.java,CAS_DELIMITER",5,1,3,1.4142540082488764,14,189.4,14,0.004837962962962962,48.0,45.40690107082417,11.0,Preventative,FALSE,TRUE,
68fa6cd26b473d8d1592fbd51b31d5a0c5af53ad,Tianshuo Deng,tdeng@twitter.com,Tue Sep 10 10:08:46 2013 -0700,1378832926,"fill in missing fields , only for str now , will refactor to visitor pattern",503,216,"parquet-thrift/src/main/java/parquet/thrift/ParquetProtocol.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ParquetReadProtocol.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/projection/ProtocolEventsAmender.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/projection/ProtocolEventsGenerator.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java,CAS_DELIMITER",6,1,3,1.61210357176632,14,192.16666666666666,22,32.78126736111111,47.0,44.40832604684184,10.0,None,FALSE,FALSE,
70226b9a97dd2ade359cb76a320727e20892b881,julien,julien@twitter.com,Tue Sep 10 08:37:32 2013 -0700,1378827452,distinguish recoverable errors,10,7,"parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java,CAS_DELIMITER",1,1,1,0.0,12,636.0,8,9.802453703703703,313.0,215.79437673445514,46.0,None,FALSE,FALSE,
b3efce20048307c7b7dd6aec2dcb08529c62320f,julien,julien@twitter.com,Mon Sep 9 18:09:47 2013 -0700,1378775387,fix compilation problems,5,5,"parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java,CAS_DELIMITER",5,3,3,2.321928094887362,13,156.8,57,22.835113425925925,312.0,215.04827732232596,57.0,Corrective,TRUE,FALSE,
5b36d9c5d89fac4b346ad0ee4fe49805c8d9b748,julien,julien@twitter.com,Mon Sep 9 17:07:30 2013 -0700,1378771650,make buffered by default,1,1,"parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java,CAS_DELIMITER",1,1,1,0.0,12,138.0,6,9.156597222222222,311.0,214.06640645771833,45.0,None,FALSE,FALSE,
47116ad7ac86c001c2e68bca0e3f75f51488c462,julien,julien@twitter.com,Mon Sep 9 15:55:18 2013 -0700,1378767318,fix schema merging,39,13,"parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java,CAS_DELIMITER",2,1,2,0.8403586716091171,14,56.0,23,11.401724537037037,310.0,213.0872886576942,46.0,Corrective,TRUE,FALSE,
12d1ac423bc3ae4b8270c4732601262f5296c553,julien,julien@twitter.com,Mon Sep 9 15:30:50 2013 -0700,1378765850,fix noisy warning,1,3,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER",1,1,1,0.0,14,167.0,27,2.167708333333333,309.0,212.0943194845853,75.0,Corrective,TRUE,FALSE,
e9f2550a40a51ff383283a88e1f8e847ad091d8c,julien,julien@twitter.com,Mon Sep 9 15:29:10 2013 -0700,1378765750,parameterize dictionary,211,136,"parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/PerfTest.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestFiltered.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java,CAS_DELIMITER",13,3,7,3.184216129901914,13,141.23076923076923,152,36.50788283475784,308.0,211.09479527018652,80.0,None,FALSE,FALSE,
e5cb3c8fec0991942a12d3d97ef9e60329a5eba3,julien,julien@twitter.com,Mon Sep 9 08:37:25 2013 -0700,1378741045,fix test,1,1,"parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java,CAS_DELIMITER",1,1,1,0.0,12,41.0,6,11.62888888888889,307.0,210.21162164160424,43.0,Corrective,TRUE,FALSE,
55c14bf93275371dbd4f4c3368dce00389be25cc,julien,julien@twitter.com,Mon Sep 9 08:27:00 2013 -0700,1378740420,javadoc,137,33,"parquet-hadoop/src/main/java/parquet/hadoop/api/InitContext.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/metadata/FileMetaData.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/metadata/GlobalMetaData.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/ParquetLoader.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/PigMetaData.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java,CAS_DELIMITER",8,3,4,2.892742121665862,14,72.0,61,3.3584143518518514,306.0,209.21455908721126,53.333333333333336,Non Functional,FALSE,TRUE,
147a3f023f68a321dad8fb55bc8b09d4f9b088ae,Tianshuo Deng,tdeng@twitter.com,Sun Sep 8 19:26:31 2013 -0700,1378693591,"start! do not check required field , failing test",5,5,"parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java,CAS_DELIMITER",2,1,2,0.7219280948873623,14,126.0,17,2.0928761574074075,46.0,43.59469248342569,9.0,Corrective,TRUE,FALSE,
7387a615dd3b9ae89a63e052f11e36e91244728e,Tianshuo Deng,tdeng@twitter.com,Sun Sep 8 19:21:58 2013 -0700,1378693318,"passed all test , fix map , removed tests for pull in required fields",36,29,"parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java,CAS_DELIMITER",2,1,2,0.9374561707820049,14,144.5,19,0.014525462962962962,45.0,42.59505051265441,8.0,Corrective,TRUE,FALSE,
00a5d5b55eac3c869291a5f6359af97a880ddfd4,Tianshuo Deng,tdeng@twitter.com,Sun Sep 8 19:01:03 2013 -0700,1378692063,"migrated to using ThriftStruct for schemaConverter , do not use thriftClass",201,196,"parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/projection/FieldsPath.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java,CAS_DELIMITER",4,1,4,0.7322723601212405,14,134.25,34,0.6251157407407408,44.0,41.59665667630141,7.0,None,FALSE,TRUE,"[""7387a615dd3b9ae89a63e052f11e36e91244728e"", ""147a3f023f68a321dad8fb55bc8b09d4f9b088ae""]"
cfc91fc79e13bd640dcb6b6605750c92d11ccb64,Tianshuo Deng,tdeng@twitter.com,Sun Sep 8 18:09:40 2013 -0700,1378688980,"almost there . . . now working on not to use thrift class , so it's compatible with scrooge",113,43,"parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java,CAS_DELIMITER",4,2,4,0.9118536420962664,14,155.5,49,2.713330439814815,43.0,40.60050507966949,16.5,None,FALSE,FALSE,
60a3468f8266eeca965c4dd3906afca7f3001300,julien,julien@twitter.com,Sat Sep 7 12:19:39 2013 -0700,1378581579,fix test,1,1,"parquet-column/src/test/java/parquet/schema/TestMessageType.java,CAS_DELIMITER",1,1,1,0.0,14,98.0,6,0.7498958333333333,305.0,208.9587902737195,121.0,Corrective,TRUE,FALSE,
8c51a420a73241036ed28563c6a0ec5f905d133d,julien,julien@twitter.com,Sat Sep 7 11:34:16 2013 -0700,1378578856,better error message,4,1,"parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java,CAS_DELIMITER",1,1,1,0.0,11,180.0,3,2.9803935185185186,304.0,207.9715098049615,72.0,Perfective,FALSE,FALSE,
26d09f4b150c49d36d7933c92651689622828f7c,julien,julien@twitter.com,Sat Sep 7 11:29:20 2013 -0700,1378578560,javadoc,144,13,"parquet-column/src/main/java/parquet/schema/GroupType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/PrimitiveType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/Type.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/api/InitContext.java,CAS_DELIMITER",7,2,3,2.5073515677185676,14,110.71428571428571,103,1.2285119047619049,303.0,206.97288317418975,95.5,Non Functional,FALSE,FALSE,
6f25a0f2e68adc13d8c2caaf87a864bba8fd8be5,David Z. Chen,david.z.chen@outlook.com,Sat Sep 7 04:41:48 2013 -0700,1378554108,Correctly handle Avro records with empty maps and arrays .,35,27,"parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java,CAS_DELIMITER",1,1,1,0.0,12,215.0,12,17.43608796296296,2.0,1.9924460211773718,2.0,None,FALSE,FALSE,
9594bba425ecd16e7a65021a4c5b0ec08921bd82,julien,julien@twitter.com,Fri Sep 6 18:19:48 2013 -0700,1378516788,address review comments,75,23,"parquet-column/src/main/java/parquet/schema/GroupType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/Type.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/schema/TestMessageType.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java,CAS_DELIMITER",6,3,5,1.9701374487003638,14,91.83333333333333,81,1.1015914351851854,302.0,206.25793705482923,77.66666666666667,Feature Addition,FALSE,FALSE,
0cedaf25e758c223ad54429c1e7bc991eb846c0a,julien,julien@twitter.com,Fri Sep 6 17:51:59 2013 -0700,1378515119,remove debugging code from hot path,6,4,"parquet-thrift/src/main/java/parquet/thrift/ParquetProtocol.java,CAS_DELIMITER",1,1,1,0.0,2,23.0,2,133.14636574074075,301.0,205.2655971282289,41.0,Corrective,TRUE,FALSE,
1a711f05d5ba1f8579efeac5b0652b3efecf27d4,julien,julien@twitter.com,Fri Sep 6 15:40:35 2013 -0700,1378507235,turn off projection from scrooge,11,3,"parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java,CAS_DELIMITER",1,1,1,0.0,14,165.0,14,0.9508912037037037,300.0,204.30153953044433,40.0,None,FALSE,FALSE,
8faaaf087ceb7c3827e1e4d0c4ff7eefd9935ed0,Tianshuo Deng,tdeng@twitter.com,Fri Sep 6 11:12:55 2013 -0700,1378491175,support projection on only key of a map,23,5,"parquet-column/src/main/java/parquet/schema/ConversionPatterns.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java,CAS_DELIMITER",3,2,3,1.3747976286297399,13,101.66666666666667,17,8.199876543209877,42.0,39.84260515455256,3.0,None,FALSE,FALSE,
f0d30dfb2274ef430d805d900f53ba8252f496ad,Tianshuo Deng,tdeng@twitter.com,Fri Sep 6 09:34:32 2013 -0700,1378485272,refactor schema converter,174,85,"parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/projection/FieldProjectionFilter.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/projection/FieldsPath.java,CAS_DELIMITER",3,1,2,1.1058086309893578,13,39.0,9,3.1755941358024695,41.0,38.849687228577835,4.0,None,FALSE,TRUE,"[""7387a615dd3b9ae89a63e052f11e36e91244728e""]"
50feb3363f202dabde35e749367e00348b3af3ee,David Z. Chen,david.z.chen@outlook.com,Fri Sep 6 02:09:39 2013 -0700,1378458579,Fix tests for reading and writing Avro records with empty arrays and maps .,6,6,"parquet-avro/src/test/java/parquet/avro/TestReadWrite.java,CAS_DELIMITER",1,1,1,0.0,3,154.0,7,0.5567592592592593,1.0,0.9984769553697013,1.0,Corrective,TRUE,FALSE,
f369a13e0500604a7cd7276e6290fbae70ecb08c,julien,julien@twitter.com,Thu Sep 5 17:02:51 2013 -0700,1378425771,validate output,16,5,"parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java,CAS_DELIMITER",1,1,1,0.0,14,243.0,4,0.008020833333333333,298.0,202.6689332594838,39.0,None,FALSE,FALSE,
c32be9e4ef2169be9267dc4ef17c0b7f06db4927,julien,julien@twitter.com,Thu Sep 5 16:51:18 2013 -0700,1378425078,thrift schema evolution support,163,21,"parquet-column/src/main/java/parquet/schema/GroupType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/MessageType.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java,CAS_DELIMITER",6,2,4,1.7490257542993135,14,208.0,47,48.3976099537037,297.0,201.67203884998577,77.5,None,FALSE,FALSE,
848fa8e1cca99ddf38b6f9827ffa73fefcdc1929,julien,julien@twitter.com,Thu Sep 5 15:41:57 2013 -0700,1378420917,support schema evolution,622,130,"parquet-column/src/main/java/parquet/schema/GroupType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/IncompatibleSchemaModificationException.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/MessageType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/PrimitiveType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/Type.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/schema/TestMessageType.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/api/InitContext.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/metadata/FileMetaData.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/metadata/GlobalMetaData.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/ParquetLoader.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/PigMetaData.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TestParquetStorer.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java,CAS_DELIMITER",21,3,8,3.924919153187152,14,54.523809523809526,191,55.52914241622575,296.0,200.69055592869833,75.66666666666667,None,FALSE,TRUE,"[""60a3468f8266eeca965c4dd3906afca7f3001300"", ""47116ad7ac86c001c2e68bca0e3f75f51488c462"", ""6da759455251c47813202cfac29056a8e3f6e834"", ""0a76cc29b703fc95949736910a5a63ce9c1c0814""]"
eb156658b9514548a005561b0c4d3642be3034fa,David Z. Chen,david.z.chen@outlook.com,Thu Sep 5 12:47:55 2013 -0700,1378410475,Add test cases for reading / writing Avro records with empty arrays and maps .,55,0,"parquet-avro/src/test/java/parquet/avro/TestReadWrite.java,CAS_DELIMITER",1,1,1,0.0,3,99.0,6,109.59946759259259,0.0,0.0,0.0,Feature Addition,FALSE,FALSE,
b045ac18d613e226bf14ff9e3e1b6a0f93c26bae,Aditya Kishore,aditya@maprtech.com,Wed Sep 4 17:30:48 2013 -0700,1378341048,"Resource leak in parquet . hadoop . ParquetFileReader . readFooter ( Configuration , FileStatus )",25,22,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER",1,1,1,0.0,11,73.0,26,0.2279861111111111,0.0,0.0,0.0,None,FALSE,FALSE,
00065cd7c76df68e0c85476880476f44e5e5e36c,Tianshuo Deng,tdeng@twitter.com,Wed Sep 4 15:03:35 2013 -0700,1378332215,"change filter key name to parquet . thrift . column . filter , remove extra filter parameter from ThriftSchemaConverter",13,13,"parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java,CAS_DELIMITER",3,1,3,1.1401156785146092,13,106.66666666666667,22,5.947349537037037,38.0,36.02920268218124,2.0,None,FALSE,FALSE,
d20e5f2c01cd770babbca030f9bec5b2549c78b2,Tianshuo Deng,tdeng@twitter.com,Wed Sep 4 14:03:28 2013 -0700,1378328608,fix tests,6,4,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/util/counters/BenchmarkCounter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedInputFormatTest.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java,CAS_DELIMITER",4,1,4,1.7609640474436812,13,114.25,43,1.8461660879629629,37.0,35.03311289824678,25.0,Corrective,TRUE,TRUE,
459a8a193f8a61e92f6fbc5dbc079b194f25ae3c,Tianshuo Deng,tdeng@twitter.com,Wed Sep 4 12:02:30 2013 -0700,1378321350,"make counter works in DeprecatedInputFormat , which is used by cascading",516,60,"parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/util/BenchmarkCounter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/util/counters/BenchmarkCounter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/util/counters/CounterLoader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/util/counters/ICounter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapred/MapRedCounterAdapter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapred/MapRedCounterLoader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapreduce/MapReduceCounterAdapter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/util/counters/mapreduce/MapReduceCounterLoader.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/DeprecatedInputFormatTest.java,CAS_DELIMITER",13,1,7,2.9621482905257315,11,33.76923076923077,57,15.943623575498576,36.0,34.040753400952866,24.0,None,FALSE,TRUE,"[""d20e5f2c01cd770babbca030f9bec5b2549c78b2""]"
30359b46fd6873defd71d5d3a224cb8675b67339,Tianshuo Deng,tdeng@twitter.com,Thu Aug 29 16:19:24 2013 -0700,1377818364,remove TODOs and fix format,13,16,"parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java,CAS_DELIMITER",3,1,3,1.334599425999111,13,107.66666666666667,19,0.03644675925925926,35.0,33.562287050507194,1.0,Corrective,TRUE,FALSE,
ec4632917549fe10e4cc26c2d6b9064a9b06e5cd,Tianshuo Deng,tdeng@twitter.com,Thu Aug 29 15:26:55 2013 -0700,1377815215,use globbing syntax to specify manual pushdown in ThriftReadSupport,690,148,"parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/TBaseRecordConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/projection/FieldProjectionFilter.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/projection/PathGlobPattern.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/projection/ThriftProjectionException.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/projection/PathGlobPatternTest.java,CAS_DELIMITER",11,2,7,2.965018674030605,13,108.45454545454545,39,42.38743581649831,34.0,32.565502675686865,11.5,None,FALSE,FALSE,
c023d63eaf92b4a9f35c134c81f0fee31de1f6d0,julien,julien@twitter.com,Wed Aug 28 17:31:49 2013 -0700,1377736309,improve thrift error message,38,11,"parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java,CAS_DELIMITER",2,1,2,0.9633355456726842,12,321.0,11,0.9451157407407407,295.0,202.7632122660887,37.0,None,FALSE,FALSE,
69ef1f447b4fbebcc528eab9cb782272eff9cb30,Tianshuo Deng,tdeng@twitter.com,Wed Aug 28 10:52:27 2013 -0700,1377712347,fix file path,1,1,"parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java,CAS_DELIMITER",1,1,1,0.0,13,228.0,17,0.000787037037037037,33.0,31.667614587517583,22.0,Corrective,TRUE,FALSE,
91c17112f18ecae914c7f670439a81dcd4041456,Tianshuo Deng,tdeng@twitter.com,Wed Aug 28 10:51:19 2013 -0700,1377712279,fix projection on required fields and refactored unit tests for column IO,100,62,"parquet-column/src/main/java/parquet/io/ColumnIOFactory.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java,CAS_DELIMITER",3,2,3,0.8509196456731708,13,162.0,44,13.924259259259259,32.0,30.66768014333387,10.5,Corrective,TRUE,FALSE,
71a6d880fb98903240b4bf996ac9d51f9c11a663,julien,julien@twitter.com,Tue Aug 27 22:20:15 2013 -0700,1377667215,add better error message,5,1,"parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java,CAS_DELIMITER",1,1,1,0.0,12,615.0,5,0.039467592592592596,294.0,202.07649198974883,36.0,Feature Addition,FALSE,FALSE,
8a8354b73f61e1aad5a04ced61be5d7fcb26caf5,julien,julien@twitter.com,Tue Aug 27 21:23:25 2013 -0700,1377663805,add better error message,86,2,"parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java,CAS_DELIMITER",1,1,1,0.0,12,531.0,4,0.25136574074074075,293.0,201.09187084883024,35.0,Feature Addition,FALSE,FALSE,
7b2ef26003ab455bb03a696ea6583bcf73c8a9ad,julien,julien@twitter.com,Tue Aug 27 15:21:27 2013 -0700,1377642087,add thrift validation on read,90,46,"parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/struct/ThriftTypeID.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java,CAS_DELIMITER",6,1,5,2.2528200338201945,12,143.0,17,79.3660686728395,292.0,200.18918462765723,34.0,Feature Addition,FALSE,FALSE,
aab7b4b672915fd587bf47640b3a82873ef7aef9,Aniket Mokashi,amokashi@twitter.com,Mon Aug 26 16:08:23 2013 -0700,1377558503,code review comments for stats,8,7,"parquet-pig/src/main/java/parquet/pig/ParquetLoader.java,CAS_DELIMITER",1,1,1,0.0,12,132.0,22,4.677824074074074,14.0,12.820910339484396,8.0,None,FALSE,FALSE,
808a90d9a11a3f17caf3dcdbd461d5b6bfda15e7,Aniket Mokashi,amokashi@twitter.com,Sun Aug 25 12:59:58 2013 -0700,1377460798,changing default block size to 128mb,2,2,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java,CAS_DELIMITER",2,1,1,1.0,10,99.0,21,15.583819444444444,13.0,11.857496309276472,4.0,None,FALSE,FALSE,
b500681226f4a87bed01cdbd99d69e603836cd6d,Aniket Mokashi,aniket486@gmail.com,Wed Aug 21 23:52:19 2013 -0700,1377154339,add getStatistics method to parquetloader,14,2,"parquet-pig/src/main/java/parquet/pig/ParquetLoader.java,CAS_DELIMITER",1,1,1,0.0,12,120.0,21,1.2350578703703703,12.0,10.963808759363875,7.0,Feature Addition,FALSE,FALSE,
9adb8e24baa3909d91691de2ee7faf2a41e6d7d6,Aniket Mokashi,aniket486@gmail.com,Wed Aug 21 15:23:44 2013 -0700,1377123824,code review changes,90,68,"parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/PrimitiveType.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java,CAS_DELIMITER",3,2,3,1.2403523889077457,12,187.0,43,3.2500655864197534,11.0,9.97353076266434,4.5,None,FALSE,TRUE,"[""49f3ad17a066dde80e9d7f84fc859a1afb791c02""]"
8cc147b37b85f22cd6a79d5d8508a1b34e91d679,Remy Pecqueur,r.pecqueur@criteo.com,Wed Aug 21 17:51:00 2013 +0200,1377100260,Add map and list to in / outputformat unit tests,146,42,"parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java,CAS_DELIMITER",4,1,1,1.88196598364922,10,188.0,30,1.262650462962963,13.0,10.616222678223632,13.0,Feature Addition,FALSE,FALSE,
8f93adfd0020939b9a58f092b88a5f62fd14b834,Aniket Mokashi,aniket486@gmail.com,Tue Aug 20 18:13:50 2013 -0700,1377047630,Map key fields should allow other types than strings,333,97,"parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/ColumnIO.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/ColumnIOFactory.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/GroupColumnIO.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/ConversionPatterns.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/GroupType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/PrimitiveType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/Type.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/ParquetLoader.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java,CAS_DELIMITER",20,4,9,2.732264682315038,12,61.7,161,89.77170659722222,10.0,8.995459642806162,1.75,None,FALSE,TRUE,"[""91c17112f18ecae914c7f670439a81dcd4041456"", ""47116ad7ac86c001c2e68bca0e3f75f51488c462"", ""e2d3bb299a29b7df44cef06a555bd1e5c5b775f5"", ""49f3ad17a066dde80e9d7f84fc859a1afb791c02""]"
e5b767ab75e8cb09fe18d2e83d061a0a285f54c8,Remy Pecqueur,r.pecqueur@criteo.com,Tue Aug 20 11:32:47 2013 +0200,1376991167,Add some nested type tests and fix Map handling - Add nested type unit tests to hive - parquet schema converter - Add map and list to the serde unit test,145,59,"parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/TestHiveSchemaConverter.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java,CAS_DELIMITER",8,1,4,2.342341897153961,10,169.625,61,63.43154513888889,12.0,9.646530385557245,12.0,Corrective,TRUE,FALSE,
fb670693ff737e2914f47943181f97ad11a12d5f,Tianshuo Deng,tdeng@twitter.com,Mon Aug 19 12:08:52 2013 -0700,1376939332,fix space format,1,1,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER",1,1,1,0.0,11,111.0,22,0.0751388888888889,30.0,29.388961789593413,19.0,Corrective,TRUE,FALSE,
77bede5537e89d83291f90f1a181d3342bd6b463,Tianshuo Deng,tdeng@twitter.com,Mon Aug 19 10:30:41 2013 -0700,1376933441,add test,6,5,"parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java,CAS_DELIMITER",1,1,1,0.0,8,117.0,12,0.026493055555555554,29.0,28.394342971630167,18.0,Feature Addition,FALSE,FALSE,
4d1b3e06819eb3e2cde75b915115ce22a6580729,Tianshuo Deng,tdeng@twitter.com,Mon Aug 19 09:52:32 2013 -0700,1376931152,add unit test,1,0,"parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java,CAS_DELIMITER",1,1,1,0.0,8,116.0,11,33.98814814814815,27.0,26.39630829123561,16.0,Feature Addition,FALSE,FALSE,
42ad7014390491ace28ac2fc3a36ed6959ee4dbc,Tianshuo Deng,tdeng@twitter.com,Mon Aug 19 09:46:16 2013 -0700,1376930776,fix test file path,1,1,"parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java,CAS_DELIMITER",1,1,1,0.0,11,206.0,15,2.7949652777777776,26.0,25.396616095258878,15.0,Corrective,TRUE,FALSE,
35c419cd8346b7db368bf1dbcfa7836ed32a9544,Tianshuo Deng,tdeng@twitter.com,Fri Aug 16 14:41:31 2013 -0700,1376689291,remove public Constants,23,23,"parquet-hadoop/src/main/java/parquet/hadoop/util/BenchmarkCounter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java,CAS_DELIMITER",2,1,2,0.9986359641585718,11,129.5,19,0.02605324074074074,25.0,24.588080444879136,14.0,None,FALSE,FALSE,
3bebb9a160a3e181445f425a0b04f01f7818c649,Tianshuo Deng,tdeng@twitter.com,Fri Aug 16 14:04:00 2013 -0700,1376687040,fix,6,4,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/util/BenchmarkCounter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java,CAS_DELIMITER",3,1,3,1.1567796494470395,11,123.0,37,7.7464660493827155,24.0,23.58980738051936,13.0,Corrective,TRUE,FALSE,
f8e2658581d8291281969aac53793b921ba49476,Tianshuo Deng,tdeng@twitter.com,Fri Aug 16 10:14:49 2013 -0700,1376673289,fix incrementCounter getConfiguration method to support 2 . 0,20,5,"parquet-hadoop/src/main/java/parquet/hadoop/util/BenchmarkCounter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/util/ContextUtil.java,CAS_DELIMITER",2,1,1,0.904381457724494,11,156.5,7,0.8327662037037037,23.0,22.599925994872176,12.0,Corrective,TRUE,FALSE,
397b4c9b59855db9ef4e27f3c72df1e043340cb4,Tianshuo Deng,tdeng@twitter.com,Thu Aug 15 16:28:01 2013 -0700,1376609281,formatting,39,39,"parquet-hadoop/src/main/java/parquet/hadoop/util/BenchmarkCounter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java,CAS_DELIMITER",2,1,2,0.7793498372920852,11,129.0,14,0.12101273148148148,21.0,20.64497043971457,10.0,None,FALSE,FALSE,
9394c097b9c19070fffd8143dcdcb4c60765be2d,Tianshuo Deng,tdeng@twitter.com,Thu Aug 15 15:55:47 2013 -0700,1376607347,fix test,15,14,"parquet-hadoop/src/test/java/parquet/hadoop/example/GroupReadSupportTest.java,CAS_DELIMITER",1,1,1,0.0,1,47.0,1,0.020902777777777777,18.0,17.64620683030047,7.0,Corrective,TRUE,FALSE,
ea62ffe142871844b605d5300bd2a07dff785f17,Tianshuo Deng,tdeng@twitter.com,Thu Aug 15 15:25:41 2013 -0700,1376605541,add unit test,47,0,"parquet-hadoop/src/test/java/parquet/hadoop/example/GroupReadSupportTest.java,CAS_DELIMITER",1,1,1,0.0,1,0.0,0,0.0,17.0,16.64719800386275,6.0,Feature Addition,FALSE,FALSE,
2cc9321b41806955d55358e361d454d31f4f0627,Tianshuo Deng,tdeng@twitter.com,Thu Aug 15 12:13:15 2013 -0700,1376593995,add test for no benchmark counters,18,6,"parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java,CAS_DELIMITER",1,1,1,0.0,11,190.0,11,0.0059722222222222225,15.0,14.652864645194661,4.0,Feature Addition,FALSE,FALSE,
43ad5e5257e03e8fb6ad738d61bf1e4ae132b6fc,Tianshuo Deng,tdeng@twitter.com,Thu Aug 15 12:04:39 2013 -0700,1376593479,fix test,1,1,"parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java,CAS_DELIMITER",1,1,1,0.0,11,190.0,10,0.0009722222222222222,14.0,13.653098952120267,3.0,Corrective,TRUE,FALSE,
a274684f2257aecb27404130a938758cd36504e9,Tianshuo Deng,tdeng@twitter.com,Thu Aug 15 12:03:15 2013 -0700,1376593395,added 3 counters to parquet for benchmarking bytes read and time spent,159,34,"parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/util/BenchmarkCounter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/util/ContextUtil.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java,CAS_DELIMITER",6,1,3,1.6755567645416998,11,94.33333333333333,57,32.41344328703704,13.0,12.653134432188047,2.0,Feature Addition,FALSE,TRUE,"[""43ad5e5257e03e8fb6ad738d61bf1e4ae132b6fc"", ""f8e2658581d8291281969aac53793b921ba49476"", ""3bebb9a160a3e181445f425a0b04f01f7818c649"", ""91c17112f18ecae914c7f670439a81dcd4041456""]"
6ff02643a66b1e25ac3edca94433ac7c7e781f7d,Tianshuo Deng,tdeng@twitter.com,Thu Aug 15 09:23:01 2013 -0700,1376583781,Implemented partial schema for GroupReadSupport,3,2,"parquet-hadoop/src/main/java/parquet/hadoop/example/GroupReadSupport.java,CAS_DELIMITER",1,1,1,0.0,1,60.0,6,148.9222800925926,12.0,11.656891478697819,1.0,None,FALSE,FALSE,
af45d9cc20d31f5fd103dac3de8b850d00b18f17,Tianshuo Deng,tdeng@twitter.com,Wed Aug 14 17:41:36 2013 -0700,1376527296,fix bug of wrong column metadata size,2,2,"parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER",1,1,1,0.0,10,56.0,20,25.760046296296295,11.0,10.677216018598676,0.0,Corrective,TRUE,FALSE,
12bc29a405b6e0bcf25c7412f1b3b6649c6819c6,julien,julien@twitter.com,Tue Aug 13 15:43:15 2013 -0700,1376433795,split out method to facilitate the inliner job,42,37,"parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/PerfTest.java,CAS_DELIMITER",2,1,2,0.09794058271817413,10,146.5,35,10.234502314814815,291.0,204.71972093707114,115.0,None,FALSE,FALSE,
87228ebd3a778ec4abacd9288a4872d7ec2c95f0,keano,alantkeane@gmail.com,Tue Aug 13 23:30:35 2013 +0100,1376433035,refactoring dictionary encoding for non string types after comments #127,555,377,"parquet-column/src/main/java/parquet/column/Encoding.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/PlainValuesDictionary.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java,CAS_DELIMITER",5,1,4,1.455439281580268,9,279.2,64,1.2591319444444444,2.0,1.9128262624474255,1.0,None,FALSE,TRUE,"[""b3efce20048307c7b7dd6aec2dcb08529c62320f"", ""562e8111552be8fbbe701c02dddfa3a3496a5f47"", ""0a36e35cf6c52a9e79fdfbbb8584a8adc3a17b6c"", ""d33aa40c7e9e9f577bfe05f0a15eb9687ad22cba""]"
8d6661106c2511b0b9525016278d5f2ec3947956,keano,alantkeane@gmail.com,Mon Aug 12 17:17:26 2013 +0100,1376324246,"adding dictionary encoding for long , double , int , float",909,199,"parquet-column/src/main/java/parquet/column/Encoding.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/PlainBinaryDictionary.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/PlainValuesDictionary.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java,CAS_DELIMITER",7,1,4,2.1200766076311752,9,109.57142857142857,74,35.646967592592596,1.0,0.919169403830502,0.0,Feature Addition,FALSE,FALSE,
f327ecff9dceb2013237a89a0b0740ffea558a0c,Tianshuo Deng,tdeng@twitter.com,Fri Aug 9 14:00:46 2013 -0700,1376082046,format,1,12,"parquet-cascading/src/test/java/parquet/cascading/TestParquetTupleScheme.java,CAS_DELIMITER,parquet-scrooge/src/test/parquet/scrooge/ParquetScroogeSchemeTest.java,CAS_DELIMITER",2,2,2,0.6193821946787638,1,5.5,1,0.0022858796296296295,9.0,8.825596376090065,3.0,None,FALSE,FALSE,
7e16d31a2729e06c9c9f753af2bbe47b3751fa44,Tianshuo Deng,tdeng@twitter.com,Fri Aug 9 13:58:58 2013 -0700,1376081938,better format,32,35,"parquet-cascading/src/test/java/parquet/cascading/ParquetTupleSchemeTest.java,CAS_DELIMITER,parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java,CAS_DELIMITER",2,1,1,0.8395304981054318,1,55.0,2,0.003321759259259259,8.0,7.825626024720239,4.0,Perfective,FALSE,FALSE,
f17b83c6a6a84a5462263593bdf106804390c648,Tianshuo Deng,tdeng@twitter.com,Fri Aug 9 13:54:11 2013 -0700,1376081651,added unit tests for parquet cascading,123,2,"parquet-cascading/src/test/java/parquet/cascading/ParquetTupleSchemeTest.java,CAS_DELIMITER,parquet-cascading/src/test/java/parquet/cascading/TestParquetTBaseScheme.java,CAS_DELIMITER,parquet-scrooge/src/test/parquet/scrooge/ParquetScroogeSchemeTest.java,CAS_DELIMITER",3,2,2,1.1500099286439809,1,0.0,0,0.0,7.0,6.825695713384923,1.5,Feature Addition,FALSE,FALSE,
a9e2c7d5fc862fe422624e29b7bcb6a8dafdb2da,Nong Li,nong@cloudera.com,Wed Aug 7 23:33:48 2013 -0700,1375943628,Fix Short and Byte types in Hive SerDe .,79,2,"parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java,CAS_DELIMITER",2,1,2,0.3809465857053901,9,21.5,7,45.78282407407407,3.0,2.795024419893455,0.0,Corrective,TRUE,FALSE,
a54414c908d68125994c9d3199f95000dc53db02,Tianshuo Deng,tdeng@twitter.com,Wed Aug 7 15:41:48 2013 -0700,1375915308,"use Mockito to mock varibles in test , fix format and variable name",8,8,"parquet-cascading/src/test/java/parquet/cascading/ParquetTBaseSchemeTest.java,CAS_DELIMITER",1,1,1,0.0,3,44.0,1,0.02013888888888889,6.0,5.860994039581737,2.0,Corrective,TRUE,FALSE,
86ae4f87c4254a74006f807aed8199d3138cc4ad,Tianshuo Deng,tdeng@twitter.com,Wed Aug 7 15:12:48 2013 -0700,1375913568,fix wrong converter : use TBaseRecordConverter for ParquetTBaseScheme ; Add unit test for getting correct record converter,46,2,"parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java,CAS_DELIMITER,parquet-cascading/src/test/java/parquet/cascading/ParquetTBaseSchemeTest.java,CAS_DELIMITER",2,1,2,0.41381685030363374,3,33.0,6,0.5405439814814815,5.0,4.861310023129562,1.0,Corrective,TRUE,FALSE,
28da58cd571f5c23397f3865333c24d434e7aa89,Nong Li,nong@cloudera.com,Tue Aug 6 19:16:00 2013 -0700,1375841760,Fix Snappy compressor in parquet - hadoop .,151,26,"parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedCompressorStream.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/codec/NonBlockedDecompressorStream.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCodec.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCompressor.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyDecompressor.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyUtil.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestSnappyCodec.java,CAS_DELIMITER",7,1,2,2.41338859436049,8,85.28571428571429,17,20.107647156084656,4.0,3.806722731533106,2.0,Corrective,TRUE,FALSE,
1fc0698ed64514c9e30de7892c3a1d142f3f5469,Nong Li,nong@cloudera.com,Tue Aug 6 17:14:45 2013 -0700,1375834485,Fix RLE bug with partial literal groups at end of stream .,38,7,"parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java,CAS_DELIMITER",5,1,3,1.8993640083276881,8,117.2,32,31.55296527777778,2.0,1.8040880236399364,0.0,Corrective,TRUE,FALSE,
c126179781821c1aba1140184be1e28b3d1924c9,Tianshuo Deng,tdeng@twitter.com,Tue Aug 6 13:16:02 2013 -0700,1375820162,remove raw type for ParquetTbaseScheme to support thrift0 . 5 ; remove scalding dependency,1,1,"parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java,CAS_DELIMITER",1,1,1,0.0,2,66.0,5,99.87217592592593,4.0,3.8753520087920705,0.0,None,FALSE,FALSE,
f8dd20889316262aaf2d8c73eeca092e27faad0e,julien,julien@twitter.com,Sat Aug 3 10:10:05 2013 -0700,1375549805,simplify end of page count,4,5,"parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java,CAS_DELIMITER",1,1,1,0.0,10,299.0,19,0.006273148148148148,289.0,206.92761298660227,113.0,None,FALSE,TRUE,
ecb2daca5bd6e2828e2a5079d0f2f326737415c9,julien,julien@twitter.com,Sat Aug 3 10:01:03 2013 -0700,1375549263,refactro column reader,201,169,"parquet-column/src/main/java/parquet/column/ColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/filter/AndRecordFilter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/filter/ColumnRecordFilter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/filter/PagedRecordFilter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/filter/RecordFilter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/FilteredRecordReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/MessageColumnIO.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/mem/TestMemPageStore.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/page/mem/MemPageStore.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/PerfTest.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestFiltered.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java,CAS_DELIMITER",20,4,10,3.18000116068083,10,66.8,178,41.40929918981482,288.0,205.93022017891911,46.75,None,FALSE,FALSE,
7d1fe7846a7973cccb683ecb8201c2b03fbc7e60,Tianshuo Deng,tdeng@twitter.com,Fri Jul 26 09:55:21 2013 -0700,1374857721,"remove space , add braces for readability",7,6,"parquet-pig/src/main/java/parquet/pig/ParquetLoader.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java,CAS_DELIMITER",2,1,2,0.8904916402194913,10,154.5,35,0.6703703703703703,3.0,2.993428934770508,3.0,Feature Addition,FALSE,FALSE,
504833e34a16b58c60fd1e43e771c258b2bebeb9,Tom White,tom@cloudera.com,Fri Jul 26 16:00:13 2013 +0100,1374850813,Make reader independent,195,135,"parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java,CAS_DELIMITER",4,1,1,1.2454783777886298,10,62.75,30,0.4706221064814815,14.0,11.267965257164233,5.0,None,FALSE,TRUE,
a7c42f93d0a2278970beaddaec26071efc4436ad,Tom White,tom@cloudera.com,Fri Jul 26 15:21:00 2013 +0100,1374848460,Make writer independent,145,96,"parquet-hadoop/src/main/java/parquet/hadoop/InternalParquetRecordWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java,CAS_DELIMITER",3,1,1,1.1593139406899093,10,44.666666666666664,22,23.506732253086415,13.0,10.26864514348761,4.0,None,FALSE,TRUE,
7a4b5626cbdfad9b4429e47fc4b6da37516a09b9,Aniket Mokashi,amokashi@twitter.com,Thu Jul 25 19:47:32 2013 -0700,1374806852,add if debug statements to parquetloader,8,7,"parquet-pig/src/main/java/parquet/pig/ParquetLoader.java,CAS_DELIMITER",1,1,1,0.0,10,120.0,18,0.12318287037037037,9.0,8.610054147323757,4.0,Corrective,TRUE,FALSE,
c4e8d261c322aca17c8789c61b4e4289dfd3b675,Tianshuo Deng,tdeng@twitter.com,Thu Jul 25 16:50:09 2013 -0700,1374796209,"optimize code format , add log info to indicate boolean will be convert to int when compatible mode is on",9,9,"parquet-pig/src/main/java/parquet/pig/ParquetLoader.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java,CAS_DELIMITER",2,1,1,0.9910760598382222,10,75.0,31,0.04003472222222222,2.0,1.9992662883036167,2.0,Feature Addition,FALSE,FALSE,
eac5aecfa40273edab7645ba81eb4816ceac9d98,Tianshuo Deng,tdeng@twitter.com,Thu Jul 25 15:52:30 2013 -0700,1374792750,1 . return compatible schema when compatible flag is set . 2 . tupleConverter set to return IntegerConverter when flag is set,30,12,"parquet-pig/src/main/java/parquet/pig/ParquetLoader.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java,CAS_DELIMITER",3,1,2,1.3959291762837418,10,106.66666666666667,44,5.522646604938273,1.0,0.9994855197728794,1.0,None,FALSE,FALSE,
4bc24334231a0565fcd6bc1126c6f1f7e16c3f3f,Tianshuo Deng,tdeng@twitter.com,Thu Jul 25 11:21:57 2013 -0700,1374776517,"[ fix validation script ] when boolean value is null , set it to 0 for being compatible .",3,0,"parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java,CAS_DELIMITER",1,1,1,0.0,1,182.0,14,37.89679398148148,0.0,0.0,0.0,Corrective,TRUE,FALSE,
be49204476dbf293cadc35528d3eaec5ce384678,julien,julien@twitter.com,Thu Jul 25 09:44:26 2013 -0700,1374770666,change default page size and add some doc,8,8,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java,CAS_DELIMITER",6,1,1,2.452819531114783,10,82.5,86,19.33849151234568,287.0,208.72098853481,67.0,Feature Addition,FALSE,FALSE,
67b8423a653fbd4c191b2c886b5c5b71143698a3,julien,julien@twitter.com,Wed Jul 24 09:33:26 2013 -0700,1374683606,ThriftParquetReader and ThriftParquetWriter,212,5,"parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftParquetReader.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftParquetWriter.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestThriftParquetReaderWriter.java,CAS_DELIMITER",5,1,3,2.202112105693541,8,37.8,15,29.323599537037033,286.0,208.1509941039494,32.0,None,FALSE,FALSE,
c1d67ee581df3581882efbb875d65bd063ec6d33,Matt Massie,massie@cs.berkeley.edu,Sat Jul 20 16:12:23 2013 -0700,1374361943,Add support for predicate pushdown in ParquetInputFormat This commit allows users to define an UnboundRecordFilter to be used when reading Parquet records from the ParquetInputFormat .,127,44,"parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/util/ConfigurationUtil.java,CAS_DELIMITER",3,2,3,1.533737821635435,11,99.33333333333333,26,0.8931134259259258,3.0,2.8392186834817124,1.5,Feature Addition,FALSE,TRUE,"[""49f3ad17a066dde80e9d7f84fc859a1afb791c02""]"
f7d098778fbb7b484e1f0c20f14b2260ec625a72,julien,julien@twitter.com,Fri Jul 19 23:45:47 2013 -0700,1374302747,fix compilation issue with 1 . 6,20,10,"parquet-pig/src/main/java/parquet/pig/ParquetLoader.java,CAS_DELIMITER",1,1,1,0.0,10,94.0,15,0.012951388888888889,285.0,209.04143249661226,41.0,Corrective,TRUE,FALSE,
6b5b8b214ebb6cc8ec3f7dd521bc072e973b5378,julien,julien@twitter.com,Fri Jul 19 23:27:08 2013 -0700,1374301628,improve memory usage of metadata,476,160,"parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkProperties.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnPath.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/metadata/EncodingList.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/ParquetLoader.java,CAS_DELIMITER",13,2,5,2.8607170693900135,10,47.30769230769231,132,12.288589743589743,283.0,207.04699730075455,52.0,None,FALSE,TRUE,"[""f7d098778fbb7b484e1f0c20f14b2260ec625a72"", ""af45d9cc20d31f5fd103dac3de8b850d00b18f17""]"
964e5da655a184a939eac7770f20acd4ef565ef6,Matt Massie,massie@cs.berkeley.edu,Thu Jul 18 16:39:23 2013 -0700,1374190763,Add support for schema projection in Avro This commit updates the AvroReadSupport and AvroParquetInputFormat classes to allow users to request a schema projection .,67,33,"parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java,CAS_DELIMITER",4,1,2,1.7689099512716948,8,73.5,13,5.41243923611111,2.0,1.8539512137384366,2.0,Feature Addition,FALSE,FALSE,
02d5ed256de093ccd8a6c3705dfae6cff9ae22c6,julien,julien@twitter.com,Wed Jul 17 11:24:53 2013 -0700,1374085493,fix merge conflict,11,54,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER",1,1,1,0.0,10,184.0,21,1.7604513888888889,281.0,206.12781471888727,63.0,Corrective,TRUE,FALSE,
aa0bc1396bdbbc736f062be9a07675c021380b5b,Matt Massie,massie@cs.berkeley.edu,Wed Jul 17 11:18:36 2013 -0700,1374085116,"Add Avro specific support to AvroParquet { Input , Output } Format This commit generalizes AvroIndexedRecordConverter , AvroReadSupport and AvroRecordMaterializer to enable Parquet to read / write Avro specific objects .",160,13,"parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroRecordMaterializer.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestSpecificInputOutputFormat.java,CAS_DELIMITER",4,1,2,0.8399394432209654,8,39.75,10,12.569019097222222,1.0,0.8597592668600234,1.0,Feature Addition,FALSE,FALSE,
61f2c86a40fa9904ede235f10fc02f6818504346,julien,julien@twitter.com,Wed Jul 17 11:07:16 2013 -0700,1374084436,add buffer to protocol pipe,368,16,"parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/BufferedProtocolReadToWrite.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ProtocolPipe.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ProtocolReadToWrite.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java,CAS_DELIMITER",7,1,3,1.7057908101797965,4,81.0,18,13.750917658730158,280.0,205.13299871571098,31.0,Feature Addition,FALSE,FALSE,
39217427aefa710e4543cd6e5310b84d14246453,Aniket Mokashi,amokashi@twitter.com,Mon Jul 15 17:09:50 2013 -0700,1373933390,small fixes for hadoop2 failure,3,13,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER",1,1,1,0.0,10,194.0,20,0.20711805555555557,8.0,7.844524168167529,3.0,Corrective,TRUE,FALSE,
5a5bb7f26efe4a31d0de99e6b4c81199752cc118,Aniket Mokashi,amokashi@twitter.com,Mon Jul 15 12:11:35 2013 -0700,1373915495,initial commit for recursive listing,59,1,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER",1,1,1,0.0,10,136.0,19,3.884212962962963,7.0,6.848893723457804,2.0,Feature Addition,FALSE,TRUE,"[""39217427aefa710e4543cd6e5310b84d14246453"", ""02d5ed256de093ccd8a6c3705dfae6cff9ae22c6""]"
d8e6ba34048a1c9eeb8613aa538b976616b3a58f,Aniket Mokashi,amokashi@twitter.com,Sun Jul 14 22:51:56 2013 -0700,1373867516,added code review changes,11,164,"parquet-pig/src/main/java/parquet/pig/ParquetLoader.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java,CAS_DELIMITER",3,1,2,0.6054266419690637,10,96.66666666666667,27,2.3145023148148147,6.0,5.859109460682427,3.0,Feature Addition,FALSE,FALSE,
3f19ce3df0f46399ae8c6fead520dd27049ca3d6,julien,julien@twitter.com,Fri Jul 12 16:41:33 2013 -0700,1373672493,reduce size of splits,146,61,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/metadata/BlockMetaData.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java,CAS_DELIMITER",6,1,2,0.8761938952399085,10,56.333333333333336,58,37.07396797839506,282.0,209.18712950149452,64.0,None,FALSE,FALSE,
feecf58ff8c992ba0ebbaad688e427de8cec93ef,Aniket Mokashi,amokashi@twitter.com,Fri Jul 12 15:19:03 2013 -0700,1373667543,adding tests and removing comments,154,27,"parquet-pig/src/main/java/parquet/pig/ParquetLoader.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java,CAS_DELIMITER",3,1,2,0.24038762978675488,10,54.333333333333336,24,0.9815277777777777,5.0,4.895636787022839,2.0,Feature Addition,FALSE,FALSE,
64814a6e48f2f68a0f7b7bb6f3ff0deb7fe8007a,julien,julien@twitter.com,Thu Jul 11 21:38:04 2013 -0700,1373603884,make fields final,2,2,"parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER",1,1,1,0.0,4,96.0,18,0.41912037037037037,275.0,202.4503482033843,60.0,None,FALSE,FALSE,
5214a653c0aad2bd2dea023a2aaf9b5fc1295bc3,Aniket Mokashi,amokashi@twitter.com,Thu Jul 11 16:09:19 2013 -0700,1373584159,minor fixes and refactor,24,11,"parquet-pig/src/main/java/parquet/pig/ParquetLoader.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java,CAS_DELIMITER",2,1,1,0.9994110647387553,10,50.5,21,57.04640046296296,4.0,3.9083516897401482,1.0,Corrective,TRUE,FALSE,
fc56631a84c4dfe20300698153a86a53cc6af603,Aniket Mokashi,amokashi@twitter.com,Thu Jul 11 14:58:19 2013 -0700,1373579899,Initial checkin for load pushdown,179,22,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/ParquetLoader.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TestParquetLoader.java,CAS_DELIMITER",3,2,3,1.5540872238830294,10,35.333333333333336,28,21.819297839506174,3.0,2.9088679532372317,0.5,Feature Addition,FALSE,FALSE,
79a310624f843cdcd59dd27aa41ec72c8527d8b6,julien,julien@twitter.com,Thu Jul 11 11:34:32 2013 -0700,1373567672,reduce memory usage of metadata,85,2,"parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER",1,1,1,0.0,4,13.0,17,63.57357638888889,274.0,201.62528945467085,59.0,None,FALSE,TRUE,
4de27444249d45f9fd4e57297f04025b66609ea1,julien,julien@twitter.com,Thu Jul 11 10:54:00 2013 -0700,1373565240,fix bad merge,2,0,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER",1,1,1,0.0,9,90.0,17,0.06039351851851852,273.0,200.63697245499517,58.0,Corrective,TRUE,FALSE,
adb46b694e94dc906922591f439997e7246d36eb,julien,julien@twitter.com,Thu Jul 11 09:27:02 2013 -0700,1373560022,make splits report actual length,37,4,"parquet-column/src/main/java/parquet/schema/GroupType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/MessageType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/PrimitiveType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/Type.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java,CAS_DELIMITER",6,2,3,2.375974399172917,9,51.833333333333336,57,57.37414737654321,272.0,199.66187819743013,83.0,None,FALSE,FALSE,
43dc88d41e345cfd5eb2c4e62dfa0cca183bdf4e,keano,alantkeane@gmail.com,Thu Jul 11 14:56:50 2013 +0100,1373551010,adding projection support for thrift types,167,26,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetToThriftReadProjection.java,CAS_DELIMITER",5,2,5,1.6323200173306014,8,214.4,36,47.95982407407407,0.0,0.0,0.0,Feature Addition,FALSE,FALSE,
806b548153532021d80de45741e51e0d2622f3e3,julien,julien@twitter.com,Tue Jul 9 18:58:56 2013 -0700,1373421536,fix for schema compatibility,4,4,"parquet-column/src/main/java/parquet/io/ColumnIOFactory.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/GroupColumnIO.java,CAS_DELIMITER",2,1,1,1.0,7,26.5,10,69.16817708333333,271.0,199.3207800740776,108.0,Corrective,TRUE,TRUE,
653a4cf53bd9ed4fd4002c8f5d87a11577747a6d,julien,julien@twitter.com,Mon Jul 8 15:08:22 2013 -0700,1373321302,collapse small classes into one class,49,161,"parquet-column/src/main/java/parquet/column/Encoding.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/DoublePlainValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/FloatPlainValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/IntegerPlainValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/LongPlainValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java,CAS_DELIMITER",6,1,2,2.4637379170892975,7,53.5,25,0.09979166666666667,269.0,197.7952349823677,106.0,None,FALSE,FALSE,
caa8e5113f56af3e186925668da2a78dc8640380,julien,julien@twitter.com,Mon Jul 8 12:44:40 2013 -0700,1373312680,split Plain reader so that the reader knows what type it's reading,170,40,"parquet-column/src/main/java/parquet/column/Encoding.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/DoublePlainValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/FloatPlainValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/IntegerPlainValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/LongPlainValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java,CAS_DELIMITER",6,1,2,2.5273084147505696,7,31.833333333333332,19,3.509527391975309,268.0,196.83578228168656,105.0,None,FALSE,FALSE,
f52a26e1a32aadf4ec6713ae12ad0d5cedeca9ed,Jacob,jacob_metcalf@hotmail.com,Sat Jul 6 15:14:14 2013 +0100,1373120054,Renamed checkValueRead .,10,10,"parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java,CAS_DELIMITER",1,1,1,0.0,7,249.0,15,2.9045717592592593,7.0,6.805295870154225,4.0,None,FALSE,FALSE,
c4b14fbc4d20034596ad56825349976e4805f456,Jacob,jacob_metcalf@hotmail.com,Sat Jul 6 15:05:15 2013 +0100,1373119515,Adding APL headers and test for union schema creation .,337,0,"parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/Ints.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/filter/AndRecordFilter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/filter/ColumnPredicates.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/filter/ColumnRecordFilter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/filter/PagedRecordFilter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/filter/RecordFilter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/filter/UnboundRecordFilter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/FilteredRecordReader.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestFiltered.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCodec.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCompressor.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyDecompressor.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyUtil.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestSnappyCodec.java,CAS_DELIMITER",22,3,10,4.453643258253953,8,92.81818181818181,55,13.07412826178451,6.0,5.805408971769162,2.6666666666666665,Feature Addition,FALSE,FALSE,
992a47e512a077ac95fcb265e7ee05236a788f6e,julien,julien@twitter.com,Wed Jul 3 09:31:39 2013 -0700,1372869099,fix call to converter,1,1,"parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java,CAS_DELIMITER",1,1,1,0.0,7,249.0,14,0.7350231481481482,267.0,197.93067558429436,104.0,Corrective,TRUE,FALSE,
efc59829cfbf19de248c9fdadb39486382c2a457,julien,julien@twitter.com,Tue Jul 2 18:26:08 2013 -0700,1372814768,fix schema compat,26,24,"parquet-column/src/main/java/parquet/column/page/Page.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/ColumnIOFactory.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER",3,1,3,0.566090653034748,7,100.33333333333333,25,36.84875,266.0,197.18866462946588,103.0,Corrective,TRUE,TRUE,"[""806b548153532021d80de45741e51e0d2622f3e3""]"
707bdf04d31fea4174c8078ed449121899dfc01c,julien,julien@twitter.com,Tue Jul 2 16:07:14 2013 -0700,1372806434,add negative tests,21,0,"parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER",1,1,1,0.0,7,212.0,18,1.2357060185185185,265.0,196.22803462239978,102.0,Feature Addition,FALSE,FALSE,
94afb195dfae10fc40699f3c0efc31bb8f23f51a,julien,julien@twitter.com,Tue Jul 2 15:53:13 2013 -0700,1372805593,fix dictionary decoding bug when more than one encoding is used,19,3,"parquet-column/src/main/java/parquet/column/Encoding.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java,CAS_DELIMITER",2,1,2,0.9940302114769565,7,204.5,25,1.5079166666666666,264.0,195.23198174454492,101.0,Corrective,TRUE,FALSE,
7b470794cde3f488f863b276721c930ab50a3c58,Aniket Mokashi,amokashi@twitter.com,Mon Jul 1 14:17:33 2013 -0700,1372713453,Should not write data if the RL / DL is all zeroes,20,8,"parquet-column/src/main/java/parquet/column/Encoding.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java,CAS_DELIMITER",2,1,2,0.5916727785823275,5,121.5,28,28.236903935185186,1.0,0.9627368101759963,1.0,None,FALSE,FALSE,
08b7aebb91af31cea3f143b4c464e853d97ad82e,julien,julien@twitter.com,Mon Jul 1 10:27:49 2013 -0700,1372699669,support for schema compatibility,196,26,"parquet-column/src/main/java/parquet/io/ColumnIOFactory.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/Type.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java,CAS_DELIMITER",7,2,4,1.8359172284396073,7,55.142857142857146,65,43.728973214285716,263.0,194.72704702687506,77.5,None,FALSE,FALSE,
1d7a5c33c935710ac8e5fa722d77e23fe55d5c5e,Jacob,jacob_metcalf@hotmail.com,Mon Jul 1 01:06:05 2013 +0100,1372637165,Fixing after code reviews,438,217,"parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroRecordMaterializer.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/filter/ColumnPredicates.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/filter/ColumnRecordFilter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/filter/NullRecordFilter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/filter/PagedRecordFilter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/filter/RecordFilter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/filter/UnboundRecordFilter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/FilteredRecordReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/MessageColumnIO.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestFiltered.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java,CAS_DELIMITER",23,3,7,3.610105904758056,7,65.6086956521739,109,11.798166264090183,5.0,4.8926206733667925,1.6666666666666667,Corrective,TRUE,FALSE,
7b742900d565271408c87df6b995d9157b9c4354,Nong Li,nong@cloudera.com,Fri Jun 28 14:55:17 2013 -0700,1372456517,Fixed test case .,6,4,"parquet-hadoop/src/test/java/parquet/hadoop/TestSnappyCodec.java,CAS_DELIMITER",1,1,1,0.0,5,65.0,1,1.0808912037037037,1.0,0.9970473979121127,1.0,Corrective,TRUE,FALSE,
e440108de57199c12d66801ca93804086e7f7632,Nong Li,nong@cloudera.com,Thu Jun 27 12:58:48 2013 -0700,1372363128,Add support for snappy compression .,454,6,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCodec.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyCompressor.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyDecompressor.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/codec/SnappyUtil.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/metadata/CompressionCodecName.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestSnappyCodec.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java,CAS_DELIMITER",8,1,5,2.265630136472482,5,29.125,17,27.35080584490741,0.0,0.0,0.0,Feature Addition,FALSE,TRUE,"[""7b742900d565271408c87df6b995d9157b9c4354"", ""28da58cd571f5c23397f3865333c24d434e7aa89""]"
4cf6ae1b5de1293eaed6e409a7a69c1ce2aac316,Mickael Lacour,m.lacour@criteo.com,Tue Jun 25 16:26:36 2013 +0200,1372170396,Code review - Add todo - Add javadoc - Rename class - Rename method - Improve tests,104,165,"parquet-column/src/main/java/parquet/io/EmptyRecordReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/MessageColumnIO.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java,CAS_DELIMITER",11,2,6,2.6729761525731752,9,142.27272727272728,79,9.846864478114478,22.0,19.827364063722325,11.0,Feature Addition,FALSE,FALSE,
ac5cbd1a48f12a0a431af07c9867b0b0ae04eceb,Jacob,jacob_metcalf@hotmail.com,Sun Jun 23 16:13:48 2013 +0100,1372000428,Implmented more efficient skip algorithm,162,20,"parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/ValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java,CAS_DELIMITER",6,1,4,2.126810871608444,6,53.0,38,26.592447916666668,4.0,3.9912335645280628,1.0,None,FALSE,FALSE,
8285b62ceafe3fe096ebe1836142445acf0a9586,Jacob,jacob_metcalf@hotmail.com,Sun Jun 23 14:13:12 2013 +0100,1371993192,"Fixed bug querying on Name , Url",75,41,"parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/filter/ColumnRecordFilter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestFiltered.java,CAS_DELIMITER",4,1,4,1.0426533302297216,5,96.75,25,1.059039351851852,3.0,2.992147564667252,0.0,Corrective,TRUE,FALSE,
f3ed65beddc41314fc19fa2a237d3379d1bdf557,Davide Savazzi,davide@davidesavazzi.net,Sun Jun 23 00:32:00 2013 +0200,1371940320,fix ValueStat max value,20,2,"parquet-pig/src/main/java/parquet/pig/summary/ValueStat.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/summary/TestSummary.java,CAS_DELIMITER",2,1,2,0.6840384356390417,1,0.0,2,122.08211805555555,0.0,0.0,0.0,Corrective,TRUE,FALSE,
61239a0aa5d41e731b6b2a53df4da2b953abe1dd,Jacob,jacob_metcalf@hotmail.com,Sat Jun 22 16:47:27 2013 +0100,1371916047,Added avro specific functionality,104,0,"parquet-avro/src/test/java/parquet/avro/TestSpecificReadWrite.java,CAS_DELIMITER",1,1,1,0.0,1,0.0,0,0.0,2.0,1.9994658082807821,1.0,Feature Addition,FALSE,FALSE,
ef5c143d0ce9fc825a0ef418c584f1c3a491435d,Jacob,jacob_metcalf@hotmail.com,Sat Jun 22 16:05:50 2013 +0100,1371913550,Added avro specific functionality,51,22,"parquet-avro/src/main/java/parquet/avro/AvroIndexedRecordConverter.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroRecordMaterializer.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java,CAS_DELIMITER",8,1,1,2.6411233355893344,6,53.875,27,34.81392361111111,1.0,0.9996240949346198,0.0,Feature Addition,FALSE,FALSE,
5f0f929e42c9a0a8cf3a7bf418a252aa7e4a1168,Jacob,jacob_metcalf@hotmail.com,Sat Jun 22 12:48:11 2013 +0100,1371901691,Added filtering functionality,524,39,"parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/ColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/filter/AndRecordFilter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/filter/ColumnRecordFilter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/filter/NullRecordFilter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/filter/PagedRecordFilter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/filter/RecordFilter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/filter/UnboundRecordFilter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/MessageColumnIO.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestFiltered.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java,CAS_DELIMITER",14,3,7,3.29434585473794,5,23.714285714285715,63,16.452673611111113,0.0,0.0,0.0,Feature Addition,FALSE,TRUE,"[""8285b62ceafe3fe096ebe1836142445acf0a9586"", ""1d7a5c33c935710ac8e5fa722d77e23fe55d5c5e"", ""b11e2a005014ecd827855dde9ce4d50b1f58aa4b""]"
2525587f8290908229c4582a2c3b0ea54067428d,Remy Pecqueur,r.pecqueur@criteo.com,Fri Jun 21 13:47:46 2013 +0200,1371815266,"Update getSplits in DeprecatedParquetInputFormat - In the case of a FileSplit , do not get the blocks , and instead compute directly from the split offset / length - Add javadoc",20,13,"parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java,CAS_DELIMITER",1,1,1,0.0,2,359.0,21,0.11201388888888889,11.0,10.120663450916268,11.0,Feature Addition,FALSE,FALSE,
eccbba1c124d1b22553cb3ef64a883f23e7dbe84,Mickael Lacour,m.lacour@criteo.com,Thu Jun 20 11:57:00 2013 +0200,1371722220,"Improve speed for queries like count ( 0 ) , in which we only need the number of lines",55,3,"parquet-column/src/main/java/parquet/io/MessageColumnIO.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/RecordReaderEmpty.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java,CAS_DELIMITER",3,1,1,0.8304809771649899,8,-6.666666666666667,32,-7.059760802469135,20.0,18.083179438340483,0.0,None,FALSE,FALSE,
21b0d9787694f3d87e4068cfce01b51749854495,Mickael Lacour,m.lacour@criteo.com,Wed Jun 19 19:28:06 2013 +0200,1371662886,Update with advices from Julien,34,31,"parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java,CAS_DELIMITER",4,1,3,1.623573605169152,2,197.75,38,4.009649884259259,19.0,17.11412610561213,19.0,None,FALSE,FALSE,
3089e834ae9bfbd212a77e12c9f9b9cf8917d63d,Mickael Lacour,m.lacour@criteo.com,Wed Jun 19 17:07:38 2013 +0200,1371654458,Manage count 0,14,10,"parquet-hive/src/main/java/parquet/hive/read/DataWritableReadSupport.java,CAS_DELIMITER",1,1,1,0.0,2,36.0,4,0.26797453703703705,18.0,16.118263183243588,18.0,None,FALSE,FALSE,
82fff8c856abc84159c09aff4670fc7c76489be5,Remy Pecqueur,r.pecqueur@criteo.com,Wed Jun 19 10:41:45 2013 +0200,1371631305,Clean up ReadSupport init,51,26,"parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/read/DataWritableReadSupport.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java,CAS_DELIMITER",5,1,3,1.7683953061244608,2,201.2,40,1.1027083333333334,10.0,9.17556943207836,10.0,Perfective,FALSE,FALSE,
c4c77ba08da97d4d4da656898a6f82506b240bea,julien,julien@twitter.com,Tue Jun 18 09:45:36 2013 -0700,1371573936,add support for ReadSupport specific info in split,70,15,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java,CAS_DELIMITER",6,1,3,2.305108960318718,4,34.833333333333336,43,54.64755979938271,262.0,199.11378639214013,54.0,Feature Addition,FALSE,FALSE,
0ec089dcaa6246e08b069a1770484e52b1e05357,Remy Pecqueur,r.pecqueur@criteo.com,Tue Jun 18 12:18:55 2013 +0200,1371550735,Add metadata in ReadContext instead of Split - Fix TaskAttemptContext in the deprecated output format - Clean up a bit how we get the split in the deprecated input format,87,165,"parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/read/DataWritableReadSupport.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java,CAS_DELIMITER",7,1,4,1.8717074044532747,2,180.28571428571428,46,1.115881283068783,9.0,8.197244415433934,9.0,Corrective,TRUE,FALSE,
bb6e2ff89644690e363a31078e94b17e76b590a9,Mickael Lacour,m.lacour@criteo.com,Tue Jun 18 11:15:19 2013 +0200,1371546919,"Hadoop 2 . 0 compatibility , hive 0 . 10 - Using ContextUtils to be able to launch with hadoop 2 . 0 - Working with hive 0 . 10 - Fix some issues with ArrayWritable to be able to reach any columns with objectInspector",114,36,"parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java,CAS_DELIMITER",7,1,4,2.301414635515422,2,180.14285714285714,38,5.012819113756613,17.0,15.167806315645967,17.0,Corrective,TRUE,FALSE,
c3596a9ddd0093890cc39e49fb15b11996f451ff,Alex Levenson,alexlevenson@twitter.com,Mon Jun 17 17:44:39 2013 -0700,1371516279,Add support for 4 byte length written at the beginning of rle columns,26,38,"parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java,CAS_DELIMITER",3,1,1,1.0352876825927722,5,146.0,14,13.30559413580247,18.0,17.207912362256756,18.0,Feature Addition,FALSE,FALSE,
c773446264808dc0fc50a495cfb24f8e4c6140d0,Aniket Mokashi,amokashi@twitter.com,Mon Jun 17 11:13:57 2013 -0700,1371492837,ability to read version number from parquet jar Version utility,18,6,"parquet-column/src/main/java/parquet/Version.java,CAS_DELIMITER",1,1,1,0.0,4,88.0,3,25.051053240740742,0.0,0.0,0.0,None,FALSE,FALSE,
543cdc2c1027a858f6d431293a496014adf53bbe,Remy Pecqueur,r.pecqueur@criteo.com,Mon Jun 17 15:53:35 2013 +0200,1371477215,Fix the size of the value array - Give the list of columns to the ReadSupport via the split - The ReadSupport then gives the GroupConverter the Hive schema converted in Parquet format,81,47,"parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/DataWritableGroupConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/DataWritableRecordConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/read/DataWritableReadSupport.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java,CAS_DELIMITER",8,1,4,2.4609532649735626,2,139.75,39,5.888483796296297,8.0,7.214776070295688,8.0,Corrective,TRUE,FALSE,
8234945c40078a911ba7a9e83fc5fd534126182b,Mickael Lacour,m.lacour@criteo.com,Thu Jun 13 11:21:59 2013 +0200,1371115319,Remove unused parameters,6,7,"parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java,CAS_DELIMITER",1,1,1,0.0,2,287.0,12,1.699872685185185,16.0,14.35588223541436,16.0,None,FALSE,FALSE,
3ee49a5e6c52b374431dfdeeb7b01546625bbfdd,Mickael Lacour,m.lacour@criteo.com,Tue Jun 11 18:34:10 2013 +0200,1370968450,"Change MapWritable to ArrayWritable ( perfomance improved ! ) Fix the ugly fix in case trouble while reading with combine hive Refactor the unit test Add more unit test Specify all the unsupported format ( next : refactor this , because we have like 4 methods for it ) Fix the fact that we were reading twice the data ( sorry : ) ) Did some profiling with the unit test",553,647,"parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/DataWritableGroupConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/DataWritableRecordConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/HiveGroupConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/MapWritableGroupConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/MapWritableRecordConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/read/DataWritableReadSupport.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/ArrayWritableObjectInspector.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/write/DataWritableWriteSupport.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/write/DataWritableWriter.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormatComplexType.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java,CAS_DELIMITER",23,1,7,4.017372914865853,2,114.26086956521739,87,26.014132950885664,15.0,13.416275114015379,15.0,Corrective,TRUE,FALSE,
174c26ae4648ca2554942008905c303be851d5b3,Remy Pecqueur,r.pecqueur@criteo.com,Mon Jun 10 16:06:45 2013 +0200,1370873205,Correct fix to CombineHive,47,10,"parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java,CAS_DELIMITER",1,1,1,0.0,2,390.0,13,0.08815972222222222,7.0,6.342186681522768,7.0,Corrective,TRUE,FALSE,
cee774c357a4af5f404249eaf1681efa0f5e085e,Remy Pecqueur,r.pecqueur@criteo.com,Mon Jun 10 13:59:48 2013 +0200,1370865588,Fix more combine stuff,37,22,"parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java,CAS_DELIMITER",1,1,1,0.0,2,375.0,12,2.989189814814815,6.0,5.3435807051704,6.0,Corrective,TRUE,FALSE,
cc6754ceb89421859afa0e9ab8e7bc9d9ad7dd10,Remy Pecqueur,r.pecqueur@criteo.com,Fri Jun 7 14:15:22 2013 +0200,1370607322,"Fix CombineHive bug - When getting splits from CombineHive , recalculate all possible splits for the path , and only keep the correct one , to keep only the correct blocks",22,24,"parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java,CAS_DELIMITER",1,1,1,0.0,2,377.0,11,2.8813194444444443,5.0,4.3829570081998055,5.0,Corrective,TRUE,FALSE,
1d13a61a1eec58e105defaa0731281f6aa8a7107,Alex Levenson,alexlevenson@twitter.com,Thu Jun 6 13:32:25 2013 -0700,1370550745,create and use checkedCast ( ),28,4,"parquet-column/src/main/java/parquet/Ints.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java,CAS_DELIMITER",2,1,2,0.6962122601251458,5,40.5,3,0.4780497685185185,17.0,16.726791915653823,17.0,Feature Addition,FALSE,FALSE,
6e6516622b26450d2030442c9a794e3d021e262f,julien,julien@twitter.com,Thu Jun 6 02:42:40 2013 -0700,1370511760,fix bit packing encoding bug,30,8,"parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/bitpacking/TestByteBasedBitPackingEncoder.java,CAS_DELIMITER",4,1,3,1.3475798306579345,5,109.25,29,2.6193055555555556,260.0,202.41494530562903,99.0,Corrective,TRUE,FALSE,
2dbd0d232e11dde8944b5cc41486aabcee6dc7d1,Alex Levenson,alexlevenson@twitter.com,Wed Jun 5 14:35:38 2013 -0700,1370468138,Remove logic for valueCount > Integer . MAX VALUE,16,49,"parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java,CAS_DELIMITER",1,1,1,0.0,5,114.0,2,0.9770601851851852,16.0,15.770015686382736,16.0,None,FALSE,FALSE,
7cf85cb4e0ea7d25223b9a2773c7a8d629830ea5,Alex Levenson,alexlevenson@twitter.com,Tue Jun 4 15:08:40 2013 -0700,1370383720,Fix RunLengthBitPackingHybridValuesReader,88,10,"parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java,CAS_DELIMITER",1,1,1,0.0,5,36.0,1,1.282314814814815,15.0,14.811734401731767,15.0,Corrective,TRUE,FALSE,
aed1dca4522647aa525b97cca13df75fb5feb751,julien,julien@twitter.com,Tue Jun 4 13:52:09 2013 -0700,1370379129,dictionary encoding header is now bitWidth instead of max dictionary entry id,10,16,"parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER",2,1,1,0.7793498372920852,5,158.5,19,2.615318287037037,259.0,202.0927152692697,98.0,None,FALSE,TRUE,"[""6e6516622b26450d2030442c9a794e3d021e262f""]"
41981533138c845508fe05253f81c78d90083b03,Mickael Lacour,m.lacour@criteo.com,Tue Jun 4 17:26:00 2013 +0200,1370359560,Fix compile with abstract methods,24,14,"parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormatComplexType.java,CAS_DELIMITER",2,1,1,1.0,2,187.0,4,18.0753125,14.0,12.652495747004933,14.0,Corrective,TRUE,FALSE,
f2d9e81bf69d3c0f4bbf3ff2b148ff04c1187289,Mickael Lacour,m.lacour@criteo.com,Tue Jun 4 17:06:16 2013 +0200,1370358376,update hadoop version,11,8,"parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java,CAS_DELIMITER",2,1,2,0.8314743880097293,2,285.5,12,33.00228009259259,13.0,11.652925657652201,13.0,None,FALSE,FALSE,
d7fe1a5d2b2129c53a5d8425f9e3ca14f42522f9,Alex Levenson,alexlevenson@twitter.com,Mon Jun 3 08:50:41 2013 -0700,1370274641,Use RLE for repetition / definition levels,91,12,"parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/ValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/ValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesWriter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java,CAS_DELIMITER",6,1,4,1.6727297783386155,5,112.83333333333333,44,11.213007330246912,14.0,13.862497512085096,14.0,None,FALSE,FALSE,
abb6e3644ad6104980831ecd12815d8fcff4acfd,Alex Levenson,alexlevenson@twitter.com,Mon Jun 3 08:22:08 2013 -0700,1370272928,Address first round of comments,74,28,"parquet-column/src/main/java/parquet/Preconditions.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/bytes/BytesUtils.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/Encoding.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridValuesReader.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java,CAS_DELIMITER",9,1,6,2.6962646134368633,5,132.55555555555554,51,2.938818158436214,13.0,12.863243160294513,13.0,Feature Addition,FALSE,FALSE,
63ed7191384053817b91910a428a028fe1ad0336,Alex Levenson,alexlevenson@twitter.com,Fri May 31 13:50:03 2013 -0700,1370033403,"Fixup / rename RLEDecoder , fix tests",134,173,"parquet-column/src/main/java/parquet/bytes/BytesUtils.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridDecoder.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/rle/RunLengthBitPackingHybridIntegrationTest.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/rle/TestRLE.java,CAS_DELIMITER",8,1,4,2.622153433287377,5,102.625,44,7.980513599537037,11.0,10.960626931272571,11.0,Corrective,TRUE,FALSE,
65fb8d3e069b321d6b6bd551e4d1c652546d37f8,Alex Levenson,alexlevenson@twitter.com,Fri May 31 01:23:36 2013 -0700,1369988616,move unpack,25,24,"parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java,CAS_DELIMITER",1,1,1,0.0,5,271.0,3,0.18864583333333335,8.0,7.976152367507043,8.0,None,FALSE,FALSE,
24f652409db7ee67faea791e896cca4c97e184b6,Alex Levenson,alexlevenson@twitter.com,Thu May 30 20:51:57 2013 -0700,1369972317,End to end test,154,11,"parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java,CAS_DELIMITER",2,1,2,0.39789373922000243,5,190.5,4,0.6341030092592592,7.0,6.980264582927058,7.0,Preventative,FALSE,FALSE,
c9c1080bebb2173585ac55e1d118a58be80d968f,Alex Levenson,alexlevenson@twitter.com,Thu May 30 17:32:08 2013 -0700,1369960328,Add bit packing overflow test,44,10,"parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java,CAS_DELIMITER",1,1,1,0.0,5,85.0,1,0.9906828703703704,6.0,5.982911785575197,6.0,Feature Addition,FALSE,FALSE,
cd3a1238950c7821e1505396270335fab989d9b3,Alex Levenson,alexlevenson@twitter.com,Wed May 29 17:45:33 2013 -0700,1369874733,Start tests for rle hybrid,89,2,"parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/rle/TestRunLengthBitPackingHybridEncoder.java,CAS_DELIMITER",2,1,2,0.35056382068186565,5,130.0,1,0.03876157407407407,5.0,4.999148297589147,5.0,Preventative,FALSE,FALSE,
d29eeb570d0b5e3c07cbd85152349c72a0f976dd,Alex Levenson,alexlevenson@twitter.com,Wed May 29 16:28:38 2013 -0700,1369870118,cleanup preconditions,12,3,"parquet-column/src/main/java/parquet/Preconditions.java,CAS_DELIMITER",1,1,1,0.0,5,52.0,4,0.024108796296296295,3.0,2.999875229171477,3.0,Perfective,FALSE,FALSE,
2ffdab725e039a33d2c34196bbbcd52fb4fb005c,Alex Levenson,alexlevenson@twitter.com,Wed May 29 16:25:37 2013 -0700,1369869937,Add test for setByte ( ),87,1,"parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/bytes/TestCapacityByteArrayOutputStream.java,CAS_DELIMITER",2,1,2,0.15649106290570153,5,179.0,13,3.1423668981481483,2.0,1.9998924462551413,2.0,Feature Addition,FALSE,FALSE,
0f9eee5ff50ea7475e34bea444ea0de2d877862f,Alex Levenson,alexlevenson@twitter.com,Wed May 29 16:00:47 2013 -0700,1369868447,Cleanup,12,5,"parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java,CAS_DELIMITER",1,1,1,0.0,5,202.0,9,0.004768518518518518,1.0,0.99998693573638,1.0,Perfective,FALSE,FALSE,
b3e94326c9488270af209f0cc978b956fb2a5380,Alex Levenson,alexlevenson@twitter.com,Wed May 29 15:53:55 2013 -0700,1369868035,First pass at RLE hybrid,338,4,"parquet-column/src/main/java/parquet/Preconditions.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/bytes/BytesUtils.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/rle/RunLengthBitPackingHybridEncoder.java,CAS_DELIMITER",4,1,3,1.1525844309938458,5,66.25,20,14.053538773148148,0.0,0.0,0.0,None,FALSE,FALSE,
0a7c59aac0bc55999d768ffbef4d503e1282e6ca,Uri Laserson,laserson@cloudera.com,Tue May 28 18:29:40 2013 -0700,1369790980,Speed up Avro string parsing,7,1,"parquet-column/src/main/java/parquet/io/api/Binary.java,CAS_DELIMITER",1,1,1,0.0,2,70.0,6,28.43162037037037,7.0,6.669294839377577,0.0,None,FALSE,TRUE,
25d8ff20756281d170ea9d26334cef0862bbac2e,julien,julien@twitter.com,Wed May 22 18:37:51 2013 -0700,1369273071,javadoc and cleanup,101,24,"parquet-column/src/main/java/parquet/column/impl/ColumnReadStoreImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/page/PageReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/IntList.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/PlainBinaryDictionary.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/api/PrimitiveConverter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER",8,2,6,2.5403554958992185,4,42.25,45,15.144088541666667,254.0,202.8394549492397,72.0,Non Functional,FALSE,FALSE,
f9784bf70bae3540dca2606b83fab08b1966cc04,julien,julien@twitter.com,Tue May 21 14:48:31 2013 -0700,1369172911,remove unnecessary keywords,7,7,"parquet-column/src/main/java/parquet/column/page/PageReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/page/PageWriter.java,CAS_DELIMITER",2,1,1,0.9852281360342516,2,6.0,8,5.570387731481481,253.0,202.36529255529717,92.0,None,FALSE,FALSE,
df1ab6f8413cf9b9b1fa33e024483cde229dc4cf,julien,julien@twitter.com,Tue May 21 11:30:11 2013 -0700,1369161011,introduce contants,32,12,"parquet-column/src/main/java/parquet/Preconditions.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java,CAS_DELIMITER",7,3,5,1.9887356469230217,4,44.857142857142854,55,10.366977513227514,251.0,200.42720553683415,51.333333333333336,None,FALSE,FALSE,
e85b3c20ad3fd4da72cd368359f62b19dfcb078a,julien,julien@twitter.com,Tue May 21 11:06:44 2013 -0700,1369159604,interfaces have public members,3,3,"parquet-column/src/main/java/parquet/column/page/PageReader.java,CAS_DELIMITER",1,1,1,0.0,1,3.0,3,25.931979166666668,250.0,199.43448274859352,89.0,None,FALSE,FALSE,
19b369b8a7f5514c346206801773425cc333a796,julien,julien@twitter.com,Tue May 21 10:50:51 2013 -0700,1369158651,use checkNotNull,33,32,"parquet-column/src/main/java/parquet/Preconditions.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/bytes/BytesInput.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnReadStoreImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/page/DictionaryPage.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/page/mem/MemPageReader.java,CAS_DELIMITER",6,1,5,2.185725686446453,4,42.833333333333336,29,15.39168209876543,249.0,198.43938189044803,88.0,None,FALSE,FALSE,
a5b478edbb89e7f168d12b7ee2b38c93cdca4a0c,julien,julien@twitter.com,Tue May 21 10:15:28 2013 -0700,1369156528,standard ordering of keywords,2,2,"parquet-column/src/main/java/parquet/column/Dictionary.java,CAS_DELIMITER",1,1,1,0.0,1,48.0,3,25.896377314814814,248.0,197.45022927461827,87.0,None,FALSE,FALSE,
05f103b33abc8c8191a2aeb59f688ddd5c41d319,Matt Massie,matt@cloudera.com,Sat May 18 22:24:41 2013 -0700,1368941081,"Fix bug that prevented writing optional Avro records , arrays or maps The writeValue method in AvroWriteSupport would correct resolve the non - null type but would incorrectly try to write records , arrays and maps with the original union schema triggering e . g . AvroRuntimeException : Not an array : [ ""null"" , { ""type"" : ""array"" , ""items"" : ""int"" } ]",15,7,"parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestReadWrite.java,CAS_DELIMITER",2,1,2,0.976020648236615,3,138.0,13,17.90813657407407,0.0,0.0,0.0,Corrective,TRUE,FALSE,
b6d1cb046418da4de3f35e5109a87df29e2cc42c,julien,julien@twitter.com,Fri May 17 16:28:29 2013 -0700,1368833309,add a validation setting to OutputFormat,97,41,"parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java,CAS_DELIMITER",7,2,3,2.266694952898089,4,72.42857142857143,47,13.963022486772486,247.0,198.10554481111197,68.0,Feature Addition,FALSE,TRUE,"[""407a52d538c31f65e3ba313c1d7be4fb5f9831b8""]"
d6157297fb3533139b98d5ceaf0ab6311c5ed724,Mickael Lacour,m.lacour@criteo.com,Fri May 17 15:37:33 2013 +0200,1368797853,Add unit test for storage,248,17,"parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormatComplexType.java,CAS_DELIMITER",2,1,1,0.8742612397515299,2,71.5,2,7.497881944444444,12.0,11.19411979746406,12.0,Feature Addition,FALSE,FALSE,
5b25bb57fc1f68dbf46e6cedab67f25120aec070,julien,julien@twitter.com,Tue May 14 11:07:11 2013 -0700,1368554831,add constants and doc,24,5,"parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java,CAS_DELIMITER",2,2,2,0.7355085815538398,4,29.5,24,3.633269675925926,246.0,198.54563373308736,67.0,Feature Addition,FALSE,FALSE,
a53dde1c7bebc1f7242f574973afa71699076cd8,julien,julien@twitter.com,Tue May 14 08:45:08 2013 -0700,1368546308,javadoc and constants,36,7,"parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java,CAS_DELIMITER",1,1,1,0.0,2,150.0,7,0.6617824074074075,245.0,197.58977432890947,84.0,Non Functional,FALSE,FALSE,
d0cc3a96ee61e132ab109c2cacd1289d372f10ca,julien,julien@twitter.com,Mon May 13 16:52:10 2013 -0700,1368489130,check initial size,3,0,"parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java,CAS_DELIMITER",1,1,1,0.0,2,147.0,6,0.01726851851851852,244.0,196.88459980158484,83.0,Feature Addition,FALSE,FALSE,
0add8d86e367ec01a3e8fe5813e53151dd6aa28a,julien,julien@twitter.com,Mon May 13 16:27:18 2013 -0700,1368487638,add constant and override annotations,6,15,"parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java,CAS_DELIMITER",1,1,1,0.0,2,156.0,5,2.0345138888888887,243.0,195.89225763399602,82.0,Feature Addition,FALSE,FALSE,
34a8fb00cf205de05f350496b20e721104119fdf,Uri Laserson,laserson@cloudera.com,Mon May 13 16:13:30 2013 -0700,1368486810,Propagated default sizes to the OutputFormat,6,8,"parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java,CAS_DELIMITER",3,2,2,1.5774062828523452,4,73.33333333333333,16,2.915528549382716,5.0,4.941731078339122,4.0,None,FALSE,FALSE,
f7e7dd7685fb0e10ab3ad30201b80a995cd7b3ed,julien,julien@twitter.com,Sat May 11 15:37:36 2013 -0700,1368311856,more unit tests for CapacityByteArrayOutputStream,84,24,"parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/bytes/TestCapacityByteArrayOutputStream.java,CAS_DELIMITER",2,1,2,0.3095434291503252,2,115.0,5,0.9484317129629629,242.0,195.79313196885008,81.0,Preventative,FALSE,FALSE,
0347e7b2b3d722a63ade36077ef02b5e22d66f5b,julien,julien@twitter.com,Fri May 10 21:29:34 2013 -0700,1368246574,adjust initial column size,3,2,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java,CAS_DELIMITER",1,1,1,0.0,4,13.0,10,0.13096064814814815,241.0,195.12777507155093,48.0,Feature Addition,FALSE,FALSE,
6a4f8d03f38cddc1d62a6fa240b601816738af33,julien,julien@twitter.com,Fri May 10 18:36:08 2013 -0700,1368236168,handle case when value is bigger than slab size,14,3,"parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java,CAS_DELIMITER",1,1,1,0.0,2,141.0,3,0.14482638888888888,240.0,194.1808949112722,80.0,None,FALSE,FALSE,
922f6c5098f8d58708e79f9640ea06c73d255519,julien,julien@twitter.com,Fri May 10 18:20:59 2013 -0700,1368235259,add setting to turn dictionary on,45,16,"parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/PerfTest.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java,CAS_DELIMITER",8,2,4,2.6392860248894827,4,37.0,65,2.8491724537037038,239.0,193.18550768465363,63.0,Feature Addition,FALSE,FALSE,
11d8e0ebf0c8c3f0f9c17217269e36152003c476,Uri Laserson,laserson@cloudera.com,Fri May 10 18:07:17 2013 -0700,1368234437,Added javadocs,40,2,"parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java,CAS_DELIMITER",2,2,2,0.9983636725938131,4,57.0,6,1.9734027777777778,3.0,2.9811200165510945,2.0,Feature Addition,FALSE,FALSE,
a0e82a878547701b0259cf9c2211f721c1fca172,julien,julien@twitter.com,Fri May 10 16:09:36 2013 -0700,1368227376,add improved memory management in hadoop layer,16,9,"parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java,CAS_DELIMITER",2,1,1,0.9895875212220557,2,27.5,22,7.592685185185186,238.0,192.22526974580344,46.0,Feature Addition,FALSE,FALSE,
b30d7fe08d26346da07c3ac873fea3f174785362,julien,julien@twitter.com,Fri May 10 15:09:31 2013 -0700,1368223771,reduce rep and def level buffer size . 8MB * 2 * #cols is way too much,1,1,"parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java,CAS_DELIMITER",1,1,1,0.0,2,126.0,6,0.0013425925925925925,237.0,191.24334468173265,78.0,None,FALSE,FALSE,
e1aa79849714d189727155ad9937436b66595256,julien,julien@twitter.com,Fri May 10 15:07:35 2013 -0700,1368223655,improve memory consumption in write,387,53,"parquet-column/src/main/java/parquet/bytes/BytesInput.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/page/PageWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/ValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/boundedint/BitWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesFactory.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/boundedint/DevNullValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/bytes/TestCapacityByteArrayOutputStream.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPackingColumn.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/boundedint/TestBoundedColumns.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/PerfTest.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java,CAS_DELIMITER",27,4,16,3.4585640919230736,2,20.11111111111111,137,31.780498971193424,236.0,190.2439226675967,46.0,None,FALSE,FALSE,
cd2535980e715b00d43ee47b2aa138167016aed3,julien,julien@twitter.com,Wed May 8 21:48:35 2013 -0700,1368074915,add library version to metadata,29,8,"parquet-column/src/main/java/parquet/Version.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/metadata/FileMetaData.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java,CAS_DELIMITER",5,2,5,2.1169094021874666,4,36.8,43,21.642115740740742,235.0,189.98323523447337,60.0,Feature Addition,FALSE,FALSE,
d636d60611371643b3ffe5c7494e9d1b315d2ac0,Uri Laserson,laserson@cloudera.com,Wed May 8 18:45:35 2013 -0700,1368063935,"Allow setting compressor , block / page size for ParquetWriter",20,6,"parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java,CAS_DELIMITER",2,2,2,0.9957274520849256,4,50.0,4,7.317905092592594,2.0,1.9972227941807013,1.0,None,FALSE,FALSE,
09a54d6c786d7258cb1baf03f821882058ea62c6,Uri Laserson,laserson@cloudera.com,Wed May 8 18:12:20 2013 -0700,1368061940,Rolled back one of the public classes,1,1,"parquet-hadoop/src/main/java/parquet/hadoop/CodecFactory.java,CAS_DELIMITER",1,1,1,0.0,3,6.0,6,0.9701967592592593,1.0,0.9973489733102572,1.0,None,FALSE,FALSE,
647825b5a7b317dfb6d1a6ef61eca87c75e6bfd2,Uri Laserson,laserson@cloudera.com,Tue May 7 18:55:15 2013 -0700,1367978115,Changed two utility classes to public AvroSchemaConverter CodecFactory,2,2,"parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/CodecFactory.java,CAS_DELIMITER",2,2,2,1.0,3,75.0,9,10.965353009259259,0.0,0.0,0.0,None,FALSE,FALSE,
5ab09189cf32c76a3bdd8fecedaf337735c1ea24,julien,julien@twitter.com,Tue May 7 11:34:01 2013 -0700,1367951641,update dependencies to hadoop - client,4,2,"parquet-test-hadoop2/src/test/java/parquet/hadoop2/TestInputOutputFormat.java,CAS_DELIMITER",1,1,1,0.0,1,137.0,1,0.7746875,234.0,189.59648683508905,1.0,None,FALSE,FALSE,
a20750a87d69823e4048d954627494505d508e2e,Tom White,tom@cloudera.com,Tue May 7 16:03:16 2013 +0100,1367938996,Replace JobContext#getConfiguration calls with reflective call .,290,33,"parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputCommitter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/example/ExampleOutputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/util/ContextUtil.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/ParquetLoader.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/PerfTest2.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftOutputFormat.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java,CAS_DELIMITER",13,4,9,1.581356679336322,4,47.92307692307692,57,40.092441239316244,12.0,11.418308385134655,3.0,None,FALSE,FALSE,
a67ea4ea283481abd324a0a799d6a09cc8002545,julien,julien@twitter.com,Mon May 6 16:58:28 2013 -0700,1367884708,add test for hadoop2,137,0,"parquet-test-hadoop2/src/test/java/parquet/hadoop2/TestInputOutputFormat.java,CAS_DELIMITER",1,1,1,0.0,1,0.0,0,0.0,233.0,188.92902084280155,0.0,Feature Addition,FALSE,FALSE,
0c250380bd15e6491857108b9463e4b9ba3c00c9,julien,julien@twitter.com,Fri May 3 18:30:57 2013 -0700,1367631057,read version information from META - INF,66,0,"parquet-column/src/main/java/parquet/Version.java,CAS_DELIMITER",1,1,1,0.0,1,0.0,0,0.0,232.0,189.1919283184276,75.0,None,FALSE,FALSE,
f5ab5ebd5e3c9e3a63f2dcc124b60fb3349679b3,julien,julien@twitter.com,Fri May 3 09:45:03 2013 -0700,1367599503,better error message when schema is unknown,5,1,"parquet-pig/src/main/java/parquet/pig/ParquetStorer.java,CAS_DELIMITER",1,1,1,0.0,1,-10.0,4,56.659675925925924,231.0,188.3492331152703,34.0,Perfective,FALSE,FALSE,
74be52851bbb1d0bed6af746eb7a83d8113bb555,Remy Pecqueur,r.pecqueur@criteo.com,Thu May 2 18:22:19 2013 +0200,1367511739,Add full support for array and map reading,79,74,"parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/HiveGroupConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/MapWritableGroupConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/MapWritableRecordConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/read/MapWritableReadSupport.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/MapWritableObjectInspector.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/write/MapWritableWriter.java,CAS_DELIMITER",12,1,5,2.7387149650282745,2,164.5,74,7.0335069444444445,4.0,3.795806341652894,4.0,Feature Addition,FALSE,FALSE,
1dc42f0bf123219d03107ff64954705fe1b104d8,Mickael Lacour,m.lacour@criteo.com,Thu May 2 15:43:39 2013 +0200,1367502219,Improve the pull request following advices from Julien,68,84,"parquet-hive/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/write/MapWritableWriter.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java,CAS_DELIMITER",6,1,4,1.5814741755809054,2,172.0,25,6.091315586419753,11.0,10.640357333776455,11.0,None,FALSE,FALSE,
75ead0a3ed59c4b821fc2973b8917a856d3067dc,julien,julien@twitter.com,Wed May 1 16:08:06 2013 -0700,1367449686,turn LOGs back to INFO,1,1,"parquet-column/src/main/java/parquet/Log.java,CAS_DELIMITER",1,1,1,0.0,1,42.0,7,0.001863425925925926,230.0,188.09497972299297,74.0,None,FALSE,FALSE,
a1fbcfb1fd229f77222fabae54a97f3b161f4d26,julien,julien@twitter.com,Wed May 1 16:05:25 2013 -0700,1367449525,make total size include header size,24,6,"parquet-column/src/main/java/parquet/Log.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java,CAS_DELIMITER",3,2,3,1.1105522511832788,1,78.33333333333333,29,25.753082561728394,229.0,187.09577925958436,58.0,None,FALSE,FALSE,
c7ebfbb14a1147b8c34d176821000140d2ec8bfc,Josh Wills,jwills@cloudera.com,Wed May 1 11:35:40 2013 -0700,1367433340,Fixes based on Julian's feedback,30,55,"parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroSchemaHelper.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java,CAS_DELIMITER",4,1,1,1.3621568171195653,3,181.5,18,3.634236111111111,1.0,0.9998152611768494,1.0,Corrective,TRUE,FALSE,
88690f97f3aba9112b25337512d1e82e9034793d,Josh Wills,jwills@cloudera.com,Wed May 1 09:58:33 2013 -0700,1367427513,Fix Avro Read / Write support to work with the union - null optional value pattern,71,10,"parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroSchemaHelper.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestInputOutputFormat.java,CAS_DELIMITER",4,1,2,1.4550168067674472,3,172.0,13,6.103015046296297,0.0,0.0,0.0,Corrective,TRUE,FALSE,
59f4b102517c472f26ea2138d353b33ee8146380,Avi Bryant,avi@avibryant.com,Wed May 1 09:45:04 2013 -0700,1367426704,Use the standard readFooters in ParquetTupleScheme,16,14,"parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java,CAS_DELIMITER,parquet-cascading/src/main/java/parquet/cascading/TupleReadSupport.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER",3,2,2,1.4294732983598406,2,142.0,33,2.4784220679012345,15.0,14.883848146333744,8.5,None,FALSE,FALSE,
aaa58d36317c6242fb086efd3a161d5aee0c85db,julien,julien@twitter.com,Tue Apr 30 13:38:16 2013 -0700,1367354296,code formating and license headers,254,134,"parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroRecordMaterializer.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestReadWrite.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingGenerator.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPacking.java,CAS_DELIMITER",10,2,3,1.8974723293426592,2,2664.3,26,14.69540972222222,228.0,186.56687781438194,36.0,None,FALSE,FALSE,
634cb777c22ee7d4b03b3c35c85f3d198e7c1691,julien,julien@twitter.com,Tue Apr 30 08:08:08 2013 -0700,1367334488,fix bug when printing a ByteBuffer based binary would consume the buffer,6,1,"parquet-column/src/main/java/parquet/io/api/Binary.java,CAS_DELIMITER",1,1,1,0.0,2,65.0,5,8.161828703703703,227.0,185.66454278881122,71.0,Corrective,TRUE,FALSE,
33e0131ff0cd7c282b6af17bc82f74155eb761a8,Mickael Lacour,m.lacour@criteo.com,Tue Apr 30 15:21:44 2013 +0200,1367328104,"Add some unit test in order to test : - HiveSerDe : fix some bugs about long and byte datas - DeprecatedParquetInputFormat : add StatsSerDe method - MapWritableWriter : fix bug if we start and close without adding values - UtilitiesTestMethods : almost everything is from parquet - pig . Very useful - TestDeprecated { Input , Output } Format : in order to test the hive stuff Update pom . xml : - Hive - * 0 . 10 version - Add column for test purpose",559,254,"parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/write/MapWritableWriter.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetInputFormat.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/TestDeprecatedParquetOuputFormat.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/TestHiveInputFormat.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/TestHiveOuputFormat.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/UtilitiesTestMethods.java,CAS_DELIMITER",10,1,4,2.754152061391449,2,130.9,30,7.510194444444444,10.0,9.69750074761576,10.0,Feature Addition,FALSE,FALSE,
ffebada1455a96e22fd24dc961ba432087ded7ba,Avi Bryant,avi@avibryant.com,Mon Apr 29 10:40:11 2013 -0700,1367257211,update ParquetTupleScheme to use DeprecatedParquetInputFormat,3,3,"parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java,CAS_DELIMITER",1,1,1,0.0,2,238.0,6,1.517789351851852,14.0,13.963649064978801,11.0,None,FALSE,FALSE,
c96e7949a85b5327b348c587dfc9906707e18d4b,julien,julien@twitter.com,Mon Apr 29 10:11:05 2013 -0700,1367255465,+ needs space,13,13,"parquet-column/src/main/java/parquet/io/MessageColumnIO.java,CAS_DELIMITER",1,1,1,0.0,2,19.0,14,2.826296296296296,226.0,185.05269677930485,70.0,None,FALSE,FALSE,
249e88935a203cda47483f7c73696000abd615e8,Avi Bryant,avi@avibryant.com,Mon Apr 29 10:01:49 2013 -0700,1367254909,Use a simpler serialization for cascading Fields to be compatible with older cascading versions,9,13,"parquet-cascading/src/main/java/parquet/cascading/TupleReadSupport.java,CAS_DELIMITER",1,1,1,0.0,2,62.0,2,1.4968055555555555,8.0,7.978881869048926,5.0,None,FALSE,FALSE,
f2ab7a27d9dbe8ec9cfa407bcaee4d4f99d3ea83,Avi Bryant,avi@avibryant.com,Mon Apr 29 10:01:49 2013 -0700,1367254909,Use a simpler serialization for cascading Fields to be compatible with older cascading versions,9,13,"parquet-cascading/src/main/java/parquet/cascading/TupleReadSupport.java,CAS_DELIMITER",1,1,1,0.0,2,120.0,5,1.4968055555555555,13.0,12.964665784809242,10.0,None,FALSE,FALSE,
fc0c7cdd92c703784b9dfa4f891ee2be59f4d7b0,julien,julien@twitter.com,Mon Apr 29 08:23:47 2013 -0700,1367249027,integrate RLE into dictionary encoding,140,30,"parquet-column/src/main/java/parquet/bytes/BytesInput.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/IntList.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/rle/RLEDecoder.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java,CAS_DELIMITER",8,2,5,2.356662861795694,1,76.875,41,7.929741030092593,224.0,183.08399244421537,50.5,None,FALSE,FALSE,
74157a052de90b429000a16809db73f1edaa82b1,0xh3x,giorgi.jvaridze@gmail.com,Mon Apr 29 15:50:27 2013 +0400,1367236227,Fixed potential Integer overflow .,3,3,"parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java,CAS_DELIMITER",1,1,1,0.0,1,21.0,10,2.5880555555555556,0.0,0.0,0.0,Corrective,TRUE,FALSE,
a49a0e929d6404d2291bc8959682ac6f8eadefa4,Avi Bryant,avi@avibryant.com,Sun Apr 28 21:47:42 2013 -0700,1367210862,don't create a TaskAttemptContext in ParquetReader,2,7,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java,CAS_DELIMITER",2,1,1,0.7642045065086203,4,45.0,10,3.491568287037037,7.0,6.9900122479998865,3.0,Feature Addition,FALSE,FALSE,
2676de9bf340c2b97d1df6ac4208eba8e1cc28dd,Avi Bryant,avi@avibryant.com,Sun Apr 28 21:35:31 2013 -0700,1367210131,Treat Fields . UNKNOWN as Fields . ALL,3,0,"parquet-cascading/src/main/java/parquet/cascading/SchemaIntersection.java,CAS_DELIMITER",1,1,1,0.0,2,42.0,1,0.9785416666666666,6.0,5.990174048321746,4.0,None,FALSE,FALSE,
1ee87d8ff65e58396a14b407e96c140fde030f77,Avi Bryant,avi@avibryant.com,Sun Apr 28 21:35:31 2013 -0700,1367210131,Treat Fields . UNKNOWN as Fields . ALL,3,0,"parquet-cascading/src/main/java/parquet/cascading/SchemaIntersection.java,CAS_DELIMITER",1,1,1,0.0,2,87.0,3,0.9785416666666666,12.0,11.983050368749282,9.0,None,FALSE,FALSE,
20a4bf72e9e64e317c9167eea88303b4f4e16f31,Avi Bryant,avi@avibryant.com,Sun Apr 28 21:20:13 2013 -0700,1367209213,DeprecatedParquetInputFormat is not abstract,1,1,"parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java,CAS_DELIMITER",1,1,1,0.0,4,204.0,1,0.21885416666666666,5.0,4.99034813959736,2.0,None,FALSE,FALSE,
5e82439eb8f99d20a5bbc55fdeaa0840b0cac90f,Avi Bryant,avi@avibryant.com,Sun Apr 28 16:20:06 2013 -0700,1367191206,fix up cascading and scrooge to use DeprecatedParquetInputFormat,9,10,"parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java,CAS_DELIMITER,parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java,CAS_DELIMITER,parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java,CAS_DELIMITER",3,2,2,1.3779630390761746,2,66.0,10,10.951782407407407,4.0,3.99319374423926,1.5,Corrective,TRUE,FALSE,
1f0a8a25ad7d3b2683f0f8b10449db3ff1c2de13,Avi Bryant,avi@avibryant.com,Sun Apr 28 16:05:04 2013 -0700,1367190304,"replace DeprecatedContainerInputFormat with DeprecatedParquetInputFormat , should build under MR2",235,389,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/mapred/Container.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/mapred/DeprecatedParquetInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/DeprecatedContainerInputFormat.java,CAS_DELIMITER",6,2,4,1.3547682699890364,4,73.33333333333333,28,12.239739583333332,3.0,2.9933077675205113,0.5,None,FALSE,TRUE,"[""f18bc49046d51e1700d419e401ad49093322771d""]"
2f0a779ba2db69649591ab2663cafe6bc0ce09f5,Avi Bryant,avi@avibryant.com,Sat Apr 27 22:14:34 2013 -0700,1367126074,short class comment for the TupleScheme,15,0,"parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java,CAS_DELIMITER",1,1,1,0.0,2,223.0,5,0.005659722222222222,11.0,11.01503043211065,8.0,None,FALSE,FALSE,
593a105cea2faa01849240e140a6f9fd03bd31f7,Avi Bryant,avi@avibryant.com,Sat Apr 27 22:14:34 2013 -0700,1367126074,short class comment for the TupleScheme,15,0,"parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java,CAS_DELIMITER",1,1,1,0.0,2,104.0,2,0.005659722222222222,2.0,1.9994030845422075,2.0,None,FALSE,FALSE,
065a3c90673a7b3eae9165db0c4f0786372153dd,Avi Bryant,avi@avibryant.com,Sat Apr 27 22:06:25 2013 -0700,1367125585,working selective tuple materialization for cascading,95,42,"parquet-cascading/src/main/java/parquet/cascading/FilterSchema.java,CAS_DELIMITER,parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java,CAS_DELIMITER,parquet-cascading/src/main/java/parquet/cascading/SchemaIntersection.java,CAS_DELIMITER,parquet-cascading/src/main/java/parquet/cascading/TupleReadSupport.java,CAS_DELIMITER,parquet-cascading/src/main/java/parquet/cascading/convert/TupleConverter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER",6,2,3,2.278473226932415,2,51.666666666666664,22,0.5361342592592592,1.0,0.9994340786928203,0.5,None,FALSE,FALSE,
62df1234e87094cc0965f04fa7444fd3ea136938,Avi Bryant,avi@avibryant.com,Sat Apr 27 22:06:25 2013 -0700,1367125585,working selective tuple materialization for cascading,95,42,"parquet-cascading/src/main/java/parquet/cascading/FilterSchema.java,CAS_DELIMITER,parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java,CAS_DELIMITER,parquet-cascading/src/main/java/parquet/cascading/SchemaIntersection.java,CAS_DELIMITER,parquet-cascading/src/main/java/parquet/cascading/TupleReadSupport.java,CAS_DELIMITER,parquet-cascading/src/main/java/parquet/cascading/convert/TupleConverter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER",6,2,3,2.278473226932415,2,107.16666666666667,35,-0.0253047839506173,10.0,10.015201468598093,5.5,None,FALSE,FALSE,
30b461eabcdcb19708468159db8edba18ff31047,Avi Bryant,avi@avibryant.com,Sat Apr 27 17:08:48 2013 -0700,1367107728,skeleton for an efficient converter from groups to cascading tuples,294,0,"parquet-cascading/src/main/java/parquet/cascading/FilterSchema.java,CAS_DELIMITER,parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java,CAS_DELIMITER,parquet-cascading/src/main/java/parquet/cascading/TupleReadSupport.java,CAS_DELIMITER,parquet-cascading/src/main/java/parquet/cascading/convert/TupleConverter.java,CAS_DELIMITER,parquet-cascading/src/main/java/parquet/cascading/convert/TupleRecordMaterializer.java,CAS_DELIMITER",5,1,2,2.0680510386506383,2,60.4,11,-0.46583564814814815,9.0,9.02088435143651,6.0,None,FALSE,FALSE,
6b867e502c1b9cfe6b10e1e7387d93ef2969e7e4,Avi Bryant,avi@avibryant.com,Sat Apr 27 17:08:48 2013 -0700,1367107728,skeleton for an efficient converter from groups to cascading tuples,294,0,"parquet-cascading/src/main/java/parquet/cascading/FilterSchema.java,CAS_DELIMITER,parquet-cascading/src/main/java/parquet/cascading/ParquetTupleScheme.java,CAS_DELIMITER,parquet-cascading/src/main/java/parquet/cascading/TupleReadSupport.java,CAS_DELIMITER,parquet-cascading/src/main/java/parquet/cascading/convert/TupleConverter.java,CAS_DELIMITER,parquet-cascading/src/main/java/parquet/cascading/convert/TupleRecordMaterializer.java,CAS_DELIMITER",5,1,2,2.0680510386506383,1,0.0,0,0.0,0.0,0.0,0.0,None,FALSE,FALSE,
7c0f1a6779e49166d2925b6afebabb58cb81bb9e,julien,julien@twitter.com,Fri Apr 26 14:41:19 2013 -0700,1367012479,rename fromSequence to concat,13,12,"parquet-column/src/main/java/parquet/bytes/BytesInput.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java,CAS_DELIMITER",5,1,5,2.2415419333359274,1,55.4,25,9.17842361111111,222.0,182.2335433584823,66.0,None,FALSE,FALSE,
3f0975142a81b681e61195b4df7aa372d8c16ee9,julien,julien@twitter.com,Fri Apr 26 14:21:13 2013 -0700,1367011273,making empty fields illegal,79,70,"parquet-column/src/main/java/parquet/io/MessageColumnIO.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ParquetProtocol.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/TBaseRecordConverter.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java,CAS_DELIMITER",7,3,6,1.6095314155321836,2,52.857142857142854,45,21.35586144179894,221.0,181.23936527816556,41.0,None,FALSE,FALSE,
1db1018e696a3be8ea4167b966b774ae87386578,julien,julien@twitter.com,Fri Apr 26 11:01:06 2013 -0700,1366999266,turn on validation for generate TPCH,1,1,"parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java,CAS_DELIMITER",1,1,1,0.0,1,1.0,5,48.9075,220.0,180.29696835845272,31.0,None,FALSE,FALSE,
280cea3b157181f4cad8cef9ddb69618caa3f5a8,julien,julien@twitter.com,Fri Apr 26 10:57:30 2013 -0700,1366999050,make the API treat empty fields the same as missing fields to avoid confusion,63,23,"parquet-column/src/main/java/parquet/io/MessageColumnIO.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER",3,1,2,1.2936094957266198,1,87.66666666666667,31,18.610570987654324,219.0,179.29799810073294,64.0,None,FALSE,FALSE,
e5484323922826f66c22e5d5d4b2dae0fe521b42,julien,julien@twitter.com,Thu Apr 25 16:38:35 2013 -0700,1366933115,add new line,1,1,"parquet-column/src/main/java/parquet/column/values/bitpacking/BytePacker.java,CAS_DELIMITER",1,1,1,0.0,1,83.0,2,0.08875,217.0,177.60898825463434,62.0,Feature Addition,FALSE,FALSE,
7cb782c35ea463da541f94576634850c58a50f34,julien,julien@twitter.com,Thu Apr 25 16:33:31 2013 -0700,1366932811,make a constant for constant value ; remove outragous System . out . println ( ),5,4,"parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java,CAS_DELIMITER",1,1,1,0.0,1,69.0,2,0.0487037037037037,216.0,176.6104136951017,61.0,None,FALSE,FALSE,
b125deea4849d3001616f426e4fa770e7e8d020e,julien,julien@twitter.com,Thu Apr 25 15:27:58 2013 -0700,1366928878,make initial capacity a constant,3,1,"parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesWriter.java,CAS_DELIMITER",1,1,1,0.0,1,2.0,3,10.166736111111112,215.0,175.62873269656845,60.0,Feature Addition,FALSE,FALSE,
999b214297a9ce4cb7558fe598de04b5a2e9bb16,julien,julien@twitter.com,Thu Apr 25 15:23:23 2013 -0700,1366928603,use BytesUtils . paddedByteCountFromBits everywhere,72,7,"parquet-column/src/main/java/parquet/column/values/bitpacking/BitPacking.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingGenerator.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/rle/RLEDecoder.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/TestLog.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/bitpacking/BitPackingPerfTest.java,CAS_DELIMITER",10,1,4,2.917288960641978,1,71.5,20,6.043578703703704,214.0,174.63000500687124,59.0,Feature Addition,FALSE,TRUE,
67a357741b65cd087836cc2230ded57c1f4850d7,julien,julien@twitter.com,Thu Apr 25 15:07:38 2013 -0700,1366927658,make field private ; add braces for one line if statements,9,5,"parquet-column/src/main/java/parquet/bytes/BytesInput.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/bytes/BytesUtils.java,CAS_DELIMITER",2,1,1,0.5916727785823275,1,59.5,15,4.608813657407407,213.0,173.63434730378006,58.0,Feature Addition,FALSE,FALSE,
aed56c954fba19095fd622cfaa39341b9a22c9c6,julien,julien@twitter.com,Thu Apr 25 14:30:47 2013 -0700,1366925447,integrate the new bit packing for perf,276,22,"parquet-column/src/main/java/parquet/bytes/BytesUtils.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/Encoding.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingEncoder.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBasedBitPackingGenerator.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/ByteBitPackingValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/BytePacker.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/IntBasedBitPackingGenerator.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/IntPacker.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/TestLog.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/bitpacking/BitPackingPerfTest.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPackingColumn.java,CAS_DELIMITER",14,1,6,2.8503000778176806,1,49.42857142857143,35,5.784529596560847,212.0,172.6444376415358,57.0,Feature Addition,FALSE,FALSE,
19e0902b3c17ef1e163b429d114f8541139863ac,julien,julien@twitter.com,Thu Apr 25 12:44:41 2013 -0700,1366919081,make converters dictionary aware,463,340,"parquet-column/src/main/java/parquet/Log.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/ColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/Dictionary.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/Encoding.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnReadStoreImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/page/DictionaryPage.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/page/PageReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/ValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/ValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/api/GroupConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/api/PrimitiveConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/PrimitiveType.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/page/mem/MemPageReader.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/page/mem/MemPageStore.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java,CAS_DELIMITER",24,3,13,3.239047511703701,1,47.625,140,15.957911844135802,211.0,171.6732948928129,42.666666666666664,None,FALSE,TRUE,"[""63ed7191384053817b91910a428a028fe1ad0336"", ""94afb195dfae10fc40699f3c0efc31bb8f23f51a"", ""992a47e512a077ac95fcb265e7ee05236a788f6e"", ""b11e2a005014ecd827855dde9ce4d50b1f58aa4b"", ""562e8111552be8fbbe701c02dddfa3a3496a5f47"", ""a79eab750d002eb91efbe4cc02abb009b9db1ee9""]"
d3c1a34f3297146695c6cf30a67e56e8b8fbdbc7,Tom White,tom@cloudera.com,Wed Apr 24 10:39:21 2013 +0100,1366796361,Fix compilation with Java 6 .,6,7,"parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER,parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java,CAS_DELIMITER",3,3,3,1.198183947911799,2,70.66666666666667,16,4.5119444444444445,11.0,10.82607348913251,0.6666666666666666,Corrective,TRUE,FALSE,
bd826ec880bc2ecda69b2bfb0b89d8dbe3c08845,Mickael Lacour,m.lacour@criteo.com,Tue Apr 23 18:25:47 2013 +0200,1366734347,Add a simple unit test for ParquetSerDe,130,0,"parquet-hive/src/test/java/parquet/hive/TestParquetSerDe.java,CAS_DELIMITER",1,1,1,0.0,1,0.0,0,0.0,9.0,8.877881180490474,9.0,Feature Addition,FALSE,FALSE,
6c219a5f1c5a18f1d7391db20245a1981c5587c6,Mickael Lacour,m.lacour@criteo.com,Tue Apr 23 18:25:17 2013 +0200,1366734317,Fix Short object for Hive ( use short for short instead of byte : ) ),10,2,"parquet-hive/src/main/java/parquet/hive/serde/MapWritableObjectInspector.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java,CAS_DELIMITER",2,1,1,0.9798687566511527,2,251.5,14,2.5025520833333332,8.0,7.877889512605006,8.0,Corrective,TRUE,FALSE,
7f534d5259ff71d8c77b9fbeb4c381b4007b188b,Mickael Lacour,m.lacour@criteo.com,Tue Apr 23 18:23:24 2013 +0200,1366734204,Implement a basic version of the SerDeStats object for ParquetHiveSerDe,32,5,"parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java,CAS_DELIMITER",1,1,1,0.0,2,276.0,6,5.002488425925926,7.0,6.877917313824165,7.0,None,FALSE,FALSE,
910e7cd962f2a516e353214a32cc1e5ceb910d0a,Mickael Lacour,m.lacour@criteo.com,Tue Apr 23 18:22:14 2013 +0200,1366734134,Add equals and hashcode methods to BinaryWritable,38,4,"parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java,CAS_DELIMITER",1,1,1,0.0,2,70.0,3,5.353634259259259,6.0,5.87793231622641,6.0,Feature Addition,FALSE,FALSE,
d64c883beb9197500ce0922b60462a686435916d,julien,julien@twitter.com,Tue Apr 23 08:52:31 2013 -0700,1366732351,mae dictionary more generic ; allow converters to understand dictionaries,193,75,"parquet-column/src/main/java/parquet/column/Dictionary.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/Encoding.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnReadStoreImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/ValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/PlainBinaryDictionary.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/MessageColumnIO.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/api/GroupConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/api/PrimitiveConverter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java,CAS_DELIMITER",13,1,9,2.9742577612118035,1,24.846153846153847,47,28.739741809116808,209.0,170.51724980376562,54.0,None,FALSE,TRUE,"[""562e8111552be8fbbe701c02dddfa3a3496a5f47""]"
f866bb844c8534c3c14975c185c3df627f640b24,julien,julien@twitter.com,Mon Apr 22 14:48:01 2013 -0700,1366667281,more tests for optional vs required,93,40,"parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER",1,1,1,0.0,1,37.0,12,2.916701388888889,208.0,169.8095121539004,53.0,Preventative,FALSE,FALSE,
64c45cbe585d6be1fdc0c4f87e4ac977b5df5eb7,Tom White,tom@cloudera.com,Mon Apr 22 12:30:57 2013 +0100,1366630257,Add test for nested records following fix in 61d5170844aaf611555a0dd63c5e24af08acf1c8,5,6,"parquet-avro/src/test/java/parquet/avro/TestReadWrite.java,CAS_DELIMITER",1,1,1,0.0,2,78.0,3,5.018773148148148,10.0,9.882492497820564,8.0,Corrective,TRUE,FALSE,
5121cd599c259d9eda51585a66ca680591398c65,Tom White,tom@cloudera.com,Mon Apr 22 12:24:00 2013 +0100,1366629840,Avoid double conversion of bytes for Avro Utf8 instances .,10,1,"parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java,CAS_DELIMITER",1,1,1,0.0,2,155.0,4,5.034849537037037,9.0,8.882621653268618,7.0,None,FALSE,FALSE,
1605cda914e596b90cd95d1adbc7001ad0557da8,Tom White,tom@cloudera.com,Mon Apr 22 12:15:06 2013 +0100,1366629306,Avoid copying bytes if ByteBuffer is array - based .,12,0,"parquet-column/src/main/java/parquet/io/api/Binary.java,CAS_DELIMITER",1,1,1,0.0,2,53.0,4,5.036203703703704,8.0,7.882770118190696,1.0,None,FALSE,FALSE,
e365840ea62f29a6cca472772bf96bee8b1a4e3c,Tom White,tom@cloudera.com,Mon Apr 22 11:54:37 2013 +0100,1366628077,Create generic Parquet reader and writer for object records .,179,95,"parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/CodecFactory.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetWriter.java,CAS_DELIMITER",5,2,2,2.043593387915517,2,25.6,6,8.078694444444444,7.0,6.883072855935273,3.5,Feature Addition,FALSE,TRUE,
8b69ad5d107946d0a52a30f879ef3f932ba72a32,Dmitriy Ryaboy,dvryaboy@gmail.com,Fri Apr 19 23:08:53 2013 -0700,1366438133,address comments from @ J,7,1,"parquet-scrooge/src/main/java/parquet/scrooge/ScroogeRecordConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/DeprecatedContainerInputFormat.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java,CAS_DELIMITER",3,2,2,1.2987949406953985,2,172.33333333333334,11,5.243622685185185,4.0,3.886721702925259,3.0,Feature Addition,FALSE,FALSE,
61d5170844aaf611555a0dd63c5e24af08acf1c8,julien,julien@twitter.com,Fri Apr 19 16:47:58 2013 -0700,1366415278,fix bug where a required field would not be created at the right level,38,3,"parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER",2,1,2,0.6593758812786992,1,-30.0,21,33.12652777777778,207.0,169.9429911145322,52.0,Corrective,TRUE,FALSE,
aa851eb7ca9edd0c364bfe39ec2c2f99c4914d01,julien,julien@twitter.com,Fri Apr 19 14:35:01 2013 -0700,1366407301,remove broken reader / writer,6,226,"parquet-column/src/main/java/parquet/column/values/bitpacking/IntBasedBitPackingValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/IntBasedBitPackingValuesWriter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPackingColumn.java,CAS_DELIMITER",3,1,2,1.2247259006035245,1,82.33333333333333,8,2.1141550925925925,206.0,168.97886853609043,51.0,None,FALSE,FALSE,
c2bdea0d004103fe74585d42abe3643a62d3da0a,Dmitriy Ryaboy,dvryaboy@gmail.com,Fri Apr 19 14:22:09 2013 -0700,1366406529,address comments from alex l .,17,24,"parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER,parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java,CAS_DELIMITER,parquet-scrooge/src/main/java/parquet/scrooge/ScroogeRecordConverter.java,CAS_DELIMITER,parquet-scrooge/src/test/java/parquet/scrooge/TestScroogeIOFormats.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/TBaseRecordConverter.java,CAS_DELIMITER",7,4,6,2.4864023440215632,2,58.714285714285715,25,15.374862764550263,3.0,2.8905112741131718,1.25,Feature Addition,FALSE,FALSE,
126da3cad286d441f6638ba94ba9d201c4081231,Mickael Lacour,m.lacour@criteo.com,Thu Apr 18 18:19:49 2013 +0200,1366301989,Give selected columns to ParquetInputFormat : Done - no more hack - works with HiveInputFormat and HiveCombine,40,91,"parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/MapWritableGroupConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/read/MapWritableReadSupport.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/MapWritableObjectInspector.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java,CAS_DELIMITER",7,1,4,2.2341713102225227,2,214.57142857142858,34,0.3519560185185186,5.0,4.957920591057233,5.0,None,FALSE,FALSE,
ebf76d4dfca1e1bf6d69f0f6c64e4860452c866e,Mickael Lacour,m.lacour@criteo.com,Thu Apr 18 09:53:00 2013 +0200,1366271580,Indentation : retab to 2 spaces . Nothing else .,1643,1634,"parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/HiveGroupConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/MapWritableGroupConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/MapWritableRecordConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/read/MapWritableReadSupport.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/MapWritableObjectInspector.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/writable/BigDecimalWritable.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/write/MapWritableWriteSupport.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/write/MapWritableWriter.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/TestHiveInputFormat.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/TestHiveSchemaConverter.java,CAS_DELIMITER",20,1,7,3.9491653208552338,2,142.85,60,1.234870949074074,4.0,3.962666049159109,4.0,None,FALSE,FALSE,
1ada3d2b48778378763985124fe66c759e288b92,Mickael Lacour,m.lacour@criteo.com,Wed Apr 17 20:15:27 2013 +0200,1366222527,"Some improvements on the hive implementation : - start to read complex type ( struct done ! , other in progress ) - start to write complex type ( struct done ! , other maybe done : ) ) - try to give only the requested schema to parquet objects but we have some troubles with the way readsupport object is initialized . Trying few work around with hive to force the jobConf to be updated ( like they do for RCFile in HiveInputFormat ) . Not working when getSplits is called because we have no path ( in progress ) . Unit test : - Just a start only one very very tiny small is working to test hiveschemaconverter - working on the SerDe testing ( trying to create a parquet file first in unit test ) The code is not clean , neither optimize . 'Make it work , Make it right , Make it fast' only on the first step : p",404,92,"parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/HiveGroupConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/read/MapWritableReadSupport.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/MapWritableObjectInspector.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/TestHiveInputFormat.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/TestHiveOuputFormat.java,CAS_DELIMITER,parquet-hive/src/test/java/parquet/hive/TestHiveSchemaConverter.java,CAS_DELIMITER",12,1,5,2.996824150112363,2,107.83333333333333,19,1.0435329861111111,3.0,2.9687822789973097,3.0,None,FALSE,FALSE,
58d8c52e91ae45252e388747f0bf17ebc859930e,Tom White,tom@cloudera.com,Wed Apr 17 12:03:55 2013 +0100,1366196635,Remove incorrect record initialization to compensate for broken support for nested records ( not yet fixed ) .,5,6,"parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestReadWrite.java,CAS_DELIMITER",2,1,2,0.4394969869215134,2,218.0,6,0.02675347222222222,6.0,5.97693529983296,5.0,Corrective,TRUE,FALSE,
e47f3b13a69672bebecb6928360dcd38aa8657b6,Tom White,tom@cloudera.com,Wed Apr 17 11:52:05 2013 +0100,1366195925,Fix creation of arrays and maps in converters .,14,7,"parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java,CAS_DELIMITER",1,1,1,0.0,2,351.0,3,0.012685185185185185,5.0,4.977069359582028,4.0,Corrective,TRUE,FALSE,
11bb824716f757ed1d69405fb0c5821975a606fd,Tom White,tom@cloudera.com,Wed Apr 17 11:33:49 2013 +0100,1366194829,Remove unnecessary level of grouping for array .,5,23,"parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java,CAS_DELIMITER",4,1,2,1.7965062604933844,2,182.25,8,2.124508101851852,4.0,3.977241559186703,3.0,None,FALSE,TRUE,"[""6f25a0f2e68adc13d8c2caaf87a864bba8fd8be5""]"
568bd7f60ffa0fa75071c4ac1675bcc1519c0c00,Tom White,tom@cloudera.com,Wed Apr 17 11:22:58 2013 +0100,1366194178,Add Binary . fromByteBuffer method .,50,4,"parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/api/Binary.java,CAS_DELIMITER",2,2,2,0.44506485705083865,2,84.5,5,9.840630787037036,3.0,2.9773232041217677,1.0,Feature Addition,FALSE,TRUE,"[""634cb777c22ee7d4b03b3c35c85f3d198e7c1691""]"
61a163d31b1fd9aac7443fc547aeb6cc73089e62,Tom White,tom@cloudera.com,Wed Apr 17 11:10:41 2013 +0100,1366193441,Honor repetitions correctly .,8,25,"parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java,CAS_DELIMITER",1,1,1,0.0,2,136.0,1,8.433981481481482,2.0,1.9773922680995646,1.0,None,FALSE,FALSE,
42c38a1e016b9fc7d280012a237101a1a2d5a0be,Tom White,tom@cloudera.com,Wed Apr 17 10:58:42 2013 +0100,1366192722,Remove unchecked generics warnings .,22,19,"parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestReadWrite.java,CAS_DELIMITER",3,1,2,1.3247497144200897,2,199.66666666666666,3,8.425659722222223,1.0,0.9774368485323429,0.0,None,FALSE,FALSE,
e3e81597fc03c12515adabfe9c69419024b9403f,julien,julien@twitter.com,Tue Apr 16 14:40:39 2013 -0700,1366148439,make things that look like closeables implement Closeable,13,4,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java,CAS_DELIMITER",2,2,2,0.7871265862012691,1,48.5,17,26.362106481481483,203.0,167.12708233307035,33.0,None,FALSE,FALSE,
b0e9609e4850fcf8e0e79a427aa0f079aaf04b10,julien,julien@twitter.com,Tue Apr 16 10:31:06 2013 -0700,1366133466,more tests and bug fixing the Bit packing,129,90,"parquet-column/src/main/java/parquet/bytes/BytesInput.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/IntBasedBitPackingValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/IntBasedBitPackingValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingBE.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingLE.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPacking.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/bitpacking/TestBitPackingColumn.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java,CAS_DELIMITER",8,1,3,2.7100115439275614,1,483.75,18,0.7053298611111112,202.0,166.19349045862342,48.0,Corrective,TRUE,FALSE,
07e54a534ab872191a247270f281de7bdc3f803a,Mickael Lacour,m.lacour@criteo.com,Tue Apr 16 15:03:24 2013 +0200,1366117404,rename one parameter,2,2,"parquet-hive/src/main/java/parquet/hive/convert/MapWritableRecordConverter.java,CAS_DELIMITER",1,1,1,0.0,2,54.0,3,0.18097222222222223,2.0,1.9786088872205436,2.0,None,FALSE,FALSE,
f5ca27b0cef7902203035319887fbe792fe36459,Mickael Lacour,m.lacour@criteo.com,Tue Apr 16 11:10:00 2013 +0200,1366103400,Improve column reading - Trying to only read the right column ( work in progress ),554,274,"parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/ManageJobConfig.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/MapWritableGroupConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/MapWritableRecordConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/read/MapWritableReadSupport.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/MapWritableObjectInspector.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/writable/BigDecimalWritable.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/write/MapWritableWriteSupport.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/write/MapWritableWriter.java,CAS_DELIMITER",14,1,6,3.557651613352842,1,130.35714285714286,16,6.894670965608465,1.0,0.9794785941252032,1.0,None,FALSE,FALSE,
b4d1c7149f861377e8b776f0d82a6b0a86dfd7d0,Remy Pecqueur,r.pecqueur@criteo.com,Tue Apr 16 10:42:48 2013 +0200,1366101768,Can read some complex types - Structs should be entirely good - Array and maps do not seem to work correctly,465,177,"parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/ArrayWritableGroupConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/HiveGroupConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/MapWritableGroupConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/MapWritableRecordConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/MapWritableObjectInspector.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveArrayInspector.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveMapInspector.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/write/MapWritableWriter.java,CAS_DELIMITER",12,1,4,3.3416648550123624,2,130.75,23,0.4045466820987655,3.0,2.9639988579412786,3.0,None,FALSE,FALSE,
a0926f380bacc3eca8afcaa208b8c4734a1e2d45,julien,julien@twitter.com,Mon Apr 15 12:02:40 2013 -0700,1366052560,add both orders as we might want to change our encoding in the future,3518,30,"parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingGenerator.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/IntBasedBitPackingValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/IntBasedBitPackingValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/IntPacker.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingBE.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingLE.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java,CAS_DELIMITER",7,1,2,0.42821756183015613,1,82.28571428571429,13,0.020714285714285713,201.0,165.55068046247595,47.0,Feature Addition,FALSE,FALSE,
4611c4778027a167f474c777573bbf30aa4a08fa,julien,julien@twitter.com,Mon Apr 15 11:27:52 2013 -0700,1366050472,writer readers for int based packing,405,83,"parquet-column/src/main/java/parquet/bytes/BytesInput.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingGenerator.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/IntBasedBitPackingValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/IntBasedBitPackingValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/IntPacker.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPackingBE.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java,CAS_DELIMITER",9,1,3,2.1806341348749876,1,35.666666666666664,15,9.710437242798355,200.0,164.5598531328127,46.0,None,FALSE,TRUE,"[""b0e9609e4850fcf8e0e79a427aa0f079aaf04b10""]"
4fe18c5386af73952c7c4d090ea4c5c8b9bcf85d,Remy Pecqueur,r.pecqueur@criteo.com,Mon Apr 15 11:08:22 2013 +0200,1366016902,Can write complex types,262,83,"parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/MapWritableGroupConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/MapWritableObjectInspector.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/write/MapWritableWriteSupport.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/write/MapWritableWriter.java,CAS_DELIMITER",6,1,3,2.0624633870088145,1,122.33333333333333,12,-1.0011342592592596,2.0,1.9719008758024201,2.0,None,FALSE,FALSE,
07c56fcb2c8448701d1542c25c9ac2afa28aba5c,julien,julien@twitter.com,Fri Apr 12 13:31:02 2013 -0700,1365798662,add notice,12,0,"parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingGenerator.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPacking.java,CAS_DELIMITER",2,1,1,1.0,1,1669.0,6,0.08940972222222222,199.0,164.66562945210617,45.0,Feature Addition,FALSE,FALSE,
f7a47d3572ccae6467a27503dda2664bb7bd424f,julien,julien@twitter.com,Fri Apr 12 11:20:52 2013 -0700,1365790852,adapt Lemire's scheme to our value ordering,2426,2413,"parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingGenerator.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPacking.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java,CAS_DELIMITER",3,1,2,0.06998702654088246,1,1127.3333333333333,3,0.8434027777777778,197.0,162.6999163176977,43.0,None,FALSE,FALSE,
4fe082c513d9388a3eddd6a857ba576b908b54da,julien,julien@twitter.com,Thu Apr 11 15:06:22 2013 -0700,1365717982,BitPacking up to 31 bits,3434,3,"parquet-column/src/main/java/parquet/bytes/BytesUtils.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingGenerator.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/LemireBitPacking.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/rle/RLEDecoder.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/bitpacking/TestLemireBitPacking.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/rle/TestRLE.java,CAS_DELIMITER",6,1,5,0.525212453548753,1,19.166666666666668,8,5.555142746913581,196.0,162.0159172905049,42.0,None,FALSE,TRUE,"[""b0e9609e4850fcf8e0e79a427aa0f079aaf04b10"", ""63ed7191384053817b91910a428a028fe1ad0336""]"
0bb5e93507c0725f3f938b38605c67bcaa507b1a,julien,julien@twitter.com,Wed Apr 10 11:10:25 2013 -0700,1365617425,first stab at rle encoding,144,0,"parquet-column/src/main/java/parquet/column/values/rle/RLEDecoder.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/rle/RLESimpleEncoder.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/rle/TestRLE.java,CAS_DELIMITER",3,1,2,1.5089913256484369,1,0.0,0,0.0,195.0,161.45083445724111,41.0,None,FALSE,FALSE,
fcc88f3e81b9b29f0bb46772f0c8f944fe531ce3,Remy Pecqueur,r.pecqueur@criteo.com,Wed Apr 10 17:06:55 2013 +0200,1365606415,"Add support for CombineHiveInputFormat - This recreates the input splits by reading each file's metadata - This is slower than being able to get our InputSplits directly , but still faster than calling getSplits over and over again",21,18,"parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java,CAS_DELIMITER",1,1,1,0.0,1,348.0,2,0.901412037037037,1.0,0.9975364619884393,1.0,Feature Addition,FALSE,FALSE,
d5b3b7d836638a9f29f7798aee5da3c289a5cad4,julien,julien@twitter.com,Tue Apr 9 15:20:57 2013 -0700,1365546057,better logging,1,1,"parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java,CAS_DELIMITER",1,1,1,0.0,1,48.0,12,4.223958333333333,194.0,160.75867844408063,40.0,Perfective,FALSE,FALSE,
2471e518729a84d6800c8b7b5abf0566f5bf8bec,Remy Pecqueur,r.pecqueur@criteo.com,Tue Apr 9 19:28:53 2013 +0200,1365528533,"Remove any K , V from DeprecatedXXFormat",30,37,"parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java,CAS_DELIMITER",2,1,1,0.9869444983748494,1,262.0,2,0.9936921296296296,0.0,0.0,0.0,None,FALSE,FALSE,
02b283dbd3c44206ca31e2fcd0bfebe6949ef4be,Tom White,tom@cloudera.com,Mon Apr 8 16:45:45 2013 -0700,1365464745,Initial support for Avro .,1175,2,"parquet-avro/src/main/java/parquet/avro/AvroGenericRecordConverter.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroParquetInputFormat.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroParquetOutputFormat.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroParquetReader.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroParquetWriter.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroReadSupport.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroRecordMaterializer.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroSchemaConverter.java,CAS_DELIMITER,parquet-avro/src/main/java/parquet/avro/AvroWriteSupport.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestAvroSchemaConverter.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestInputOutputFormat.java,CAS_DELIMITER,parquet-avro/src/test/java/parquet/avro/TestReadWrite.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/CodecFactory.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java,CAS_DELIMITER",14,2,3,3.086087898780568,2,1.2142857142857142,10,3.727254464285714,0.0,0.0,0.0,Feature Addition,FALSE,FALSE,
08c8f82011925d3ba083f8b23b8f1c0af29c0d7e,Dmitriy Ryaboy,dvryaboy@gmail.com,Mon Apr 8 15:36:50 2013 -0700,1365460610,"use published EB , fix NPE in ThriftMetaData",1,1,"parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java,CAS_DELIMITER",1,1,1,0.0,2,34.0,2,4.982743055555556,2.0,1.9765365220513824,2.0,Corrective,TRUE,FALSE,
c7a8eafa62be64a12a7f6f518e43733a67e6f39f,Mickael Lacour,m.lacour@criteo.com,Mon Apr 8 19:37:58 2013 +0200,1365442678,"Start implementation parquet for hive : - Read simple data ( INT32 , INT64 , DOUBLE , FLOAT , BOOLEAN , BINARY - String ) - Write simple data ( INT32 , INT64 , FLOAT , DOUBLE , BOOLEAN , BINARY - String ) - Read data works only if HiveInputFormat is set ( not CombineHive ) TODO : - Support complex type ( struct , map , array ) - Support CombineHive - Unit test : )",1829,0,"parquet-hive/src/main/java/parquet/hive/DeprecatedParquetInputFormat.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/DeprecatedParquetOutputFormat.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/ETypeConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/HiveSchemaConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/MapWritableGroupConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/convert/MapWritableRecordConverter.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/read/MapWritableReadSupport.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/MapWritableObjectInspector.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/serde/ParquetHiveSerDe.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/writable/BigDecimalWritable.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/writable/BinaryWritable.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/write/MapWritableWriteSupport.java,CAS_DELIMITER,parquet-hive/src/main/java/parquet/hive/write/MapWritableWriter.java,CAS_DELIMITER",13,1,6,3.431394146713359,1,0.0,0,0.0,0.0,0.0,0.0,None,FALSE,FALSE,
9656ef2806fc4a35e7754eee8b1a742e921bf9eb,julien,julien@twitter.com,Fri Apr 5 09:58:27 2013 -0700,1365181107,improve api ; improve logs ; improve PrintFooter,33,33,"parquet-column/src/main/java/parquet/column/values/ValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java,CAS_DELIMITER",4,2,3,1.681918821016414,1,65.25,23,6.631993634259259,193.0,161.33997364917943,39.5,None,FALSE,FALSE,
073421762e172b68af81c97374b5c45234ce4f17,Dmitriy Ryaboy,dvryaboy@gmail.com,Thu Apr 4 23:09:54 2013 -0700,1365142194,add license headers,473,11,"parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java,CAS_DELIMITER,parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java,CAS_DELIMITER,parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java,CAS_DELIMITER,parquet-scrooge/src/main/java/parquet/scrooge/ScroogeRecordConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/Container.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/DeprecatedContainerInputFormat.java,CAS_DELIMITER",6,3,3,1.3469616623521543,2,32.166666666666664,4,0.8649151234567901,1.0,0.9964581436233774,0.3333333333333333,Feature Addition,FALSE,FALSE,
9c62f41d3b4e4294d3d7a009e2bceda19d854c75,julien,julien@twitter.com,Thu Apr 4 22:15:53 2013 -0700,1365138953,improve dictionary,201,181,"parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/BinaryEncodingPickerValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/ValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java,CAS_DELIMITER",7,2,5,2.2394555574445363,1,60.285714285714285,30,1.185304232804233,192.0,160.5233200748802,38.5,None,FALSE,TRUE,"[""63ed7191384053817b91910a428a028fe1ad0336"", ""6e6516622b26450d2030442c9a794e3d021e262f"", ""562e8111552be8fbbe701c02dddfa3a3496a5f47"", ""256a3a1eb328e6f02eebc82eb37d91ad69e475d5""]"
8fc53c49b9c0ea287e131b30a975e1ecbb8cc3ff,julien,julien@twitter.com,Thu Apr 4 11:21:28 2013 -0700,1365099688,improve logging,14,2,"parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java,CAS_DELIMITER",2,2,2,0.5435644431995964,1,62.0,13,0.8534837962962963,191.0,159.69323497637643,37.5,None,FALSE,FALSE,
a4f133aab1e6908f9c7244d755df0b90a9d12a38,julien,julien@twitter.com,Wed Apr 3 18:03:19 2013 -0700,1365037399,cleaning methods,23,43,"parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/ParquetLoader.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java,CAS_DELIMITER",7,2,6,2.183054979893311,1,72.0,71,9.982276785714285,190.0,158.96155439857,32.5,Perfective,FALSE,TRUE,
8f9f0c77ab4e2972192ca76a6ee7b5228fe10b7b,julien,julien@twitter.com,Wed Apr 3 17:48:04 2013 -0700,1365036484,integrate thrift change in format,18,61,"parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER",2,1,2,0.17033057560105985,1,52.5,28,0.12195601851851852,189.0,157.96547370227097,35.0,None,FALSE,FALSE,
90b5eae8ba0e7230dc5c379c14ebda076b4dd283,Dmitriy Ryaboy,dvryaboy@gmail.com,Wed Apr 3 16:01:41 2013 -0700,1365030101,add scrooge and cascading support,312,21,"parquet-cascading/src/main/java/parquet/cascading/ParquetTBaseScheme.java,CAS_DELIMITER,parquet-cascading/src/main/java/parquet/cascading/ParquetValueScheme.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER,parquet-scrooge/src/main/java/parquet/scrooge/ParquetScroogeScheme.java,CAS_DELIMITER,parquet-scrooge/src/main/java/parquet/scrooge/ScroogeRecordConverter.java,CAS_DELIMITER,parquet-scrooge/src/test/java/parquet/scrooge/TestScroogeIOFormats.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftInputFormat.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/TBaseRecordConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java,CAS_DELIMITER",10,4,6,2.966230790560491,2,20.3,18,11.75808449074074,0.0,0.0,0.0,Feature Addition,FALSE,TRUE,"[""5e82439eb8f99d20a5bbc55fdeaa0840b0cac90f"", ""86ae4f87c4254a74006f807aed8199d3138cc4ad""]"
4a69511fea03a2f4051df3f90e1fd0f982d7def0,julien,julien@twitter.com,Wed Apr 3 14:52:27 2013 -0700,1365025947,dictionary encoding,190,12,"parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/BinaryEncodingPickerValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/ValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java,CAS_DELIMITER",12,3,8,2.4210451450978017,1,33.333333333333336,70,5.765497685185185,187.0,156.01006494883399,31.666666666666668,None,FALSE,FALSE,
827a5bc4a7a00c624dd6062804ae7f4f42be16a8,julien,julien@twitter.com,Wed Apr 3 08:21:08 2013 -0700,1365002468,fix dictionary encoding,30,10,"parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/page/DictionaryPage.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/ValuesReader.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/page/mem/MemPageReader.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER",7,2,6,2.1715232620314477,1,38.857142857142854,30,0.5767708333333333,186.0,155.10852376944112,34.5,Corrective,TRUE,FALSE,
e18d38bc1d6527439919e61fb19c429921acdadc,julien,julien@twitter.com,Tue Apr 2 18:30:35 2013 -0700,1364952635,dictionary encoding,546,129,"parquet-column/src/main/java/parquet/bytes/BytesInput.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/Dictionary.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/Encoding.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/page/DictionaryPage.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/page/PageReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/page/PageWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/ValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/ValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/dictionary/PlainDictionary.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/page/mem/MemPageReader.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/page/mem/MemPageStore.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER",23,2,10,4.158782737576786,1,17.217391304347824,76,12.783960849436394,185.0,154.31633312955708,33.5,None,FALSE,TRUE,"[""827a5bc4a7a00c624dd6062804ae7f4f42be16a8"", ""562e8111552be8fbbe701c02dddfa3a3496a5f47""]"
5c60ed8459b88d44eb6c555fff8c3cd1b3e26d17,julien,julien@twitter.com,Thu Mar 28 13:06:05 2013 -0700,1364501165,remove one array copy,6,2,"parquet-column/src/main/java/parquet/bytes/BytesInput.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java,CAS_DELIMITER",2,1,2,0.5435644431995964,1,18.5,6,12.420844907407407,184.0,155.2105439582264,34.0,None,FALSE,FALSE,
8246e0bbb229f54bf8fcb03f6133d7c5f8f4036c,julien,julien@twitter.com,Thu Mar 28 11:26:13 2013 -0700,1364495173,"fix perf problem with new String ( bytes , offset , length , encoding )",5,1,"parquet-column/src/main/java/parquet/io/api/Binary.java,CAS_DELIMITER",1,1,1,0.0,1,0.0,2,15.588136574074074,183.0,154.23581143779634,33.0,Corrective,TRUE,FALSE,
1b2694e462abaff27a134a2ebaed837f8a306aef,julien,julien@twitter.com,Wed Mar 27 18:16:55 2013 -0700,1364433415,fix offset,3,2,"parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java,CAS_DELIMITER",1,1,1,0.0,1,38.0,1,0.013101851851851852,182.0,153.4947616247931,32.0,Corrective,TRUE,TRUE,"[""8305bdb1937a24bc7e778ec497ceafb8b883be42""]"
cf5ba492d2c4acc00305c880dddc661909e66ff4,julien,julien@twitter.com,Wed Mar 27 18:09:01 2013 -0700,1364432941,fix perf test,11,4,"parquet-column/src/main/java/parquet/example/DummyRecordConverter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/PerfTest.java,CAS_DELIMITER",2,1,2,0.9709505944546686,1,52.0,16,7.1395833333333325,181.0,152.49673747748258,31.0,Corrective,TRUE,FALSE,
f5b2cb8e8bfd75f65b31b8dcb153f3cd094e762c,julien,julien@twitter.com,Wed Mar 27 17:58:03 2013 -0700,1364432283,add better Bytes plain decoder,41,12,"parquet-column/src/main/java/parquet/column/Encoding.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/BinaryPlainValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java,CAS_DELIMITER",3,1,2,1.0638509635882258,1,34.0,6,9.506458333333333,179.0,150.49951332478193,29.0,Feature Addition,FALSE,FALSE,
56faa1be0d3334fab7366c454c08da300d726e25,julien,julien@twitter.com,Wed Mar 27 17:29:47 2013 -0700,1364430587,first stab at dict encoding,69,0,"parquet-column/src/main/java/parquet/column/values/dictionary/DictionaryColumnWriter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/dictionary/TestDictionary.java,CAS_DELIMITER",2,1,2,0.63292089848238,1,0.0,0,0.0,180.0,151.50647615928807,30.0,None,FALSE,FALSE,
fce6998edbebee642c8194d8d74f90e6ab887fca,julien,julien@twitter.com,Thu Mar 21 16:43:00 2013 -0700,1363909380,avoid string decoding recoding,1,1,"parquet-thrift/src/main/java/parquet/thrift/ProtocolReadToWrite.java,CAS_DELIMITER",1,1,1,0.0,1,18.0,1,13.949918981481481,178.0,151.66059672158508,23.0,None,FALSE,FALSE,
696bce4436dcfbe5bb6aec164932bd2195f69128,julien,julien@twitter.com,Tue Mar 19 15:13:40 2013 -0700,1363731220,use constant for settings,3,1,"parquet-pig/src/main/java/parquet/pig/ParquetLoader.java,CAS_DELIMITER",1,1,1,0.0,1,14.0,7,0.16578703703703704,175.0,149.40027757824598,28.0,None,FALSE,FALSE,
5dfa1b22e5eb7f07c64f3d78bdee67fa07e5980e,julien,julien@twitter.com,Tue Mar 19 15:06:41 2013 -0700,1363730801,deal with elephantbird handling of numbers,69,20,"parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/convert/TupleRecordMaterializer.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestThriftToPigCompatibility.java,CAS_DELIMITER",5,2,3,1.5715229724563946,1,63.8,32,2.121914351851852,174.0,148.4019986141441,24.5,None,FALSE,FALSE,
071b8f4626f125c81a01a5c07111d4d52102dbdf,julien,julien@twitter.com,Tue Mar 19 11:14:56 2013 -0700,1363716896,change ReadSupport api to fix projection support,398,243,"parquet-column/src/main/java/parquet/schema/MessageType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/PrimitiveType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/Type.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputCommitter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/api/WriteSupport.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/example/GroupReadSupport.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/metadata/FileMetaData.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/metadata/ParquetMetadata.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/ParquetLoader.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestThriftToPigCompatibility.java,CAS_DELIMITER",26,4,12,3.7661543012109564,1,30.5,145,8.870888532763532,173.0,147.45869488331647,26.0,Corrective,TRUE,FALSE,
e0879089422d33387d25acce29d5cc39e29cfcfd,julien,julien@twitter.com,Mon Mar 18 10:50:34 2013 -0700,1363629034,integrate elaphantbird 3 . 0 . 8,45,54,"parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/struct/ThriftField.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java,CAS_DELIMITER",5,1,3,1.047052573811225,1,13.2,9,8.242143518518517,172.0,146.8151680540435,20.0,None,FALSE,FALSE,
d81380a358cbb8100d99ac0e0f9ea1fdcd144738,julien,julien@twitter.com,Mon Mar 18 10:13:54 2013 -0700,1363626834,add test to ensure enums are equivalent,103,12,"parquet-column/src/main/java/parquet/column/Encoding.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/PrimitiveType.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java,CAS_DELIMITER",4,2,4,1.935894617148994,1,42.75,22,9.397991898148149,171.0,145.8240465468677,27.5,Feature Addition,FALSE,TRUE,"[""a79eab750d002eb91efbe4cc02abb009b9db1ee9""]"
4828f1dcf1dc1fa2d1b33617469885acf632af69,julien,julien@twitter.com,Mon Mar 18 08:33:56 2013 -0700,1363620836,fix metadata conversion,5,34,"parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER",1,1,1,0.0,1,67.0,9,2.706377314814815,170.0,144.8480678481124,29.0,Corrective,TRUE,FALSE,
df3e94ad9e4d6cd87f487087616d220e90cf192e,julien,julien@twitter.com,Fri Mar 15 15:36:45 2013 -0700,1363387005,change default level encoding to bit packed ; instanciate reader from page header encoding,210,87,"parquet-column/src/main/java/parquet/column/Encoding.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/page/Page.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/page/PageWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/ValuesType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/ValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/boundedint/DevNullValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/mem/TestMemPageStore.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java,CAS_DELIMITER",21,3,13,3.8911446855684244,1,14.095238095238095,72,5.816547619047618,169.0,144.78336065479502,25.666666666666668,None,FALSE,FALSE,
e93e35cfe4e102b9b98deb171065509fe6668ba9,julien,julien@twitter.com,Fri Mar 15 13:26:45 2013 -0700,1363379205,fix metadata file in mr mode,19,8,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputCommitter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java,CAS_DELIMITER",4,1,1,1.4762856555827248,1,20.0,22,9.49537037037037,168.0,143.81452339828297,27.0,Corrective,TRUE,FALSE,
ef0069eecb6448270b5ca60fb82caf8ab77811b0,julien,julien@twitter.com,Thu Mar 14 15:58:32 2013 -0700,1363301912,incorporate feddback ; more tests,160,26,"parquet-column/src/main/java/parquet/example/data/Group.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/convert/ParentValueContainer.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java,CAS_DELIMITER",5,2,3,1.8871308216694576,1,6.0,29,2.521902777777778,167.0,143.12160625132256,23.5,Preventative,FALSE,FALSE,
c44ff2de4cb9ddc8d8ae42f4cf8336902d7208a3,julien,julien@twitter.com,Thu Mar 14 11:23:55 2013 -0700,1363285435,cleanup,2,5,"parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestThriftToPigCompatibility.java,CAS_DELIMITER",3,2,2,1.5566567074628228,1,77.66666666666667,15,0.008067129629629629,166.0,142.186718211204,21.0,Perfective,FALSE,FALSE,
65364a46bc72bb99fbdc4f19cb51a0db2ab8030e,julien,julien@twitter.com,Thu Mar 14 11:12:18 2013 -0700,1363284738,fix map of primitive ; add thrift to pig compat,382,97,"parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/convert/TupleRecordMaterializer.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/convert/ValueContainer.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestThriftToPigCompatibility.java,CAS_DELIMITER",8,2,3,1.9053929188047298,1,55.75,27,4.02033130787037,165.0,141.18945176003464,20.0,Corrective,TRUE,FALSE,
5fe97c8b3a293cd37e7dfc2f611a370bab6a9b0f,julien,julien@twitter.com,Tue Mar 12 21:20:07 2013 -0700,1363148407,add pig schema in thrift metadata,17,3,"parquet-pig/src/main/java/parquet/pig/PigMetaData.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java,CAS_DELIMITER",3,2,2,1.4406454496153462,1,13.333333333333334,14,4.337372685185185,164.0,140.72184093796696,19.0,Feature Addition,FALSE,FALSE,
de8bc0d11b0834aca31f65159c641e4051844ac1,julien,julien@twitter.com,Tue Mar 12 21:19:18 2013 -0700,1363148358,fix java 6 compiler compatibility,2,2,"parquet-column/src/main/java/parquet/io/api/Binary.java,CAS_DELIMITER",1,1,1,0.0,1,0.0,1,4.336805555555555,163.0,139.72203146724203,22.0,Corrective,TRUE,FALSE,
241634e6990bb929236863b985d362e6cc8698a7,julien,julien@twitter.com,Tue Mar 12 18:14:34 2013 -0700,1363137274,better exception when reading unknown field,9,6,"parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java,CAS_DELIMITER",1,1,1,0.0,1,31.0,5,4.2085185185185185,162.0,138.7647918228609,16.0,Perfective,FALSE,FALSE,
7bd223aba6584ea4caa3b40180c2c414be9e185f,julien,julien@twitter.com,Tue Mar 12 08:15:51 2013 -0700,1363101351,improved OutputFormat javadoc and defaults,22,8,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER",1,1,1,0.0,1,33.0,3,4.597731481481482,161.0,137.9024193961879,26.0,Non Functional,FALSE,FALSE,
bdec17ea2af932e60db3133d3d13cad7fa6e74f6,julien,julien@twitter.com,Mon Mar 11 15:01:50 2013 -0700,1363039310,integrate Todd's feedback,1,3,"parquet-column/src/main/java/parquet/bytes/BytesUtils.java,CAS_DELIMITER",1,1,1,0.0,1,14.0,5,6.575671296296297,160.0,137.1387917767167,21.0,None,FALSE,FALSE,
aa6dca8666b7f05e02c09f424e29f6f964c5a273,julien,julien@twitter.com,Mon Mar 11 14:19:02 2013 -0700,1363036742,integrate thrift format changes,3,10,"parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java,CAS_DELIMITER",2,1,2,0.8904916402194913,1,108.0,12,0.21614583333333331,159.0,136.14851197483617,25.0,None,FALSE,FALSE,
37b704153bc2bf50129b9e0a6ada3e2530876114,julien,julien@twitter.com,Mon Mar 11 13:53:01 2013 -0700,1363035181,better tests for new summary file,64,14,"parquet-hadoop/src/main/java/parquet/hadoop/Footer.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java,CAS_DELIMITER",3,1,2,0.6303018599887807,1,33.666666666666664,16,2.0851774691358025,158.0,135.15437173472444,24.0,Feature Addition,FALSE,FALSE,
251855be5bf1000d00371f4be7a04f3c83b438e4,julien,julien@twitter.com,Mon Mar 11 09:49:42 2013 -0700,1363020582,better metadata file tests,70,2,"parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java,CAS_DELIMITER",2,1,2,0.5435644431995964,1,75.0,9,2.8579166666666667,156.0,133.20868780857973,23.0,Perfective,FALSE,FALSE,
12b99b1a78478999ef8da2c5617d65a5b0e687ac,julien,julien@twitter.com,Mon Mar 11 08:25:52 2013 -0700,1363015552,metadata file in parquet format,109,31,"parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/metadata/BlockMetaData.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/metadata/FileMetaData.java,CAS_DELIMITER",6,1,3,1.9861105731024136,1,13.833333333333334,23,8.776332947530866,155.0,132.22710984395658,22.0,None,FALSE,TRUE,"[""071b8f4626f125c81a01a5c07111d4d52102dbdf"", ""3803d2d478ef73e1bccc2d887daad4b30647d854""]"
5a52fe124ab877876f5c884ee295d14d6573bd7d,julien,julien@twitter.com,Fri Mar 8 17:56:43 2013 -0800,1362794203,fix Filesystem access issues mentioned by Dmitriy,5,3,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER",1,1,1,0.0,1,33.0,6,0.23778935185185185,154.0,132.03586597852615,21.0,Corrective,TRUE,FALSE,
6e33c3d317965c8a26a98b79e6595a6b2062beb4,julien,julien@twitter.com,Fri Mar 8 14:35:12 2013 -0800,1362782112,fix Filesystem access issues mentioned by Dmitriy,3,3,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER",1,1,1,0.0,1,32.0,6,0.13358796296296296,153.0,131.07994915549875,20.0,Corrective,TRUE,FALSE,
e0dc2f324e555d3fe46665f2c02530b55a3d0060,julien,julien@twitter.com,Fri Mar 8 12:14:18 2013 -0800,1362773658,reorganizing packages and deleting old classes,183,573,"parquet-column/src/main/java/parquet/column/ColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/ColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnReadStoreImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/ValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/ValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/boundedint/DevNullValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/DummyRecordConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/Group.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/GroupRecordConsumer.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/GroupValueSource.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/GroupWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/BinaryValue.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/BooleanValue.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/DoubleValue.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/FloatValue.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/IntegerValue.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/LongValue.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/Primitive.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/convert/GroupRecordConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/convert/SimpleGroupConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/BaseRecordReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/MessageColumnIO.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/RecordMaterializer.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/api/Binary.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/api/Converter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/api/GroupConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/api/PrimitiveConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/api/RecordConsumer.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/api/RecordMaterializer.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/MessageTypeParser.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/PrimitiveType.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/ConverterConsumer.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/PerfTest.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/parser/TestParquetParser.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/schema/TestMessageType.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/api/WriteSupport.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/example/GroupReadSupport.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/example/GroupWriteSupport.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/PigMetaData.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/TupleRecordConsumer.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/convert/TupleRecordConverter.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestThriftSchemaConverter.java,CAS_DELIMITER",75,4,27,4.4978803289132845,1,26.44,223,3.173369598765433,152.0,130.11052160561317,18.25,None,FALSE,FALSE,
6b9366b1978f236f68e8bd8bf555fbdb5c82c8a9,julien,julien@twitter.com,Fri Mar 8 11:51:25 2013 -0800,1362772285,renaming classes and packages based on feedback,160,126,"parquet-column/src/main/java/parquet/column/Encoding.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnReadStoreImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnReaderImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnWriteStoreImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/impl/ColumnWriterImpl.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/DataValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/ValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/ValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/BitPacking.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/bitpacking/BitPackingValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/boundedint/BitReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/boundedint/BitWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesFactory.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/boundedint/BoundedIntValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/boundedint/DevNullValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/boundedint/ZeroIntegerValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/BooleanPlainValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/PlainValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/values/plain/PlainValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/MessageColumnIO.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/page/mem/MemPageReader.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/page/mem/MemPageStore.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/page/mem/MemPageWriter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/primitive/TestBitPacking.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/primitive/TestBitPackingColumn.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/values/boundedint/TestBoundedColumns.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/PerfTest.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java,CAS_DELIMITER",38,4,15,4.603196737227673,1,-1.8157894736842106,58,0.20239156920077966,151.0,129.11544465190738,17.25,None,FALSE,FALSE,
45138bb6736ef986f493b2c72fb0e9a61531bee7,julien,julien@twitter.com,Fri Mar 8 11:22:50 2013 -0800,1362770570,integrating feedback from Todd ; renaming PrimitiveColumnW / R to ValuesW / R,171,224,"parquet-column/src/main/java/parquet/column//MemColumnReadStore.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column//MemColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column//MemColumnWriteStore.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column//MemColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/page/Page.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/page/PageReadStore.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/page/PageReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/page/PageWriteStore.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/page/PageWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/page/mem/MemPageReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/page/mem/MemPageStore.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/page/mem/MemPageWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/BitPackingValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/BitPackingValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/BoundedIntValuesFactory.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/BoundedIntValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/BoundedIntValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/DataValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/DevNullColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/DevNullValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/PlainValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/PlainValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/ValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/ValuesWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/ZeroIntegerValuesReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/MessageColumnIO.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/mem/TestMemPageStore.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/primitive/TestBitPackingColumn.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/primitive/TestBoundedColumns.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/PerfTest.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java,CAS_DELIMITER",45,4,12,4.522619823648349,1,0.06666666666666667,82,2.1568392489711936,150.0,128.12154012322935,16.25,None,FALSE,FALSE,
668d74df8addad24ad0bd2e53a23a4ad07e5ad47,julien,julien@twitter.com,Thu Mar 7 16:55:07 2013 -0800,1362704107,exception cleanup ; creation of parquet . hadoop . api package ; thrift from bytes support ; bug fixes,574,111,"parquet-hadoop/src/main/java/parquet/hadoop/CodecFactory.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/PrintFooter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/api/ReadSupport.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/api/WriteSupport.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/example/GroupReadSupport.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/example/GroupWriteSupport.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/ParquetLoader.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/ParquetStorer.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/SchemaConversionException.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftBytesOutputFormat.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftInputFormat.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftOutputFormat.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftBytesWriteSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftToParquetFileWriter.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ParquetProtocol.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ParquetReadProtocol.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ProtocolReadToWrite.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/struct/ThriftTypeID.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftToParquetFileWriter.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestProtocolReadToWrite.java,CAS_DELIMITER",35,3,10,3.978695763131195,1,15.714285714285714,69,3.8383045634920654,149.0,127.35610207582042,14.666666666666666,Corrective,TRUE,TRUE,"[""071b8f4626f125c81a01a5c07111d4d52102dbdf""]"
5daf06892b533a06fa0d80c83006f84b74e429f8,julien,julien@twitter.com,Wed Mar 6 17:29:16 2013 -0800,1362619756,more thrift bug fixes,207,33,"parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/mem/MemColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/Binary.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ParquetReadToWriteProtocol.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestParquetReadProtocol.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestParquetReadWriteProtocol.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java,CAS_DELIMITER",10,2,5,2.646549990928256,1,172.3,35,0.5647291666666665,148.0,126.65236976454305,14.0,Corrective,TRUE,FALSE,
b9463550d01f4b0118f725ed957e6e4354b0e4ba,julien,julien@twitter.com,Wed Mar 6 15:32:07 2013 -0800,1362612727,thrift enum and list fixes ; ParquetReadToWrite,806,364,"parquet-column/src/main/java/parquet/io/Binary.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/ConversionPatterns.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ParquetReadToWriteProtocol.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetWriteProtocol.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet//thrift/TestParquetReadProtocol.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestParquetReadWriteProtocol.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/thrift/TestParquetWriteProtocol.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet//thrift/TestThriftSchemaConverter.java,CAS_DELIMITER",12,3,7,2.6569649220954217,1,79.66666666666667,17,1.6070949074074072,147.0,125.67689803131067,13.666666666666666,Corrective,TRUE,TRUE,"[""5daf06892b533a06fa0d80c83006f84b74e429f8"", ""668d74df8addad24ad0bd2e53a23a4ad07e5ad47"", ""de8bc0d11b0834aca31f65159c641e4051844ac1"", ""e2d3bb299a29b7df44cef06a555bd1e5c5b775f5"", ""0a76cc29b703fc95949736910a5a63ce9c1c0814"", ""8af5a22fd64699fe6c7063870a82704c81dd8bff""]"
25608ae6eb4088a81a7fe4969409c30ecc81a7a1,julien,julien@twitter.com,Tue Mar 5 18:04:19 2013 -0800,1362535459,cleanup,3,4,"parquet-column/src/main/java/parquet/io/MessageColumnIO.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/ConverterConsumer.java,CAS_DELIMITER",3,1,2,0.9852281360342516,1,-18.666666666666668,12,0.35660879629629627,146.0,124.94471128759079,15.0,Perfective,FALSE,FALSE,
962dd9e8bbacab7f86159da53f165fe8c569fd3b,Todd Lipcon,todd@cloudera.com,Tue Mar 5 16:15:31 2013 -0800,1362528931,More cleanup / renames,128,84,"parquet-column/src/main/java/parquet/column/mem/PageReadStore.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/CodecFactory.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ColumnData.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/Footer.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/PageConsumer.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestReadIntTestFile.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java,CAS_DELIMITER",17,3,6,2.660405530024845,1,-1.8235294117647058,49,3.021399782135077,1.0,0.9981718224792435,0.3333333333333333,Perfective,FALSE,TRUE,"[""668d74df8addad24ad0bd2e53a23a4ad07e5ad47"", ""6e33c3d317965c8a26a98b79e6595a6b2062beb4""]"
76fd1d8011bf4f125118e28f11f5aa5539f06fbd,julien,julien@twitter.com,Tue Mar 5 16:09:59 2013 -0800,1362528599,cleanup,0,201,"parquet-hadoop/src/main/java/parquet/hadoop/BlockData.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ColumnData.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/PageConsumer.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnMetaData.java,CAS_DELIMITER",4,1,2,1.8418888935222233,1,0.0,4,12.921261574074075,145.0,123.96832663680873,15.0,Perfective,FALSE,FALSE,
0973e7dd05799d75a3907c0e27415b68310c90ea,julien,julien@twitter.com,Tue Mar 5 14:56:57 2013 -0800,1362524217,removed outdated comment,1,1,"parquet-thrift/src/main/java/parquet/thrift/ThriftSchemaConverter.java,CAS_DELIMITER",1,1,1,0.0,1,0.0,0,0.0,143.0,121.9832189612547,9.0,None,FALSE,FALSE,
54dd652ef68572c3796efbbe636699bf00d3fc6c,julien,julien@twitter.com,Tue Mar 5 13:47:25 2013 -0800,1362520045,integrate the thrift changes,39,33,"parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/metadata/ParquetMetadata.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestReadIntTestFile.java,CAS_DELIMITER",5,1,4,1.5881747653124707,1,25.6,15,3.1200254629629627,142.0,120.99719191069497,13.0,None,FALSE,TRUE,
ee8ec11a25ede3279df609ee1e402476d8b6d028,julien,julien@twitter.com,Tue Mar 5 11:41:50 2013 -0800,1362512510,javadoc ; turn off the compatibility test for now,153,27,"parquet-hadoop/src/test/java/parquet/hadoop/TestReadIntTestFile.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java,CAS_DELIMITER",2,2,2,0.9007196798623593,1,351.5,8,0.5432928240740741,141.0,120.02219752626962,10.0,Non Functional,FALSE,FALSE,
d35c264e8f922667d9d04263df2e3b18ec9205cc,julien,julien@twitter.com,Tue Mar 5 10:15:13 2013 -0800,1362507313,turn byte [ ] into Binary object in the api,200,83,"parquet-column/src/main/java/parquet/column/ColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/ColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/mem/MemColumnReadStore.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/mem/MemColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/DevNullColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/DevNullColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/PlainColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/PlainColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/Group.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/GroupRecordConsumer.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/GroupValueSource.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/BinaryValue.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/Primitive.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/BaseRecordReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/Binary.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/ConverterConsumer.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/MessageColumnIO.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/RecordConsumer.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/ValidatingRecordConsumer.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/convert/PrimitiveConverter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/mem/TestMemColumn.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/TupleRecordConsumer.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/GenerateTPCH.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ParquetWriteProtocol.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java,CAS_DELIMITER",37,3,14,4.113689262282933,1,31.405405405405407,91,6.3392505005005,139.0,118.03928234766218,11.0,None,FALSE,TRUE,"[""b9463550d01f4b0118f725ed957e6e4354b0e4ba"", ""668d74df8addad24ad0bd2e53a23a4ad07e5ad47"", ""65364a46bc72bb99fbdc4f19cb51a0db2ab8030e"", ""8246e0bbb229f54bf8fcb03f6133d7c5f8f4036c"", ""cc59cb82675499870e9b0433c350f01a3522c2c9""]"
003299e4240a1f131c4d1b9d3fe5f3b4ff9fd0e6,Todd Lipcon,todd@cloudera.com,Tue Mar 5 00:12:52 2013 -0800,1362471172,"Style cleanup and other miscellanea ( javadoc , etc ) Added other review comments as TODOs",236,176,"parquet-column/src/main/java/parquet/bytes/BytesUtils.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/bytes/LittleEndianDataInputStream.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/bytes/LittleEndianDataOutputStream.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/ColumnDescriptor.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/ColumnReadStore.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/ColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/ColumnWriteStore.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/ColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/UnknownColumnException.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/mem/MemColumnWriteStore.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/mem/MemColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/mem/MemPageStore.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/BitPacking.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/BitReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/BitWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/BoundedColumnFactory.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/BoundedIntColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/BoundedIntColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/DevNullColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/DevNullColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/PlainColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/PlainColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/BaseRecordReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/convert/RecordConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/parser/MessageTypeParser.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/ConversionPatterns.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/GroupType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/MessageType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/PrimitiveType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/Type.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/primitive/TestBitPacking.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/schema/TestMessageType.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER",42,2,12,4.945094902009894,1,15.095238095238095,132,5.153362268518518,0.0,0.0,0.0,Feature Addition,FALSE,FALSE,
e8f8429e11372c04afffdcd133199ff87872eebf,julien,julien@twitter.com,Mon Mar 4 16:15:54 2013 -0800,1362442554,populate encodings in column metadata,74,22,"parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestParquetFileWriter.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java,CAS_DELIMITER",7,2,5,2.6317163625497026,1,0.7142857142857143,14,6.649902447089947,138.0,117.24851256630372,12.0,None,FALSE,FALSE,
ecf19dc3d917d124c33d463d662a1fb885bfb243,julien,julien@twitter.com,Mon Mar 4 12:09:31 2013 -0800,1362427771,add encoding information for the column reader ; allow column writer to specify the encoding,254,24,"parquet-column/src/main/java/parquet/column/Encoding.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/mem/MemColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/mem/MemPageWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/mem/Page.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/mem/PageWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/DataColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/PlainColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/convert/GroupConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/convert/PrimitiveConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/TypeConverter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/mem/TestMemPageStore.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/convert/TupleRecordConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/TBaseRecordConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftReader.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetReadProtocol.java,CAS_DELIMITER",23,4,11,4.237984253226061,1,44.34782608695652,45,5.32113929146538,137.0,116.29591152426013,9.75,Feature Addition,FALSE,FALSE,
9c79b0876401264707d3bfae37362afc72445df5,julien,julien@twitter.com,Mon Mar 4 11:37:30 2013 -0800,1362425850,thrift input / output format support,53,29,"parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftMetaData.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/struct/ThriftType.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java,CAS_DELIMITER",5,1,4,1.9662232313804378,1,51.2,4,1.9273101851851853,136.0,115.30201278993452,4.0,None,FALSE,FALSE,
25b755958b1906dd3d4f6767a2008d8566746062,julien,julien@twitter.com,Mon Mar 4 11:02:05 2013 -0800,1362423725,thrift read protocol ; fix repetition level size in little endian,523,225,"parquet-column/src/main/java/parquet/Log.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/bytes/BytesInput.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/bytes/BytesUtils.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/BoundedIntColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/GroupValueSource.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/BinaryValue.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/DoubleValue.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/FloatValue.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/convert/GroupRecordConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/convert/SimpleGroupConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/GroupType.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/bytes/TestBytesUtil.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestReadIntTestFile.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/TBaseRecordConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetReadProtocol.java,CAS_DELIMITER",23,3,15,2.33838633540458,1,43.30434782608695,50,6.719508353462158,135.0,114.30869534579354,7.666666666666667,Corrective,TRUE,FALSE,
af20471a423684375533774320b874a49195d4f8,julien,julien@twitter.com,Fri Mar 1 16:32:46 2013 -0800,1362184366,javadoc ; bug fixes ; thrift support ; refactoring,1450,1183,"parquet-column/src/main/java/parquet/Log.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/bytes/BytesUtils.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/DummyRecordConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/convert/GroupRecordConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/convert/SimpleGroupConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/ConverterConsumer.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/convert/Converter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/convert/GroupConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/convert/PrimitiveConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/convert/RecordConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/GroupType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/MessageType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/PrimitiveType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/Type.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/TypeConverter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/PerfTest.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/convert/TupleRecordConverter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/converter/BagConverter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/converter/Converter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/converter/MapConverter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/converter/MapKeyValueConverter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/converter/MessageConverter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/converter/TupleConverter.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetReadProtocol.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftOutputFormat.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet//thrift/ParquetProtocol.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ParquetReadProtocol.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet//thrift/ParquetWriteProtocol.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet//thrift/ThriftMetaData.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftReader.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/thrift/ThriftRecordConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet//thrift/ThriftSchemaConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet//thrift/struct/JSON.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet//thrift/struct/ThriftField.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet//thrift/struct/ThriftType.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet//thrift/struct/ThriftTypeID.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/hadoop/thrift/TestInputOutputFormat.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetReadProtocol.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetWriteProtocol.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftSchemaConverter.java,CAS_DELIMITER",49,3,18,4.598725486070483,1,15.408163265306122,73,3.4358153817082395,134.0,114.05882614209497,7.666666666666667,Corrective,TRUE,FALSE,
77097b63b08eb366a2d667b41a73e87b401dccdd,julien,julien@twitter.com,Thu Feb 28 10:30:20 2013 -0800,1362076220,ThriftParquetOutputFormat,2483,0,"parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetProtocol.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetReadProtocol.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftInputFormat.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetThriftOutputFormat.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ParquetWriteProtocol.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftMetaData.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftReadSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftSchemaConverter.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/ThriftWriteSupport.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/struct/JSON.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/struct/ThriftField.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/struct/ThriftType.java,CAS_DELIMITER,parquet-thrift/src/main/java/parquet/hadoop/thrift/struct/ThriftTypeID.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/hadoop/thrift/TestParquetProtocol.java,CAS_DELIMITER,parquet-thrift/src/test/java/parquet/hadoop/thrift/TestThriftSchemaConverter.java,CAS_DELIMITER",15,1,3,3.300976528651405,1,0.0,0,0.0,131.0,111.39758083148313,0.0,None,FALSE,TRUE,"[""af20471a423684375533774320b874a49195d4f8"", ""b9463550d01f4b0118f725ed957e6e4354b0e4ba"", ""5daf06892b533a06fa0d80c83006f84b74e429f8"", ""668d74df8addad24ad0bd2e53a23a4ad07e5ad47"", ""08c8f82011925d3ba083f8b23b8f1c0af29c0d7e""]"
f2746e71fa579f5b56e055e8304ca292392e1ebb,julien,julien@twitter.com,Thu Feb 28 10:27:23 2013 -0800,1362076043,adding example output / input formats,282,16,"parquet-column/src/main/java/parquet/Log.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/ColumnIO.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/ColumnIOFactory.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/GroupColumnIO.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/MessageColumnIO.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/PrimitiveColumnIO.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ReadSupport.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/example/ExampleInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/example/ExampleOutputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/example/GroupReadSupport.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/example/GroupWriteSupport.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/example/TestInputOutputFormat.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java,CAS_DELIMITER",14,3,7,2.755980489201271,1,6.0,25,2.179541170634921,130.0,110.39812011006725,8.333333333333334,Feature Addition,FALSE,TRUE,"[""668d74df8addad24ad0bd2e53a23a4ad07e5ad47"", ""071b8f4626f125c81a01a5c07111d4d52102dbdf""]"
ad9dcbe0a0dcf3b94de5e7be868a273c076c52ba,julien,julien@twitter.com,Tue Feb 26 13:57:41 2013 -0800,1361915861,javadoc ; original type support,1007,66,"parquet-column/src/main/java/parquet/Log.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/ParquetRuntimeException.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/bytes/BytesInput.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/bytes/CapacityByteArrayOutputStream.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/ColumnDescriptor.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/ColumnReadStore.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/ColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/ColumnWriteStore.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/ColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/mem/Page.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/mem/PageReadStore.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/mem/PageReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/mem/PageWriteStore.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/mem/PageWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/PrimitiveColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/DummyRecordConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/convert/GroupRecordConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/convert/SimpleGroupConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/ColumnIOFactory.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/CompilationException.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/GroupColumnIO.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/InvalidRecordException.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/MessageColumnIO.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/ParquetDecodingException.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/ParquetEncodingException.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/PrimitiveColumnIO.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/convert/RecordConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/parser/MessageTypeParser.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/ConversionPatterns.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/GroupType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/MessageType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/OriginalType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/PrimitiveType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/Type.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/BadConfigurationException.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/ConverterConsumer.java,CAS_DELIMITER",44,3,15,5.003531030539901,1,12.431818181818182,65,5.352562868265992,128.0,108.88304639769883,7.0,Non Functional,FALSE,FALSE,
b2efb50d011d65644ad00fbbc7511731d9f8c47d,julien,julien@twitter.com,Fri Feb 22 14:50:10 2013 -0800,1361573410,refactor the read / write support,296,209,"parquet-hadoop/src/main/java/parquet/hadoop/BadConfigurationException.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetInputSplit.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordReader.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ParquetRecordWriter.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ReadSupport.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/WriteSupport.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/ParquetLoader.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/ParquetStorer.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/PigMetaData.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/TupleWriteSupport.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java,CAS_DELIMITER",16,2,4,3.592546837026224,1,-1.25,26,1.490789207175926,127.0,108.91283577666437,6.0,None,FALSE,FALSE,
9058bae13942bb17e96ee5ba371b0013a58d473f,julien,julien@twitter.com,Thu Feb 21 16:23:12 2013 -0800,1361492592,improve use of summary file,44,38,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/ParquetLoader.java,CAS_DELIMITER",2,2,2,0.8721617883411701,1,1.5,4,0.07333333333333333,126.0,108.15618190464457,5.0,None,FALSE,TRUE,"[""071b8f4626f125c81a01a5c07111d4d52102dbdf"", ""7a4b5626cbdfad9b4429e47fc4b6da37516a09b9"", ""6da759455251c47813202cfac29056a8e3f6e834""]"
78ff38c7e17cd5349bc92ccda18e7310c8e0274c,julien,julien@twitter.com,Thu Feb 21 14:37:36 2013 -0800,1361486256,improve logs,9,3,"parquet-hadoop/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/ParquetLoader.java,CAS_DELIMITER",2,2,2,0.6500224216483541,1,-1.5,2,0.9338773148148148,125.0,107.17510549851748,4.0,None,FALSE,TRUE,
f6adf0b5e678b5aff29cc3eeef9b3e9b240c0385,julien,julien@twitter.com,Thu Feb 21 12:18:11 2013 -0800,1361477891,integrate new converter ; cleanup,729,496,"parquet-column/src/main/java/parquet/column/mem/MemColumnReadStore.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/mem/MemColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/mem/MemPageReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/mem/MemPageWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/BitReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/BoundedIntColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/BoundedIntColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/PlainColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/PlainColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/DummyRecordConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet//example/Paper.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/Group.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/GroupFactory.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/GroupRecordConsumer.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/GroupValueSource.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/GroupWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/BinaryValue.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/BooleanValue.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/DoubleValue.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/FloatValue.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/IntegerValue.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/LongValue.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/Primitive.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/SimpleGroup.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/SimpleGroupFactory.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/convert/GroupRecordConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/convert/SimpleGroupConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/example/data/simple/convert/SimplePrimitiveConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/BaseRecordReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/GroupColumnIO.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/MessageColumnIO.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/ParquetDecodingException.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/ParquetEncodingException.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/RecordConsumerLoggingWrapper.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/convert/RecordConverter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/PrimitiveType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/utils/Varint.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/ExpectationValidatingConverter.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/PerfTest.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/schema/TestMessageType.java,CAS_DELIMITER,parquet-hadoop/src/main/java/parquet/hadoop/ReadSupport.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestInputFormat.java,CAS_DELIMITER,parquet-hadoop/src/test/java/parquet/hadoop/TestReadIntTestFile.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/ConverterConsumer.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java,CAS_DELIMITER",57,3,19,4.245558970094038,1,-0.49122807017543857,65,0.4907368827160494,124.0,106.19983402328641,4.0,Feature Addition,FALSE,FALSE,
cfdcdffee41711ba91109378605265200b2d9a25,julien,julien@twitter.com,Wed Feb 20 17:32:39 2013 -0800,1361410359,turn off customer test,2,2,"parquet-pig/src/test/java/parquet/hadoop/TestReadIntTestFile.java,CAS_DELIMITER",1,1,1,0.0,1,56.0,2,0.11788194444444444,122.0,104.3976913816861,4.0,Preventative,FALSE,FALSE,
5141722756ae6a9f10924242f5d89cd9afebedad,julien,julien@twitter.com,Wed Feb 20 17:30:11 2013 -0800,1361410211,integrate thrift changes,4,4,"parquet-pig/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER",3,1,1,1.5,1,-0.6666666666666666,4,0.13049768518518517,121.0,103.39811655923955,3.0,None,FALSE,FALSE,
85d8f09fa96ec16d413bd5bc01269fff6ed595f4,julien,julien@twitter.com,Wed Feb 20 16:51:00 2013 -0800,1361407860,removed brennus dependency ( for now ),5,366,"parquet-column/src/main/java/parquet/io/RecordReaderCompiler.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/PerfTest.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestRecordReaderCompiler.java,CAS_DELIMITER",3,1,2,1.0098896087956362,1,-2.3333333333333335,6,0.09179783950617283,119.0,101.4047787832495,4.0,None,FALSE,FALSE,
4a0bb74123d353df85e4a29a26e5d439bd1a5993,julien,julien@twitter.com,Wed Feb 20 16:39:47 2013 -0800,1361407187,cleanup exceptions,93,52,"parquet-column/src/main/java/parquet/column/mem/MemColumnReadStore.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/mem/MemPageReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/mem/MemPageWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/BitPackingColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/BitReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/BoundedIntColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/BoundedIntColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/PlainColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/PlainColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/BaseRecordReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/ColumnIO.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/CompilationException.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/GroupColumnIO.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/MessageColumnIO.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/RecordReaderCompiler.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/RecordReaderImplementation.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/GroupType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/MessageType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/PrimitiveType.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/schema/Type.java,CAS_DELIMITER",24,1,4,4.1128684346688855,1,-0.4583333333333333,28,0.1456495949074074,118.0,100.40664846246983,3.0,Perfective,FALSE,TRUE,
bd1fde90f05a3aec05f7cad24d90633ea680d9f9,julien,julien@twitter.com,Wed Feb 20 14:42:54 2013 -0800,1361400174,cleanup,52,72,"parquet-column/src/main/java/parquet/column/ColumnDescriptor.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/mem/MemColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/mem/MemColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/mem/ParquetDecodingException.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/mem/ParquetEncodingException.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/BooleanPlainColumnWriter.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/primitive/PlainColumnReader.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/MessageColumnIO.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/column/primitive/TestBitPackingColumn.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/ExpectationValidatingRecordConsumer.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/PerfTest.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/io/TestColumnIO.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/hadoop/metadata/FileMetaData.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/hadoop/metadata/ParquetMetadata.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/ParquetStorer.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/hadoop/TestParquetFileWriter.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/hadoop/TestReadIntTestFile.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java,CAS_DELIMITER",19,2,10,3.6542491624882714,1,3.1052631578947367,19,0.05644919590643274,117.0,99.42591319236993,2.0,Perfective,FALSE,FALSE,
ac3a80616248e6facf9c756ac8d831bcf5e978a1,julien,julien@twitter.com,Wed Feb 20 14:22:16 2013 -0800,1361398936,renamed to parquet,337,309,"parquet-column/src/main/java/parquet/ParquetRuntimeException.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/column/UnknownColumnException.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/InvalidRecordException.java,CAS_DELIMITER,parquet-column/src/main/java/parquet/io/RecordReaderCompiler.java,CAS_DELIMITER,parquet-column/src/test/java/parquet/parser/TestParquetParser.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/hadoop/Footer.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/hadoop/ParquetFileReader.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/hadoop/ParquetFileWriter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/hadoop/ParquetInputFormat.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/hadoop/ParquetInputSplit.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/hadoop/ParquetOutputCommitter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/hadoop/ParquetOutputFormat.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/hadoop/ParquetRecordReader.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/hadoop/ParquetRecordWriter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/hadoop/PrintFooter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/hadoop/ReadSupport.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/hadoop/WriteSupport.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/hadoop/metadata/ParquetMetadata.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/ParquetLoader.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/ParquetStorer.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/PigSchemaConverter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/TupleConversionException.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/TupleReadSupport.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/convert/MapConverter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/convert/TupleConverter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/converter/BagConverter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/converter/MapConverter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/converter/MapKeyValueConverter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/converter/MessageConverter.java,CAS_DELIMITER,parquet-pig/src/main/java/parquet/pig/converter/TupleConverter.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/hadoop/TestInputFormat.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/hadoop/TestParquetFileWriter.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/hadoop/TestReadIntTestFile.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/GenerateIntTestFile.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/PerfTest.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/PerfTest2.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TestParquetStorer.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java,CAS_DELIMITER,parquet-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java,CAS_DELIMITER",41,2,12,4.9307930913327365,1,0.0,25,0.04595048554652212,116.0,98.42927550134878,1.0,None,FALSE,TRUE,"[""25b755958b1906dd3d4f6767a2008d8566746062""]"
33aad25b805a927f4ead3c7cbcfad39a518a87a0,julien,julien@twitter.com,Wed Feb 20 12:16:33 2013 -0800,1361391393,rename package to parquet,180,127,"redelm-pig/src/main/java/parquet/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/hadoop/BlockData.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/hadoop/CodecFactory.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/hadoop/ColumnChunkPageReadStore.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/hadoop/ColumnData.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/hadoop/Footer.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/hadoop/PageConsumer.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/hadoop/PrintFooter.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/hadoop/ReadSupport.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/hadoop/RedelmFileReader.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/hadoop/RedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/hadoop/RedelmInputFormat.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/hadoop/RedelmInputSplit.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/hadoop/RedelmOutputCommitter.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/hadoop/RedelmOutputFormat.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/hadoop/RedelmRecordReader.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/hadoop/RedelmRecordWriter.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/hadoop/WriteSupport.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/hadoop/metadata/BlockMetaData.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/hadoop/metadata/ColumnChunkMetaData.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/hadoop/metadata/ColumnMetaData.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/hadoop/metadata/CompressionCodecName.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/hadoop/metadata/FileMetaData.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/hadoop/metadata/RedelmMetaData.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/pig/PigMetaData.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/pig/PigSchemaConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/pig/RedelmLoader.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/pig/RedelmStorer.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/pig/TupleConversionException.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/pig/TupleReadSupport.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/pig/TupleRecordConsumer.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/pig/TupleWriteSupport.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/pig/convert/MapConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/pig/convert/TupleConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/pig/converter/BagConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/pig/converter/Converter.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/pig/converter/MapConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/pig/converter/MapKeyValueConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/pig/converter/MessageConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/pig/converter/TupleConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/pig/summary/BagSummaryData.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/pig/summary/EnumStat.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/pig/summary/FieldSummaryData.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/pig/summary/MapSummaryData.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/pig/summary/NumberSummaryData.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/pig/summary/StringSummaryData.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/pig/summary/Summary.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/pig/summary/SummaryData.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/pig/summary/TupleSummaryData.java,CAS_DELIMITER,redelm-pig/src/main/java/parquet/pig/summary/ValueStat.java,CAS_DELIMITER,redelm-pig/src/test/java/parquet/format/converter/TestParquetMetadataConverter.java,CAS_DELIMITER,redelm-pig/src/test/java/parquet/hadoop/TestInputFormat.java,CAS_DELIMITER,redelm-pig/src/test/java/parquet/hadoop/TestRedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/test/java/parquet/pig/GenerateIntTestFile.java,CAS_DELIMITER,redelm-pig/src/test/java/parquet/pig/GenerateTPCH.java,CAS_DELIMITER,redelm-pig/src/test/java/parquet/pig/PerfTest.java,CAS_DELIMITER,redelm-pig/src/test/java/parquet/pig/PerfTest2.java,CAS_DELIMITER,redelm-pig/src/test/java/parquet/pig/PerfTestReadAllCols.java,CAS_DELIMITER,redelm-pig/src/test/java/parquet/pig/TestPigSchemaConverter.java,CAS_DELIMITER,redelm-pig/src/test/java/parquet/pig/TestRedelmStorer.java,CAS_DELIMITER,redelm-pig/src/test/java/parquet/pig/TestTupleRecordConsumer.java,CAS_DELIMITER,redelm-pig/src/test/java/parquet/pig/TupleConsumerPerfTest.java,CAS_DELIMITER,redelm-pig/src/test/java/parquet/pig/summary/TestSummary.java,CAS_DELIMITER",64,1,11,5.65731617735474,1,0.0,0,0.0,113.0,95.44948594404909,71.0,None,FALSE,FALSE,
90f027efe123343a663e51e12d485ef7b302b093,julien,julien@twitter.com,Wed Feb 20 11:04:53 2013 -0800,1361387093,change magic number to PAR1,2,2,"redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java,CAS_DELIMITER",1,1,1,0.0,2,38.0,16,0.0059375,111.0,93.46061542581296,69.0,None,FALSE,FALSE,
b598378e02af0d862bf27b985bc62ebd2d24b9e0,julien,julien@twitter.com,Wed Feb 20 10:56:20 2013 -0800,1361386580,removed reference to red file,53,52,"redelm-pig/src/main/java/redelm/format/converter/ParquetMetadataConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageWriteStore.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/metadata/CompressionCodecName.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/format/converter/TestParquetMetadataConverter.java,CAS_DELIMITER",6,1,4,2.354410528832822,2,53.666666666666664,41,0.005586419753086419,110.0,92.46191204261793,68.0,None,FALSE,TRUE,
1823220da70a749b88f97d7fc7f06eb7c1d67176,julien,julien@twitter.com,Wed Feb 20 10:44:16 2013 -0800,1361385856,rename the metadata package,38,35,"redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageWriteStore.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/metadata/CompressionCodecName.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/redfile/RedFileMetadataConverter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/redfile/TestRedFileMetadataConverter.java,CAS_DELIMITER",6,1,4,2.0526088010329553,2,120.5,50,5.764660493827161,109.0,91.46371906931952,67.0,None,FALSE,FALSE,
15f6bebccc09b2af0908b34eb8769ddfd25b3795,julien,julien@twitter.com,Tue Feb 19 17:17:18 2013 -0800,1361323038,expose schema to pig,98,12,"redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmLoader.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java,CAS_DELIMITER",3,1,3,0.8791169235767734,2,179.66666666666666,27,17.857399691358022,108.0,90.61878290620565,66.0,None,FALSE,TRUE,"[""071b8f4626f125c81a01a5c07111d4d52102dbdf"", ""6da759455251c47813202cfac29056a8e3f6e834""]"
a62af63205961bffb3d9559454b9c289808333e6,julien,julien@twitter.com,Tue Feb 19 16:20:30 2013 -0800,1361319630,fix bit packing,319,58,"redelm-column/src/main/java/redelm/column/primitive/BitPacking.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/BitPackingColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/BooleanPlainColumnReader.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/column/primitive/TestBitPacking.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/column/primitive/TestBitPackingColumn.java,CAS_DELIMITER",5,1,2,1.267114090579105,2,184.6,6,8.961074074074073,107.0,89.62710256782383,78.0,Corrective,TRUE,FALSE,
b38de8abc55fb2ee9068760c38d7e0e809c1c8bd,julien,julien@twitter.com,Tue Feb 19 07:56:43 2013 -0800,1361289403,add allocated usage monitoring,140,44,"redelm-column/src/main/java/redelm/bytes/CapacityByteArrayOutputStream.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumnWriteStore.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemPageWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/PageWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/BitPackingColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/BitWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/BooleanPlainColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/DevNullColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/PlainColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnWriter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageWriteStore.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/converter/TupleConverter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/GenerateIntTestFile.java,CAS_DELIMITER",20,2,7,3.9832612176148805,2,85.4,120,7.824037037037039,106.0,88.70000150017884,71.0,Feature Addition,FALSE,FALSE,
372b9f3e6a61054528393bb4c4e7630fb17abeab,julien,julien@twitter.com,Thu Feb 14 16:24:19 2013 -0800,1360887859,fix projection using pig schema,270,33,"redelm-column/src/main/java/redelm/io/MessageColumnIO.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/GroupType.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/MessageType.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/PrimitiveType.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/Type.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/PrintFooter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/converter/BagConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/converter/Converter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/converter/MapConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/converter/MapKeyValueConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/converter/TupleConverter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java,CAS_DELIMITER",18,2,6,3.204946638150321,2,150.27777777777777,188,14.52339827674897,105.0,88.66702781349038,70.0,Corrective,TRUE,FALSE,
113f8b8509072ebf978cf3934ebafa2239503530,julien,julien@twitter.com,Thu Feb 14 12:00:11 2013 -0800,1360872011,reworked converter framework,465,0,"redelm-column/src/main/java/redelm/bytes/BytesUtils.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/convert/GroupConverter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/convert/PrimitiveConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/convert/MapConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/convert/TupleConverter.java,CAS_DELIMITER",5,2,3,1.720765542988814,2,16.8,3,1.2041134259259259,104.0,87.70512921259765,69.0,None,FALSE,FALSE,
4b060586ee79815e4cec5923ec211db9dda3e8bb,julien,julien@twitter.com,Thu Feb 14 08:26:24 2013 -0800,1360859184,move compression to decode time and fix compressor init overhead,193,222,"redelm-column/src/main/java/redelm/column/mem/MemPageReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemPageStore.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemPageWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/Page.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/PageReadStore.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/PageReader.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/column/mem/TestMemPageStore.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/CodecFactory.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageReadStore.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageWriteStore.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/GenerateIntTestFile.java,CAS_DELIMITER",17,2,5,3.2233830500503666,2,73.88235294117646,97,3.1720567810457503,103.0,86.735584957444,68.0,Corrective,TRUE,FALSE,
2ea29543f34e957cbdbee77ce1795c9ecf2150a3,julien,julien@twitter.com,Wed Feb 13 15:18:31 2013 -0800,1360797511,split stores,257,157,"redelm-column/src/main/java/redelm/column/ColumnReadStore.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/ColumnWriteStore.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumnReadStore.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumnWriteStore.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemPageStore.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/PageReadStore.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/PageWriteStore.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/MessageColumnIO.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordReader.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/PerfTest.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/TestColumnIO.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageReadStore.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageWriteStore.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/GenerateIntTestFile.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/GenerateTPCH.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java,CAS_DELIMITER",19,2,7,3.6960768087788765,2,99.84210526315789,155,1.4664735623781673,102.0,85.88035789676933,67.0,None,FALSE,FALSE,
d8a18ce3cf48509ffda49f4838603037118894ba,julien,julien@twitter.com,Tue Feb 12 18:24:54 2013 -0800,1360722294,fix PrintFooter ; fix string encoding ; rewrite split generation ; fix block reading logic,177,110,"redelm-pig/src/main/java/redelm/hadoop/PrintFooter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/metadata/CompressionCodecName.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/TupleWriteSupport.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java,CAS_DELIMITER",8,1,4,1.7628501329161996,2,102.75,63,3.757737268518519,101.0,85.05519674262203,60.0,Corrective,TRUE,FALSE,
04b60eebb2be71b8253b011d64dbc0601ca85de3,julien,julien@twitter.com,Tue Feb 12 11:45:50 2013 -0800,1360698350,rework compression,298,101,"redelm-column/src/main/java/redelm/column/mem/MemColumn.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/PerfTest.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/TestColumnIO.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/CodecFactory.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/ColumnChunkPageStore.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/PageConsumer.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/GenerateIntTestFile.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/GenerateTPCH.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java,CAS_DELIMITER",19,2,6,3.1203448000997858,2,140.68421052631578,186,3.109775828460039,100.0,84.11024495988335,65.5,None,FALSE,FALSE,
18d5082bb927a3f55717a2ffeafa304e0d921386,julien,julien@twitter.com,Mon Feb 11 16:59:03 2013 -0800,1360630743,fix decompression,114,31,"redelm-column/src/main/java/redelm/bytes/BytesInput.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemPageWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/PageWriter.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/column/mem/TestMemPageStore.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/PageConsumer.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/metadata/CompressionCodecName.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/GenerateIntTestFile.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java,CAS_DELIMITER",15,2,7,3.3134239175652795,2,119.4,91,3.8105787037037038,99.0,83.26391749984252,64.5,Corrective,TRUE,FALSE,
9c7e5f57e92419cc255e4597444afe7acb2c92aa,julien,julien@twitter.com,Mon Feb 11 14:45:28 2013 -0800,1360622728,add compression back ; make page size configurable ; rename children count to num children,117,64,"redelm-column/src/main/java/redelm/Log.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/CodecFactory.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/metadata/CompressionCodecName.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/redfile/RedFileMetadataConverter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/GenerateIntTestFile.java,CAS_DELIMITER",9,2,6,2.5087668073125147,2,106.33333333333333,60,6.345389660493826,98.0,82.2819192519352,63.5,Feature Addition,FALSE,FALSE,
867e24b84c57f768949aa385553c76f442993dda,julien,julien@twitter.com,Fri Feb 8 16:06:09 2013 -0800,1360368369,fix repetition for root,8,5,"redelm-pig/src/main/java/redelm/redfile/RedFileMetadataConverter.java,CAS_DELIMITER",1,1,1,0.0,2,344.0,9,0.006377314814814815,97.0,81.84919719429169,56.0,Corrective,TRUE,FALSE,
07d7aa0f26044e95cef3749454e6f16fcf6c2bf7,julien,julien@twitter.com,Fri Feb 8 15:56:58 2013 -0800,1360367818,change children indices for children count in schema representation,11,13,"redelm-pig/src/main/java/redelm/redfile/RedFileMetadataConverter.java,CAS_DELIMITER",1,1,1,0.0,2,346.0,8,0.006307870370370371,96.0,80.85041716036586,55.0,None,FALSE,FALSE,
1bd47c349d5416bd2fdfd62ad603ea581622de09,julien,julien@twitter.com,Fri Feb 8 15:47:53 2013 -0800,1360367273,generate TPCH customer,239,107,"redelm-column/src/main/java/redelm/Log.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/bytes/BytesInput.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/ColumnDescriptor.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/simple/example/Paper.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/MessageColumnIO.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/parser/MessageTypeParser.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/MessageType.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/PrimitiveType.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/column/mem/TestMemPageStore.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/parser/TestRedelmParser.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/metadata/ColumnChunkMetaData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/TupleWriteSupport.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/redfile/RedFileMetadataConverter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/hadoop/TestInputFormat.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/GenerateIntTestFile.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/GenerateTPCH.java,CAS_DELIMITER",22,2,15,3.296232053427346,2,132.54545454545453,176,13.500150989057238,95.0,79.85160659590167,61.5,None,FALSE,TRUE,"[""867e24b84c57f768949aa385553c76f442993dda"", ""18d5082bb927a3f55717a2ffeafa304e0d921386"", ""4b060586ee79815e4cec5923ec211db9dda3e8bb"", ""372b9f3e6a61054528393bb4c4e7630fb17abeab"", ""b9463550d01f4b0118f725ed957e6e4354b0e4ba"", ""3803d2d478ef73e1bccc2d887daad4b30647d854"", ""b11e2a005014ecd827855dde9ce4d50b1f58aa4b""]"
781f40f97c09807ed21be2c00dbd708708d5ad43,julien,julien@twitter.com,Fri Feb 8 11:37:07 2013 -0800,1360352227,PLAIN encoding comformance,11,21,"redelm-column/src/main/java/redelm/column/primitive/PlainColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/PlainColumnWriter.java,CAS_DELIMITER",2,1,1,0.9886994082884974,2,0.0,2,0.0030324074074074073,94.0,78.88398038605223,68.0,None,FALSE,FALSE,
f3adb6e39ada1ee15879295d1379e890045d37f1,julien,julien@twitter.com,Fri Feb 8 11:32:45 2013 -0800,1360351965,renamed to Plain to match the Encoding name,10,10,"redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/PlainColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/PlainColumnWriter.java,CAS_DELIMITER",4,1,2,1.9709505944546688,2,86.0,21,0.0007581018518518518,93.0,77.88453604640037,67.0,None,FALSE,FALSE,
6cdf6aaabbc05e2b693dbb7a1688e908ffe98e09,julien,julien@twitter.com,Fri Feb 8 11:31:02 2013 -0800,1360351862,generator for the int test file,104,0,"redelm-pig/src/test/java/redelm/pig/GenerateIntTestFile.java,CAS_DELIMITER",1,1,1,0.0,1,0.0,0,0.0,92.0,76.88475122907215,53.0,Preventative,FALSE,FALSE,
be0088631c6253e2f8ee7ba3715f3ea8d6dd001f,julien,julien@twitter.com,Fri Feb 8 11:30:34 2013 -0800,1360351834,better support for plain encoding,906,57,"redelm-column/src/main/java/redelm/bytes/BytesUtils.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/bytes/LittleEndianDataInputStream.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/bytes/LittleEndianDataOutputStream.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/BitPacking.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/BitPackingColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/BitPackingColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/BooleanPlainColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/BooleanPlainColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/DevNullColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnWriter.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/column/primitive/TestBitPacking.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/column/primitive/TestBoundedColumns.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/redfile/RedFileMetadataConverter.java,CAS_DELIMITER",19,2,6,2.8603491423991874,2,122.84210526315789,67,2.2427960526315793,91.0,75.88480883766508,59.0,Perfective,FALSE,FALSE,
2e09b42cbdbc2a4a903c7fdf4989b6635f4bc9eb,julien,julien@twitter.com,Wed Feb 6 18:06:02 2013 -0800,1360202762,cleanup string type,6,221,"redelm-column/src/main/java/redelm/column/ColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumn.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/DevNullColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/DevNullColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/simple/BinaryValue.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/simple/SimpleGroup.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/simple/StringValue.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/MessageColumnIO.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordConsumer.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordConsumerLoggingWrapper.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/PrimitiveType.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/TestColumnIO.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/redfile/RedFileMetadataConverter.java,CAS_DELIMITER",22,2,11,3.9192422041584316,2,140.4090909090909,195,2.0672359006734,90.0,75.1880081931399,58.0,Perfective,FALSE,FALSE,
3043e759f82d447ffe236f07722ae9800259bdd9,julien,julien@twitter.com,Wed Feb 6 16:59:21 2013 -0800,1360198761,optimize buffer copy ; revert parent,63,48,"redelm-column/src/main/java/redelm/bytes/BytesInput.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/redfile/RedFileMetadataConverter.java,CAS_DELIMITER",2,2,2,0.546717536611747,2,270.0,6,0.9723148148148149,89.0,74.19605269732997,57.0,None,FALSE,FALSE,
cd9e8fe1b7aa65b65f71b0b2c297c49e6ad45321,julien,julien@twitter.com,Tue Feb 5 18:00:01 2013 -0800,1360116001,integrate the schema change from children to parent,57,53,"redelm-column/src/main/java/redelm/schema/MessageType.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/redfile/RedFileMetadataConverter.java,CAS_DELIMITER",2,2,2,0.4085534883345498,2,209.5,16,0.028888888888888888,88.0,73.36021119361082,56.0,None,FALSE,FALSE,
d63ded4da366c4d81f5044c07f087ada719055f4,julien,julien@twitter.com,Tue Feb 5 17:18:25 2013 -0800,1360113505,remove string type ; make schema in footer use object model ; make ints little endian,393,202,"redelm-column/src/main/java/redelm/Log.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/bytes/BytesInput.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/bytes/BytesUtils.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/ColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumn.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/Group.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/simple/BinaryValue.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/simple/SimpleGroup.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/simple/StringValue.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/simple/example/Paper.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/MessageColumnIO.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordConsumer.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordConsumerLoggingWrapper.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/MessageType.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/PrimitiveType.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/bytes/TestBytesUtil.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/PerfTest.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/TestColumnIO.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/parser/TestRedelmParser.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmInputSplit.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/metadata/FileMetaData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/TupleWriteSupport.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/converter/MapKeyValueConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/converter/TupleConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/redfile/RedFileMetadataConverter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/hadoop/TestInputFormat.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/redfile/TestRedFileMetadataConverter.java,CAS_DELIMITER",40,2,22,4.501512573286374,2,121.125,301,29.180545717592583,87.0,72.36509436386055,55.0,None,FALSE,FALSE,
8ec8a9dae12484273453a57defba7cac80b82f58,julien,julien@twitter.com,Mon Feb 4 15:19:28 2013 -0800,1360019968,fix storer problem with page storage,32,7,"redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemPageReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemPageStore.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemPageWriter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java,CAS_DELIMITER",7,2,3,2.6854702585135564,2,136.57142857142858,34,17.306810515873018,86.0,71.54558905896339,54.0,Corrective,TRUE,TRUE,"[""4b060586ee79815e4cec5923ec211db9dda3e8bb""]"
f25dfdcc0302f29349e6ad85ea4341320268b86d,julien,julien@twitter.com,Mon Feb 4 10:48:25 2013 -0800,1360003705,fix row count per rowgroup persistence,3,2,"redelm-pig/src/main/java/redelm/redfile/RedFileMetadataConverter.java,CAS_DELIMITER",1,1,1,0.0,2,220.0,1,2.6855787037037038,85.0,70.57654786586528,46.0,Corrective,TRUE,FALSE,
17271e7299de20b95b88140753b6e6685ecf7c6e,julien,julien@twitter.com,Fri Feb 1 18:21:11 2013 -0800,1359771671,initial integration with the new metadata,3082,1236,"redelm-column/src/main/java/redelm/Log.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/bytes/BytesInput.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/bytes/BytesUtils.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/ColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/ColumnsStore.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/UnknownColumnException.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumn.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemPageReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemPageStore.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemPageWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/Page.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/PageReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/PageStore.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/PageWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/BitPacking.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/BitReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/BitWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/DevNullColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/DevNullColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/GroupType.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/MessageType.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/PrimitiveType.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/Type.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/bytes/TestBytesUtil.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/column/mem/TestMemPageStore.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/column/primitive/TestBitPacking.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/column/primitive/TestBoundedColumns.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/PerfTest.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/TestColumnIO.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/BlockData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/CodecFactory.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/ColumnMetaData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/Footer.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/PageConsumer.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/PrintFooter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/ReadSupport.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmInputSplit.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/WriteSupport.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/metadata/BlockMetaData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/metadata/ColumnChunkMetaData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/metadata/ColumnMetaData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/metadata/CompressionCodecName.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/metadata/FileMetaData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/metadata/RedelmMetaData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/PigMetaData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmStorer.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/TupleWriteSupport.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/redfile/RedFileMetadataConverter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/hadoop/TestInputFormat.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/redfile/TestRedFileMetadataConverter.java,CAS_DELIMITER",70,2,17,5.184253644008319,2,77.7,300,41.086953373015874,84.0,70.01380365118192,52.5,Feature Addition,FALSE,TRUE,"[""f25dfdcc0302f29349e6ad85ea4341320268b86d"", ""8ec8a9dae12484273453a57defba7cac80b82f58"", ""18d5082bb927a3f55717a2ffeafa304e0d921386"", ""d8a18ce3cf48509ffda49f4838603037118894ba"", ""4b060586ee79815e4cec5923ec211db9dda3e8bb"", ""372b9f3e6a61054528393bb4c4e7630fb17abeab"", ""a62af63205961bffb3d9559454b9c289808333e6"", ""af20471a423684375533774320b874a49195d4f8"", ""25b755958b1906dd3d4f6767a2008d8566746062"", ""668d74df8addad24ad0bd2e53a23a4ad07e5ad47"", ""6e33c3d317965c8a26a98b79e6595a6b2062beb4"", ""4828f1dcf1dc1fa2d1b33617469885acf632af69"", ""827a5bc4a7a00c624dd6062804ae7f4f42be16a8"", ""b0e9609e4850fcf8e0e79a427aa0f079aaf04b10"", ""8285b62ceafe3fe096ebe1836142445acf0a9586"", ""407a52d538c31f65e3ba313c1d7be4fb5f9831b8""]"
b89750bfe652dd83c8feed49cb55e0e6b47c31dd,julien,julien@twitter.com,Thu Jan 17 14:24:38 2013 -0800,1358461478,some cleanup based on Jco's comments,77,32,"redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/BaseRecordReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordReaderImplementation.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/PerfTest.java,CAS_DELIMITER",5,1,3,1.4682528084671735,2,242.2,52,5.902085648148147,83.0,71.54567854202352,59.0,Perfective,FALSE,TRUE,
2883f89341e2d29b33fc1687d07d6f965eaee796,julien,julien@twitter.com,Mon Jan 14 18:24:29 2013 -0800,1358216669,merge both switch statements to optimize,56,60,"redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordReaderImplementation.java,CAS_DELIMITER",2,1,1,0.9575534837147482,2,377.0,16,5.097482638888889,82.0,71.03154144847731,58.0,Non Functional,FALSE,FALSE,
2a3d6af012ffcb649704e5d1b177322e261f5e05,julien,julien@twitter.com,Thu Jan 10 08:19:38 2013 -0800,1357834778,make BaseRecordReader its own class,151,134,"redelm-column/src/main/java/redelm/io/BaseRecordReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java,CAS_DELIMITER",2,1,1,0.9974319084927061,2,199.5,10,0.003946759259259259,81.0,70.79063162793145,57.0,None,FALSE,FALSE,
cd7117b691ab04ce75b5ac0835ab278ae6bf7766,julien,julien@twitter.com,Wed Jan 9 14:50:58 2013 -0800,1357771858,some modification to understand better impact of gc,3,1,"redelm-column/src/test/java/redelm/io/PerfTest.java,CAS_DELIMITER",1,1,1,0.0,2,143.0,25,0.6163773148148148,78.0,67.91315996326074,54.0,Perfective,FALSE,FALSE,
d2025609870d1fb68c0e75ded650906dbde00c29,Jonathan Coveney,jcoveney@gmail.com,Wed Jan 9 13:38:26 2013 -0800,1357767506,Incorporate Julien's comments,23,40,"redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java,CAS_DELIMITER",1,1,1,0.0,2,277.0,13,0.15322916666666667,18.0,15.38677286710691,12.0,None,FALSE,FALSE,
48d9105d1b5e845a1af037968c88dad6aa374b4c,Jonathan Coveney,jcoveney@gmail.com,Wed Jan 9 09:57:47 2013 -0800,1357754267,Revert PigSchemaConverter to static,38,37,"redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmLoader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmStorer.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java,CAS_DELIMITER",6,1,2,2.3219225538128168,2,194.83333333333334,61,1.7208641975308643,17.0,14.392328551544688,11.0,None,FALSE,FALSE,
b896112db485fadc5ca86ee441c7357ed1ef3931,julien,julien@twitter.com,Wed Jan 9 00:03:23 2013 -0800,1357718603,trigger full gc before starting,1,1,"redelm-column/src/test/java/redelm/io/PerfTest.java,CAS_DELIMITER",1,1,1,0.0,2,143.0,24,0.010277777777777778,77.0,67.01391827752363,53.0,None,FALSE,FALSE,
e5dec2bf0ca372aa7d4053482cf29c79ed23df7e,julien,julien@twitter.com,Tue Jan 8 23:48:35 2013 -0800,1357717715,optimizations ; fix some bugs,56,31,"redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordReaderImplementation.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/PerfTest.java,CAS_DELIMITER",4,1,3,1.7816833552713938,2,289.0,41,9.483012152777777,76.0,66.01557276503489,52.0,Corrective,TRUE,FALSE,
770cf4d97a1cc27f9f07171c3a99bfff547904e8,julien,julien@twitter.com,Tue Jan 8 16:56:29 2013 -0800,1357692989,more optimizations,266,160,"redelm-column/src/main/java/redelm/Log.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordReaderImplementation.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/PerfTest.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/TestRecordReaderCompiler.java,CAS_DELIMITER",5,1,3,1.2336946244191025,2,217.8,48,0.8035,75.0,65.0608896955619,51.0,None,FALSE,FALSE,
7aaf6f95908add6f9a0ef0f41290ed82fcee6b9b,julien,julien@twitter.com,Mon Jan 7 21:44:13 2013 -0800,1357623853,removed unecessary readOneRecord ( ) method and commented out old code,7,15,"redelm-column/src/main/java/redelm/io/RecordReader.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/PerfTest.java,CAS_DELIMITER",2,1,2,0.5746356978376794,2,89.5,43,3.8510532407407405,74.0,64.18573576465607,50.0,None,FALSE,FALSE,
db75e0be88ce935f290b71ea6198c75c4a6a341a,julien,julien@twitter.com,Mon Jan 7 21:38:15 2013 -0800,1357623495,add missing base implementations,68,19,"redelm-column/src/main/java/redelm/Log.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordReaderImplementation.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/TestRecordReaderCompiler.java,CAS_DELIMITER",4,1,3,1.2152233154074696,2,227.75,22,13.077575231481482,73.0,63.18637214590767,49.0,Feature Addition,FALSE,FALSE,
676c471db22d895f08c04c240d3eb9616e48b0e2,Jonathan Coveney,jcoveney@gmail.com,Mon Jan 7 17:59:19 2013 -0800,1357610359,Make maps work with sigle column case,94,2,"redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java,CAS_DELIMITER",2,1,2,1.0,2,179.5,20,0.08289351851851852,16.0,13.448396178711253,10.0,None,FALSE,FALSE,
d71d754eee3773b072af89330b440bb8dbca01f8,Jonathan Coveney,jcoveney@gmail.com,Mon Jan 7 15:59:57 2013 -0800,1357603197,Make PigSchemaConverter Static,37,38,"redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmLoader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmStorer.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java,CAS_DELIMITER",6,1,2,2.3219225538128168,2,179.66666666666666,53,32.58403163580247,15.0,12.450970860931351,9.0,None,FALSE,FALSE,
faf756e88f6faef5526f8b2bf736ec0ba8d0b488,julien,julien@twitter.com,Mon Jan 7 11:51:12 2013 -0800,1357588272,fixed visibility,1,1,"redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java,CAS_DELIMITER",1,1,1,0.0,2,244.0,5,1.870474537037037,72.0,62.247928609651495,48.0,Corrective,TRUE,FALSE,
fa4c4ba7f075586b7eed9152bd7ea231c873cfca,julien,julien@twitter.com,Sun Jan 6 17:12:54 2013 -0800,1357521174,removed unnecessary whitespace,1,1,"redelm-column/src/test/java/redelm/io/TestColumnIO.java,CAS_DELIMITER",1,1,1,0.0,2,386.0,25,1.083449074074074,71.0,61.36339296573423,47.0,None,FALSE,FALSE,
1954277c4ea81c9a748131b206f9df8ba69b9382,julien,julien@twitter.com,Sun Jan 6 17:11:55 2013 -0800,1357521115,removed cheesy comment and hardcoded max depth based on jco's comment,10,6,"redelm-column/src/main/java/redelm/io/MessageColumnIO.java,CAS_DELIMITER",1,1,1,0.0,2,267.0,16,4.241145833333333,70.0,60.363492813612076,46.0,None,FALSE,FALSE,
180222e874d74fd26322786d612a418866fa020d,julien,julien@twitter.com,Sat Jan 5 15:12:44 2013 -0800,1357427564,rename RecordConsumerWrapper,10,10,"redelm-column/src/main/java/redelm/io/RecordConsumerLoggingWrapper.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/PerfTest.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/TestColumnIO.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java,CAS_DELIMITER",5,2,3,2.2464393446710154,2,193.0,60,14.45825925925926,69.0,59.51924963885252,44.5,None,FALSE,FALSE,
c4c6991f1afe6b252a96794cb951d66c7890d656,julien,julien@twitter.com,Sat Jan 5 14:57:43 2013 -0800,1357426663,rewrite of the code generation bit ( work in progress ),340,139,"redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordReaderImplementation.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/PrimitiveType.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/TestColumnIO.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/TestRecordReaderCompiler.java,CAS_DELIMITER",5,1,3,1.262588084808988,2,237.8,45,11.760407407407408,68.0,58.520725110048794,44.0,None,FALSE,FALSE,
eaeff045457b3e31fd556744b2c134fc9cfaae61,julien,julien@twitter.com,Wed Jan 2 11:24:40 2013 -0800,1357154680,refactor reader,377,340,"redelm-column/src/main/java/redelm/io/MessageColumnIO.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordReaderImplementation.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/TestColumnIO.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/TestRecordReaderCompiler.java,CAS_DELIMITER",6,1,2,1.4908358760939204,2,205.5,63,13.157496141975308,67.0,57.96081172015034,43.0,None,FALSE,FALSE,
e7354598b543a3f86ca304e07596d08c27d1660b,julien,julien@twitter.com,Wed Dec 19 22:15:56 2012 -0800,1355984156,remove unecessary class parameter,2,3,"redelm-column/src/main/java/redelm/io/RecordReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java,CAS_DELIMITER",2,1,1,0.9709505944546686,2,282.0,27,2.5766840277777776,65.0,57.89475240654472,41.0,None,FALSE,FALSE,
7dd9300aa63c3abf783ae5d8046c4bad8f1ccde3,julien,julien@twitter.com,Wed Dec 19 22:04:41 2012 -0800,1355983481,remove dependency of column io on column store,87,86,"redelm-column/src/main/java/redelm/io/ColumnIO.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/ColumnIOFactory.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/GroupColumnIO.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/MessageColumnIO.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordReader.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/PerfTest.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/TestColumnIO.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java,CAS_DELIMITER",10,2,3,2.8077609564849446,2,193.8,110,10.577996527777778,64.0,56.89586228680968,41.0,None,FALSE,FALSE,
8f2c7e598dde293312f6d1894affb7630bb62591,julien,julien@twitter.com,Wed Dec 19 17:57:14 2012 -0800,1355968634,slight improvement to the record reader,49,28,"redelm-column/src/main/java/redelm/io/RecordReader.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/PerfTest.java,CAS_DELIMITER",2,1,2,0.4394969869215134,2,229.5,36,3.1576215277777777,63.0,55.91981452701332,39.0,None,FALSE,FALSE,
27c93d0622e49ad44d4d1c2a10a0a11c4ae1b241,julien,julien@twitter.com,Tue Dec 18 09:34:11 2012 -0800,1355852051,more use of the state class,72,48,"redelm-column/src/main/java/redelm/io/RecordReader.java,CAS_DELIMITER",1,1,1,0.0,2,303.0,17,0.7569791666666666,62.0,55.104890945042854,38.0,None,FALSE,FALSE,
4e5da20979304e9005f67bb93cca165ef9ed6f56,julien,julien@twitter.com,Mon Dec 17 15:24:08 2012 -0800,1355786648,introduce state object,35,8,"redelm-column/src/main/java/redelm/io/RecordReader.java,CAS_DELIMITER",1,1,1,0.0,2,276.0,16,0.30215277777777777,61.0,54.20718066767569,37.0,None,FALSE,FALSE,
b6f0ca6b2b764a5697f05659626206fcdee10954,julien,julien@twitter.com,Mon Dec 17 08:09:02 2012 -0800,1355760542,remove unnecessary constructor param,6,6,"redelm-column/src/main/java/redelm/io/MessageColumnIO.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordReader.java,CAS_DELIMITER",2,1,1,0.6500224216483541,2,259.0,28,2.5574305555555554,60.0,53.24728837622554,36.0,None,FALSE,FALSE,
48f0e8f83705dff3bf85bd4be91309144c7fa0ae,julien,julien@twitter.com,Fri Dec 14 18:46:20 2012 -0800,1355539580,refactor record consumer materializer,97,81,"redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/ColumnIOFactory.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/MessageColumnIO.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordConsumer.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordMaterializer.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/PerfTest.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/TestColumnIO.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/ReadSupport.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java,CAS_DELIMITER",15,2,7,3.651174752404163,2,159.73333333333332,143,5.297793981481478,59.0,52.58210906520841,38.0,None,FALSE,TRUE,"[""af20471a423684375533774320b874a49195d4f8""]"
072db3ed0a02e5f5476f5366eb4b654e837c3d62,julien,julien@twitter.com,Fri Dec 14 18:02:20 2012 -0800,1355536940,change record reader init lifecycle,168,169,"redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/MessageColumnIO.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordConsumer.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/PerfTest.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/TestColumnIO.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/ReadSupport.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java,CAS_DELIMITER",14,2,7,3.3381720731770836,2,180.78571428571428,133,22.336702215608465,58.0,51.58605127826436,37.0,None,FALSE,FALSE,
c4a41dd9e06334829a3d0ddd8535a8a7fa7ad0e1,julien,julien@twitter.com,Fri Dec 14 07:58:38 2012 -0800,1355500718,more fsa codegen,114,39,"redelm-column/src/main/java/redelm/io/ColumnIO.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/TestRecordReaderCompiler.java,CAS_DELIMITER",5,1,2,1.3978708607520138,2,127.6,24,27.073412037037038,57.0,50.639050352775286,33.0,None,FALSE,FALSE,
104b21971a95cc16042f7af2df55321ec45d63af,julien,julien@twitter.com,Mon Dec 3 15:03:15 2012 -0800,1354575795,remove currentNodePath from reader and improve perf a lot,4,7,"redelm-column/src/main/java/redelm/io/RecordReader.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/PerfTest.java,CAS_DELIMITER",2,1,2,0.4394969869215134,2,215.5,26,2.524224537037037,56.0,51.000224263816435,32.0,None,FALSE,FALSE,
0f88e2922f930a1c4486dbe8a7aea80df5a4dd7f,julien,julien@twitter.com,Mon Dec 3 14:57:39 2012 -0800,1354575459,simplified record reader ; a little more of reader compiler,74,19,"redelm-column/src/main/java/redelm/io/RecordReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java,CAS_DELIMITER",2,1,1,0.8069896049203008,2,170.0,11,0.7048032407407407,55.0,50.000721444243794,31.0,None,FALSE,FALSE,
73d4fde0e069b31efc63e2a91a1d7c10984d9db1,julien,julien@twitter.com,Sun Dec 2 22:02:44 2012 -0800,1354514564,first stab at record reader compiler,304,133,"redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordReaderCompiler.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/ExpectationValidatingRecordConsumer.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/TestColumnIO.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/TestRecordReaderCompiler.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java,CAS_DELIMITER",7,2,4,2.1139824410276518,2,156.14285714285714,33,7.550591931216931,54.0,49.089054372560035,34.5,None,FALSE,FALSE,
e186b7dcde95264a2dfdd2b179a23e1e2e4861f5,julien,julien@twitter.com,Fri Nov 30 09:20:57 2012 -0800,1354296057,fix UDFContext collision when multiple stores,59,14,"redelm-pig/src/main/java/redelm/pig/RedelmStorer.java,CAS_DELIMITER",1,1,1,0.0,2,197.0,8,14.942372685185186,53.0,48.40163572425766,38.0,Corrective,TRUE,FALSE,
615c23c3c573109646ffcc5e244e3cb4ff551328,julien,julien@twitter.com,Thu Nov 29 22:40:42 2012 -0800,1354257642,make splits contain all data blocks starting in the same HDFS block,129,40,"redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmInputSplit.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/hadoop/TestInputFormat.java,CAS_DELIMITER",6,2,3,1.9807149413248624,2,120.66666666666667,22,5.821261574074074,51.0,46.45577877893407,32.5,None,FALSE,FALSE,
ee02094ff08af675b619412686ef55dee6c7e09c,julien,julien@twitter.com,Wed Nov 28 13:59:05 2012 -0800,1354139945,better logging and perf tests,381,36,"redelm-column/src/test/java/redelm/io/PerfTest.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmInputSplit.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmMetaData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/PerfTest2.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/PerfTestReadAllCols.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TupleConsumerPerfTest.java,CAS_DELIMITER",8,2,3,1.7940175482272653,2,98.375,32,8.832333622685185,50.0,45.61494683964957,31.5,Perfective,FALSE,FALSE,
c73105c4c37bef5618c255b5988ebc29166c7737,julien,julien@twitter.com,Wed Nov 21 14:33:55 2012 -0800,1353537235,fix exceptions in Converters,41,10,"redelm-pig/src/main/java/redelm/pig/TupleConversionException.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/converter/BagConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/converter/MapConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/converter/TupleConverter.java,CAS_DELIMITER",5,1,2,1.925410635240724,2,87.2,19,0.7393587962962964,49.0,45.428014873978896,34.0,Corrective,TRUE,FALSE,
48ef66b4dfbdae93218f3886894f3ce4ccb7fc99,julien,julien@twitter.com,Wed Nov 21 14:25:20 2012 -0800,1353536720,fix exception handling,7,7,"redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java,CAS_DELIMITER",1,1,1,0.0,2,235.0,12,2.1939583333333332,48.0,44.42870573618579,33.0,Corrective,TRUE,FALSE,
bce0f0d01c5ca92ac1f76d741e60701ef87bb12d,julien,julien@twitter.com,Wed Nov 21 13:19:32 2012 -0800,1353532772,fix Codec Logging,13,6,"redelm-column/src/main/java/redelm/Log.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java,CAS_DELIMITER",4,2,4,1.719553828322125,2,85.75,25,7.566235532407408,47.0,43.43387739440572,29.5,Corrective,TRUE,FALSE,
bdc5a6e184f02ae130bbd345e8fd69b287a42957,julien,julien@twitter.com,Wed Nov 21 11:13:44 2012 -0800,1353525224,fix compression javadoc,13,7,"redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java,CAS_DELIMITER",2,1,1,0.9927744539878084,2,42.5,10,3.429641203703704,46.0,42.44352881399839,31.0,Corrective,TRUE,FALSE,
88ed7fe5cebbef0dd1cafab50fe72354a73e5e86,julien,julien@twitter.com,Tue Nov 20 09:54:59 2012 -0800,1353434099,Support for short int columns by JCoveney https : / / github . com / jcoveney / redelm rep def column add pig snapshot,1259,301,"redelm-column/src/main/java/redelm/column/ColumnDescriptor.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/ColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/RedelmByteArrayOutputStream.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumn.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/BitReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/BitWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/BoundedColumnFactory.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/BoundedIntColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/DevNullColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/DevNullColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/GroupWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/MessageColumnIO.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/GroupType.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/MessageType.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/PrimitiveType.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/Type.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/utils/Varint.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/column/primitive/TestBoundedColumns.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/PerfTest.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/TestColumnIO.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/ColumnData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java,CAS_DELIMITER",35,2,12,4.268398686615937,2,97.17142857142858,159,16.446854166666657,44.0,40.55747990141083,27.0,None,FALSE,FALSE,
27c02555d97e41eb635b2441da69a36b940730b4,julien,julien@twitter.com,Tue Nov 20 09:02:19 2012 -0800,1353430939,make Map work,190,72,"redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/converter/BagConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/converter/Converter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/converter/MapConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/converter/MapKeyValueConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/converter/TupleConverter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java,CAS_DELIMITER",8,1,3,2.821796363077902,2,68.125,20,0.9444632523148149,42.0,38.573991046857614,27.0,None,FALSE,FALSE,
0094892b0c7b8466afb50f4296309a83449fb359,julien,julien@twitter.com,Mon Nov 19 09:46:02 2012 -0800,1353347162,use non spillable databag for records,8,2,"redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java,CAS_DELIMITER",1,1,1,0.0,2,229.0,11,0.7382986111111111,41.0,37.66873873893039,26.0,None,FALSE,FALSE,
87744511868c1c68c4ac6468f9eda84bd319d37a,julien,julien@twitter.com,Mon Nov 19 09:39:43 2012 -0800,1353346783,first stab at pregenerated Pig consumer,312,1,"redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/converter/BagConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/converter/Converter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/converter/MapConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/converter/MessageConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/converter/TupleConverter.java,CAS_DELIMITER",6,1,2,2.410689333453976,2,9.166666666666666,3,0.6227854938271605,40.0,36.669156413247684,25.0,None,FALSE,FALSE,
fbf8333a47d71e054db84334d18747f565ff9731,julien,julien@twitter.com,Sun Nov 18 16:02:53 2012 -0800,1353283373,cleanup unnecessary variables,1,4,"redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java,CAS_DELIMITER",1,1,1,0.0,2,232.0,10,0.003599537037037037,39.0,35.73715338731892,24.0,Perfective,FALSE,FALSE,
06ab2ed602ab7172a7dd55b35830b785ba737eca,julien,julien@twitter.com,Sun Nov 18 15:57:42 2012 -0800,1353283062,implement empty bag ! = null bag,373,174,"redelm-column/src/main/java/redelm/Log.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/TupleWriteSupport.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java,CAS_DELIMITER",6,2,3,2.307339602986673,2,125.66666666666667,44,14.650300925925926,38.0,34.73747764667247,23.0,None,FALSE,FALSE,
ffe80dde0f3eb13cc40ec5c3efbe6ee8cb556b84,julien,julien@twitter.com,Thu Nov 15 15:55:07 2012 -0800,1353023707,add summary file,410,20,"redelm-column/src/main/java/redelm/RedelmRuntimeException.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/InvalidRecordException.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/Footer.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/MetaDataBlock.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/ReadSupport.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmOutputCommitter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/WriteSupport.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/PigMetaData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java,CAS_DELIMITER",17,2,5,3.6611297816958324,2,66.0,45,-0.15937908496732028,43.0,40.05206086366737,26.0,Feature Addition,FALSE,FALSE,
b507f7dd6f56971f3ba6cbfab786a255e47451c1,julien,julien@twitter.com,Thu Nov 15 11:56:05 2012 -0800,1353009365,make block size configurable,25,7,"redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java,CAS_DELIMITER",2,1,1,0.7578784625383955,2,43.5,4,0.5485185185185185,36.0,33.01593558114398,21.0,None,FALSE,FALSE,
fe6066bd2defd83af96c6416e1d06273278e1b6c,julien,julien@twitter.com,Thu Nov 15 10:43:56 2012 -0800,1353005036,get the compression codec from Configuration properties,84,52,"redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmStorer.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/PerfTest2.java,CAS_DELIMITER",6,1,4,2.185784914715886,2,70.5,19,1.1125270061728396,35.0,32.020108614123544,20.0,None,FALSE,FALSE,
4fb9a480910ab56af1de975e2b48aa4dd0431866,julien,julien@twitter.com,Wed Nov 14 10:48:30 2012 -0800,1352918910,moved hadoop implementation into its own hadoop package without dependencies on pig packages,700,111,"redelm-pig/src/main/java/redelm/hadoop/BlockData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/BlockMetaData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/ColumnData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/ColumnMetaData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/MetaDataBlock.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/PrintFooter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/ReadSupport.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmInputSplit.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmMetaData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmRecordWriter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/WriteSupport.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/TupleWriteSupport.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/hadoop/TestRedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/PerfTest.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/PerfTest2.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java,CAS_DELIMITER",22,1,4,3.9237255964454474,2,37.86363636363637,40,1.5558985690235687,34.0,31.100613773687122,19.0,None,FALSE,FALSE,
130e213b8bec04b7691e100450a5bc1d7be169f2,julien,julien@twitter.com,Tue Nov 13 18:08:52 2012 -0800,1352858932,better hadoop layer decoupling,424,365,"redelm-pig/src/main/java/redelm/hadoop/BlockData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/BlockMetaData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/ColumnData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/ColumnMetaData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/MetaDataBlock.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/PrintFooter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/ReadSupport.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedElmMetaData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmFileReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmInputFormat.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmInputSplit.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmOutputFormat.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/RedelmRecordReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/hadoop/WriteSupport.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/PigMetaData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/ReadSupport.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmLoader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmStorer.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/TupleWriteSupport.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/summary/BagSummaryData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/summary/FieldSummaryData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/summary/MapSummaryData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/summary/NumberSummaryData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/summary/StringSummaryData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/summary/SummaryData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/summary/TupleSummaryData.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/PerfTest2.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/summary/TestSummary.java,CAS_DELIMITER",34,1,5,3.4303585299996455,2,92.5,87,7.9050939542483665,33.0,30.155012347318323,18.0,Perfective,FALSE,FALSE,
76ded4f933f058c4299384cea192dda0677fa18c,julien,julien@twitter.com,Tue Nov 13 08:20:31 2012 -0800,1352823631,store count of metadatablocks in footer,8,3,"redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java,CAS_DELIMITER",2,1,1,0.9456603046006402,2,265.0,22,0.9346064814814815,32.0,29.18599822383231,17.0,None,FALSE,FALSE,
e2e3eeb5c02895d5737556bf96c775e86b740a41,julien,julien@twitter.com,Mon Nov 12 09:54:41 2012 -0800,1352742881,first stab a decoupling the Input / OutputFormat from Pig,302,77,"redelm-pig/src/main/java/redelm/pig/Footer.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/MetaDataBlock.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/PigMetaData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/PrintFooter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/ReadSupport.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmLoader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmOutputFormat.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmStorer.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/TupleReadSupport.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/TupleWriteSupport.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/WriteSupport.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java,CAS_DELIMITER",16,1,2,3.474865327280083,2,134.125,80,6.3888953993055555,31.0,28.254551212281044,16.0,None,FALSE,FALSE,
df97795af630d28c0d884dc21d40a731e9e20d00,julien,julien@twitter.com,Fri Nov 9 09:51:55 2012 -0800,1352483515,javadoc,320,12,"redelm-column/src/main/java/redelm/data/simple/example/Paper.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/parser/MessageTypeParser.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/GroupType.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/MessageType.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/PrimitiveType.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/Type.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/TypeVisitor.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/summary/Summary.java,CAS_DELIMITER",12,2,6,3.161061477647801,2,161.0,71,13.187715084876544,30.0,27.468650710828314,18.0,Non Functional,FALSE,FALSE,
3b8ad08b3c0b40221096f5db00e2b1524dbf9315,julien,julien@twitter.com,Thu Nov 8 08:16:26 2012 -0800,1352391386,cleanup logs,4,7,"redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java,CAS_DELIMITER",2,1,1,0.9456603046006402,2,317.5,21,0.7304861111111111,29.0,26.542556372640355,14.0,Perfective,FALSE,FALSE,
fd5bd4a8734b9b7bb1ab983ad1d3e61b87069b93,julien,julien@twitter.com,Wed Nov 7 14:44:32 2012 -0800,1352328272,record uncompressed size in footer ; add detailed report of size and compression per column,233,17,"redelm-pig/src/main/java/redelm/pig/ColumnMetaData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/PrintFooter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java,CAS_DELIMITER",6,1,2,1.1536078092888986,2,236.83333333333334,46,9.375887345679011,28.0,25.591411622495016,13.0,Feature Addition,FALSE,FALSE,
32bb525182f3e847ad9714d10f5788b214d7e9bd,Jonathan Coveney,jcoveney@gmail.com,Tue Nov 6 12:05:00 2012 -0800,1352232300,work,92,0,"redelm-column/src/main/java/redelm/parser/MessageTypeParser.java,CAS_DELIMITER",1,1,1,0.0,1,0.0,0,0.0,14.0,13.502022933289709,13.0,None,FALSE,FALSE,
c2ed3ee089da179c16fc49be0078f564a81d973d,Jonathan Coveney,jcoveney@gmail.com,Mon Nov 5 14:44:12 2012 -0800,1352155452,work,81,208,"redelm-column/src/main/java/redelm/parser/RedelmParser.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/GroupType.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/MessageType.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/PrimitiveType.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/Type.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/parser/TestRedelmParser.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/schema/TestMessageType.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java,CAS_DELIMITER",10,2,6,2.2313115731349122,2,144.7,73,11.783900462962965,13.0,12.533844719218035,10.0,None,FALSE,FALSE,
94781b0e7b3c0e7d8c3e1b642f1fe6cc45fe9628,julien,julien@twitter.com,Fri Nov 2 16:06:08 2012 -0700,1351897568,VarInt for String length,20,2,"redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnWriter.java,CAS_DELIMITER",2,1,1,0.976020648236615,2,127.0,8,0.9680092592592593,26.0,23.915685715084578,19.0,None,FALSE,FALSE,
1a0284da7ab5fb84644d4066b376bec6f3f582bc,julien,julien@twitter.com,Thu Nov 1 16:57:16 2012 -0700,1351814236,fix empty string bug,14,10,"redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java,CAS_DELIMITER",1,1,1,0.0,2,116.0,4,0.007037037037037037,25.0,22.97411113470658,18.0,Corrective,TRUE,FALSE,
4bfca1f14f549a6b116d25fd7aadf257b746296e,julien,julien@twitter.com,Thu Nov 1 16:47:08 2012 -0700,1351813628,make Codec configurable,70,22,"redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnWriter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/Footer.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmInputSplit.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmOutputFormat.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmStorer.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java,CAS_DELIMITER",10,2,3,3.2380218578236764,2,221.5,58,6.587851851851852,24.0,21.97451918527509,14.5,None,FALSE,FALSE,
46a3458add4df4a325d804c37f60f8866041fb4d,julien,julien@twitter.com,Wed Oct 31 16:37:34 2012 -0700,1351726654,first pass at adding compression,84,7,"redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java,CAS_DELIMITER",2,1,1,0.944850643976409,2,213.5,13,10.100515046296296,23.0,21.030275097263825,11.0,Feature Addition,FALSE,FALSE,
ba06716ed8eecd9ec7d2ac7d8afb3d3f4517533c,Jonathan Coveney,jcoveney@gmail.com,Wed Oct 31 13:38:44 2012 -0700,1351715924,remove a use of StringBuffer,1,1,"redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java,CAS_DELIMITER",1,1,1,0.0,1,141.0,6,13.577731481481482,12.0,11.704636470737526,11.0,None,FALSE,FALSE,
063486db8c7112f8790527b6c24e98198760d5ba,Jonathan Coveney,jcoveney@gmail.com,Wed Oct 31 13:07:49 2012 -0700,1351714069,work,6,6,"redelm-column/src/main/java/redelm/data/simple/IntegerValue.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/simple/Primitive.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/simple/SimpleGroup.java,CAS_DELIMITER",3,1,1,1.4591479170272446,2,21.666666666666668,10,0.5626003086419753,11.0,10.705308329729345,10.0,None,FALSE,FALSE,
4cd5bc1d011e44d43b3d25d3ab20c3f7d4b7ca83,Jonathan Coveney,jcoveney@gmail.com,Wed Oct 31 12:57:55 2012 -0700,1351713475,work,41,0,"redelm-column/src/main/java/redelm/data/simple/BooleanValue.java,CAS_DELIMITER",1,1,1,0.0,1,0.0,0,0.0,10.0,9.705504649821515,9.0,None,FALSE,FALSE,
525d3aece83ed9a0d46ab2c0568277f6345bba91,Jonathan Coveney,jcoveney@gmail.com,Wed Oct 31 12:57:44 2012 -0700,1351713464,work,69,17,"redelm-column/src/main/java/redelm/parser/RedelmParser.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java,CAS_DELIMITER",2,2,2,0.6127425554686624,2,255.0,12,7.302685185185185,9.0,8.705507936638876,7.5,None,FALSE,FALSE,
9c34678e5cfd2e228664261b25dcce8033ea22bb,Jonathan Coveney,jcoveney@gmail.com,Tue Oct 30 16:52:36 2012 -0700,1351641156,work,17,62,"redelm-column/src/main/java/redelm/column/ColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/GroupValueSource.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/simple/BoolValue.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/simple/Primitive.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/simple/SimpleGroup.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/TupleWriter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java,CAS_DELIMITER",8,2,6,2.206328441763822,2,70.75,33,11.036472800925928,8.0,7.7248637691756175,6.5,None,FALSE,FALSE,
da419bfe8ddb40261da15a88d5dad6520ed91ec2,julien,julien@twitter.com,Mon Oct 29 16:19:14 2012 -0700,1351552754,fix bug regarding null values in message,2,3,"redelm-column/src/main/java/redelm/io/MessageColumnIO.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java,CAS_DELIMITER",2,1,1,0.7219280948873623,2,182.5,16,4.980567129629629,22.0,20.137065977505383,16.0,Corrective,TRUE,FALSE,
d0806980aaed917ab5139533446449af33602a30,julien,julien@twitter.com,Thu Oct 25 14:31:10 2012 -0700,1351200670,adding schema validation,224,3,"redelm-column/src/main/java/redelm/RedelmRuntimeException.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/simple/LongValue.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/InvalidRecordException.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/ValidatingRecordConsumer.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/TestColumnIO.java,CAS_DELIMITER",5,1,4,1.689590252137547,2,89.2,16,0.18110416666666668,21.0,19.345350357448645,15.0,Feature Addition,FALSE,TRUE,
e12b27f08595a0696ac182a81623c78fd8deb8d7,julien,julien@twitter.com,Wed Oct 24 16:47:13 2012 -0700,1351122433,fix support for int / long and map,400,89,"redelm-column/src/main/java/redelm/column/ColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/ColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumn.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/Group.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/simple/Primitive.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/simple/SimpleGroup.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/simple/example/Paper.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/GroupColumnIO.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/MessageColumnIO.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordConsumer.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/PrimitiveType.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/PerfTest.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/TestColumnIO.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/Footer.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmInputSplit.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmOutputFormat.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmStorer.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/TupleWriter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java,CAS_DELIMITER",31,2,12,3.9846591210403988,2,149.0,171,5.4668313172043,20.0,18.389733960591,12.0,Corrective,TRUE,FALSE,
30e3849451d4734bc776116316ecd547612743d7,Jonathan Coveney,jcoveney@gmail.com,Tue Oct 23 18:36:31 2012 -0700,1351042591,work,86,26,"redelm-column/src/main/java/redelm/column/ColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumn.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/simple/IntValue.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/MessageColumnIO.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordConsumer.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/parser/RedelmParser.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/PrimitiveType.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/PerfTest.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/TestColumnIO.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/parser/TestRedelmParser.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/schema/TestMessageType.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/TupleWriter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java,CAS_DELIMITER",19,2,13,3.7792969605423226,2,133.31578947368422,104,6.784706993177388,7.0,6.8691118288965365,5.5,None,FALSE,FALSE,
f84fa2786b1951b81ab39f62a42b194bccee0dca,Jonathan Coveney,jcoveney@gmail.com,Tue Oct 23 18:11:02 2012 -0700,1351041062,work,47,28,"redelm-column/src/main/java/redelm/parser/RedelmParser.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/parser/TestRedelmParser.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/schema/TestMessageType.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/TupleWriter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/PerfTest.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java,CAS_DELIMITER",8,2,5,2.2346825438522293,2,134.875,30,6.479986979166667,6.0,5.869438715431408,4.5,None,FALSE,FALSE,
38434c66f24ddd47d7a0b3683e3fcfefcadbfedd,Jonathan Coveney,jcoveney@gmail.com,Thu Oct 18 14:23:20 2012 -0700,1350595400,work,46,46,"redelm-column/src/test/java/redelm/io/PerfTest.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/PerfTest2.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/summary/TestSummary.java,CAS_DELIMITER",5,2,3,2.040332700679088,2,217.8,25,1.5722731481481482,5.0,4.9517278310342965,3.5,None,FALSE,FALSE,
02b40db07adcb0c382de4b7bfa4fc019d4a06fa0,Jonathan Coveney,jcoveney@gmail.com,Thu Oct 18 14:10:11 2012 -0700,1350594611,work,184,164,"redelm-column/src/main/java/redelm/parser/RedelmParser.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/GroupType.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/MessageType.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/PrimitiveType.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/Type.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/TestColumnIO.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/schema/TestMessageType.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java,CAS_DELIMITER",12,2,6,3.1954066653809896,2,175.25,65,1.8975684799382722,4.0,3.9518505424476227,2.5,None,FALSE,FALSE,
1e7152b65092572a7bbe7e58dd18e163fce51cc2,Jonathan Coveney,jcoveney@gmail.com,Thu Oct 18 11:38:26 2012 -0700,1350585506,work,2495,0,"redelm-column/src/main/java/redelm/parser/RedelmParser.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/parser/TestRedelmParser.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/schema/TestMessageType.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/BlockMetaData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/ColumnData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/ColumnMetaData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/Footer.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/PrintFooter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmInputSplit.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmOutputFormat.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmStorer.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/summary/BagSummaryData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/summary/EnumStat.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/summary/FieldSummaryData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/summary/MapSummaryData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/summary/NumberSummaryData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/summary/StringSummaryData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/summary/Summary.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/summary/SummaryData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/summary/TupleSummaryData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/summary/ValueStat.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/summary/TestSummary.java,CAS_DELIMITER",29,2,7,4.602953978552359,2,102.93103448275862,73,0.4579741379310346,2.0,1.9529482953821344,1.0,None,FALSE,FALSE,
246efae86ecfd6a816c619c501b183a0e6dd9190,julien,julien@twitter.com,Wed Oct 17 23:46:48 2012 -0700,1350542808,refactor of the columns,1101,554,"redelm-column/src/main/java/redelm/column/BytesOutput.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/ColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/ColumnsStore.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/RedelmByteArrayOutputStream.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumn.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/PrimitiveColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/primitive/SimplePrimitiveColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordReader.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/TestColumnIO.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/BlockData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/ColumnData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/ColumnMetaData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmOutputFormat.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java,CAS_DELIMITER",23,2,8,3.6410207386039044,1,90.0,52,7.0715786030595815,18.0,16.70628715816226,10.0,None,FALSE,FALSE,
00257682aed55ab3ba05ee798cf38b56d51ecf62,julien,julien@twitter.com,Thu Oct 11 22:07:17 2012 -0700,1350018437,fixed tests,1,1,"redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java,CAS_DELIMITER",1,1,1,0.0,1,27.0,1,7.561145833333334,17.0,15.968403822737802,7.0,Corrective,TRUE,FALSE,
591da70b6153261c1aff895dce6f629e997a2966,julien,julien@twitter.com,Thu Oct 11 11:27:24 2012 -0700,1349980044,adding support for Float and Double,791,232,"redelm-column/src/main/java/redelm/column/ColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/ColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumn.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/Group.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/GroupWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/simple/BinaryValue.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/simple/BoolValue.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/simple/DoubleValue.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/simple/FloatValue.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/simple/IntValue.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/simple/Primitive.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/simple/SimpleGroup.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/simple/StringValue.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/GroupColumnIO.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/MessageColumnIO.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordConsumer.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/GroupType.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/MessageType.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/PrimitiveType.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/Type.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/PerfTest.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/TestColumnIO.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/PerfTest.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/PerfTest2.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java,CAS_DELIMITER",32,2,9,3.8359560992339445,1,88.9375,106,8.8721484375,16.0,14.986700211433508,8.5,Feature Addition,FALSE,FALSE,
40d512bf0ff7aaba12f6eb13acf37d760535572a,Jonathan Coveney,jcoveney@gmail.com,Wed Oct 10 14:18:07 2012 -0700,1349903887,work,88,91,"redelm-column/src/main/java/redelm/column/mem/MemColumn.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/GroupType.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/MessageType.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/PrimitiveType.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/Type.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/TestColumnIO.java,CAS_DELIMITER",6,1,3,1.9931358437444355,1,201.33333333333334,33,1.8138194444444444,1.0,0.9950552041709018,0.0,None,FALSE,FALSE,
bdd363578611c60a10d970323a0e0e60281fdaa9,Jonathan Coveney,jcoveney@gmail.com,Mon Oct 8 18:46:13 2012 -0700,1349747173,Add some comments and tests,197,99,"redelm-column/src/main/java/redelm/column/mem/MemColumn.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/GroupType.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/MessageType.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/PrimitiveType.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/Type.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/TestColumnIO.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmLoader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/TupleWriter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java,CAS_DELIMITER",10,2,5,2.690926673912843,1,153.4,41,7.405133101851851,0.0,0.0,0.0,Feature Addition,FALSE,FALSE,
575c221dbdc572bac7c6c7219cd172f12f62964e,julien,julien@twitter.com,Thu Oct 4 22:48:09 2012 -0700,1349416089,PrintFooter tool,71,47,"redelm-pig/src/main/java/redelm/pig/BlockMetaData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/Footer.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/PrintFooter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmInputSplit.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmLoader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmOutputFormat.java,CAS_DELIMITER",9,1,1,2.6128440359658587,1,82.44444444444444,11,0.524022633744856,15.0,14.242165553599607,5.0,None,FALSE,FALSE,
2302fe4656a799d20e7a86aee10459eabdc82a6f,julien,julien@twitter.com,Thu Oct 4 08:39:14 2012 -0700,1349365154,first version of the Loader / Storer,2494,67,"redelm-column/src/main/java/redelm/column/mem/MemColumn.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/GroupType.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/MessageType.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/PrimitiveType.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/schema/TestMessageType.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/BlockMetaData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/ColumnData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/ColumnMetaData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/Footer.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/PigSchemaConverter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmFileReader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmInputFormat.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmInputSplit.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmLoader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmOutputFormat.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmStorer.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/summary/BagSummaryData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/summary/EnumStat.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/summary/FieldSummaryData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/summary/MapSummaryData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/summary/NumberSummaryData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/summary/StringSummaryData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/summary/Summary.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/summary/SummaryData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/summary/TupleSummaryData.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/summary/ValueStat.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestPigSchemaConverter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestRedelmFileWriter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestRedelmStorer.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/summary/TestSummary.java,CAS_DELIMITER",32,2,7,4.6912570793413675,1,25.65625,17,1.4262044270833334,14.0,13.264050548204626,7.0,None,FALSE,TRUE,"[""00257682aed55ab3ba05ee798cf38b56d51ecf62"", ""e12b27f08595a0696ac182a81623c78fd8deb8d7"", ""bce0f0d01c5ca92ac1f76d741e60701ef87bb12d"", ""e186b7dcde95264a2dfdd2b179a23e1e2e4861f5"", ""8ec8a9dae12484273453a57defba7cac80b82f58"", ""4b060586ee79815e4cec5923ec211db9dda3e8bb"", ""b9463550d01f4b0118f725ed957e6e4354b0e4ba"", ""668d74df8addad24ad0bd2e53a23a4ad07e5ad47"", ""071b8f4626f125c81a01a5c07111d4d52102dbdf"", ""f3ed65beddc41314fc19fa2a237d3379d1bdf557""]"
cf5ba988c56a2b5166dfeaf13743b9a99fb4a552,julien,julien@twitter.com,Fri Sep 28 09:53:11 2012 -0700,1348851191,fix source encoding,2,2,"redelm-column/src/test/java/redelm/io/PerfTest.java,CAS_DELIMITER",1,1,1,0.0,1,172.0,8,1.6577777777777778,13.0,12.472139525077136,9.0,Corrective,TRUE,FALSE,
f2ea25f2097ea0359e9e4ba0815b6f9a63b3359f,julien,julien@twitter.com,Sat Sep 15 16:51:08 2012 -0700,1347753068,turning off logs,8,2,"redelm-column/src/main/java/redelm/Log.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/PerfTest.java,CAS_DELIMITER",2,1,2,0.7219280948873623,1,140.5,11,0.05695601851851852,11.0,10.87208007128394,7.0,None,FALSE,FALSE,
82e0324ec300f370d5416e8d60999c910998dc58,julien,julien@twitter.com,Sat Sep 15 15:29:07 2012 -0700,1347748147,pig Tuple consumer and writer,418,246,"redelm-column/src/main/java/redelm/Log.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/Group.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/simple/BinaryValue.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/simple/BoolValue.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/simple/IntValue.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/simple/Primitive.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/simple/SimpleGroup.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/simple/SimpleGroupFactory.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/simple/StringValue.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/simple/example/Paper.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/GroupColumnIO.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/MessageColumnIO.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/PerfTest.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/TestColumnIO.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/TupleWriter.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java,CAS_DELIMITER,redelm-thrift/src/main/java/redelm/thrift/ThriftConverter.java,CAS_DELIMITER,redelm-thrift/src/main/java/redelm/thrift/ThriftSchemaPrinter.java,CAS_DELIMITER",21,3,9,3.056861073354632,1,69.61904761904762,33,2.090892305996473,9.0,8.873755904513425,3.0,None,FALSE,FALSE,
f689f90b485b23c0cc5076088093ec6977358d09,julien,julien@twitter.com,Fri Sep 14 08:10:48 2012 -0700,1347635448,fix compilation issue,1,6,"redelm-pig/src/main/java/redelm/pig/RedelmLoader.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java,CAS_DELIMITER",2,1,2,0.863120568566631,1,64.0,2,13.689768518518518,8.0,7.905137114296778,1.0,Corrective,TRUE,FALSE,
c4109e21cac4743062f15d800dbec8366201e98b,julien,julien@twitter.com,Fri Sep 14 08:09:38 2012 -0700,1347635378,fix compilation and dependency issue,23,11,"redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java,CAS_DELIMITER",1,1,1,0.0,1,102.0,1,13.688958333333334,7.0,6.905154455195188,0.0,Corrective,TRUE,FALSE,
968fd551c58a091b5b13387038c57b15035a198e,julien,julien@twitter.com,Thu Sep 13 15:41:03 2012 -0700,1347576063,remove dependency on group from the io implementation,498,224,"redelm-column/src/main/java/redelm/Log.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/GroupRecordConsumer.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/GroupWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/ColumnIO.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/ColumnIOFactory.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/GroupColumnIO.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/MessageColumnIO.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/GroupType.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/PrimitiveType.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/data/simple/SimpleGroup.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/PerfTest.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/TestColumnIO.java,CAS_DELIMITER",15,1,6,2.9912195171570883,1,112.33333333333333,35,4.245287808641975,6.0,5.917991377828192,5.0,None,FALSE,TRUE,"[""e12b27f08595a0696ac182a81623c78fd8deb8d7"", ""cc59cb82675499870e9b0433c350f01a3522c2c9""]"
34124edc109127e0819d859fce91df960256571d,julien,julien@twitter.com,Tue Sep 11 16:42:46 2012 -0700,1347406966,remove depedency on Group from RecordReader,9,22,"redelm-column/src/main/java/redelm/io/ColumnIOFactory.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/MessageColumnIO.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordReader.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/PerfTest.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/TestColumnIO.java,CAS_DELIMITER",5,1,2,2.258466264732138,1,197.2,15,2.8567685185185185,5.0,4.949459737298782,4.0,None,FALSE,FALSE,
9b68b394fa8f8b339db1b85b5eb1ab744c89ca5c,julien,julien@twitter.com,Tue Sep 11 16:37:57 2012 -0700,1347406677,"make field started and ended only once when value is repeated , refactor out SimpleGroupRecordConsumer",367,186,"redelm-column/src/main/java/redelm/Log.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordReader.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/data/simple/SimpleGroupRecordConsumer.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/PerfTest.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/TestColumnIO.java,CAS_DELIMITER",5,1,4,1.8251524014257419,1,152.2,11,1.824162037037037,4.0,3.949504641473135,3.0,None,FALSE,FALSE,
a1a04d51312b169e5f2576c146351c67366a6212,julien,julien@twitter.com,Mon Sep 10 08:35:12 2012 -0700,1347291312,move closing records at the begining of the loop,107,115,"redelm-column/src/main/java/redelm/io/RecordReader.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/TestColumnIO.java,CAS_DELIMITER",2,1,2,0.9830133796037189,1,328.0,5,1.884259259259259,3.0,2.9638234902294567,2.0,None,FALSE,FALSE,
741c6fd77e6ccbebf47eacf021e68379d5063d53,julien,julien@twitter.com,Sat Sep 8 11:30:01 2012 -0700,1347129001,adding push parser test,138,0,"redelm-column/src/test/java/redelm/io/TestColumnIO.java,CAS_DELIMITER",1,1,1,0.0,1,260.0,2,0.011319444444444444,2.0,1.978972413838085,1.0,Feature Addition,FALSE,FALSE,
5fb63e9a0743a23735f5b6043abd202a85173202,julien,julien@twitter.com,Sat Sep 8 11:13:43 2012 -0700,1347128023,refactoring tuples to use indices instead of field names,304,146,"redelm-column/src/main/java/redelm/Log.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/ColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumn.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/Group.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/GroupValueSource.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/ColumnIO.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/GroupColumnIO.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/MessageColumnIO.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordConsumer.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/PrimitiveType.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/data/simple/SimpleGroup.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/PerfTest.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/TestColumnIO.java,CAS_DELIMITER",16,1,8,3.0660763856908506,1,97.5625,16,7.8167939814814815,1.0,0.9790331495048752,0.0,None,FALSE,FALSE,
a8c10efccf35977193cab80b0f17d6a2f7d066d9,julien,julien@twitter.com,Fri Aug 31 15:37:32 2012 -0700,1346452652,initial commit,2818,0,"redelm-column/src/main/java/redelm/Log.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/ColumnDescriptor.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/ColumnReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/ColumnWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/ColumnsStore.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumn.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/column/mem/MemColumnsStore.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/Group.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/GroupFactory.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/data/GroupValueSource.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/ColumnIO.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/ColumnIOFactory.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/GroupColumnIO.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/MessageColumnIO.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/PrimitiveColumnIO.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordConsumer.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordConsumerWrapper.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordReader.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/io/RecordWriter.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/GroupType.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/MessageType.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/PrimitiveType.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/Type.java,CAS_DELIMITER,redelm-column/src/main/java/redelm/schema/TypeVisitor.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/column/mem/TestMemColumn.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/data/simple/BinaryValue.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/data/simple/BoolValue.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/data/simple/IntValue.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/data/simple/Primitive.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/data/simple/SimpleGroup.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/data/simple/SimpleGroupFactory.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/data/simple/StringValue.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/PerfTest.java,CAS_DELIMITER,redelm-column/src/test/java/redelm/io/TestColumnIO.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/RedelmLoader.java,CAS_DELIMITER,redelm-pig/src/main/java/redelm/pig/TupleRecordConsumer.java,CAS_DELIMITER,redelm-pig/src/test/java/redelm/pig/TestTupleRecordConsumer.java,CAS_DELIMITER,redelm-thrift/src/main/java/redelm/thrift/SchemaConverter.java,CAS_DELIMITER,redelm-thrift/src/main/java/redelm/thrift/ThriftConverter.java,CAS_DELIMITER,redelm-thrift/src/main/java/redelm/thrift/ThriftRandomGenerator.java,CAS_DELIMITER",40,3,12,4.828864416839012,1,0.0,0,0.0,0.0,0.0,0.0,Feature Addition,FALSE,TRUE,"[""c4109e21cac4743062f15d800dbec8366201e98b"", ""f689f90b485b23c0cc5076088093ec6977358d09"", ""e12b27f08595a0696ac182a81623c78fd8deb8d7"", ""da419bfe8ddb40261da15a88d5dad6520ed91ec2"", ""af20471a423684375533774320b874a49195d4f8"", ""071b8f4626f125c81a01a5c07111d4d52102dbdf"", ""806b548153532021d80de45741e51e0d2622f3e3"", ""91c17112f18ecae914c7f670439a81dcd4041456"", ""b11e2a005014ecd827855dde9ce4d50b1f58aa4b"", ""cc59cb82675499870e9b0433c350f01a3522c2c9""]"
